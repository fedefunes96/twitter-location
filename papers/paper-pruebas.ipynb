{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleasant-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, KFold, cross_val_predict, cross_validate\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import scipy.sparse\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from math import radians, sin, cos, atan2, sqrt\n",
    "import re\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.neighbors import KDTree\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from shapely.geometry import Polygon, box\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Concatenate, Input, Dropout, Bidirectional, concatenate\n",
    "from tensorflow.keras.layers import Reshape, Flatten, MultiHeadAttention, Attention\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.backend import clear_session\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, SGD\n",
    "import os.path\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from pecanpy import node2vec\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2, SelectKBest, SelectFromModel, SelectFpr, SelectFdr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import hstack \n",
    "import stellargraph as sg\n",
    "from io import BytesIO\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "portable-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "unTPath = \"../../../../../unT/ffunes/\"\n",
    "tmp_save = unTPath + \"tmp_saves/\"\n",
    "figuresPath = unTPath + \"figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "egyptian-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"METIS_DLL\"] = '/usr/local/lib/libmetis.so'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twenty-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "registered-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_oslom(filename):\n",
    "    \"\"\"Funcion que extrae las comunidades detectadas por OSLOM a las que pertence un vertice de la red.\"\"\"\n",
    "    #clusters = {}\n",
    "    #hashtag_clusters = {}\n",
    "    data = []\n",
    "    \n",
    "    clusters = []\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        cluster = \"\"\n",
    "        for line in f:\n",
    "            m = re.search(\"^#module\\s([0-9]+).*\", line)\n",
    "            #print line\n",
    "            if (m is not None):\n",
    "                cluster = int(m.group(1))\n",
    "            else:\n",
    "                l = line.replace('\\n', ' ').strip().split(\" \")\n",
    "                l = list(map(int, l))\n",
    "                \n",
    "                clusters.append(cluster)\n",
    "                #clusters[cluster] = l\n",
    "                for i in l:\n",
    "                    #if not i in hashtag_clusters:\n",
    "                    #    hashtag_clusters[i] = set()\n",
    "                    #hashtag_clusters[i].add(cluster)\n",
    "                    data.append([i, cluster])\n",
    "    return pd.DataFrame(data=data, columns=[\"id\", \"cluster\"]), clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "damaged-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_oslom(folder):\n",
    "    basename = 'tp'\n",
    "    \n",
    "    all_clusters = {}\n",
    "    \n",
    "    train, clusters = extract_oslom(folder + basename)\n",
    "    \n",
    "    all_clusters[0] = clusters\n",
    "    \n",
    "    train = train.groupby(\n",
    "        [\"id\"]\n",
    "    )['cluster'].apply(list).reset_index(name='clusters')\n",
    "    \n",
    "    level = 1\n",
    "    \n",
    "    while os.path.isfile(folder + basename + str(level)):\n",
    "        l_train, l_clusters = extract_oslom(folder + basename + str(level))\n",
    "        \n",
    "        l_train = l_train.groupby(\n",
    "            [\"id\"]\n",
    "        )['cluster'].apply(list).reset_index(name='clusters_' + str(level))\n",
    "        \n",
    "        train = pd.merge(\n",
    "            left=train,\n",
    "            right=l_train,\n",
    "            how='left',\n",
    "            validate='1:1'\n",
    "        )\n",
    "        \n",
    "        all_clusters[level] = l_clusters\n",
    "        \n",
    "        level += 1\n",
    "    \n",
    "    return train, all_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-relay",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afraid-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, atan2, sqrt\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = radians(lat2-lat1)\n",
    "    dlon = radians(lon2-lon1)\n",
    "    a = sin(dlat/2) * sin(dlat/2) + cos(radians(lat1)) \\\n",
    "        * cos(radians(lat2)) * sin(dlon/2) * sin(dlon/2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def determine_dist(row):\n",
    "    return haversine_distance(\n",
    "        row[\"latitude_real\"],\n",
    "        row[\"longitude_real\"],\n",
    "        row[\"latitude_pred\"],\n",
    "        row[\"longitude_pred\"]\n",
    "    )\n",
    "    \n",
    "def determine_latlon(row):\n",
    "    global leaves\n",
    "        \n",
    "    return leaves[row[\"real_place\"]]['y_med_points'],\\\n",
    "        leaves[row[\"real_place\"]]['x_med_points'],\\\n",
    "        leaves[row[\"predicted_place\"]]['y_med_points'],\\\n",
    "        leaves[row[\"predicted_place\"]]['x_med_points']\n",
    "    \n",
    "\n",
    "def accuracy_161km(real_places, pred_places):    \n",
    "    df_prediction = pd.DataFrame({\n",
    "        'predicted_place': pred_places,\n",
    "        'real_place': real_places\n",
    "    }, dtype=int)\n",
    "            \n",
    "    df_prediction[[\n",
    "        \"latitude_real\",\n",
    "        \"longitude_real\",\n",
    "        \"latitude_pred\",\n",
    "        \"longitude_pred\"\n",
    "    ]] = df_prediction.apply(determine_latlon, axis=1, result_type=\"expand\")\n",
    "        \n",
    "    dif_distance = df_prediction.apply(determine_dist, axis=1)\n",
    "            \n",
    "    total_positives = 0\n",
    "    \n",
    "    for val in dif_distance:\n",
    "        if val <= 161:\n",
    "            total_positives += 1\n",
    "    \n",
    "    return total_positives / len(dif_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, atan2, sqrt\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = radians(lat2-lat1)\n",
    "    dlon = radians(lon2-lon1)\n",
    "    a = sin(dlat/2) * sin(dlat/2) + cos(radians(lat1)) \\\n",
    "        * cos(radians(lat2)) * sin(dlon/2) * sin(dlon/2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def determine_distance(row):\n",
    "    predicted_lat = row['predicted_lat']\n",
    "    predicted_lon = row['predicted_lon']\n",
    "    real_lat = row['real_lat']\n",
    "    real_long = row['real_lon']\n",
    "    \n",
    "    return haversine_distance(predicted_lat, predicted_lon, real_lat, real_long)\n",
    "\n",
    "def get_difference_distance(real_place, predicted_place, places_with_coords):\n",
    "    df_prediction = pd.DataFrame({\n",
    "        'predicted_place': predicted_place,\n",
    "        #'real_place': real_place,\n",
    "        'real_lat': real_place[:,0],\n",
    "        'real_lon': real_place[:,1]\n",
    "    })#, dtype={'str'})\n",
    "        \n",
    "    df_prediction = df_prediction.astype({'predicted_place': str, 'real_lat': np.float64, 'real_lon': np.float64})\n",
    "        \n",
    "    df_prediction = pd.merge(\n",
    "        left=df_prediction,\n",
    "        right=places_with_coords,\n",
    "        how='inner',\n",
    "        left_on='predicted_place',\n",
    "        right_on='class',\n",
    "        #validate='m:1'\n",
    "    ).rename(columns={'latitude': 'predicted_lat', 'longitude': 'predicted_lon'})\n",
    "        \n",
    "    '''df_prediction = pd.merge(\n",
    "        left=df_prediction,\n",
    "        right=places_with_coords,\n",
    "        how='inner',\n",
    "        left_on='real_place',\n",
    "        right_on='class',\n",
    "        #validate='m:1'\n",
    "    ).rename(columns={'latitude': 'real_lat', 'longitude': 'real_lon'})    '''\n",
    "        \n",
    "    return df_prediction.apply(determine_distance, axis=1)\n",
    "\n",
    "def accuracy_161km(real_place, pred_place, places_with_coords):\n",
    "    dif_distance = get_difference_distance(real_place, pred_place, places_with_coords)\n",
    "    \n",
    "    total_positives = 0\n",
    "    \n",
    "    for val in dif_distance:\n",
    "        if val <= 161:\n",
    "            total_positives += 1\n",
    "\n",
    "    return total_positives / len(dif_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "freelance-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fold:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def unpack(self, val_split=None, random_state=40):\n",
    "        if val_split:\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=random_state)\n",
    "                                \n",
    "            for train_ix, val_ix in sss.split(self.X_train, self.y_train):\n",
    "                X_train_ = self.X_train.iloc[train_ix]\n",
    "                X_val = self.X_train.iloc[val_ix]\n",
    "                    \n",
    "                y_train_, y_val = self.y_train[train_ix], self.y_train[val_ix]\n",
    "                    \n",
    "                return X_train_, y_train_, X_val, y_val, self.X_test, self.y_test\n",
    "        \n",
    "        return self.X_train, self.y_train, self.X_test, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incorporated-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldGen:\n",
    "    def create_folds(self, X, y, outer_cv=5, random_state=40):\n",
    "        outer_cv_fold = StratifiedKFold(n_splits=outer_cv, shuffle=True, random_state=random_state)\n",
    "\n",
    "        folds = []    \n",
    "        test_idx = np.array([])\n",
    "\n",
    "        for train_ix, test_ix in outer_cv_fold.split(X, y):\n",
    "            X_train = X.iloc[train_ix]\n",
    "            X_test = X.iloc[test_ix]\n",
    "\n",
    "            y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "            folds.append(Fold(X_train, y_train, X_test, y_test))\n",
    "\n",
    "            test_idx = np.concatenate([test_idx, test_ix])\n",
    "\n",
    "        return folds, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vocal-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "    def __init__(self, name, encoder=None):\n",
    "        self.name = name\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    def classes_order(self):\n",
    "        if self.encoder:\n",
    "            return self.encoder.classes_\n",
    "        \n",
    "        return self.classes_\n",
    "            \n",
    "    def predict_proba(self, clf, X):\n",
    "        return clf.predict_proba(X)\n",
    "    \n",
    "    def cross_predict(\n",
    "            self, folds, test_idx, outer_cv=5, predict_proba=True, random_state=40, preprocess=None, *args, **kwargs\n",
    "        ):\n",
    "        results = None\n",
    "        \n",
    "        for fold in folds:\n",
    "            if self.encoder:\n",
    "                X_train, y_train, X_test, y_test = fold.unpack()\n",
    "                \n",
    "                if self.encoder:\n",
    "                    self.encoder.fit(y_train)\n",
    "                \n",
    "                    y_train = self.encoder.transform(y_train)\n",
    "                    y_test = self.encoder.transform(y_test)                    \n",
    "                \n",
    "                fold = Fold(X_train, y_train, X_test, y_test)\n",
    "            \n",
    "            if preprocess is not None:\n",
    "                clf, X_test = preprocess(fold)\n",
    "            \n",
    "            try:\n",
    "                self.classes_ = clf.classes_\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Print best params when searching for best params\n",
    "            try:\n",
    "                print(\"Best params: \", clf.best_params_)\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "            y_pred = self.predict_proba(clf, X_test)\n",
    "    \n",
    "            if not predict_proba:\n",
    "                y_pred = np.array([self.classes_order()[x] for x in np.argmax(y_pred, axis=1)])\n",
    "            \n",
    "            if results is None:\n",
    "                results = y_pred\n",
    "            else:\n",
    "                results = np.concatenate((results, y_pred))\n",
    "            \n",
    "        preds = results[test_idx.argsort()]\n",
    "\n",
    "        return preds\n",
    "    \n",
    "class KerasCrossValidator(CrossValidator):\n",
    "    def predict_proba(self, clf, X):\n",
    "        return clf.predict(X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "simplified-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_class_gen(df, min_samples_split=2):\n",
    "    latitudes = df.latitude.values\n",
    "    longitudes = df.longitude.values\n",
    "    indexes = df.index.values\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    leaves = {str(i): [longitudes, latitudes, indexes]}\n",
    "    final_leaves = []\n",
    "\n",
    "    #next_split_axis = 0 # X Axis\n",
    "\n",
    "    finished = False\n",
    "\n",
    "    while not finished:\n",
    "        split_ocurred = False\n",
    "\n",
    "        for leaf_id, coords in list(leaves.items()):\n",
    "            dif_lon = np.max(coords[0]) - np.min(coords[0])\n",
    "            dif_lat = np.max(coords[1]) - np.min(coords[1])\n",
    "                            \n",
    "            next_split_axis = 1 if dif_lat > dif_lon else 0\n",
    "            \n",
    "            median_val = np.median(coords[next_split_axis])\n",
    "                \n",
    "            l_split = [\n",
    "                i for i, x in enumerate(coords[next_split_axis]) if x <= median_val\n",
    "            ]\n",
    "\n",
    "            r_split = [\n",
    "                i for i, x in enumerate(coords[next_split_axis]) if x > median_val\n",
    "            ]\n",
    "            \n",
    "            if len(l_split) >= min_samples_split and len(r_split) >= min_samples_split:                                \n",
    "                main_axis_l = [coords[next_split_axis][x] for x in l_split]\n",
    "                other_axis_l = [coords[(next_split_axis + 1) % 2][x] for x in l_split]\n",
    "                \n",
    "                main_axis_r = [coords[next_split_axis][x] for x in r_split]\n",
    "                other_axis_r = [coords[(next_split_axis + 1) % 2][x] for x in r_split]\n",
    "                \n",
    "                if (next_split_axis == 0):\n",
    "                    leaves[str(i+1)] = [\n",
    "                        main_axis_l,\n",
    "                        other_axis_l,\n",
    "                        [coords[2][x] for x in l_split]\n",
    "                    ]\n",
    "\n",
    "                    leaves[str(i+2)] = [\n",
    "                        main_axis_r,\n",
    "                        other_axis_r,\n",
    "                        [coords[2][x] for x in r_split]\n",
    "                    ]\n",
    "                else:\n",
    "                    leaves[str(i+1)] = [\n",
    "                        other_axis_l,\n",
    "                        main_axis_l,\n",
    "                        [coords[2][x] for x in l_split]\n",
    "                    ]\n",
    "\n",
    "                    leaves[str(i+2)] = [\n",
    "                        other_axis_r,\n",
    "                        main_axis_r,\n",
    "                        [coords[2][x] for x in r_split]\n",
    "                    ]\n",
    "                \n",
    "                del leaves[leaf_id]\n",
    "                i += 2\n",
    "                split_ocurred = True\n",
    "            else:\n",
    "                df.loc[coords[2], 'class'] = len(final_leaves)\n",
    "                \n",
    "                final_leaves.append({\n",
    "                    \"x_min\": np.min(coords[0]),\n",
    "                    \"x_max\": np.max(coords[0]),\n",
    "                    \"y_min\": np.min(coords[1]),\n",
    "                    \"y_max\": np.max(coords[1]),\n",
    "                    \"points\": len(coords[0]),\n",
    "                    'x_med_points': np.median(df.loc[coords[2], [\"longitude\"]]),\n",
    "                    'y_med_points': np.median(df.loc[coords[2], [\"latitude\"]]),\n",
    "                    'x_cent_points': np.sum(df.loc[coords[2], [\"longitude\"]].values)/len(coords[2]),\n",
    "                    'y_cent_points': np.sum(df.loc[coords[2], [\"latitude\"]].values)/len(coords[2]),\n",
    "                    'class': int(len(final_leaves))\n",
    "                })\n",
    "\n",
    "                del leaves[leaf_id]\n",
    "        \n",
    "        if split_ocurred:\n",
    "            pass\n",
    "            #next_split_axis = (next_split_axis + 1) % 2\n",
    "        else:\n",
    "            finished = True\n",
    "    \n",
    "    return final_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beginning-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(y_true, y_pred, classes_order, places_with_coords, users_coords):\n",
    "    y_true_ = np.array([classes_order[x] for x in np.argmax(y_true, axis=1)])\n",
    "    y_pred_ = np.array([classes_order[x] for x in np.argmax(y_pred, axis=1)])\n",
    "    \n",
    "    acc = accuracy_score(y_true_, y_pred_)\n",
    "    acc_161 = accuracy_161km(users_coords, y_pred_, places_with_coords)\n",
    "    bal_acc = balanced_accuracy_score(y_true_, y_pred_)\n",
    "    \n",
    "    try:\n",
    "        roc_auc_ovo = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovo')\n",
    "    except:\n",
    "        roc_auc_ovo = \"NaN\"\n",
    "        \n",
    "    diffs_distance = get_difference_distance(users_coords, y_pred_, places_with_coords)\n",
    "    \n",
    "    #diffs_distance_ge_zero = [dist for dist in diffs_distance if dist > 0]\n",
    "        \n",
    "    return \"Accuracy: {}\\\n",
    "        \\nAcc@161: {}\\\n",
    "        \\nBalanced Acc: {}\\\n",
    "        \\nROC AUC Ovo: {}\\\n",
    "        \\nMean Dist Err: {}\\\n",
    "        \\nMedian Dist Err: {}\".format(\n",
    "        acc, acc_161, bal_acc, roc_auc_ovo, np.mean(diffs_distance), np.median(diffs_distance)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-billy",
   "metadata": {},
   "source": [
    "# Mahmud Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "renewable-commissioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: ../Mahmud_ICWSM_2012/README.txt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../Mahmud_ICWSM_2012/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affecting-reasoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "mahmud = pd.read_csv(\"../paper_data/tweets_ids_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "incorporated-merit",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mahmud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-2e0cf5b72049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmahmud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mahmud' is not defined"
     ]
    }
   ],
   "source": [
    "mahmud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naughty-elite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['coordinates', 'created_at', 'hashtags', 'media', 'urls',\n",
       "       'favorite_count', 'id', 'in_reply_to_screen_name',\n",
       "       'in_reply_to_status_id', 'in_reply_to_user_id', 'lang', 'place',\n",
       "       'possibly_sensitive', 'retweet_count', 'retweet_id',\n",
       "       'retweet_screen_name', 'source', 'text', 'tweet_url', 'user_created_at',\n",
       "       'user_screen_name', 'user_default_profile_image', 'user_description',\n",
       "       'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
       "       'user_listed_count', 'user_location', 'user_name', 'user_screen_name.1',\n",
       "       'user_statuses_count', 'user_time_zone', 'user_urls', 'user_verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahmud.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "blessed-allah",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'false' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-b63514db81cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Tue Jun 28 19:45:35 +0000 2011\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m85796001729884160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id_str\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"85796001729884160\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"@mvanhorn Is that a filter, or is the room *really* that purple? /cc @hutchins @mager\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"truncated\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"display_text_range\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"hashtags\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"symbols\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"user_mentions\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"screen_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"mvanhorn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Matt Van Horn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6238012\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id_str\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"6238012\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"indices\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"screen_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"hutchins\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Chris Hutchins\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8953722\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id_str\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"8953722\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"indices\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m69\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m78\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"screen_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"mager\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Andrew Mager ‚ô´\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m632023\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id_str\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"632023\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"indices\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m79\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"urls\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"in_reply_to_status_id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m85795091842732030\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"in_reply_to_status_id_str\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"85795091842732032\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"in_reply_to_user_id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6238012\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"in_reply_to_user_id_str\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"6238012\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"in_reply_to_screen_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"mvanhorn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m607\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"id_str\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"607\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Matt Galligan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"screen_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"mg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"location\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"üíªüè°‚õ∞‚úàÔ∏èüåé\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"VP of Design @earnestresearch, üë¶üèº Nash‚Äôs dad, üåΩ Midwesterner, üé∏ musician, üç∫ craft beer & coffee lover, üçî burger fiend, üåé remote worker, üì∫ GIF enthusiast\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"https://t.co/8Mlgh9MvHh\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"urls\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"https://t.co/8Mlgh9MvHh\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"expanded_url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"https://galligan.co/about\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"display_url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"galligan.co/about\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"indices\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"urls\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"protected\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"followers_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25074\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"friends_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m948\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"listed_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1441\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Thu Jul 13 18:21:58 +0000 2006\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"favourites_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m14548\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"utc_offset\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"time_zone\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"geo_enabled\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"verified\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"statuses_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m35726\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lang\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"contributors_enabled\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"is_translator\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"is_translation_enabled\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_background_color\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"F0E8DD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_background_image_url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"http://abs.twimg.com/images/themes/theme1/bg.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_background_image_url_https\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"https://abs.twimg.com/images/themes/theme1/bg.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_background_tile\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_image_url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"http://pbs.twimg.com/profile_images/897144392712044547/9PWpsOB8_normal.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_image_url_https\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"https://pbs.twimg.com/profile_images/897144392712044547/9PWpsOB8_normal.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_banner_url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"https://pbs.twimg.com/profile_banners/607/1472249744\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_link_color\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"5898AE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_sidebar_border_color\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"FFFFFF\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_sidebar_fill_color\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"030516\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_text_color\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"A7394D\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"profile_use_background_image\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"has_extended_profile\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"default_profile\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"default_profile_image\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"following\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"follow_request_sent\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"notifications\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"translator_type\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"regular\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"geo\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"coordinates\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"place\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"2b6ff8c22edd9576\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"https://api.twitter.com/1.1/geo/id/2b6ff8c22edd9576.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"place_type\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"neighborhood\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"SoMa\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"full_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"SoMa, San Francisco\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"country_code\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"US\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"country\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"United States\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"contained_within\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"bounding_box\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Polygon\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"coordinates\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m122.42284884\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m37.76893497\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m122.3964\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m37.76893497\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m122.3964\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m37.78752897\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m122.42284884\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m37.78752897\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"attributes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"contributors\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"is_quote_status\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"retweet_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"favorite_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"favorited\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"retweeted\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lang\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'false' is not defined"
     ]
    }
   ],
   "source": [
    "{\"created_at\":\"Tue Jun 28 19:45:35 +0000 2011\",\n",
    " \"id\":85796001729884160,\n",
    " \"id_str\":\"85796001729884160\",\n",
    " \"full_text\":\"@mvanhorn Is that a filter, or is the room *really* that purple? /cc @hutchins @mager\",\n",
    " \"truncated\":false,\n",
    " \"display_text_range\":[0,85],\n",
    " \"entities\":{\"hashtags\":[],\"symbols\":[],\n",
    "             \"user_mentions\":[{\"screen_name\":\"mvanhorn\",\"name\":\"Matt Van Horn\",\"id\":6238012,\"id_str\":\"6238012\",\"indices\":[0,9]},{\"screen_name\":\"hutchins\",\"name\":\"Chris Hutchins\",\"id\":8953722,\"id_str\":\"8953722\",\"indices\":[69,78]},{\"screen_name\":\"mager\",\"name\":\"Andrew Mager ‚ô´\",\"id\":632023,\"id_str\":\"632023\",\"indices\":[79,85]}],\"urls\":[]}\n",
    " ,\"source\":\"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\",\"in_reply_to_status_id\":85795091842732030,\"in_reply_to_status_id_str\":\"85795091842732032\",\"in_reply_to_user_id\":6238012,\"in_reply_to_user_id_str\":\"6238012\",\"in_reply_to_screen_name\":\"mvanhorn\",\n",
    " \"user\":{\"id\":607,\"id_str\":\"607\",\"name\":\"Matt Galligan\",\"screen_name\":\"mg\",\"location\":\"üíªüè°‚õ∞‚úàÔ∏èüåé\",\"description\":\"VP of Design @earnestresearch, üë¶üèº Nash‚Äôs dad, üåΩ Midwesterner, üé∏ musician, üç∫ craft beer & coffee lover, üçî burger fiend, üåé remote worker, üì∫ GIF enthusiast\",\"url\":\"https://t.co/8Mlgh9MvHh\",\"entities\":{\"url\":{\"urls\":[{\"url\":\"https://t.co/8Mlgh9MvHh\",\"expanded_url\":\"https://galligan.co/about\",\"display_url\":\"galligan.co/about\",\"indices\":[0,23]}]},\"description\":{\"urls\":[]}},\"protected\":false,\"followers_count\":25074,\"friends_count\":948,\"listed_count\":1441,\"created_at\":\"Thu Jul 13 18:21:58 +0000 2006\",\"favourites_count\":14548,\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":true,\"verified\":true,\"statuses_count\":35726,\"lang\":null,\"contributors_enabled\":false,\"is_translator\":false,\"is_translation_enabled\":false,\"profile_background_color\":\"F0E8DD\",\"profile_background_image_url\":\"http://abs.twimg.com/images/themes/theme1/bg.png\",\"profile_background_image_url_https\":\"https://abs.twimg.com/images/themes/theme1/bg.png\",\"profile_background_tile\":false,\"profile_image_url\":\"http://pbs.twimg.com/profile_images/897144392712044547/9PWpsOB8_normal.jpg\",\"profile_image_url_https\":\"https://pbs.twimg.com/profile_images/897144392712044547/9PWpsOB8_normal.jpg\",\"profile_banner_url\":\"https://pbs.twimg.com/profile_banners/607/1472249744\",\"profile_link_color\":\"5898AE\",\"profile_sidebar_border_color\":\"FFFFFF\",\"profile_sidebar_fill_color\":\"030516\",\"profile_text_color\":\"A7394D\",\"profile_use_background_image\":false,\"has_extended_profile\":true,\"default_profile\":false,\"default_profile_image\":false,\"following\":false,\"follow_request_sent\":false,\"notifications\":false,\"translator_type\":\"regular\"},\"geo\":null,\"coordinates\":null,\"place\":{\"id\":\"2b6ff8c22edd9576\",\"url\":\"https://api.twitter.com/1.1/geo/id/2b6ff8c22edd9576.json\",\"place_type\":\"neighborhood\",\"name\":\"SoMa\",\"full_name\":\"SoMa, San Francisco\",\"country_code\":\"US\",\"country\":\"United States\",\"contained_within\":[],\"bounding_box\":{\"type\":\"Polygon\",\"coordinates\":[[[-122.42284884,37.76893497],[-122.3964,37.76893497],[-122.3964,37.78752897],[-122.42284884,37.78752897]]]},\"attributes\":{}},\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"favorited\":false,\"retweeted\":false,\"lang\":\"en\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distinct-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = [\n",
    "    \"coordinates\",\n",
    "    \"hashtags\",\n",
    "    \"id\",\n",
    "    \"text\",\n",
    "    \"source\",\n",
    "    \"user_location\",\n",
    "    \"user_name\",\n",
    "    \"user_screen_name\",\n",
    "    \"tweet_url\",\n",
    "    \"urls\",\n",
    "    \"user_time_zone\"\n",
    "]\n",
    "\n",
    "mahmud = mahmud.loc[:, usecols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "typical-reading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235005, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahmud.dropna(subset=[\"coordinates\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aerial-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_time_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85796001729884160</td>\n",
       "      <td>@mvanhorn Is that a filter, or is the room *re...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>üíªüè°‚õ∞‚úàÔ∏èüåé</td>\n",
       "      <td>Matt Galligan</td>\n",
       "      <td>mg</td>\n",
       "      <td>https://twitter.com/mg/status/85796001729884160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110475105649438720</td>\n",
       "      <td>@JonCart Beautiful! Thank you.</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/11047510564943...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>picklesforever</td>\n",
       "      <td>108948131726630912</td>\n",
       "      <td>This roughly equates #picklesforever  http://t...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/10894813172663...</td>\n",
       "      <td>http://yfrog.com/18ptqej</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109461576297357312</td>\n",
       "      <td>@hilatron @blackbeered lawlz</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/10946157629735...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109732858414895104</td>\n",
       "      <td>@pinwheel @taryncowart @zackfranceschi I was i...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/10973285841489...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coordinates        hashtags                  id  \\\n",
       "0         NaN             NaN   85796001729884160   \n",
       "1         NaN             NaN  110475105649438720   \n",
       "2         NaN  picklesforever  108948131726630912   \n",
       "3         NaN             NaN  109461576297357312   \n",
       "4         NaN             NaN  109732858414895104   \n",
       "\n",
       "                                                text  \\\n",
       "0  @mvanhorn Is that a filter, or is the room *re...   \n",
       "1                     @JonCart Beautiful! Thank you.   \n",
       "2  This roughly equates #picklesforever  http://t...   \n",
       "3                       @hilatron @blackbeered lawlz   \n",
       "4  @pinwheel @taryncowart @zackfranceschi I was i...   \n",
       "\n",
       "                                              source user_location  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        üíªüè°‚õ∞‚úàÔ∏èüåé   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  Portland, OR   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...  Portland, OR   \n",
       "3  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  Portland, OR   \n",
       "4  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  Portland, OR   \n",
       "\n",
       "       user_name user_screen_name  \\\n",
       "0  Matt Galligan               mg   \n",
       "1   Lane Collins             lane   \n",
       "2   Lane Collins             lane   \n",
       "3   Lane Collins             lane   \n",
       "4   Lane Collins             lane   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0    https://twitter.com/mg/status/85796001729884160   \n",
       "1  https://twitter.com/lane/status/11047510564943...   \n",
       "2  https://twitter.com/lane/status/10894813172663...   \n",
       "3  https://twitter.com/lane/status/10946157629735...   \n",
       "4  https://twitter.com/lane/status/10973285841489...   \n",
       "\n",
       "                       urls  user_time_zone  \n",
       "0                       NaN             NaN  \n",
       "1                       NaN             NaN  \n",
       "2  http://yfrog.com/18ptqej             NaN  \n",
       "3                       NaN             NaN  \n",
       "4                       NaN             NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahmud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ranking-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_mentions(row):\n",
    "    if row[\"text\"] is None:\n",
    "        return None\n",
    "    \n",
    "    return [x[1:] for x in re.findall(r'@\\w+', str(row[\"text\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wireless-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "mahmud[\"mentions\"] = mahmud.apply(retrieve_mentions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fossil-finish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_time_zone</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85796001729884160</td>\n",
       "      <td>@mvanhorn Is that a filter, or is the room *re...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>üíªüè°‚õ∞‚úàÔ∏èüåé</td>\n",
       "      <td>Matt Galligan</td>\n",
       "      <td>mg</td>\n",
       "      <td>https://twitter.com/mg/status/85796001729884160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[mvanhorn, hutchins, mager]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110475105649438720</td>\n",
       "      <td>@JonCart Beautiful! Thank you.</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/11047510564943...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[JonCart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>picklesforever</td>\n",
       "      <td>108948131726630912</td>\n",
       "      <td>This roughly equates #picklesforever  http://t...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/10894813172663...</td>\n",
       "      <td>http://yfrog.com/18ptqej</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109461576297357312</td>\n",
       "      <td>@hilatron @blackbeered lawlz</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/10946157629735...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[hilatron, blackbeered]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109732858414895104</td>\n",
       "      <td>@pinwheel @taryncowart @zackfranceschi I was i...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>Lane Collins</td>\n",
       "      <td>lane</td>\n",
       "      <td>https://twitter.com/lane/status/10973285841489...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[pinwheel, taryncowart, zackfranceschi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coordinates        hashtags                  id  \\\n",
       "0         NaN             NaN   85796001729884160   \n",
       "1         NaN             NaN  110475105649438720   \n",
       "2         NaN  picklesforever  108948131726630912   \n",
       "3         NaN             NaN  109461576297357312   \n",
       "4         NaN             NaN  109732858414895104   \n",
       "\n",
       "                                                text  \\\n",
       "0  @mvanhorn Is that a filter, or is the room *re...   \n",
       "1                     @JonCart Beautiful! Thank you.   \n",
       "2  This roughly equates #picklesforever  http://t...   \n",
       "3                       @hilatron @blackbeered lawlz   \n",
       "4  @pinwheel @taryncowart @zackfranceschi I was i...   \n",
       "\n",
       "                                              source user_location  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...        üíªüè°‚õ∞‚úàÔ∏èüåé   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  Portland, OR   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...  Portland, OR   \n",
       "3  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  Portland, OR   \n",
       "4  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  Portland, OR   \n",
       "\n",
       "       user_name user_screen_name  \\\n",
       "0  Matt Galligan               mg   \n",
       "1   Lane Collins             lane   \n",
       "2   Lane Collins             lane   \n",
       "3   Lane Collins             lane   \n",
       "4   Lane Collins             lane   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0    https://twitter.com/mg/status/85796001729884160   \n",
       "1  https://twitter.com/lane/status/11047510564943...   \n",
       "2  https://twitter.com/lane/status/10894813172663...   \n",
       "3  https://twitter.com/lane/status/10946157629735...   \n",
       "4  https://twitter.com/lane/status/10973285841489...   \n",
       "\n",
       "                       urls  user_time_zone  \\\n",
       "0                       NaN             NaN   \n",
       "1                       NaN             NaN   \n",
       "2  http://yfrog.com/18ptqej             NaN   \n",
       "3                       NaN             NaN   \n",
       "4                       NaN             NaN   \n",
       "\n",
       "                                  mentions  \n",
       "0              [mvanhorn, hutchins, mager]  \n",
       "1                                [JonCart]  \n",
       "2                                       []  \n",
       "3                  [hilatron, blackbeered]  \n",
       "4  [pinwheel, taryncowart, zackfranceschi]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahmud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "configured-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "mahmud_mentions = mahmud.loc[:, [\"user_screen_name\", \"mentions\"]].groupby(\n",
    "        [\"user_screen_name\"]\n",
    "    ).agg({'mentions': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "convinced-sewing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['007freddybond24', '01101001', '01560', ..., 'zuki_mike_82',\n",
       "       'zulucal79', 'zztype'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = mahmud_mentions[\"user_screen_name\"].unique()\n",
    "users_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "killing-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()\n",
    "for x in mahmud_mentions[\"mentions\"].values:\n",
    "    for val in x:\n",
    "        a.add(str(val))\n",
    "        \n",
    "all_users_mentioned = list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "modular-tourist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users ids:  13042  - All users ids mentions:  156957\n"
     ]
    }
   ],
   "source": [
    "print(\"Users ids: \", len(users_ids), \" - All users ids mentions: \", len(all_users_mentioned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polish-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users = np.concatenate([users_ids, all_users_mentioned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "periodic-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = OrderedDict.fromkeys(total_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forward-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users = list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "thirty-extension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total users:  167848\n"
     ]
    }
   ],
   "source": [
    "print(\"total users: \", len(total_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "changing-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007freddybond24</td>\n",
       "      <td>[bucbabe39, bucbabe39, RuthMcmullen1, QBKILLA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01101001</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01560</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01babylove</td>\n",
       "      <td>[RuthlessO_o, ChevySitnPretty, PrincessQui23, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02540</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13037</th>\n",
       "      <td>ztbarr</td>\n",
       "      <td>[maggie_welsford, hjstaton, Dezeen, nmkjeldsen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13038</th>\n",
       "      <td>ztftw</td>\n",
       "      <td>[iMagineerLeader, kmcwilliams21, asbergman, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13039</th>\n",
       "      <td>zuki_mike_82</td>\n",
       "      <td>[kelimepie, YonderalonsoU, D_Train35, C_Fn_Mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040</th>\n",
       "      <td>zulucal79</td>\n",
       "      <td>[4browngirl, 4Browngirl, zulucal79]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13041</th>\n",
       "      <td>zztype</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13042 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_screen_name                                           mentions\n",
       "0      007freddybond24  [bucbabe39, bucbabe39, RuthMcmullen1, QBKILLA,...\n",
       "1             01101001                                                 []\n",
       "2                01560                                                 []\n",
       "3           01babylove  [RuthlessO_o, ChevySitnPretty, PrincessQui23, ...\n",
       "4                02540                                                 []\n",
       "...                ...                                                ...\n",
       "13037           ztbarr  [maggie_welsford, hjstaton, Dezeen, nmkjeldsen...\n",
       "13038            ztftw  [iMagineerLeader, kmcwilliams21, asbergman, St...\n",
       "13039     zuki_mike_82  [kelimepie, YonderalonsoU, D_Train35, C_Fn_Mas...\n",
       "13040        zulucal79                [4browngirl, 4Browngirl, zulucal79]\n",
       "13041           zztype                                                 []\n",
       "\n",
       "[13042 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahmud_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "devoted-flash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19390, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_and_tweets_mahmud = pd.read_csv(\"../Mahmud_ICWSM_2012/topcitiesusersandtweets.csv\")\n",
    "users_and_tweets_mahmud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-native",
   "metadata": {},
   "source": [
    "Nos faltan 6k usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "exact-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>SW LAT</th>\n",
       "      <th>SW LONG</th>\n",
       "      <th>NE LAT</th>\n",
       "      <th>NE LONG</th>\n",
       "      <th>USER ID</th>\n",
       "      <th>TWEET ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.4774</td>\n",
       "      <td>-74.2591</td>\n",
       "      <td>40.9176</td>\n",
       "      <td>-73.7003</td>\n",
       "      <td>158433699</td>\n",
       "      <td>85580385068650496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.4774</td>\n",
       "      <td>-74.2591</td>\n",
       "      <td>40.9176</td>\n",
       "      <td>-73.7003</td>\n",
       "      <td>37861099</td>\n",
       "      <td>85580392429649920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City     State   SW LAT  SW LONG   NE LAT  NE LONG    USER ID  \\\n",
       "0  New York  New York  40.4774 -74.2591  40.9176 -73.7003  158433699   \n",
       "1  New York  New York  40.4774 -74.2591  40.9176 -73.7003   37861099   \n",
       "\n",
       "            TWEET ID  \n",
       "0  85580385068650496  \n",
       "1  85580392429649920  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_and_tweets_mahmud.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-northeast",
   "metadata": {},
   "source": [
    "Como no tenemos los user id en nuestros datos, tenemos conseguir el user name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "chubby-uniform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5816, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_and_tweets_mahmud = pd.merge(\n",
    "    left=users_and_tweets_mahmud,\n",
    "    right=mahmud,\n",
    "    how='inner',\n",
    "    left_on=\"TWEET ID\",\n",
    "    right_on=\"id\",\n",
    "    validate=\"1:m\"\n",
    ").loc[:, [\"user_screen_name\", \"City\"]]\n",
    "\n",
    "users_and_tweets_mahmud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-homeless",
   "metadata": {},
   "source": [
    "Esto es un inconveniente, de los 13.000 usuarios que rescatamos de los 19.000, solo pudimos conseguir los tweets que ubican a dichos usuarios de solo 5800 de ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "liberal-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>mentions</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01560</td>\n",
       "      <td>[]</td>\n",
       "      <td>Worcester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02540</td>\n",
       "      <td>[]</td>\n",
       "      <td>Worcester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0305_adriana</td>\n",
       "      <td>[agustinarana, agustinarana, Ventaneando13, se...</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017leech</td>\n",
       "      <td>[KiddJamNIGGA, Kodi_Paige, Kodi_Paige, Kodi_Pa...</td>\n",
       "      <td>Columbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101SweetCandy</td>\n",
       "      <td>[Da20thLetter, Jebreh800man, DeeTheDeeva, Meet...</td>\n",
       "      <td>Madison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_screen_name                                           mentions  \\\n",
       "0            01560                                                 []   \n",
       "1            02540                                                 []   \n",
       "2     0305_adriana  [agustinarana, agustinarana, Ventaneando13, se...   \n",
       "3        1017leech  [KiddJamNIGGA, Kodi_Paige, Kodi_Paige, Kodi_Pa...   \n",
       "4    101SweetCandy  [Da20thLetter, Jebreh800man, DeeTheDeeva, Meet...   \n",
       "\n",
       "        City  \n",
       "0  Worcester  \n",
       "1  Worcester  \n",
       "2   San Jose  \n",
       "3   Columbus  \n",
       "4    Madison  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahmud_mentions = pd.merge(\n",
    "    left=mahmud_mentions,\n",
    "    right=users_and_tweets_mahmud,\n",
    "    how='inner',\n",
    "    on='user_screen_name',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "\n",
    "mahmud_mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "boxed-penetration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13042x167848 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 194081 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents=\"ascii\",\n",
    "    lowercase=False,\n",
    "    vocabulary=total_users\n",
    ")\n",
    "\n",
    "vector_of_mentions = vectorizer.fit_transform(mahmud_mentions[\"mentions\"].apply(lambda x: ' '.join(x))).astype('bool').astype('int')\n",
    "vector_of_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pursuant-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_mentions.tocoo()\n",
    "edges = []\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    format_str = str(i) + \" \" + str(j) + \" \" + str(v)\n",
    "    edges.append(format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "silver-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194081"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "approved-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"edges\": edges})\n",
    "df.to_csv(\"../results/papers/matrix/mentions/edges_mentions_weighted.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "featured-recruitment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting -f\n",
      "setting -w\n",
      "setting -r\n",
      "setting -seed\n",
      "setting -cp\n",
      "**************************************\n",
      "Threshold:\t\t\t0.1\n",
      "Network file:\t\t\t../../results/papers/matrix/mentions/edges_mentions_weighted.csv\n",
      "Weighted: yes\n",
      "First Level Runs:\t\t\t10\n",
      "Higher Level Runs:\t\t\t50\n",
      "-cp:\t\t\t0.5\n",
      "Random number generator seed:\t\t\t430430\n",
      "**************************************\n",
      "\n",
      "allocating 192420 factorials...\n",
      "done\n",
      "rm: cannot remove '../../results/papers/matrix/mentions/edges_mentions_weighted.csv_oslo_files/*': No such file or directory\n",
      "output files will be written in directory: ../../results/papers/matrix/mentions/edges_mentions_weighted.csv_oslo_files\n",
      "network:: 167203 nodes and 192420 stubs;\t average degree = 1.15082\n",
      "STARTING! HIERARCHICAL LEVEL: 0\n",
      "***************************************************************** RUN: #1\n",
      "iteration: 0 number of modules: 12926\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11721. Percentage nodes done: 0\n",
      "checked 100 modules 6 were found significant.  Modules to check: 11621. Percentage nodes done: 0.0156995\n",
      "checked 200 modules 14 were found significant.  Modules to check: 11521. Percentage nodes done: 0.0275653\n",
      "checked 300 modules 16 were found significant.  Modules to check: 11421. Percentage nodes done: 0.037589\n",
      "checked 400 modules 28 were found significant.  Modules to check: 11321. Percentage nodes done: 0.0508843\n",
      "checked 500 modules 33 were found significant.  Modules to check: 11221. Percentage nodes done: 0.0607346\n",
      "checked 600 modules 40 were found significant.  Modules to check: 11121. Percentage nodes done: 0.0718408\n",
      "checked 700 modules 46 were found significant.  Modules to check: 11021. Percentage nodes done: 0.0831504\n",
      "checked 800 modules 46 were found significant.  Modules to check: 10921. Percentage nodes done: 0.0946335\n",
      "checked 900 modules 53 were found significant.  Modules to check: 10821. Percentage nodes done: 0.10632\n",
      "checked 1000 modules 56 were found significant.  Modules to check: 10721. Percentage nodes done: 0.116577\n",
      "checked 1100 modules 75 were found significant.  Modules to check: 10621. Percentage nodes done: 0.12867\n",
      "checked 1200 modules 88 were found significant.  Modules to check: 10521. Percentage nodes done: 0.139023\n",
      "checked 1300 modules 93 were found significant.  Modules to check: 10421. Percentage nodes done: 0.147509\n",
      "checked 1400 modules 103 were found significant.  Modules to check: 10321. Percentage nodes done: 0.157748\n",
      "checked 1500 modules 116 were found significant.  Modules to check: 10221. Percentage nodes done: 0.16855\n",
      "checked 1600 modules 124 were found significant.  Modules to check: 10121. Percentage nodes done: 0.178107\n",
      "checked 1700 modules 135 were found significant.  Modules to check: 10021. Percentage nodes done: 0.187927\n",
      "checked 1800 modules 151 were found significant.  Modules to check: 9921. Percentage nodes done: 0.200026\n",
      "checked 1900 modules 161 were found significant.  Modules to check: 9821. Percentage nodes done: 0.210517\n",
      "checked 2000 modules 168 were found significant.  Modules to check: 9721. Percentage nodes done: 0.219625\n",
      "checked 2100 modules 176 were found significant.  Modules to check: 9621. Percentage nodes done: 0.230253\n",
      "checked 2200 modules 182 were found significant.  Modules to check: 9521. Percentage nodes done: 0.239188\n",
      "checked 2300 modules 189 were found significant.  Modules to check: 9421. Percentage nodes done: 0.248781\n",
      "checked 2400 modules 201 were found significant.  Modules to check: 9321. Percentage nodes done: 0.259379\n",
      "checked 2500 modules 210 were found significant.  Modules to check: 9221. Percentage nodes done: 0.26987\n",
      "checked 2600 modules 215 were found significant.  Modules to check: 9121. Percentage nodes done: 0.27853\n",
      "checked 2700 modules 217 were found significant.  Modules to check: 9021. Percentage nodes done: 0.287872\n",
      "checked 2800 modules 232 were found significant.  Modules to check: 8921. Percentage nodes done: 0.298739\n",
      "checked 2900 modules 234 were found significant.  Modules to check: 8821. Percentage nodes done: 0.309151\n",
      "checked 3000 modules 245 were found significant.  Modules to check: 8721. Percentage nodes done: 0.320293\n",
      "checked 3100 modules 250 were found significant.  Modules to check: 8621. Percentage nodes done: 0.329623\n",
      "checked 3200 modules 256 were found significant.  Modules to check: 8521. Percentage nodes done: 0.339761\n",
      "checked 3300 modules 261 were found significant.  Modules to check: 8421. Percentage nodes done: 0.348068\n",
      "checked 3400 modules 267 were found significant.  Modules to check: 8321. Percentage nodes done: 0.358289\n",
      "checked 3500 modules 272 were found significant.  Modules to check: 8221. Percentage nodes done: 0.367386\n",
      "checked 3600 modules 278 were found significant.  Modules to check: 8121. Percentage nodes done: 0.375849\n",
      "checked 3700 modules 281 were found significant.  Modules to check: 8021. Percentage nodes done: 0.384443\n",
      "checked 3800 modules 285 were found significant.  Modules to check: 7921. Percentage nodes done: 0.393516\n",
      "checked 3900 modules 290 were found significant.  Modules to check: 7821. Percentage nodes done: 0.402044\n",
      "checked 4000 modules 294 were found significant.  Modules to check: 7721. Percentage nodes done: 0.410985\n",
      "checked 4100 modules 303 were found significant.  Modules to check: 7621. Percentage nodes done: 0.420638\n",
      "checked 4200 modules 307 were found significant.  Modules to check: 7521. Percentage nodes done: 0.429699\n",
      "checked 4300 modules 312 were found significant.  Modules to check: 7421. Percentage nodes done: 0.438341\n",
      "checked 4400 modules 317 were found significant.  Modules to check: 7321. Percentage nodes done: 0.447211\n",
      "checked 4500 modules 323 were found significant.  Modules to check: 7221. Percentage nodes done: 0.454777\n",
      "checked 4600 modules 328 were found significant.  Modules to check: 7121. Percentage nodes done: 0.462384\n",
      "checked 4700 modules 334 were found significant.  Modules to check: 7021. Percentage nodes done: 0.472641\n",
      "checked 4800 modules 341 were found significant.  Modules to check: 6921. Percentage nodes done: 0.481146\n",
      "checked 4900 modules 349 were found significant.  Modules to check: 6821. Percentage nodes done: 0.490428\n",
      "checked 5000 modules 355 were found significant.  Modules to check: 6721. Percentage nodes done: 0.500194\n",
      "checked 5100 modules 357 were found significant.  Modules to check: 6621. Percentage nodes done: 0.508526\n",
      "checked 5200 modules 364 were found significant.  Modules to check: 6521. Percentage nodes done: 0.517311\n",
      "checked 5300 modules 369 were found significant.  Modules to check: 6421. Percentage nodes done: 0.526085\n",
      "checked 5400 modules 376 were found significant.  Modules to check: 6321. Percentage nodes done: 0.533597\n",
      "checked 5500 modules 382 were found significant.  Modules to check: 6221. Percentage nodes done: 0.542341\n",
      "checked 5600 modules 386 were found significant.  Modules to check: 6121. Percentage nodes done: 0.550295\n",
      "checked 5700 modules 393 were found significant.  Modules to check: 6021. Percentage nodes done: 0.558662\n",
      "checked 5800 modules 397 were found significant.  Modules to check: 5921. Percentage nodes done: 0.567789\n",
      "checked 5900 modules 404 were found significant.  Modules to check: 5821. Percentage nodes done: 0.577185\n",
      "checked 6000 modules 405 were found significant.  Modules to check: 5721. Percentage nodes done: 0.585348\n",
      "checked 6100 modules 407 were found significant.  Modules to check: 5621. Percentage nodes done: 0.593476\n",
      "checked 6200 modules 411 were found significant.  Modules to check: 5521. Percentage nodes done: 0.601813\n",
      "checked 6300 modules 411 were found significant.  Modules to check: 5421. Percentage nodes done: 0.609678\n",
      "checked 6400 modules 412 were found significant.  Modules to check: 5321. Percentage nodes done: 0.61841\n",
      "checked 6500 modules 417 were found significant.  Modules to check: 5221. Percentage nodes done: 0.625982\n",
      "checked 6600 modules 425 were found significant.  Modules to check: 5121. Percentage nodes done: 0.63506\n",
      "checked 6700 modules 431 were found significant.  Modules to check: 5021. Percentage nodes done: 0.64274\n",
      "checked 6800 modules 433 were found significant.  Modules to check: 4921. Percentage nodes done: 0.65204\n",
      "checked 6900 modules 437 were found significant.  Modules to check: 4821. Percentage nodes done: 0.659133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 7000 modules 440 were found significant.  Modules to check: 4721. Percentage nodes done: 0.667679\n",
      "checked 7100 modules 446 were found significant.  Modules to check: 4621. Percentage nodes done: 0.676112\n",
      "checked 7200 modules 447 were found significant.  Modules to check: 4521. Percentage nodes done: 0.683522\n",
      "checked 7300 modules 452 were found significant.  Modules to check: 4421. Percentage nodes done: 0.691262\n",
      "checked 7400 modules 455 were found significant.  Modules to check: 4321. Percentage nodes done: 0.700029\n",
      "checked 7500 modules 459 were found significant.  Modules to check: 4221. Percentage nodes done: 0.706363\n",
      "checked 7600 modules 459 were found significant.  Modules to check: 4121. Percentage nodes done: 0.714126\n",
      "checked 7700 modules 463 were found significant.  Modules to check: 4021. Percentage nodes done: 0.722206\n",
      "checked 7800 modules 467 were found significant.  Modules to check: 3921. Percentage nodes done: 0.729748\n",
      "checked 7900 modules 469 were found significant.  Modules to check: 3821. Percentage nodes done: 0.739419\n",
      "checked 8000 modules 474 were found significant.  Modules to check: 3721. Percentage nodes done: 0.746589\n",
      "checked 8100 modules 476 were found significant.  Modules to check: 3621. Percentage nodes done: 0.753264\n",
      "checked 8200 modules 479 were found significant.  Modules to check: 3521. Percentage nodes done: 0.759448\n",
      "checked 8300 modules 480 were found significant.  Modules to check: 3421. Percentage nodes done: 0.767414\n",
      "checked 8400 modules 483 were found significant.  Modules to check: 3321. Percentage nodes done: 0.774932\n",
      "checked 8500 modules 489 were found significant.  Modules to check: 3221. Percentage nodes done: 0.783748\n",
      "checked 8600 modules 491 were found significant.  Modules to check: 3121. Percentage nodes done: 0.791242\n",
      "checked 8700 modules 495 were found significant.  Modules to check: 3021. Percentage nodes done: 0.798377\n",
      "checked 8800 modules 502 were found significant.  Modules to check: 2921. Percentage nodes done: 0.805793\n",
      "checked 8900 modules 507 were found significant.  Modules to check: 2821. Percentage nodes done: 0.813137\n",
      "checked 9000 modules 512 were found significant.  Modules to check: 2721. Percentage nodes done: 0.820446\n",
      "checked 9100 modules 513 were found significant.  Modules to check: 2621. Percentage nodes done: 0.827156\n",
      "checked 9200 modules 513 were found significant.  Modules to check: 2521. Percentage nodes done: 0.833747\n",
      "checked 9300 modules 518 were found significant.  Modules to check: 2421. Percentage nodes done: 0.841091\n",
      "checked 9400 modules 521 were found significant.  Modules to check: 2321. Percentage nodes done: 0.847862\n",
      "checked 9500 modules 522 were found significant.  Modules to check: 2221. Percentage nodes done: 0.854817\n",
      "checked 9600 modules 523 were found significant.  Modules to check: 2121. Percentage nodes done: 0.862227\n",
      "checked 9700 modules 523 were found significant.  Modules to check: 2021. Percentage nodes done: 0.870092\n",
      "checked 9800 modules 524 were found significant.  Modules to check: 1921. Percentage nodes done: 0.877466\n",
      "checked 9900 modules 525 were found significant.  Modules to check: 1821. Percentage nodes done: 0.8849\n",
      "checked 10000 modules 527 were found significant.  Modules to check: 1721. Percentage nodes done: 0.891916\n",
      "checked 10100 modules 529 were found significant.  Modules to check: 1621. Percentage nodes done: 0.899278\n",
      "checked 10200 modules 530 were found significant.  Modules to check: 1521. Percentage nodes done: 0.906742\n",
      "checked 10300 modules 533 were found significant.  Modules to check: 1421. Percentage nodes done: 0.913381\n",
      "checked 10400 modules 536 were found significant.  Modules to check: 1321. Percentage nodes done: 0.919565\n",
      "checked 10500 modules 538 were found significant.  Modules to check: 1221. Percentage nodes done: 0.925791\n",
      "checked 10600 modules 540 were found significant.  Modules to check: 1121. Percentage nodes done: 0.93228\n",
      "checked 10700 modules 542 were found significant.  Modules to check: 1021. Percentage nodes done: 0.939672\n",
      "checked 10800 modules 542 were found significant.  Modules to check: 921. Percentage nodes done: 0.945109\n",
      "checked 10900 modules 542 were found significant.  Modules to check: 821. Percentage nodes done: 0.951394\n",
      "checked 11000 modules 542 were found significant.  Modules to check: 721. Percentage nodes done: 0.95838\n",
      "checked 11100 modules 543 were found significant.  Modules to check: 621. Percentage nodes done: 0.964534\n",
      "checked 11200 modules 545 were found significant.  Modules to check: 521. Percentage nodes done: 0.970563\n",
      "checked 11300 modules 546 were found significant.  Modules to check: 421. Percentage nodes done: 0.976729\n",
      "checked 11400 modules 547 were found significant.  Modules to check: 321. Percentage nodes done: 0.982291\n",
      "checked 11500 modules 548 were found significant.  Modules to check: 221. Percentage nodes done: 0.987488\n",
      "checked 11600 modules 548 were found significant.  Modules to check: 121. Percentage nodes done: 0.993343\n",
      "checked 11700 modules 549 were found significant.  Modules to check: 21. Percentage nodes done: 0.99878\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11170\n",
      "iteration: 0 number of modules: 4843\n",
      "iteration: 20 number of modules: 3397\n",
      "iteration: 40 number of modules: 3358\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 960\n",
      "iteration: 0 number of modules: 297\n",
      "iteration: 20 number of modules: 132\n",
      "iteration: 40 number of modules: 131\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 264 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12494\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11347\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 15\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 246 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #2\n",
      "iteration: 0 number of modules: 12928\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11711. Percentage nodes done: 0\n",
      "checked 100 modules 6 were found significant.  Modules to check: 11611. Percentage nodes done: 0.0150476\n",
      "checked 200 modules 14 were found significant.  Modules to check: 11511. Percentage nodes done: 0.0284863\n",
      "checked 300 modules 22 were found significant.  Modules to check: 11411. Percentage nodes done: 0.0384562\n",
      "checked 400 modules 29 were found significant.  Modules to check: 11311. Percentage nodes done: 0.0532287\n",
      "checked 500 modules 34 were found significant.  Modules to check: 11211. Percentage nodes done: 0.0643649\n",
      "checked 600 modules 41 were found significant.  Modules to check: 11111. Percentage nodes done: 0.0752678\n",
      "checked 700 modules 47 were found significant.  Modules to check: 11011. Percentage nodes done: 0.0850164\n",
      "checked 800 modules 50 were found significant.  Modules to check: 10911. Percentage nodes done: 0.0962303\n",
      "checked 900 modules 63 were found significant.  Modules to check: 10811. Percentage nodes done: 0.107893\n",
      "checked 1000 modules 73 were found significant.  Modules to check: 10711. Percentage nodes done: 0.118628\n",
      "checked 1100 modules 85 were found significant.  Modules to check: 10611. Percentage nodes done: 0.130201\n",
      "checked 1200 modules 92 were found significant.  Modules to check: 10511. Percentage nodes done: 0.141002\n",
      "checked 1300 modules 99 were found significant.  Modules to check: 10411. Percentage nodes done: 0.150476\n",
      "checked 1400 modules 106 were found significant.  Modules to check: 10311. Percentage nodes done: 0.160356\n",
      "checked 1500 modules 114 were found significant.  Modules to check: 10211. Percentage nodes done: 0.169979\n",
      "checked 1600 modules 124 were found significant.  Modules to check: 10111. Percentage nodes done: 0.178567\n",
      "checked 1700 modules 131 were found significant.  Modules to check: 10011. Percentage nodes done: 0.188143\n",
      "checked 1800 modules 141 were found significant.  Modules to check: 9911. Percentage nodes done: 0.19837\n",
      "checked 1900 modules 155 were found significant.  Modules to check: 9811. Percentage nodes done: 0.209524\n",
      "checked 2000 modules 162 were found significant.  Modules to check: 9711. Percentage nodes done: 0.218812\n",
      "checked 2100 modules 164 were found significant.  Modules to check: 9611. Percentage nodes done: 0.230444\n",
      "checked 2200 modules 175 were found significant.  Modules to check: 9511. Percentage nodes done: 0.240289\n",
      "checked 2300 modules 180 were found significant.  Modules to check: 9411. Percentage nodes done: 0.249146\n",
      "checked 2400 modules 195 were found significant.  Modules to check: 9311. Percentage nodes done: 0.258709\n",
      "checked 2500 modules 200 were found significant.  Modules to check: 9211. Percentage nodes done: 0.267525\n",
      "checked 2600 modules 207 were found significant.  Modules to check: 9111. Percentage nodes done: 0.277369\n",
      "checked 2700 modules 208 were found significant.  Modules to check: 9011. Percentage nodes done: 0.286353\n",
      "checked 2800 modules 223 were found significant.  Modules to check: 8911. Percentage nodes done: 0.2971\n",
      "checked 2900 modules 227 were found significant.  Modules to check: 8811. Percentage nodes done: 0.306986\n",
      "checked 3000 modules 235 were found significant.  Modules to check: 8711. Percentage nodes done: 0.31747\n",
      "checked 3100 modules 239 were found significant.  Modules to check: 8611. Percentage nodes done: 0.326711\n",
      "checked 3200 modules 242 were found significant.  Modules to check: 8511. Percentage nodes done: 0.336824\n",
      "checked 3300 modules 243 were found significant.  Modules to check: 8411. Percentage nodes done: 0.344779\n",
      "checked 3400 modules 256 were found significant.  Modules to check: 8311. Percentage nodes done: 0.355939\n",
      "checked 3500 modules 264 were found significant.  Modules to check: 8211. Percentage nodes done: 0.366249\n",
      "checked 3600 modules 268 were found significant.  Modules to check: 8111. Percentage nodes done: 0.374383\n",
      "checked 3700 modules 272 were found significant.  Modules to check: 8011. Percentage nodes done: 0.382876\n",
      "checked 3800 modules 279 were found significant.  Modules to check: 7911. Percentage nodes done: 0.39202\n",
      "checked 3900 modules 284 were found significant.  Modules to check: 7811. Percentage nodes done: 0.40077\n",
      "checked 4000 modules 285 were found significant.  Modules to check: 7711. Percentage nodes done: 0.410256\n",
      "checked 4100 modules 291 were found significant.  Modules to check: 7611. Percentage nodes done: 0.4215\n",
      "checked 4200 modules 297 were found significant.  Modules to check: 7511. Percentage nodes done: 0.430644\n",
      "checked 4300 modules 305 were found significant.  Modules to check: 7411. Percentage nodes done: 0.438736\n",
      "checked 4400 modules 309 were found significant.  Modules to check: 7311. Percentage nodes done: 0.447223\n",
      "checked 4500 modules 315 were found significant.  Modules to check: 7211. Percentage nodes done: 0.455105\n",
      "checked 4600 modules 319 were found significant.  Modules to check: 7111. Percentage nodes done: 0.46309\n",
      "checked 4700 modules 323 were found significant.  Modules to check: 7011. Percentage nodes done: 0.471259\n",
      "checked 4800 modules 330 were found significant.  Modules to check: 6911. Percentage nodes done: 0.481092\n",
      "checked 4900 modules 333 were found significant.  Modules to check: 6811. Percentage nodes done: 0.490978\n",
      "checked 5000 modules 337 were found significant.  Modules to check: 6711. Percentage nodes done: 0.500751\n",
      "checked 5100 modules 342 were found significant.  Modules to check: 6611. Percentage nodes done: 0.509339\n",
      "checked 5200 modules 347 were found significant.  Modules to check: 6511. Percentage nodes done: 0.51779\n",
      "checked 5300 modules 353 were found significant.  Modules to check: 6411. Percentage nodes done: 0.526534\n",
      "checked 5400 modules 358 were found significant.  Modules to check: 6311. Percentage nodes done: 0.534344\n",
      "checked 5500 modules 362 were found significant.  Modules to check: 6211. Percentage nodes done: 0.543483\n",
      "checked 5600 modules 369 were found significant.  Modules to check: 6111. Percentage nodes done: 0.550989\n",
      "checked 5700 modules 374 were found significant.  Modules to check: 6011. Percentage nodes done: 0.559661\n",
      "checked 5800 modules 378 were found significant.  Modules to check: 5911. Percentage nodes done: 0.568596\n",
      "checked 5900 modules 383 were found significant.  Modules to check: 5811. Percentage nodes done: 0.578345\n",
      "checked 6000 modules 388 were found significant.  Modules to check: 5711. Percentage nodes done: 0.586951\n",
      "checked 6100 modules 390 were found significant.  Modules to check: 5611. Percentage nodes done: 0.594654\n",
      "checked 6200 modules 393 were found significant.  Modules to check: 5511. Percentage nodes done: 0.602764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 6300 modules 393 were found significant.  Modules to check: 5411. Percentage nodes done: 0.610378\n",
      "checked 6400 modules 395 were found significant.  Modules to check: 5311. Percentage nodes done: 0.619403\n",
      "checked 6500 modules 395 were found significant.  Modules to check: 5211. Percentage nodes done: 0.627471\n",
      "checked 6600 modules 403 were found significant.  Modules to check: 5111. Percentage nodes done: 0.636394\n",
      "checked 6700 modules 406 were found significant.  Modules to check: 5011. Percentage nodes done: 0.644976\n",
      "checked 6800 modules 415 were found significant.  Modules to check: 4911. Percentage nodes done: 0.652967\n",
      "checked 6900 modules 422 were found significant.  Modules to check: 4811. Percentage nodes done: 0.660796\n",
      "checked 7000 modules 424 were found significant.  Modules to check: 4711. Percentage nodes done: 0.667889\n",
      "checked 7100 modules 431 were found significant.  Modules to check: 4611. Percentage nodes done: 0.675879\n",
      "checked 7200 modules 431 were found significant.  Modules to check: 4511. Percentage nodes done: 0.684067\n",
      "checked 7300 modules 435 were found significant.  Modules to check: 4411. Percentage nodes done: 0.691453\n",
      "checked 7400 modules 438 were found significant.  Modules to check: 4311. Percentage nodes done: 0.699688\n",
      "checked 7500 modules 442 were found significant.  Modules to check: 4211. Percentage nodes done: 0.706817\n",
      "checked 7600 modules 444 were found significant.  Modules to check: 4111. Percentage nodes done: 0.714664\n",
      "checked 7700 modules 448 were found significant.  Modules to check: 4011. Percentage nodes done: 0.72342\n",
      "checked 7800 modules 450 were found significant.  Modules to check: 3911. Percentage nodes done: 0.730071\n",
      "checked 7900 modules 452 were found significant.  Modules to check: 3811. Percentage nodes done: 0.738617\n",
      "checked 8000 modules 461 were found significant.  Modules to check: 3711. Percentage nodes done: 0.74632\n",
      "checked 8100 modules 465 were found significant.  Modules to check: 3611. Percentage nodes done: 0.752953\n",
      "checked 8200 modules 466 were found significant.  Modules to check: 3511. Percentage nodes done: 0.759131\n",
      "checked 8300 modules 467 were found significant.  Modules to check: 3411. Percentage nodes done: 0.767253\n",
      "checked 8400 modules 470 were found significant.  Modules to check: 3311. Percentage nodes done: 0.774837\n",
      "checked 8500 modules 478 were found significant.  Modules to check: 3211. Percentage nodes done: 0.78379\n",
      "checked 8600 modules 481 were found significant.  Modules to check: 3111. Percentage nodes done: 0.791176\n",
      "checked 8700 modules 484 were found significant.  Modules to check: 3011. Percentage nodes done: 0.797534\n",
      "checked 8800 modules 487 were found significant.  Modules to check: 2911. Percentage nodes done: 0.805691\n",
      "checked 8900 modules 493 were found significant.  Modules to check: 2811. Percentage nodes done: 0.812832\n",
      "checked 9000 modules 499 were found significant.  Modules to check: 2711. Percentage nodes done: 0.820607\n",
      "checked 9100 modules 501 were found significant.  Modules to check: 2611. Percentage nodes done: 0.82776\n",
      "checked 9200 modules 505 were found significant.  Modules to check: 2511. Percentage nodes done: 0.834632\n",
      "checked 9300 modules 509 were found significant.  Modules to check: 2411. Percentage nodes done: 0.842108\n",
      "checked 9400 modules 513 were found significant.  Modules to check: 2311. Percentage nodes done: 0.849147\n",
      "checked 9500 modules 514 were found significant.  Modules to check: 2211. Percentage nodes done: 0.856241\n",
      "checked 9600 modules 514 were found significant.  Modules to check: 2111. Percentage nodes done: 0.863196\n",
      "checked 9700 modules 515 were found significant.  Modules to check: 2011. Percentage nodes done: 0.869913\n",
      "checked 9800 modules 516 were found significant.  Modules to check: 1911. Percentage nodes done: 0.877155\n",
      "checked 9900 modules 517 were found significant.  Modules to check: 1811. Percentage nodes done: 0.884326\n",
      "checked 10000 modules 524 were found significant.  Modules to check: 1711. Percentage nodes done: 0.891599\n",
      "checked 10100 modules 527 were found significant.  Modules to check: 1611. Percentage nodes done: 0.898405\n",
      "checked 10200 modules 528 were found significant.  Modules to check: 1511. Percentage nodes done: 0.905564\n",
      "checked 10300 modules 530 were found significant.  Modules to check: 1411. Percentage nodes done: 0.912813\n",
      "checked 10400 modules 530 were found significant.  Modules to check: 1311. Percentage nodes done: 0.919296\n",
      "checked 10500 modules 531 were found significant.  Modules to check: 1211. Percentage nodes done: 0.926335\n",
      "checked 10600 modules 532 were found significant.  Modules to check: 1111. Percentage nodes done: 0.932543\n",
      "checked 10700 modules 535 were found significant.  Modules to check: 1011. Percentage nodes done: 0.939588\n",
      "checked 10800 modules 536 were found significant.  Modules to check: 911. Percentage nodes done: 0.945946\n",
      "checked 10900 modules 536 were found significant.  Modules to check: 811. Percentage nodes done: 0.951987\n",
      "checked 11000 modules 537 were found significant.  Modules to check: 711. Percentage nodes done: 0.959217\n",
      "checked 11100 modules 537 were found significant.  Modules to check: 611. Percentage nodes done: 0.965282\n",
      "checked 11200 modules 538 were found significant.  Modules to check: 511. Percentage nodes done: 0.971406\n",
      "checked 11300 modules 538 were found significant.  Modules to check: 411. Percentage nodes done: 0.977064\n",
      "checked 11400 modules 538 were found significant.  Modules to check: 311. Percentage nodes done: 0.982889\n",
      "checked 11500 modules 538 were found significant.  Modules to check: 211. Percentage nodes done: 0.987877\n",
      "checked 11600 modules 538 were found significant.  Modules to check: 111. Percentage nodes done: 0.993882\n",
      "checked 11700 modules 539 were found significant.  Modules to check: 11. Percentage nodes done: 0.999438\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11172\n",
      "iteration: 0 number of modules: 4836\n",
      "iteration: 20 number of modules: 3410\n",
      "iteration: 40 number of modules: 3381\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 985\n",
      "iteration: 0 number of modules: 328\n",
      "iteration: 20 number of modules: 134\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 254 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12501\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11366\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 22\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 239 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #3\n",
      "iteration: 0 number of modules: 12946\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11707. Percentage nodes done: 0\n",
      "checked 100 modules 5 were found significant.  Modules to check: 11607. Percentage nodes done: 0.0143418\n",
      "checked 200 modules 8 were found significant.  Modules to check: 11507. Percentage nodes done: 0.0276969\n",
      "checked 300 modules 15 were found significant.  Modules to check: 11407. Percentage nodes done: 0.0387792\n",
      "checked 400 modules 25 were found significant.  Modules to check: 11307. Percentage nodes done: 0.0507886\n",
      "checked 500 modules 33 were found significant.  Modules to check: 11207. Percentage nodes done: 0.0620922\n",
      "checked 600 modules 40 were found significant.  Modules to check: 11107. Percentage nodes done: 0.0725166\n",
      "checked 700 modules 45 were found significant.  Modules to check: 11007. Percentage nodes done: 0.0861169\n",
      "checked 800 modules 51 were found significant.  Modules to check: 10907. Percentage nodes done: 0.0974624\n",
      "checked 900 modules 58 were found significant.  Modules to check: 10807. Percentage nodes done: 0.108126\n",
      "checked 1000 modules 60 were found significant.  Modules to check: 10707. Percentage nodes done: 0.119735\n",
      "checked 1100 modules 70 were found significant.  Modules to check: 10607. Percentage nodes done: 0.132043\n",
      "checked 1200 modules 83 were found significant.  Modules to check: 10507. Percentage nodes done: 0.142521\n",
      "checked 1300 modules 88 were found significant.  Modules to check: 10407. Percentage nodes done: 0.151606\n",
      "checked 1400 modules 95 were found significant.  Modules to check: 10307. Percentage nodes done: 0.161074\n",
      "checked 1500 modules 99 were found significant.  Modules to check: 10207. Percentage nodes done: 0.17038\n",
      "checked 1600 modules 105 were found significant.  Modules to check: 10107. Percentage nodes done: 0.180517\n",
      "checked 1700 modules 109 were found significant.  Modules to check: 10007. Percentage nodes done: 0.191462\n",
      "checked 1800 modules 117 were found significant.  Modules to check: 9907. Percentage nodes done: 0.199584\n",
      "checked 1900 modules 127 were found significant.  Modules to check: 9807. Percentage nodes done: 0.213997\n",
      "checked 2000 modules 132 were found significant.  Modules to check: 9707. Percentage nodes done: 0.223746\n",
      "checked 2100 modules 139 were found significant.  Modules to check: 9607. Percentage nodes done: 0.233716\n",
      "checked 2200 modules 146 were found significant.  Modules to check: 9507. Percentage nodes done: 0.244493\n",
      "checked 2300 modules 150 were found significant.  Modules to check: 9407. Percentage nodes done: 0.253303\n",
      "checked 2400 modules 157 were found significant.  Modules to check: 9307. Percentage nodes done: 0.263961\n",
      "checked 2500 modules 164 were found significant.  Modules to check: 9207. Percentage nodes done: 0.273948\n",
      "checked 2600 modules 179 were found significant.  Modules to check: 9107. Percentage nodes done: 0.283775\n",
      "checked 2700 modules 181 were found significant.  Modules to check: 9007. Percentage nodes done: 0.292297\n",
      "checked 2800 modules 183 were found significant.  Modules to check: 8907. Percentage nodes done: 0.301992\n",
      "checked 2900 modules 195 were found significant.  Modules to check: 8807. Percentage nodes done: 0.312758\n",
      "checked 3000 modules 200 were found significant.  Modules to check: 8707. Percentage nodes done: 0.322913\n",
      "checked 3100 modules 208 were found significant.  Modules to check: 8607. Percentage nodes done: 0.332793\n",
      "checked 3200 modules 211 were found significant.  Modules to check: 8507. Percentage nodes done: 0.342267\n",
      "checked 3300 modules 218 were found significant.  Modules to check: 8407. Percentage nodes done: 0.350771\n",
      "checked 3400 modules 223 were found significant.  Modules to check: 8307. Percentage nodes done: 0.35997\n",
      "checked 3500 modules 234 were found significant.  Modules to check: 8207. Percentage nodes done: 0.369922\n",
      "checked 3600 modules 236 were found significant.  Modules to check: 8107. Percentage nodes done: 0.378253\n",
      "checked 3700 modules 243 were found significant.  Modules to check: 8007. Percentage nodes done: 0.386147\n",
      "checked 3800 modules 251 were found significant.  Modules to check: 7907. Percentage nodes done: 0.39522\n",
      "checked 3900 modules 253 were found significant.  Modules to check: 7807. Percentage nodes done: 0.403964\n",
      "checked 4000 modules 257 were found significant.  Modules to check: 7707. Percentage nodes done: 0.412672\n",
      "checked 4100 modules 261 were found significant.  Modules to check: 7607. Percentage nodes done: 0.422181\n",
      "checked 4200 modules 267 were found significant.  Modules to check: 7507. Percentage nodes done: 0.431565\n",
      "checked 4300 modules 272 were found significant.  Modules to check: 7407. Percentage nodes done: 0.440369\n",
      "checked 4400 modules 276 were found significant.  Modules to check: 7307. Percentage nodes done: 0.448951\n",
      "checked 4500 modules 282 were found significant.  Modules to check: 7207. Percentage nodes done: 0.456553\n",
      "checked 4600 modules 288 were found significant.  Modules to check: 7107. Percentage nodes done: 0.464872\n",
      "checked 4700 modules 294 were found significant.  Modules to check: 7007. Percentage nodes done: 0.475673\n",
      "checked 4800 modules 300 were found significant.  Modules to check: 6907. Percentage nodes done: 0.485703\n",
      "checked 4900 modules 304 were found significant.  Modules to check: 6807. Percentage nodes done: 0.49535\n",
      "checked 5000 modules 307 were found significant.  Modules to check: 6707. Percentage nodes done: 0.503908\n",
      "checked 5100 modules 312 were found significant.  Modules to check: 6607. Percentage nodes done: 0.511809\n",
      "checked 5200 modules 319 were found significant.  Modules to check: 6507. Percentage nodes done: 0.520571\n",
      "checked 5300 modules 324 were found significant.  Modules to check: 6407. Percentage nodes done: 0.527885\n",
      "checked 5400 modules 331 were found significant.  Modules to check: 6307. Percentage nodes done: 0.535475\n",
      "checked 5500 modules 335 were found significant.  Modules to check: 6207. Percentage nodes done: 0.544195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 5600 modules 340 were found significant.  Modules to check: 6107. Percentage nodes done: 0.552257\n",
      "checked 5700 modules 348 were found significant.  Modules to check: 6007. Percentage nodes done: 0.561156\n",
      "checked 5800 modules 351 were found significant.  Modules to check: 5907. Percentage nodes done: 0.569876\n",
      "checked 5900 modules 357 were found significant.  Modules to check: 5807. Percentage nodes done: 0.578776\n",
      "checked 6000 modules 359 were found significant.  Modules to check: 5707. Percentage nodes done: 0.586682\n",
      "checked 6100 modules 360 were found significant.  Modules to check: 5607. Percentage nodes done: 0.595294\n",
      "checked 6200 modules 364 were found significant.  Modules to check: 5507. Percentage nodes done: 0.603165\n",
      "checked 6300 modules 367 were found significant.  Modules to check: 5407. Percentage nodes done: 0.611789\n",
      "checked 6400 modules 368 were found significant.  Modules to check: 5307. Percentage nodes done: 0.620414\n",
      "checked 6500 modules 375 were found significant.  Modules to check: 5207. Percentage nodes done: 0.628565\n",
      "checked 6600 modules 380 were found significant.  Modules to check: 5107. Percentage nodes done: 0.637632\n",
      "checked 6700 modules 383 were found significant.  Modules to check: 5007. Percentage nodes done: 0.645006\n",
      "checked 6800 modules 390 were found significant.  Modules to check: 4907. Percentage nodes done: 0.653595\n",
      "checked 6900 modules 392 were found significant.  Modules to check: 4807. Percentage nodes done: 0.661005\n",
      "checked 7000 modules 395 were found significant.  Modules to check: 4707. Percentage nodes done: 0.668792\n",
      "checked 7100 modules 399 were found significant.  Modules to check: 4607. Percentage nodes done: 0.677362\n",
      "checked 7200 modules 406 were found significant.  Modules to check: 4507. Percentage nodes done: 0.684503\n",
      "checked 7300 modules 409 were found significant.  Modules to check: 4407. Percentage nodes done: 0.692452\n",
      "checked 7400 modules 415 were found significant.  Modules to check: 4307. Percentage nodes done: 0.700167\n",
      "checked 7500 modules 416 were found significant.  Modules to check: 4207. Percentage nodes done: 0.708097\n",
      "checked 7600 modules 416 were found significant.  Modules to check: 4107. Percentage nodes done: 0.716871\n",
      "checked 7700 modules 419 were found significant.  Modules to check: 4007. Percentage nodes done: 0.725406\n",
      "checked 7800 modules 420 were found significant.  Modules to check: 3907. Percentage nodes done: 0.732678\n",
      "checked 7900 modules 423 were found significant.  Modules to check: 3807. Percentage nodes done: 0.741422\n",
      "checked 8000 modules 428 were found significant.  Modules to check: 3707. Percentage nodes done: 0.749107\n",
      "checked 8100 modules 430 were found significant.  Modules to check: 3607. Percentage nodes done: 0.75574\n",
      "checked 8200 modules 436 were found significant.  Modules to check: 3507. Percentage nodes done: 0.761822\n",
      "checked 8300 modules 437 were found significant.  Modules to check: 3407. Percentage nodes done: 0.769358\n",
      "checked 8400 modules 442 were found significant.  Modules to check: 3307. Percentage nodes done: 0.776786\n",
      "checked 8500 modules 447 were found significant.  Modules to check: 3207. Percentage nodes done: 0.784795\n",
      "checked 8600 modules 449 were found significant.  Modules to check: 3107. Percentage nodes done: 0.792552\n",
      "checked 8700 modules 455 were found significant.  Modules to check: 3007. Percentage nodes done: 0.798849\n",
      "checked 8800 modules 459 were found significant.  Modules to check: 2907. Percentage nodes done: 0.805757\n",
      "checked 8900 modules 464 were found significant.  Modules to check: 2807. Percentage nodes done: 0.813275\n",
      "checked 9000 modules 469 were found significant.  Modules to check: 2707. Percentage nodes done: 0.820757\n",
      "checked 9100 modules 471 were found significant.  Modules to check: 2607. Percentage nodes done: 0.82785\n",
      "checked 9200 modules 476 were found significant.  Modules to check: 2507. Percentage nodes done: 0.83459\n",
      "checked 9300 modules 481 were found significant.  Modules to check: 2407. Percentage nodes done: 0.841839\n",
      "checked 9400 modules 484 were found significant.  Modules to check: 2307. Percentage nodes done: 0.848663\n",
      "checked 9500 modules 484 were found significant.  Modules to check: 2207. Percentage nodes done: 0.855655\n",
      "checked 9600 modules 485 were found significant.  Modules to check: 2107. Percentage nodes done: 0.862455\n",
      "checked 9700 modules 485 were found significant.  Modules to check: 2007. Percentage nodes done: 0.868998\n",
      "checked 9800 modules 485 were found significant.  Modules to check: 1907. Percentage nodes done: 0.876444\n",
      "checked 9900 modules 487 were found significant.  Modules to check: 1807. Percentage nodes done: 0.884344\n",
      "checked 10000 modules 491 were found significant.  Modules to check: 1707. Percentage nodes done: 0.891653\n",
      "checked 10100 modules 494 were found significant.  Modules to check: 1607. Percentage nodes done: 0.898028\n",
      "checked 10200 modules 495 were found significant.  Modules to check: 1507. Percentage nodes done: 0.905618\n",
      "checked 10300 modules 498 were found significant.  Modules to check: 1407. Percentage nodes done: 0.912514\n",
      "checked 10400 modules 501 were found significant.  Modules to check: 1307. Percentage nodes done: 0.919039\n",
      "checked 10500 modules 502 were found significant.  Modules to check: 1207. Percentage nodes done: 0.925181\n",
      "checked 10600 modules 503 were found significant.  Modules to check: 1107. Percentage nodes done: 0.932071\n",
      "checked 10700 modules 506 were found significant.  Modules to check: 1007. Percentage nodes done: 0.938895\n",
      "checked 10800 modules 507 were found significant.  Modules to check: 907. Percentage nodes done: 0.94463\n",
      "checked 10900 modules 507 were found significant.  Modules to check: 807. Percentage nodes done: 0.950737\n",
      "checked 11000 modules 507 were found significant.  Modules to check: 707. Percentage nodes done: 0.958547\n",
      "checked 11100 modules 508 were found significant.  Modules to check: 607. Percentage nodes done: 0.964731\n",
      "checked 11200 modules 509 were found significant.  Modules to check: 507. Percentage nodes done: 0.971113\n",
      "checked 11300 modules 511 were found significant.  Modules to check: 407. Percentage nodes done: 0.977267\n",
      "checked 11400 modules 512 were found significant.  Modules to check: 307. Percentage nodes done: 0.982997\n",
      "checked 11500 modules 513 were found significant.  Modules to check: 207. Percentage nodes done: 0.988086\n",
      "checked 11600 modules 513 were found significant.  Modules to check: 107. Percentage nodes done: 0.994235\n",
      "checked 11700 modules 516 were found significant.  Modules to check: 7. Percentage nodes done: 0.999647\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11191\n",
      "iteration: 0 number of modules: 5238\n",
      "iteration: 20 number of modules: 3773\n",
      "iteration: 40 number of modules: 3749\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1028\n",
      "iteration: 0 number of modules: 346\n",
      "iteration: 20 number of modules: 135\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 255 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12508\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11322\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 19\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 240 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #4\n",
      "iteration: 0 number of modules: 12908\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11714. Percentage nodes done: 0\n",
      "checked 100 modules 6 were found significant.  Modules to check: 11614. Percentage nodes done: 0.0148801\n",
      "checked 200 modules 11 were found significant.  Modules to check: 11514. Percentage nodes done: 0.0273619\n",
      "checked 300 modules 16 were found significant.  Modules to check: 11414. Percentage nodes done: 0.0376787\n",
      "checked 400 modules 26 were found significant.  Modules to check: 11314. Percentage nodes done: 0.0533603\n",
      "checked 500 modules 29 were found significant.  Modules to check: 11214. Percentage nodes done: 0.0640957\n",
      "checked 600 modules 36 were found significant.  Modules to check: 11114. Percentage nodes done: 0.0753097\n",
      "checked 700 modules 45 were found significant.  Modules to check: 11014. Percentage nodes done: 0.0857999\n",
      "checked 800 modules 51 were found significant.  Modules to check: 10914. Percentage nodes done: 0.0959612\n",
      "checked 900 modules 63 were found significant.  Modules to check: 10814. Percentage nodes done: 0.106314\n",
      "checked 1000 modules 68 were found significant.  Modules to check: 10714. Percentage nodes done: 0.116254\n",
      "checked 1100 modules 80 were found significant.  Modules to check: 10614. Percentage nodes done: 0.12815\n",
      "checked 1200 modules 92 were found significant.  Modules to check: 10514. Percentage nodes done: 0.138742\n",
      "checked 1300 modules 99 were found significant.  Modules to check: 10414. Percentage nodes done: 0.147336\n",
      "checked 1400 modules 106 were found significant.  Modules to check: 10314. Percentage nodes done: 0.156588\n",
      "checked 1500 modules 114 were found significant.  Modules to check: 10214. Percentage nodes done: 0.165906\n",
      "checked 1600 modules 125 were found significant.  Modules to check: 10114. Percentage nodes done: 0.175679\n",
      "checked 1700 modules 128 were found significant.  Modules to check: 10014. Percentage nodes done: 0.185541\n",
      "checked 1800 modules 140 were found significant.  Modules to check: 9914. Percentage nodes done: 0.195152\n",
      "checked 1900 modules 153 were found significant.  Modules to check: 9814. Percentage nodes done: 0.209231\n",
      "checked 2000 modules 159 were found significant.  Modules to check: 9714. Percentage nodes done: 0.218902\n",
      "checked 2100 modules 167 were found significant.  Modules to check: 9614. Percentage nodes done: 0.229625\n",
      "checked 2200 modules 176 were found significant.  Modules to check: 9514. Percentage nodes done: 0.238429\n",
      "checked 2300 modules 179 were found significant.  Modules to check: 9414. Percentage nodes done: 0.248046\n",
      "checked 2400 modules 192 were found significant.  Modules to check: 9314. Percentage nodes done: 0.258464\n",
      "checked 2500 modules 199 were found significant.  Modules to check: 9214. Percentage nodes done: 0.268255\n",
      "checked 2600 modules 207 were found significant.  Modules to check: 9114. Percentage nodes done: 0.278386\n",
      "checked 2700 modules 209 were found significant.  Modules to check: 9014. Percentage nodes done: 0.287501\n",
      "checked 2800 modules 213 were found significant.  Modules to check: 8914. Percentage nodes done: 0.29765\n",
      "checked 2900 modules 223 were found significant.  Modules to check: 8814. Percentage nodes done: 0.307686\n",
      "checked 3000 modules 227 were found significant.  Modules to check: 8714. Percentage nodes done: 0.31765\n",
      "checked 3100 modules 233 were found significant.  Modules to check: 8614. Percentage nodes done: 0.327518\n",
      "checked 3200 modules 237 were found significant.  Modules to check: 8514. Percentage nodes done: 0.337602\n",
      "checked 3300 modules 238 were found significant.  Modules to check: 8414. Percentage nodes done: 0.345395\n",
      "checked 3400 modules 249 were found significant.  Modules to check: 8314. Percentage nodes done: 0.356291\n",
      "checked 3500 modules 255 were found significant.  Modules to check: 8214. Percentage nodes done: 0.364928\n",
      "checked 3600 modules 259 were found significant.  Modules to check: 8114. Percentage nodes done: 0.373438\n",
      "checked 3700 modules 261 were found significant.  Modules to check: 8014. Percentage nodes done: 0.381566\n",
      "checked 3800 modules 267 were found significant.  Modules to check: 7914. Percentage nodes done: 0.390501\n",
      "checked 3900 modules 274 were found significant.  Modules to check: 7814. Percentage nodes done: 0.399335\n",
      "checked 4000 modules 280 were found significant.  Modules to check: 7714. Percentage nodes done: 0.409054\n",
      "checked 4100 modules 287 were found significant.  Modules to check: 7614. Percentage nodes done: 0.418707\n",
      "checked 4200 modules 293 were found significant.  Modules to check: 7514. Percentage nodes done: 0.427953\n",
      "checked 4300 modules 297 were found significant.  Modules to check: 7414. Percentage nodes done: 0.438323\n",
      "checked 4400 modules 301 were found significant.  Modules to check: 7314. Percentage nodes done: 0.446631\n",
      "checked 4500 modules 306 were found significant.  Modules to check: 7214. Percentage nodes done: 0.455991\n",
      "checked 4600 modules 314 were found significant.  Modules to check: 7114. Percentage nodes done: 0.464376\n",
      "checked 4700 modules 316 were found significant.  Modules to check: 7014. Percentage nodes done: 0.472773\n",
      "checked 4800 modules 324 were found significant.  Modules to check: 6914. Percentage nodes done: 0.481594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 4900 modules 331 were found significant.  Modules to check: 6814. Percentage nodes done: 0.49114\n",
      "checked 5000 modules 334 were found significant.  Modules to check: 6714. Percentage nodes done: 0.500105\n",
      "checked 5100 modules 337 were found significant.  Modules to check: 6614. Percentage nodes done: 0.508627\n",
      "checked 5200 modules 347 were found significant.  Modules to check: 6514. Percentage nodes done: 0.517246\n",
      "checked 5300 modules 349 were found significant.  Modules to check: 6414. Percentage nodes done: 0.525218\n",
      "checked 5400 modules 354 were found significant.  Modules to check: 6314. Percentage nodes done: 0.533465\n",
      "checked 5500 modules 359 were found significant.  Modules to check: 6214. Percentage nodes done: 0.542\n",
      "checked 5600 modules 364 were found significant.  Modules to check: 6114. Percentage nodes done: 0.550534\n",
      "checked 5700 modules 370 were found significant.  Modules to check: 6014. Percentage nodes done: 0.558776\n",
      "checked 5800 modules 374 were found significant.  Modules to check: 5914. Percentage nodes done: 0.56731\n",
      "checked 5900 modules 380 were found significant.  Modules to check: 5814. Percentage nodes done: 0.576323\n",
      "checked 6000 modules 387 were found significant.  Modules to check: 5714. Percentage nodes done: 0.584242\n",
      "checked 6100 modules 388 were found significant.  Modules to check: 5614. Percentage nodes done: 0.593016\n",
      "checked 6200 modules 392 were found significant.  Modules to check: 5514. Percentage nodes done: 0.601383\n",
      "checked 6300 modules 393 were found significant.  Modules to check: 5414. Percentage nodes done: 0.610587\n",
      "checked 6400 modules 396 were found significant.  Modules to check: 5314. Percentage nodes done: 0.619152\n",
      "checked 6500 modules 402 were found significant.  Modules to check: 5214. Percentage nodes done: 0.626328\n",
      "checked 6600 modules 407 were found significant.  Modules to check: 5114. Percentage nodes done: 0.634965\n",
      "checked 6700 modules 411 were found significant.  Modules to check: 5014. Percentage nodes done: 0.642315\n",
      "checked 6800 modules 416 were found significant.  Modules to check: 4914. Percentage nodes done: 0.651621\n",
      "checked 6900 modules 420 were found significant.  Modules to check: 4814. Percentage nodes done: 0.658505\n",
      "checked 7000 modules 422 were found significant.  Modules to check: 4714. Percentage nodes done: 0.666657\n",
      "checked 7100 modules 427 were found significant.  Modules to check: 4614. Percentage nodes done: 0.674563\n",
      "checked 7200 modules 433 were found significant.  Modules to check: 4514. Percentage nodes done: 0.682524\n",
      "checked 7300 modules 437 were found significant.  Modules to check: 4414. Percentage nodes done: 0.689928\n",
      "checked 7400 modules 442 were found significant.  Modules to check: 4314. Percentage nodes done: 0.69744\n",
      "checked 7500 modules 442 were found significant.  Modules to check: 4214. Percentage nodes done: 0.704413\n",
      "checked 7600 modules 443 were found significant.  Modules to check: 4114. Percentage nodes done: 0.712864\n",
      "checked 7700 modules 445 were found significant.  Modules to check: 4014. Percentage nodes done: 0.720956\n",
      "checked 7800 modules 446 were found significant.  Modules to check: 3914. Percentage nodes done: 0.729748\n",
      "checked 7900 modules 451 were found significant.  Modules to check: 3814. Percentage nodes done: 0.737881\n",
      "checked 8000 modules 457 were found significant.  Modules to check: 3714. Percentage nodes done: 0.745645\n",
      "checked 8100 modules 459 were found significant.  Modules to check: 3614. Percentage nodes done: 0.751613\n",
      "checked 8200 modules 464 were found significant.  Modules to check: 3514. Percentage nodes done: 0.759012\n",
      "checked 8300 modules 467 were found significant.  Modules to check: 3414. Percentage nodes done: 0.767277\n",
      "checked 8400 modules 470 were found significant.  Modules to check: 3314. Percentage nodes done: 0.775255\n",
      "checked 8500 modules 478 were found significant.  Modules to check: 3214. Percentage nodes done: 0.783359\n",
      "checked 8600 modules 480 were found significant.  Modules to check: 3114. Percentage nodes done: 0.790452\n",
      "checked 8700 modules 484 were found significant.  Modules to check: 3014. Percentage nodes done: 0.796804\n",
      "checked 8800 modules 486 were found significant.  Modules to check: 2914. Percentage nodes done: 0.805111\n",
      "checked 8900 modules 490 were found significant.  Modules to check: 2814. Percentage nodes done: 0.812109\n",
      "checked 9000 modules 496 were found significant.  Modules to check: 2714. Percentage nodes done: 0.819752\n",
      "checked 9100 modules 499 were found significant.  Modules to check: 2614. Percentage nodes done: 0.826767\n",
      "checked 9200 modules 502 were found significant.  Modules to check: 2514. Percentage nodes done: 0.834184\n",
      "checked 9300 modules 504 were found significant.  Modules to check: 2414. Percentage nodes done: 0.841205\n",
      "checked 9400 modules 509 were found significant.  Modules to check: 2314. Percentage nodes done: 0.848101\n",
      "checked 9500 modules 510 were found significant.  Modules to check: 2214. Percentage nodes done: 0.855553\n",
      "checked 9600 modules 510 were found significant.  Modules to check: 2114. Percentage nodes done: 0.862425\n",
      "checked 9700 modules 510 were found significant.  Modules to check: 2014. Percentage nodes done: 0.869398\n",
      "checked 9800 modules 512 were found significant.  Modules to check: 1914. Percentage nodes done: 0.8763\n",
      "checked 9900 modules 513 were found significant.  Modules to check: 1814. Percentage nodes done: 0.883656\n",
      "checked 10000 modules 517 were found significant.  Modules to check: 1714. Percentage nodes done: 0.89069\n",
      "checked 10100 modules 520 were found significant.  Modules to check: 1614. Percentage nodes done: 0.897897\n",
      "checked 10200 modules 520 were found significant.  Modules to check: 1514. Percentage nodes done: 0.905271\n",
      "checked 10300 modules 523 were found significant.  Modules to check: 1414. Percentage nodes done: 0.912071\n",
      "checked 10400 modules 525 were found significant.  Modules to check: 1314. Percentage nodes done: 0.918076\n",
      "checked 10500 modules 527 were found significant.  Modules to check: 1214. Percentage nodes done: 0.9242\n",
      "checked 10600 modules 528 were found significant.  Modules to check: 1114. Percentage nodes done: 0.931383\n",
      "checked 10700 modules 532 were found significant.  Modules to check: 1014. Percentage nodes done: 0.93798\n",
      "checked 10800 modules 534 were found significant.  Modules to check: 914. Percentage nodes done: 0.943751\n",
      "checked 10900 modules 535 were found significant.  Modules to check: 814. Percentage nodes done: 0.950372\n",
      "checked 11000 modules 535 were found significant.  Modules to check: 714. Percentage nodes done: 0.958009\n",
      "checked 11100 modules 535 were found significant.  Modules to check: 614. Percentage nodes done: 0.964301\n",
      "checked 11200 modules 535 were found significant.  Modules to check: 514. Percentage nodes done: 0.971131\n",
      "checked 11300 modules 535 were found significant.  Modules to check: 414. Percentage nodes done: 0.977524\n",
      "checked 11400 modules 535 were found significant.  Modules to check: 314. Percentage nodes done: 0.983116\n",
      "checked 11500 modules 535 were found significant.  Modules to check: 214. Percentage nodes done: 0.988092\n",
      "checked 11600 modules 535 were found significant.  Modules to check: 114. Percentage nodes done: 0.99366\n",
      "checked 11700 modules 537 were found significant.  Modules to check: 14. Percentage nodes done: 0.999055\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11177\n",
      "iteration: 0 number of modules: 5175\n",
      "iteration: 20 number of modules: 3747\n",
      "iteration: 40 number of modules: 3725\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1018\n",
      "iteration: 0 number of modules: 359\n",
      "iteration: 20 number of modules: 137\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 257 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12521\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11342\n",
      "checked 0 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 20\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 241 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #5\n",
      "iteration: 0 number of modules: 12901\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11712. Percentage nodes done: 0\n",
      "checked 100 modules 4 were found significant.  Modules to check: 11612. Percentage nodes done: 0.0151433\n",
      "checked 200 modules 9 were found significant.  Modules to check: 11512. Percentage nodes done: 0.027356\n",
      "checked 300 modules 16 were found significant.  Modules to check: 11412. Percentage nodes done: 0.0379778\n",
      "checked 400 modules 28 were found significant.  Modules to check: 11312. Percentage nodes done: 0.0510816\n",
      "checked 500 modules 34 were found significant.  Modules to check: 11212. Percentage nodes done: 0.0632764\n",
      "checked 600 modules 39 were found significant.  Modules to check: 11112. Percentage nodes done: 0.0753396\n",
      "checked 700 modules 46 were found significant.  Modules to check: 11012. Percentage nodes done: 0.0867568\n",
      "checked 800 modules 52 were found significant.  Modules to check: 10912. Percentage nodes done: 0.0989336\n",
      "checked 900 modules 64 were found significant.  Modules to check: 10812. Percentage nodes done: 0.109681\n",
      "checked 1000 modules 65 were found significant.  Modules to check: 10712. Percentage nodes done: 0.119818\n",
      "checked 1100 modules 76 were found significant.  Modules to check: 10612. Percentage nodes done: 0.13129\n",
      "checked 1200 modules 89 were found significant.  Modules to check: 10512. Percentage nodes done: 0.14166\n",
      "checked 1300 modules 97 were found significant.  Modules to check: 10412. Percentage nodes done: 0.149938\n",
      "checked 1400 modules 105 were found significant.  Modules to check: 10312. Percentage nodes done: 0.160147\n",
      "checked 1500 modules 111 were found significant.  Modules to check: 10212. Percentage nodes done: 0.169668\n",
      "checked 1600 modules 119 were found significant.  Modules to check: 10112. Percentage nodes done: 0.178573\n",
      "checked 1700 modules 124 were found significant.  Modules to check: 10012. Percentage nodes done: 0.188794\n",
      "checked 1800 modules 135 were found significant.  Modules to check: 9912. Percentage nodes done: 0.197795\n",
      "checked 1900 modules 147 were found significant.  Modules to check: 9812. Percentage nodes done: 0.210415\n",
      "checked 2000 modules 155 were found significant.  Modules to check: 9712. Percentage nodes done: 0.22005\n",
      "checked 2100 modules 156 were found significant.  Modules to check: 9612. Percentage nodes done: 0.230588\n",
      "checked 2200 modules 161 were found significant.  Modules to check: 9512. Percentage nodes done: 0.240002\n",
      "checked 2300 modules 167 were found significant.  Modules to check: 9412. Percentage nodes done: 0.249218\n",
      "checked 2400 modules 177 were found significant.  Modules to check: 9312. Percentage nodes done: 0.259194\n",
      "checked 2500 modules 184 were found significant.  Modules to check: 9212. Percentage nodes done: 0.269361\n",
      "checked 2600 modules 196 were found significant.  Modules to check: 9112. Percentage nodes done: 0.279822\n",
      "checked 2700 modules 197 were found significant.  Modules to check: 9012. Percentage nodes done: 0.288775\n",
      "checked 2800 modules 206 were found significant.  Modules to check: 8912. Percentage nodes done: 0.29899\n",
      "checked 2900 modules 214 were found significant.  Modules to check: 8812. Percentage nodes done: 0.309911\n",
      "checked 3000 modules 221 were found significant.  Modules to check: 8712. Percentage nodes done: 0.320359\n",
      "checked 3100 modules 226 were found significant.  Modules to check: 8612. Percentage nodes done: 0.330269\n",
      "checked 3200 modules 232 were found significant.  Modules to check: 8512. Percentage nodes done: 0.340508\n",
      "checked 3300 modules 234 were found significant.  Modules to check: 8412. Percentage nodes done: 0.34881\n",
      "checked 3400 modules 241 were found significant.  Modules to check: 8312. Percentage nodes done: 0.3593\n",
      "checked 3500 modules 250 were found significant.  Modules to check: 8212. Percentage nodes done: 0.368516\n",
      "checked 3600 modules 257 were found significant.  Modules to check: 8112. Percentage nodes done: 0.376967\n",
      "checked 3700 modules 263 were found significant.  Modules to check: 8012. Percentage nodes done: 0.385489\n",
      "checked 3800 modules 267 were found significant.  Modules to check: 7912. Percentage nodes done: 0.395136\n",
      "checked 3900 modules 272 were found significant.  Modules to check: 7812. Percentage nodes done: 0.403868\n",
      "checked 4000 modules 278 were found significant.  Modules to check: 7712. Percentage nodes done: 0.413186\n",
      "checked 4100 modules 284 were found significant.  Modules to check: 7612. Percentage nodes done: 0.423049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 4200 modules 291 were found significant.  Modules to check: 7512. Percentage nodes done: 0.433072\n",
      "checked 4300 modules 295 were found significant.  Modules to check: 7412. Percentage nodes done: 0.442229\n",
      "checked 4400 modules 300 were found significant.  Modules to check: 7312. Percentage nodes done: 0.450052\n",
      "checked 4500 modules 306 were found significant.  Modules to check: 7212. Percentage nodes done: 0.458\n",
      "checked 4600 modules 316 were found significant.  Modules to check: 7112. Percentage nodes done: 0.466804\n",
      "checked 4700 modules 316 were found significant.  Modules to check: 7012. Percentage nodes done: 0.476295\n",
      "checked 4800 modules 323 were found significant.  Modules to check: 6912. Percentage nodes done: 0.484561\n",
      "checked 4900 modules 328 were found significant.  Modules to check: 6812. Percentage nodes done: 0.494369\n",
      "checked 5000 modules 332 were found significant.  Modules to check: 6712. Percentage nodes done: 0.503681\n",
      "checked 5100 modules 334 were found significant.  Modules to check: 6612. Percentage nodes done: 0.51224\n",
      "checked 5200 modules 342 were found significant.  Modules to check: 6512. Percentage nodes done: 0.520684\n",
      "checked 5300 modules 346 were found significant.  Modules to check: 6412. Percentage nodes done: 0.52895\n",
      "checked 5400 modules 355 were found significant.  Modules to check: 6312. Percentage nodes done: 0.536874\n",
      "checked 5500 modules 362 were found significant.  Modules to check: 6212. Percentage nodes done: 0.545002\n",
      "checked 5600 modules 368 were found significant.  Modules to check: 6112. Percentage nodes done: 0.553973\n",
      "checked 5700 modules 372 were found significant.  Modules to check: 6012. Percentage nodes done: 0.561557\n",
      "checked 5800 modules 374 were found significant.  Modules to check: 5912. Percentage nodes done: 0.570085\n",
      "checked 5900 modules 382 were found significant.  Modules to check: 5812. Percentage nodes done: 0.578907\n",
      "checked 6000 modules 386 were found significant.  Modules to check: 5712. Percentage nodes done: 0.588052\n",
      "checked 6100 modules 390 were found significant.  Modules to check: 5612. Percentage nodes done: 0.59609\n",
      "checked 6200 modules 392 were found significant.  Modules to check: 5512. Percentage nodes done: 0.604367\n",
      "checked 6300 modules 393 were found significant.  Modules to check: 5412. Percentage nodes done: 0.612154\n",
      "checked 6400 modules 394 were found significant.  Modules to check: 5312. Percentage nodes done: 0.620617\n",
      "checked 6500 modules 401 were found significant.  Modules to check: 5212. Percentage nodes done: 0.628727\n",
      "checked 6600 modules 408 were found significant.  Modules to check: 5112. Percentage nodes done: 0.637985\n",
      "checked 6700 modules 412 were found significant.  Modules to check: 5012. Percentage nodes done: 0.645186\n",
      "checked 6800 modules 417 were found significant.  Modules to check: 4912. Percentage nodes done: 0.654623\n",
      "checked 6900 modules 421 were found significant.  Modules to check: 4812. Percentage nodes done: 0.662189\n",
      "checked 7000 modules 424 were found significant.  Modules to check: 4712. Percentage nodes done: 0.670251\n",
      "checked 7100 modules 431 were found significant.  Modules to check: 4612. Percentage nodes done: 0.677595\n",
      "checked 7200 modules 437 were found significant.  Modules to check: 4512. Percentage nodes done: 0.684814\n",
      "checked 7300 modules 438 were found significant.  Modules to check: 4412. Percentage nodes done: 0.692858\n",
      "checked 7400 modules 442 were found significant.  Modules to check: 4312. Percentage nodes done: 0.700938\n",
      "checked 7500 modules 442 were found significant.  Modules to check: 4212. Percentage nodes done: 0.707194\n",
      "checked 7600 modules 444 were found significant.  Modules to check: 4112. Percentage nodes done: 0.715567\n",
      "checked 7700 modules 446 were found significant.  Modules to check: 4012. Percentage nodes done: 0.723635\n",
      "checked 7800 modules 447 were found significant.  Modules to check: 3912. Percentage nodes done: 0.73165\n",
      "checked 7900 modules 450 were found significant.  Modules to check: 3812. Percentage nodes done: 0.739945\n",
      "checked 8000 modules 456 were found significant.  Modules to check: 3712. Percentage nodes done: 0.747905\n",
      "checked 8100 modules 458 were found significant.  Modules to check: 3612. Percentage nodes done: 0.754717\n",
      "checked 8200 modules 462 were found significant.  Modules to check: 3512. Percentage nodes done: 0.76062\n",
      "checked 8300 modules 464 were found significant.  Modules to check: 3412. Percentage nodes done: 0.768084\n",
      "checked 8400 modules 468 were found significant.  Modules to check: 3312. Percentage nodes done: 0.775339\n",
      "checked 8500 modules 476 were found significant.  Modules to check: 3212. Percentage nodes done: 0.783868\n",
      "checked 8600 modules 480 were found significant.  Modules to check: 3112. Percentage nodes done: 0.791631\n",
      "checked 8700 modules 483 were found significant.  Modules to check: 3012. Percentage nodes done: 0.79797\n",
      "checked 8800 modules 488 were found significant.  Modules to check: 2912. Percentage nodes done: 0.805231\n",
      "checked 8900 modules 493 were found significant.  Modules to check: 2812. Percentage nodes done: 0.812473\n",
      "checked 9000 modules 498 were found significant.  Modules to check: 2712. Percentage nodes done: 0.820577\n",
      "checked 9100 modules 499 were found significant.  Modules to check: 2612. Percentage nodes done: 0.827491\n",
      "checked 9200 modules 502 were found significant.  Modules to check: 2512. Percentage nodes done: 0.834387\n",
      "checked 9300 modules 506 were found significant.  Modules to check: 2412. Percentage nodes done: 0.841965\n",
      "checked 9400 modules 510 were found significant.  Modules to check: 2312. Percentage nodes done: 0.849285\n",
      "checked 9500 modules 512 were found significant.  Modules to check: 2212. Percentage nodes done: 0.856701\n",
      "checked 9600 modules 512 were found significant.  Modules to check: 2112. Percentage nodes done: 0.863226\n",
      "checked 9700 modules 512 were found significant.  Modules to check: 2012. Percentage nodes done: 0.869901\n",
      "checked 9800 modules 515 were found significant.  Modules to check: 1912. Percentage nodes done: 0.876814\n",
      "checked 9900 modules 518 were found significant.  Modules to check: 1812. Percentage nodes done: 0.884284\n",
      "checked 10000 modules 522 were found significant.  Modules to check: 1712. Percentage nodes done: 0.891892\n",
      "checked 10100 modules 525 were found significant.  Modules to check: 1612. Percentage nodes done: 0.89868\n",
      "checked 10200 modules 526 were found significant.  Modules to check: 1512. Percentage nodes done: 0.905917\n",
      "checked 10300 modules 527 were found significant.  Modules to check: 1412. Percentage nodes done: 0.913028\n",
      "checked 10400 modules 531 were found significant.  Modules to check: 1312. Percentage nodes done: 0.91923\n",
      "checked 10500 modules 533 were found significant.  Modules to check: 1212. Percentage nodes done: 0.925462\n",
      "checked 10600 modules 534 were found significant.  Modules to check: 1112. Percentage nodes done: 0.932435\n",
      "checked 10700 modules 535 were found significant.  Modules to check: 1012. Percentage nodes done: 0.938996\n",
      "checked 10800 modules 536 were found significant.  Modules to check: 912. Percentage nodes done: 0.944666\n",
      "checked 10900 modules 539 were found significant.  Modules to check: 812. Percentage nodes done: 0.950587\n",
      "checked 11000 modules 539 were found significant.  Modules to check: 712. Percentage nodes done: 0.957937\n",
      "checked 11100 modules 539 were found significant.  Modules to check: 612. Percentage nodes done: 0.963864\n",
      "checked 11200 modules 540 were found significant.  Modules to check: 512. Percentage nodes done: 0.970114\n",
      "checked 11300 modules 540 were found significant.  Modules to check: 412. Percentage nodes done: 0.976603\n",
      "checked 11400 modules 540 were found significant.  Modules to check: 312. Percentage nodes done: 0.982261\n",
      "checked 11500 modules 542 were found significant.  Modules to check: 212. Percentage nodes done: 0.987536\n",
      "checked 11600 modules 542 were found significant.  Modules to check: 112. Percentage nodes done: 0.993654\n",
      "checked 11700 modules 543 were found significant.  Modules to check: 12. Percentage nodes done: 0.99927\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11168\n",
      "iteration: 0 number of modules: 4834\n",
      "iteration: 20 number of modules: 3374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 40 number of modules: 3359\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 965\n",
      "iteration: 0 number of modules: 302\n",
      "iteration: 20 number of modules: 118\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 262 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12547\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11363\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 22\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 245 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #6\n",
      "iteration: 0 number of modules: 12894\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11687. Percentage nodes done: 0\n",
      "checked 100 modules 4 were found significant.  Modules to check: 11587. Percentage nodes done: 0.0153107\n",
      "checked 200 modules 12 were found significant.  Modules to check: 11487. Percentage nodes done: 0.0284804\n",
      "checked 300 modules 17 were found significant.  Modules to check: 11387. Percentage nodes done: 0.0407887\n",
      "checked 400 modules 32 were found significant.  Modules to check: 11287. Percentage nodes done: 0.0564583\n",
      "checked 500 modules 38 were found significant.  Modules to check: 11187. Percentage nodes done: 0.0685095\n",
      "checked 600 modules 45 were found significant.  Modules to check: 11087. Percentage nodes done: 0.079849\n",
      "checked 700 modules 51 were found significant.  Modules to check: 10987. Percentage nodes done: 0.0909972\n",
      "checked 800 modules 58 were found significant.  Modules to check: 10887. Percentage nodes done: 0.10199\n",
      "checked 900 modules 68 were found significant.  Modules to check: 10787. Percentage nodes done: 0.113592\n",
      "checked 1000 modules 76 were found significant.  Modules to check: 10687. Percentage nodes done: 0.124687\n",
      "checked 1100 modules 90 were found significant.  Modules to check: 10587. Percentage nodes done: 0.136523\n",
      "checked 1200 modules 99 were found significant.  Modules to check: 10487. Percentage nodes done: 0.146941\n",
      "checked 1300 modules 103 were found significant.  Modules to check: 10387. Percentage nodes done: 0.15544\n",
      "checked 1400 modules 111 were found significant.  Modules to check: 10287. Percentage nodes done: 0.165278\n",
      "checked 1500 modules 120 were found significant.  Modules to check: 10187. Percentage nodes done: 0.174973\n",
      "checked 1600 modules 129 were found significant.  Modules to check: 10087. Percentage nodes done: 0.183974\n",
      "checked 1700 modules 132 were found significant.  Modules to check: 9987. Percentage nodes done: 0.193842\n",
      "checked 1800 modules 146 were found significant.  Modules to check: 9887. Percentage nodes done: 0.203232\n",
      "checked 1900 modules 154 were found significant.  Modules to check: 9787. Percentage nodes done: 0.213082\n",
      "checked 2000 modules 161 were found significant.  Modules to check: 9687. Percentage nodes done: 0.22249\n",
      "checked 2100 modules 166 were found significant.  Modules to check: 9587. Percentage nodes done: 0.23356\n",
      "checked 2200 modules 172 were found significant.  Modules to check: 9487. Percentage nodes done: 0.243189\n",
      "checked 2300 modules 178 were found significant.  Modules to check: 9387. Percentage nodes done: 0.252777\n",
      "checked 2400 modules 190 were found significant.  Modules to check: 9287. Percentage nodes done: 0.262561\n",
      "checked 2500 modules 198 were found significant.  Modules to check: 9187. Percentage nodes done: 0.273422\n",
      "checked 2600 modules 201 were found significant.  Modules to check: 9087. Percentage nodes done: 0.282668\n",
      "checked 2700 modules 203 were found significant.  Modules to check: 8987. Percentage nodes done: 0.292118\n",
      "checked 2800 modules 213 were found significant.  Modules to check: 8887. Percentage nodes done: 0.301813\n",
      "checked 2900 modules 219 were found significant.  Modules to check: 8787. Percentage nodes done: 0.311735\n",
      "checked 3000 modules 227 were found significant.  Modules to check: 8687. Percentage nodes done: 0.32372\n",
      "checked 3100 modules 230 were found significant.  Modules to check: 8587. Percentage nodes done: 0.332476\n",
      "checked 3200 modules 232 were found significant.  Modules to check: 8487. Percentage nodes done: 0.340783\n",
      "checked 3300 modules 233 were found significant.  Modules to check: 8387. Percentage nodes done: 0.349581\n",
      "checked 3400 modules 243 were found significant.  Modules to check: 8287. Percentage nodes done: 0.35982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 3500 modules 251 were found significant.  Modules to check: 8187. Percentage nodes done: 0.36802\n",
      "checked 3600 modules 254 were found significant.  Modules to check: 8087. Percentage nodes done: 0.376638\n",
      "checked 3700 modules 256 were found significant.  Modules to check: 7987. Percentage nodes done: 0.385155\n",
      "checked 3800 modules 264 were found significant.  Modules to check: 7887. Percentage nodes done: 0.394156\n",
      "checked 3900 modules 268 were found significant.  Modules to check: 7787. Percentage nodes done: 0.402786\n",
      "checked 4000 modules 274 were found significant.  Modules to check: 7687. Percentage nodes done: 0.412546\n",
      "checked 4100 modules 281 were found significant.  Modules to check: 7587. Percentage nodes done: 0.422857\n",
      "checked 4200 modules 285 were found significant.  Modules to check: 7487. Percentage nodes done: 0.431404\n",
      "checked 4300 modules 291 were found significant.  Modules to check: 7387. Percentage nodes done: 0.440542\n",
      "checked 4400 modules 293 were found significant.  Modules to check: 7287. Percentage nodes done: 0.447659\n",
      "checked 4500 modules 300 were found significant.  Modules to check: 7187. Percentage nodes done: 0.455919\n",
      "checked 4600 modules 305 were found significant.  Modules to check: 7087. Percentage nodes done: 0.465937\n",
      "checked 4700 modules 308 were found significant.  Modules to check: 6987. Percentage nodes done: 0.476074\n",
      "checked 4800 modules 316 were found significant.  Modules to check: 6887. Percentage nodes done: 0.485398\n",
      "checked 4900 modules 320 were found significant.  Modules to check: 6787. Percentage nodes done: 0.495601\n",
      "checked 5000 modules 324 were found significant.  Modules to check: 6687. Percentage nodes done: 0.504333\n",
      "checked 5100 modules 332 were found significant.  Modules to check: 6587. Percentage nodes done: 0.512491\n",
      "checked 5200 modules 338 were found significant.  Modules to check: 6487. Percentage nodes done: 0.520983\n",
      "checked 5300 modules 342 were found significant.  Modules to check: 6387. Percentage nodes done: 0.528579\n",
      "checked 5400 modules 346 were found significant.  Modules to check: 6287. Percentage nodes done: 0.536677\n",
      "checked 5500 modules 352 were found significant.  Modules to check: 6187. Percentage nodes done: 0.544601\n",
      "checked 5600 modules 359 were found significant.  Modules to check: 6087. Percentage nodes done: 0.552227\n",
      "checked 5700 modules 364 were found significant.  Modules to check: 5987. Percentage nodes done: 0.560983\n",
      "checked 5800 modules 371 were found significant.  Modules to check: 5887. Percentage nodes done: 0.569739\n",
      "checked 5900 modules 376 were found significant.  Modules to check: 5787. Percentage nodes done: 0.578183\n",
      "checked 6000 modules 381 were found significant.  Modules to check: 5687. Percentage nodes done: 0.585689\n",
      "checked 6100 modules 384 were found significant.  Modules to check: 5587. Percentage nodes done: 0.594636\n",
      "checked 6200 modules 387 were found significant.  Modules to check: 5487. Percentage nodes done: 0.601975\n",
      "checked 6300 modules 390 were found significant.  Modules to check: 5387. Percentage nodes done: 0.610491\n",
      "checked 6400 modules 394 were found significant.  Modules to check: 5287. Percentage nodes done: 0.618721\n",
      "checked 6500 modules 401 were found significant.  Modules to check: 5187. Percentage nodes done: 0.627273\n",
      "checked 6600 modules 408 were found significant.  Modules to check: 5087. Percentage nodes done: 0.636454\n",
      "checked 6700 modules 411 were found significant.  Modules to check: 4987. Percentage nodes done: 0.644564\n",
      "checked 6800 modules 417 were found significant.  Modules to check: 4887. Percentage nodes done: 0.65369\n",
      "checked 6900 modules 419 were found significant.  Modules to check: 4787. Percentage nodes done: 0.661095\n",
      "checked 7000 modules 427 were found significant.  Modules to check: 4687. Percentage nodes done: 0.669294\n",
      "checked 7100 modules 427 were found significant.  Modules to check: 4587. Percentage nodes done: 0.676932\n",
      "checked 7200 modules 433 were found significant.  Modules to check: 4487. Percentage nodes done: 0.684545\n",
      "checked 7300 modules 439 were found significant.  Modules to check: 4387. Percentage nodes done: 0.692769\n",
      "checked 7400 modules 442 were found significant.  Modules to check: 4287. Percentage nodes done: 0.700215\n",
      "checked 7500 modules 443 were found significant.  Modules to check: 4187. Percentage nodes done: 0.708032\n",
      "checked 7600 modules 446 were found significant.  Modules to check: 4087. Percentage nodes done: 0.716207\n",
      "checked 7700 modules 448 were found significant.  Modules to check: 3987. Percentage nodes done: 0.724072\n",
      "checked 7800 modules 449 were found significant.  Modules to check: 3887. Percentage nodes done: 0.73287\n",
      "checked 7900 modules 451 were found significant.  Modules to check: 3787. Percentage nodes done: 0.740962\n",
      "checked 8000 modules 455 were found significant.  Modules to check: 3687. Percentage nodes done: 0.748264\n",
      "checked 8100 modules 457 were found significant.  Modules to check: 3587. Percentage nodes done: 0.75461\n",
      "checked 8200 modules 460 were found significant.  Modules to check: 3487. Percentage nodes done: 0.762127\n",
      "checked 8300 modules 460 were found significant.  Modules to check: 3387. Percentage nodes done: 0.770016\n",
      "checked 8400 modules 467 were found significant.  Modules to check: 3287. Percentage nodes done: 0.777755\n",
      "checked 8500 modules 472 were found significant.  Modules to check: 3187. Percentage nodes done: 0.786798\n",
      "checked 8600 modules 472 were found significant.  Modules to check: 3087. Percentage nodes done: 0.793646\n",
      "checked 8700 modules 478 were found significant.  Modules to check: 2987. Percentage nodes done: 0.80038\n",
      "checked 8800 modules 486 were found significant.  Modules to check: 2887. Percentage nodes done: 0.808102\n",
      "checked 8900 modules 490 were found significant.  Modules to check: 2787. Percentage nodes done: 0.815637\n",
      "checked 9000 modules 492 were found significant.  Modules to check: 2687. Percentage nodes done: 0.822838\n",
      "checked 9100 modules 492 were found significant.  Modules to check: 2587. Percentage nodes done: 0.829441\n",
      "checked 9200 modules 495 were found significant.  Modules to check: 2487. Percentage nodes done: 0.836648\n",
      "checked 9300 modules 497 were found significant.  Modules to check: 2387. Percentage nodes done: 0.843687\n",
      "checked 9400 modules 499 were found significant.  Modules to check: 2287. Percentage nodes done: 0.850816\n",
      "checked 9500 modules 501 were found significant.  Modules to check: 2187. Percentage nodes done: 0.857718\n",
      "checked 9600 modules 502 were found significant.  Modules to check: 2087. Percentage nodes done: 0.863752\n",
      "checked 9700 modules 504 were found significant.  Modules to check: 1987. Percentage nodes done: 0.8706\n",
      "checked 9800 modules 505 were found significant.  Modules to check: 1887. Percentage nodes done: 0.877574\n",
      "checked 9900 modules 509 were found significant.  Modules to check: 1787. Percentage nodes done: 0.885008\n",
      "checked 10000 modules 511 were found significant.  Modules to check: 1687. Percentage nodes done: 0.892257\n",
      "checked 10100 modules 517 were found significant.  Modules to check: 1587. Percentage nodes done: 0.899757\n",
      "checked 10200 modules 518 were found significant.  Modules to check: 1487. Percentage nodes done: 0.907011\n",
      "checked 10300 modules 520 were found significant.  Modules to check: 1387. Percentage nodes done: 0.913991\n",
      "checked 10400 modules 520 were found significant.  Modules to check: 1287. Percentage nodes done: 0.920438\n",
      "checked 10500 modules 522 were found significant.  Modules to check: 1187. Percentage nodes done: 0.927077\n",
      "checked 10600 modules 525 were found significant.  Modules to check: 1087. Percentage nodes done: 0.933446\n",
      "checked 10700 modules 526 were found significant.  Modules to check: 987. Percentage nodes done: 0.940169\n",
      "checked 10800 modules 527 were found significant.  Modules to check: 887. Percentage nodes done: 0.946185\n",
      "checked 10900 modules 527 were found significant.  Modules to check: 787. Percentage nodes done: 0.95286\n",
      "checked 11000 modules 528 were found significant.  Modules to check: 687. Percentage nodes done: 0.959421\n",
      "checked 11100 modules 529 were found significant.  Modules to check: 587. Percentage nodes done: 0.965395\n",
      "checked 11200 modules 529 were found significant.  Modules to check: 487. Percentage nodes done: 0.971466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 11300 modules 530 were found significant.  Modules to check: 387. Percentage nodes done: 0.97811\n",
      "checked 11400 modules 530 were found significant.  Modules to check: 287. Percentage nodes done: 0.983385\n",
      "checked 11500 modules 530 were found significant.  Modules to check: 187. Percentage nodes done: 0.989097\n",
      "checked 11600 modules 531 were found significant.  Modules to check: 87. Percentage nodes done: 0.995191\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11155\n",
      "iteration: 0 number of modules: 4860\n",
      "iteration: 20 number of modules: 3426\n",
      "iteration: 40 number of modules: 3392\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1002\n",
      "iteration: 0 number of modules: 339\n",
      "iteration: 20 number of modules: 128\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 269 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12549\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11361\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 25\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 243 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #7\n",
      "iteration: 0 number of modules: 12968\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11700. Percentage nodes done: 0\n",
      "checked 100 modules 4 were found significant.  Modules to check: 11600. Percentage nodes done: 0.0157114\n",
      "checked 200 modules 12 were found significant.  Modules to check: 11500. Percentage nodes done: 0.0285461\n",
      "checked 300 modules 16 were found significant.  Modules to check: 11400. Percentage nodes done: 0.0398199\n",
      "checked 400 modules 31 were found significant.  Modules to check: 11300. Percentage nodes done: 0.0542454\n",
      "checked 500 modules 33 were found significant.  Modules to check: 11200. Percentage nodes done: 0.0663684\n",
      "checked 600 modules 40 were found significant.  Modules to check: 11100. Percentage nodes done: 0.077056\n",
      "checked 700 modules 48 were found significant.  Modules to check: 11000. Percentage nodes done: 0.0892209\n",
      "checked 800 modules 54 were found significant.  Modules to check: 10900. Percentage nodes done: 0.100004\n",
      "checked 900 modules 62 were found significant.  Modules to check: 10800. Percentage nodes done: 0.110895\n",
      "checked 1000 modules 65 were found significant.  Modules to check: 10700. Percentage nodes done: 0.120937\n",
      "checked 1100 modules 75 were found significant.  Modules to check: 10600. Percentage nodes done: 0.13169\n",
      "checked 1200 modules 85 were found significant.  Modules to check: 10500. Percentage nodes done: 0.144902\n",
      "checked 1300 modules 92 were found significant.  Modules to check: 10400. Percentage nodes done: 0.153723\n",
      "checked 1400 modules 101 were found significant.  Modules to check: 10300. Percentage nodes done: 0.163879\n",
      "checked 1500 modules 104 were found significant.  Modules to check: 10200. Percentage nodes done: 0.172868\n",
      "checked 1600 modules 113 were found significant.  Modules to check: 10100. Percentage nodes done: 0.182401\n",
      "checked 1700 modules 120 were found significant.  Modules to check: 10000. Percentage nodes done: 0.191881\n",
      "checked 1800 modules 129 were found significant.  Modules to check: 9900. Percentage nodes done: 0.201294\n",
      "checked 1900 modules 144 were found significant.  Modules to check: 9800. Percentage nodes done: 0.213441\n",
      "checked 2000 modules 154 were found significant.  Modules to check: 9700. Percentage nodes done: 0.223351\n",
      "checked 2100 modules 158 were found significant.  Modules to check: 9600. Percentage nodes done: 0.234541\n",
      "checked 2200 modules 165 were found significant.  Modules to check: 9500. Percentage nodes done: 0.243931\n",
      "checked 2300 modules 171 were found significant.  Modules to check: 9400. Percentage nodes done: 0.253255\n",
      "checked 2400 modules 185 were found significant.  Modules to check: 9300. Percentage nodes done: 0.26304\n",
      "checked 2500 modules 190 were found significant.  Modules to check: 9200. Percentage nodes done: 0.27332\n",
      "checked 2600 modules 201 were found significant.  Modules to check: 9100. Percentage nodes done: 0.283673\n",
      "checked 2700 modules 203 were found significant.  Modules to check: 9000. Percentage nodes done: 0.292369\n",
      "checked 2800 modules 208 were found significant.  Modules to check: 8900. Percentage nodes done: 0.302136\n",
      "checked 2900 modules 218 were found significant.  Modules to check: 8800. Percentage nodes done: 0.31314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 3000 modules 225 were found significant.  Modules to check: 8700. Percentage nodes done: 0.322889\n",
      "checked 3100 modules 232 were found significant.  Modules to check: 8600. Percentage nodes done: 0.33244\n",
      "checked 3200 modules 238 were found significant.  Modules to check: 8500. Percentage nodes done: 0.342703\n",
      "checked 3300 modules 243 were found significant.  Modules to check: 8400. Percentage nodes done: 0.351082\n",
      "checked 3400 modules 247 were found significant.  Modules to check: 8300. Percentage nodes done: 0.360843\n",
      "checked 3500 modules 258 were found significant.  Modules to check: 8200. Percentage nodes done: 0.370113\n",
      "checked 3600 modules 262 were found significant.  Modules to check: 8100. Percentage nodes done: 0.378492\n",
      "checked 3700 modules 267 were found significant.  Modules to check: 8000. Percentage nodes done: 0.386626\n",
      "checked 3800 modules 274 were found significant.  Modules to check: 7900. Percentage nodes done: 0.39525\n",
      "checked 3900 modules 280 were found significant.  Modules to check: 7800. Percentage nodes done: 0.404173\n",
      "checked 4000 modules 284 were found significant.  Modules to check: 7700. Percentage nodes done: 0.412983\n",
      "checked 4100 modules 290 were found significant.  Modules to check: 7600. Percentage nodes done: 0.42248\n",
      "checked 4200 modules 297 were found significant.  Modules to check: 7500. Percentage nodes done: 0.431446\n",
      "checked 4300 modules 304 were found significant.  Modules to check: 7400. Percentage nodes done: 0.440471\n",
      "checked 4400 modules 310 were found significant.  Modules to check: 7300. Percentage nodes done: 0.449484\n",
      "checked 4500 modules 311 were found significant.  Modules to check: 7200. Percentage nodes done: 0.457593\n",
      "checked 4600 modules 316 were found significant.  Modules to check: 7100. Percentage nodes done: 0.465129\n",
      "checked 4700 modules 321 were found significant.  Modules to check: 7000. Percentage nodes done: 0.473706\n",
      "checked 4800 modules 323 were found significant.  Modules to check: 6900. Percentage nodes done: 0.482414\n",
      "checked 4900 modules 328 were found significant.  Modules to check: 6800. Percentage nodes done: 0.493059\n",
      "checked 5000 modules 333 were found significant.  Modules to check: 6700. Percentage nodes done: 0.501731\n",
      "checked 5100 modules 337 were found significant.  Modules to check: 6600. Percentage nodes done: 0.510116\n",
      "checked 5200 modules 344 were found significant.  Modules to check: 6500. Percentage nodes done: 0.518621\n",
      "checked 5300 modules 349 were found significant.  Modules to check: 6400. Percentage nodes done: 0.52764\n",
      "checked 5400 modules 354 were found significant.  Modules to check: 6300. Percentage nodes done: 0.535236\n",
      "checked 5500 modules 360 were found significant.  Modules to check: 6200. Percentage nodes done: 0.542933\n",
      "checked 5600 modules 366 were found significant.  Modules to check: 6100. Percentage nodes done: 0.551192\n",
      "checked 5700 modules 370 were found significant.  Modules to check: 6000. Percentage nodes done: 0.559721\n",
      "checked 5800 modules 375 were found significant.  Modules to check: 5900. Percentage nodes done: 0.567908\n",
      "checked 5900 modules 382 were found significant.  Modules to check: 5800. Percentage nodes done: 0.576772\n",
      "checked 6000 modules 387 were found significant.  Modules to check: 5700. Percentage nodes done: 0.586826\n",
      "checked 6100 modules 388 were found significant.  Modules to check: 5600. Percentage nodes done: 0.596042\n",
      "checked 6200 modules 390 were found significant.  Modules to check: 5500. Percentage nodes done: 0.604056\n",
      "checked 6300 modules 391 were found significant.  Modules to check: 5400. Percentage nodes done: 0.61216\n",
      "checked 6400 modules 392 were found significant.  Modules to check: 5300. Percentage nodes done: 0.620551\n",
      "checked 6500 modules 401 were found significant.  Modules to check: 5200. Percentage nodes done: 0.628984\n",
      "checked 6600 modules 405 were found significant.  Modules to check: 5100. Percentage nodes done: 0.638565\n",
      "checked 6700 modules 408 were found significant.  Modules to check: 5000. Percentage nodes done: 0.646101\n",
      "checked 6800 modules 414 were found significant.  Modules to check: 4900. Percentage nodes done: 0.654755\n",
      "checked 6900 modules 416 were found significant.  Modules to check: 4800. Percentage nodes done: 0.661017\n",
      "checked 7000 modules 423 were found significant.  Modules to check: 4700. Percentage nodes done: 0.669264\n",
      "checked 7100 modules 424 were found significant.  Modules to check: 4600. Percentage nodes done: 0.67735\n",
      "checked 7200 modules 431 were found significant.  Modules to check: 4500. Percentage nodes done: 0.685113\n",
      "checked 7300 modules 434 were found significant.  Modules to check: 4400. Percentage nodes done: 0.693008\n",
      "checked 7400 modules 437 were found significant.  Modules to check: 4300. Percentage nodes done: 0.700508\n",
      "checked 7500 modules 437 were found significant.  Modules to check: 4200. Percentage nodes done: 0.707834\n",
      "checked 7600 modules 442 were found significant.  Modules to check: 4100. Percentage nodes done: 0.715693\n",
      "checked 7700 modules 443 were found significant.  Modules to check: 4000. Percentage nodes done: 0.723001\n",
      "checked 7800 modules 444 were found significant.  Modules to check: 3900. Percentage nodes done: 0.73141\n",
      "checked 7900 modules 448 were found significant.  Modules to check: 3800. Percentage nodes done: 0.739963\n",
      "checked 8000 modules 452 were found significant.  Modules to check: 3700. Percentage nodes done: 0.74717\n",
      "checked 8100 modules 454 were found significant.  Modules to check: 3600. Percentage nodes done: 0.752756\n",
      "checked 8200 modules 459 were found significant.  Modules to check: 3500. Percentage nodes done: 0.760112\n",
      "checked 8300 modules 461 were found significant.  Modules to check: 3400. Percentage nodes done: 0.768216\n",
      "checked 8400 modules 468 were found significant.  Modules to check: 3300. Percentage nodes done: 0.775811\n",
      "checked 8500 modules 471 were found significant.  Modules to check: 3200. Percentage nodes done: 0.784184\n",
      "checked 8600 modules 471 were found significant.  Modules to check: 3100. Percentage nodes done: 0.790871\n",
      "checked 8700 modules 475 were found significant.  Modules to check: 3000. Percentage nodes done: 0.798245\n",
      "checked 8800 modules 482 were found significant.  Modules to check: 2900. Percentage nodes done: 0.805733\n",
      "checked 8900 modules 488 were found significant.  Modules to check: 2800. Percentage nodes done: 0.813281\n",
      "checked 9000 modules 494 were found significant.  Modules to check: 2700. Percentage nodes done: 0.820601\n",
      "checked 9100 modules 494 were found significant.  Modules to check: 2600. Percentage nodes done: 0.826857\n",
      "checked 9200 modules 499 were found significant.  Modules to check: 2500. Percentage nodes done: 0.834255\n",
      "checked 9300 modules 502 were found significant.  Modules to check: 2400. Percentage nodes done: 0.841749\n",
      "checked 9400 modules 505 were found significant.  Modules to check: 2300. Percentage nodes done: 0.848388\n",
      "checked 9500 modules 506 were found significant.  Modules to check: 2200. Percentage nodes done: 0.855625\n",
      "checked 9600 modules 508 were found significant.  Modules to check: 2100. Percentage nodes done: 0.862197\n",
      "checked 9700 modules 510 were found significant.  Modules to check: 2000. Percentage nodes done: 0.868746\n",
      "checked 9800 modules 511 were found significant.  Modules to check: 1900. Percentage nodes done: 0.876575\n",
      "checked 9900 modules 513 were found significant.  Modules to check: 1800. Percentage nodes done: 0.883836\n",
      "checked 10000 modules 517 were found significant.  Modules to check: 1700. Percentage nodes done: 0.89115\n",
      "checked 10100 modules 522 were found significant.  Modules to check: 1600. Percentage nodes done: 0.898214\n",
      "checked 10200 modules 522 were found significant.  Modules to check: 1500. Percentage nodes done: 0.905145\n",
      "checked 10300 modules 523 were found significant.  Modules to check: 1400. Percentage nodes done: 0.912681\n",
      "checked 10400 modules 523 were found significant.  Modules to check: 1300. Percentage nodes done: 0.91905\n",
      "checked 10500 modules 525 were found significant.  Modules to check: 1200. Percentage nodes done: 0.925223\n",
      "checked 10600 modules 527 were found significant.  Modules to check: 1100. Percentage nodes done: 0.931772\n",
      "checked 10700 modules 530 were found significant.  Modules to check: 1000. Percentage nodes done: 0.938548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 10800 modules 530 were found significant.  Modules to check: 900. Percentage nodes done: 0.944253\n",
      "checked 10900 modules 531 were found significant.  Modules to check: 800. Percentage nodes done: 0.950216\n",
      "checked 11000 modules 531 were found significant.  Modules to check: 700. Percentage nodes done: 0.957291\n",
      "checked 11100 modules 531 were found significant.  Modules to check: 600. Percentage nodes done: 0.963434\n",
      "checked 11200 modules 533 were found significant.  Modules to check: 500. Percentage nodes done: 0.970395\n",
      "checked 11300 modules 534 were found significant.  Modules to check: 400. Percentage nodes done: 0.976783\n",
      "checked 11400 modules 535 were found significant.  Modules to check: 300. Percentage nodes done: 0.982925\n",
      "checked 11500 modules 537 were found significant.  Modules to check: 200. Percentage nodes done: 0.987979\n",
      "checked 11600 modules 537 were found significant.  Modules to check: 100. Percentage nodes done: 0.994504\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11161\n",
      "iteration: 0 number of modules: 4821\n",
      "iteration: 20 number of modules: 3441\n",
      "iteration: 40 number of modules: 3421\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1028\n",
      "iteration: 0 number of modules: 329\n",
      "iteration: 20 number of modules: 135\n",
      "iteration: 40 number of modules: 135\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 260 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12443\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11329\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 19\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 239 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #8\n",
      "iteration: 0 number of modules: 12930\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11732. Percentage nodes done: 0\n",
      "checked 100 modules 5 were found significant.  Modules to check: 11632. Percentage nodes done: 0.0145691\n",
      "checked 200 modules 13 were found significant.  Modules to check: 11532. Percentage nodes done: 0.0277387\n",
      "checked 300 modules 22 were found significant.  Modules to check: 11432. Percentage nodes done: 0.0389048\n",
      "checked 400 modules 34 were found significant.  Modules to check: 11332. Percentage nodes done: 0.0507467\n",
      "checked 500 modules 37 were found significant.  Modules to check: 11232. Percentage nodes done: 0.0606628\n",
      "checked 600 modules 42 were found significant.  Modules to check: 11132. Percentage nodes done: 0.072714\n",
      "checked 700 modules 48 were found significant.  Modules to check: 11032. Percentage nodes done: 0.0844363\n",
      "checked 800 modules 51 were found significant.  Modules to check: 10932. Percentage nodes done: 0.0952614\n",
      "checked 900 modules 60 were found significant.  Modules to check: 10832. Percentage nodes done: 0.105823\n",
      "checked 1000 modules 63 were found significant.  Modules to check: 10732. Percentage nodes done: 0.116021\n",
      "checked 1100 modules 75 were found significant.  Modules to check: 10632. Percentage nodes done: 0.126469\n",
      "checked 1200 modules 83 were found significant.  Modules to check: 10532. Percentage nodes done: 0.138114\n",
      "checked 1300 modules 93 were found significant.  Modules to check: 10432. Percentage nodes done: 0.14788\n",
      "checked 1400 modules 99 were found significant.  Modules to check: 10332. Percentage nodes done: 0.157437\n",
      "checked 1500 modules 100 were found significant.  Modules to check: 10232. Percentage nodes done: 0.167563\n",
      "checked 1600 modules 115 were found significant.  Modules to check: 10132. Percentage nodes done: 0.178657\n",
      "checked 1700 modules 122 were found significant.  Modules to check: 10032. Percentage nodes done: 0.188651\n",
      "checked 1800 modules 132 were found significant.  Modules to check: 9932. Percentage nodes done: 0.196928\n",
      "checked 1900 modules 143 were found significant.  Modules to check: 9832. Percentage nodes done: 0.212089\n",
      "checked 2000 modules 155 were found significant.  Modules to check: 9732. Percentage nodes done: 0.222622\n",
      "checked 2100 modules 161 were found significant.  Modules to check: 9632. Percentage nodes done: 0.233004\n",
      "checked 2200 modules 165 were found significant.  Modules to check: 9532. Percentage nodes done: 0.242221\n",
      "checked 2300 modules 166 were found significant.  Modules to check: 9432. Percentage nodes done: 0.250803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 2400 modules 173 were found significant.  Modules to check: 9332. Percentage nodes done: 0.260217\n",
      "checked 2500 modules 183 were found significant.  Modules to check: 9232. Percentage nodes done: 0.269941\n",
      "checked 2600 modules 193 were found significant.  Modules to check: 9132. Percentage nodes done: 0.279702\n",
      "checked 2700 modules 194 were found significant.  Modules to check: 9032. Percentage nodes done: 0.288589\n",
      "checked 2800 modules 199 were found significant.  Modules to check: 8932. Percentage nodes done: 0.29762\n",
      "checked 2900 modules 211 were found significant.  Modules to check: 8832. Percentage nodes done: 0.309259\n",
      "checked 3000 modules 216 were found significant.  Modules to check: 8732. Percentage nodes done: 0.319677\n",
      "checked 3100 modules 227 were found significant.  Modules to check: 8632. Percentage nodes done: 0.330634\n",
      "checked 3200 modules 231 were found significant.  Modules to check: 8532. Percentage nodes done: 0.339611\n",
      "checked 3300 modules 234 were found significant.  Modules to check: 8432. Percentage nodes done: 0.347859\n",
      "checked 3400 modules 241 were found significant.  Modules to check: 8332. Percentage nodes done: 0.357488\n",
      "checked 3500 modules 251 were found significant.  Modules to check: 8232. Percentage nodes done: 0.368044\n",
      "checked 3600 modules 257 were found significant.  Modules to check: 8132. Percentage nodes done: 0.376752\n",
      "checked 3700 modules 266 were found significant.  Modules to check: 8032. Percentage nodes done: 0.384951\n",
      "checked 3800 modules 270 were found significant.  Modules to check: 7932. Percentage nodes done: 0.394299\n",
      "checked 3900 modules 275 were found significant.  Modules to check: 7832. Percentage nodes done: 0.402947\n",
      "checked 4000 modules 280 were found significant.  Modules to check: 7732. Percentage nodes done: 0.411607\n",
      "checked 4100 modules 287 were found significant.  Modules to check: 7632. Percentage nodes done: 0.422672\n",
      "checked 4200 modules 291 were found significant.  Modules to check: 7532. Percentage nodes done: 0.430985\n",
      "checked 4300 modules 300 were found significant.  Modules to check: 7432. Percentage nodes done: 0.439149\n",
      "checked 4400 modules 305 were found significant.  Modules to check: 7332. Percentage nodes done: 0.448042\n",
      "checked 4500 modules 310 were found significant.  Modules to check: 7232. Percentage nodes done: 0.456613\n",
      "checked 4600 modules 318 were found significant.  Modules to check: 7132. Percentage nodes done: 0.464142\n",
      "checked 4700 modules 322 were found significant.  Modules to check: 7032. Percentage nodes done: 0.473508\n",
      "checked 4800 modules 325 were found significant.  Modules to check: 6932. Percentage nodes done: 0.483245\n",
      "checked 4900 modules 333 were found significant.  Modules to check: 6832. Percentage nodes done: 0.493089\n",
      "checked 5000 modules 337 were found significant.  Modules to check: 6732. Percentage nodes done: 0.502569\n",
      "checked 5100 modules 341 were found significant.  Modules to check: 6632. Percentage nodes done: 0.511378\n",
      "checked 5200 modules 345 were found significant.  Modules to check: 6532. Percentage nodes done: 0.519632\n",
      "checked 5300 modules 352 were found significant.  Modules to check: 6432. Percentage nodes done: 0.528119\n",
      "checked 5400 modules 358 were found significant.  Modules to check: 6332. Percentage nodes done: 0.535917\n",
      "checked 5500 modules 362 were found significant.  Modules to check: 6232. Percentage nodes done: 0.54444\n",
      "checked 5600 modules 367 were found significant.  Modules to check: 6132. Percentage nodes done: 0.552454\n",
      "checked 5700 modules 373 were found significant.  Modules to check: 6032. Percentage nodes done: 0.560361\n",
      "checked 5800 modules 376 were found significant.  Modules to check: 5932. Percentage nodes done: 0.56993\n",
      "checked 5900 modules 384 were found significant.  Modules to check: 5832. Percentage nodes done: 0.579822\n",
      "checked 6000 modules 387 were found significant.  Modules to check: 5732. Percentage nodes done: 0.587783\n",
      "checked 6100 modules 390 were found significant.  Modules to check: 5632. Percentage nodes done: 0.595294\n",
      "checked 6200 modules 394 were found significant.  Modules to check: 5532. Percentage nodes done: 0.603859\n",
      "checked 6300 modules 394 were found significant.  Modules to check: 5432. Percentage nodes done: 0.611436\n",
      "checked 6400 modules 396 were found significant.  Modules to check: 5332. Percentage nodes done: 0.620551\n",
      "checked 6500 modules 402 were found significant.  Modules to check: 5232. Percentage nodes done: 0.628529\n",
      "checked 6600 modules 409 were found significant.  Modules to check: 5132. Percentage nodes done: 0.637979\n",
      "checked 6700 modules 412 were found significant.  Modules to check: 5032. Percentage nodes done: 0.646053\n",
      "checked 6800 modules 420 were found significant.  Modules to check: 4932. Percentage nodes done: 0.654827\n",
      "checked 6900 modules 424 were found significant.  Modules to check: 4832. Percentage nodes done: 0.662458\n",
      "checked 7000 modules 428 were found significant.  Modules to check: 4732. Percentage nodes done: 0.670909\n",
      "checked 7100 modules 436 were found significant.  Modules to check: 4632. Percentage nodes done: 0.678887\n",
      "checked 7200 modules 442 were found significant.  Modules to check: 4532. Percentage nodes done: 0.686004\n",
      "checked 7300 modules 444 were found significant.  Modules to check: 4432. Percentage nodes done: 0.693546\n",
      "checked 7400 modules 448 were found significant.  Modules to check: 4332. Percentage nodes done: 0.701375\n",
      "checked 7500 modules 448 were found significant.  Modules to check: 4232. Percentage nodes done: 0.708313\n",
      "checked 7600 modules 449 were found significant.  Modules to check: 4132. Percentage nodes done: 0.716805\n",
      "checked 7700 modules 451 were found significant.  Modules to check: 4032. Percentage nodes done: 0.723617\n",
      "checked 7800 modules 453 were found significant.  Modules to check: 3932. Percentage nodes done: 0.7322\n",
      "checked 7900 modules 456 were found significant.  Modules to check: 3832. Percentage nodes done: 0.74031\n",
      "checked 8000 modules 462 were found significant.  Modules to check: 3732. Percentage nodes done: 0.74754\n",
      "checked 8100 modules 464 were found significant.  Modules to check: 3632. Percentage nodes done: 0.753862\n",
      "checked 8200 modules 468 were found significant.  Modules to check: 3532. Percentage nodes done: 0.760285\n",
      "checked 8300 modules 470 were found significant.  Modules to check: 3432. Percentage nodes done: 0.767971\n",
      "checked 8400 modules 475 were found significant.  Modules to check: 3332. Percentage nodes done: 0.775459\n",
      "checked 8500 modules 480 were found significant.  Modules to check: 3232. Percentage nodes done: 0.784472\n",
      "checked 8600 modules 480 were found significant.  Modules to check: 3132. Percentage nodes done: 0.791457\n",
      "checked 8700 modules 483 were found significant.  Modules to check: 3032. Percentage nodes done: 0.798389\n",
      "checked 8800 modules 487 were found significant.  Modules to check: 2932. Percentage nodes done: 0.806307\n",
      "checked 8900 modules 492 were found significant.  Modules to check: 2832. Percentage nodes done: 0.813508\n",
      "checked 9000 modules 495 were found significant.  Modules to check: 2732. Percentage nodes done: 0.820793\n",
      "checked 9100 modules 498 were found significant.  Modules to check: 2632. Percentage nodes done: 0.827832\n",
      "checked 9200 modules 504 were found significant.  Modules to check: 2532. Percentage nodes done: 0.834806\n",
      "checked 9300 modules 507 were found significant.  Modules to check: 2432. Percentage nodes done: 0.842024\n",
      "checked 9400 modules 512 were found significant.  Modules to check: 2332. Percentage nodes done: 0.849285\n",
      "checked 9500 modules 514 were found significant.  Modules to check: 2232. Percentage nodes done: 0.856336\n",
      "checked 9600 modules 514 were found significant.  Modules to check: 2132. Percentage nodes done: 0.862778\n",
      "checked 9700 modules 515 were found significant.  Modules to check: 2032. Percentage nodes done: 0.869614\n",
      "checked 9800 modules 517 were found significant.  Modules to check: 1932. Percentage nodes done: 0.877078\n",
      "checked 9900 modules 521 were found significant.  Modules to check: 1832. Percentage nodes done: 0.884195\n",
      "checked 10000 modules 524 were found significant.  Modules to check: 1732. Percentage nodes done: 0.891276\n",
      "checked 10100 modules 527 were found significant.  Modules to check: 1632. Percentage nodes done: 0.898004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 10200 modules 527 were found significant.  Modules to check: 1532. Percentage nodes done: 0.905097\n",
      "checked 10300 modules 528 were found significant.  Modules to check: 1432. Percentage nodes done: 0.912466\n",
      "checked 10400 modules 530 were found significant.  Modules to check: 1332. Percentage nodes done: 0.919033\n",
      "checked 10500 modules 534 were found significant.  Modules to check: 1232. Percentage nodes done: 0.92527\n",
      "checked 10600 modules 535 were found significant.  Modules to check: 1132. Percentage nodes done: 0.931634\n",
      "checked 10700 modules 539 were found significant.  Modules to check: 1032. Percentage nodes done: 0.938356\n",
      "checked 10800 modules 540 were found significant.  Modules to check: 932. Percentage nodes done: 0.944247\n",
      "checked 10900 modules 541 were found significant.  Modules to check: 832. Percentage nodes done: 0.950695\n",
      "checked 11000 modules 541 were found significant.  Modules to check: 732. Percentage nodes done: 0.958057\n",
      "checked 11100 modules 545 were found significant.  Modules to check: 632. Percentage nodes done: 0.963942\n",
      "checked 11200 modules 548 were found significant.  Modules to check: 532. Percentage nodes done: 0.970377\n",
      "checked 11300 modules 550 were found significant.  Modules to check: 432. Percentage nodes done: 0.976173\n",
      "checked 11400 modules 551 were found significant.  Modules to check: 332. Percentage nodes done: 0.982207\n",
      "checked 11500 modules 553 were found significant.  Modules to check: 232. Percentage nodes done: 0.987536\n",
      "checked 11600 modules 553 were found significant.  Modules to check: 132. Percentage nodes done: 0.992524\n",
      "checked 11700 modules 553 were found significant.  Modules to check: 32. Percentage nodes done: 0.998248\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11178\n",
      "iteration: 0 number of modules: 4847\n",
      "iteration: 20 number of modules: 3430\n",
      "iteration: 40 number of modules: 3404\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1025\n",
      "iteration: 0 number of modules: 322\n",
      "iteration: 20 number of modules: 120\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 265 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12504\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11348\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 17\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 247 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #9\n",
      "iteration: 0 number of modules: 12921\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11732. Percentage nodes done: 0\n",
      "checked 100 modules 6 were found significant.  Modules to check: 11632. Percentage nodes done: 0.0144674\n",
      "checked 200 modules 11 were found significant.  Modules to check: 11532. Percentage nodes done: 0.0275593\n",
      "checked 300 modules 15 were found significant.  Modules to check: 11432. Percentage nodes done: 0.0385818\n",
      "checked 400 modules 23 were found significant.  Modules to check: 11332. Percentage nodes done: 0.0534261\n",
      "checked 500 modules 29 were found significant.  Modules to check: 11232. Percentage nodes done: 0.0639761\n",
      "checked 600 modules 34 were found significant.  Modules to check: 11132. Percentage nodes done: 0.0760393\n",
      "checked 700 modules 38 were found significant.  Modules to check: 11032. Percentage nodes done: 0.0868884\n",
      "checked 800 modules 43 were found significant.  Modules to check: 10932. Percentage nodes done: 0.0989994\n",
      "checked 900 modules 54 were found significant.  Modules to check: 10832. Percentage nodes done: 0.109567\n",
      "checked 1000 modules 57 were found significant.  Modules to check: 10732. Percentage nodes done: 0.119412\n",
      "checked 1100 modules 67 were found significant.  Modules to check: 10632. Percentage nodes done: 0.131397\n",
      "checked 1200 modules 71 were found significant.  Modules to check: 10532. Percentage nodes done: 0.141152\n",
      "checked 1300 modules 79 were found significant.  Modules to check: 10432. Percentage nodes done: 0.151289\n",
      "checked 1400 modules 87 were found significant.  Modules to check: 10332. Percentage nodes done: 0.160452\n",
      "checked 1500 modules 89 were found significant.  Modules to check: 10232. Percentage nodes done: 0.171971\n",
      "checked 1600 modules 102 were found significant.  Modules to check: 10132. Percentage nodes done: 0.181767\n",
      "checked 1700 modules 107 were found significant.  Modules to check: 10032. Percentage nodes done: 0.191348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1800 modules 114 were found significant.  Modules to check: 9932. Percentage nodes done: 0.200182\n",
      "checked 1900 modules 122 were found significant.  Modules to check: 9832. Percentage nodes done: 0.212263\n",
      "checked 2000 modules 132 were found significant.  Modules to check: 9732. Percentage nodes done: 0.222992\n",
      "checked 2100 modules 139 were found significant.  Modules to check: 9632. Percentage nodes done: 0.23356\n",
      "checked 2200 modules 144 were found significant.  Modules to check: 9532. Percentage nodes done: 0.243124\n",
      "checked 2300 modules 147 were found significant.  Modules to check: 9432. Percentage nodes done: 0.251712\n",
      "checked 2400 modules 158 were found significant.  Modules to check: 9332. Percentage nodes done: 0.262023\n",
      "checked 2500 modules 165 were found significant.  Modules to check: 9232. Percentage nodes done: 0.271275\n",
      "checked 2600 modules 176 were found significant.  Modules to check: 9132. Percentage nodes done: 0.281879\n",
      "checked 2700 modules 183 were found significant.  Modules to check: 9032. Percentage nodes done: 0.290282\n",
      "checked 2800 modules 188 were found significant.  Modules to check: 8932. Percentage nodes done: 0.300371\n",
      "checked 2900 modules 194 were found significant.  Modules to check: 8832. Percentage nodes done: 0.310826\n",
      "checked 3000 modules 200 were found significant.  Modules to check: 8732. Percentage nodes done: 0.320539\n",
      "checked 3100 modules 211 were found significant.  Modules to check: 8632. Percentage nodes done: 0.330927\n",
      "checked 3200 modules 215 were found significant.  Modules to check: 8532. Percentage nodes done: 0.340012\n",
      "checked 3300 modules 223 were found significant.  Modules to check: 8432. Percentage nodes done: 0.348833\n",
      "checked 3400 modules 228 were found significant.  Modules to check: 8332. Percentage nodes done: 0.357882\n",
      "checked 3500 modules 238 were found significant.  Modules to check: 8232. Percentage nodes done: 0.367422\n",
      "checked 3600 modules 243 were found significant.  Modules to check: 8132. Percentage nodes done: 0.376309\n",
      "checked 3700 modules 249 were found significant.  Modules to check: 8032. Percentage nodes done: 0.384281\n",
      "checked 3800 modules 252 were found significant.  Modules to check: 7932. Percentage nodes done: 0.393103\n",
      "checked 3900 modules 256 were found significant.  Modules to check: 7832. Percentage nodes done: 0.402152\n",
      "checked 4000 modules 262 were found significant.  Modules to check: 7732. Percentage nodes done: 0.41095\n",
      "checked 4100 modules 269 were found significant.  Modules to check: 7632. Percentage nodes done: 0.420537\n",
      "checked 4200 modules 276 were found significant.  Modules to check: 7532. Percentage nodes done: 0.429221\n",
      "checked 4300 modules 282 were found significant.  Modules to check: 7432. Percentage nodes done: 0.438001\n",
      "checked 4400 modules 287 were found significant.  Modules to check: 7332. Percentage nodes done: 0.447492\n",
      "checked 4500 modules 290 were found significant.  Modules to check: 7232. Percentage nodes done: 0.455823\n",
      "checked 4600 modules 297 were found significant.  Modules to check: 7132. Percentage nodes done: 0.463574\n",
      "checked 4700 modules 301 were found significant.  Modules to check: 7032. Percentage nodes done: 0.47221\n",
      "checked 4800 modules 306 were found significant.  Modules to check: 6932. Percentage nodes done: 0.481696\n",
      "checked 4900 modules 313 were found significant.  Modules to check: 6832. Percentage nodes done: 0.490852\n",
      "checked 5000 modules 319 were found significant.  Modules to check: 6732. Percentage nodes done: 0.499931\n",
      "checked 5100 modules 324 were found significant.  Modules to check: 6632. Percentage nodes done: 0.508747\n",
      "checked 5200 modules 328 were found significant.  Modules to check: 6532. Percentage nodes done: 0.517018\n",
      "checked 5300 modules 334 were found significant.  Modules to check: 6432. Percentage nodes done: 0.525822\n",
      "checked 5400 modules 338 were found significant.  Modules to check: 6332. Percentage nodes done: 0.532861\n",
      "checked 5500 modules 346 were found significant.  Modules to check: 6232. Percentage nodes done: 0.541031\n",
      "checked 5600 modules 348 were found significant.  Modules to check: 6132. Percentage nodes done: 0.549135\n",
      "checked 5700 modules 356 were found significant.  Modules to check: 6032. Percentage nodes done: 0.557059\n",
      "checked 5800 modules 360 were found significant.  Modules to check: 5932. Percentage nodes done: 0.566054\n",
      "checked 5900 modules 366 were found significant.  Modules to check: 5832. Percentage nodes done: 0.575827\n",
      "checked 6000 modules 371 were found significant.  Modules to check: 5732. Percentage nodes done: 0.584326\n",
      "checked 6100 modules 375 were found significant.  Modules to check: 5632. Percentage nodes done: 0.591449\n",
      "checked 6200 modules 377 were found significant.  Modules to check: 5532. Percentage nodes done: 0.600073\n",
      "checked 6300 modules 377 were found significant.  Modules to check: 5432. Percentage nodes done: 0.607375\n",
      "checked 6400 modules 377 were found significant.  Modules to check: 5332. Percentage nodes done: 0.616155\n",
      "checked 6500 modules 378 were found significant.  Modules to check: 5232. Percentage nodes done: 0.624277\n",
      "checked 6600 modules 387 were found significant.  Modules to check: 5132. Percentage nodes done: 0.632955\n",
      "checked 6700 modules 390 were found significant.  Modules to check: 5032. Percentage nodes done: 0.642297\n",
      "checked 6800 modules 392 were found significant.  Modules to check: 4932. Percentage nodes done: 0.650999\n",
      "checked 6900 modules 401 were found significant.  Modules to check: 4832. Percentage nodes done: 0.658732\n",
      "checked 7000 modules 403 were found significant.  Modules to check: 4732. Percentage nodes done: 0.665795\n",
      "checked 7100 modules 407 were found significant.  Modules to check: 4632. Percentage nodes done: 0.673858\n",
      "checked 7200 modules 413 were found significant.  Modules to check: 4532. Percentage nodes done: 0.68226\n",
      "checked 7300 modules 418 were found significant.  Modules to check: 4432. Percentage nodes done: 0.689952\n",
      "checked 7400 modules 421 were found significant.  Modules to check: 4332. Percentage nodes done: 0.697416\n",
      "checked 7500 modules 428 were found significant.  Modules to check: 4232. Percentage nodes done: 0.704754\n",
      "checked 7600 modules 428 were found significant.  Modules to check: 4132. Percentage nodes done: 0.711626\n",
      "checked 7700 modules 431 were found significant.  Modules to check: 4032. Percentage nodes done: 0.71967\n",
      "checked 7800 modules 434 were found significant.  Modules to check: 3932. Percentage nodes done: 0.728276\n",
      "checked 7900 modules 438 were found significant.  Modules to check: 3832. Percentage nodes done: 0.73647\n",
      "checked 8000 modules 442 were found significant.  Modules to check: 3732. Percentage nodes done: 0.744101\n",
      "checked 8100 modules 446 were found significant.  Modules to check: 3632. Percentage nodes done: 0.751565\n",
      "checked 8200 modules 447 were found significant.  Modules to check: 3532. Percentage nodes done: 0.757768\n",
      "checked 8300 modules 450 were found significant.  Modules to check: 3432. Percentage nodes done: 0.76556\n",
      "checked 8400 modules 454 were found significant.  Modules to check: 3332. Percentage nodes done: 0.773186\n",
      "checked 8500 modules 457 were found significant.  Modules to check: 3232. Percentage nodes done: 0.780327\n",
      "checked 8600 modules 462 were found significant.  Modules to check: 3132. Percentage nodes done: 0.788257\n",
      "checked 8700 modules 464 were found significant.  Modules to check: 3032. Percentage nodes done: 0.795147\n",
      "checked 8800 modules 468 were found significant.  Modules to check: 2932. Percentage nodes done: 0.802055\n",
      "checked 8900 modules 473 were found significant.  Modules to check: 2832. Percentage nodes done: 0.809866\n",
      "checked 9000 modules 481 were found significant.  Modules to check: 2732. Percentage nodes done: 0.817455\n",
      "checked 9100 modules 484 were found significant.  Modules to check: 2632. Percentage nodes done: 0.824668\n",
      "checked 9200 modules 485 were found significant.  Modules to check: 2532. Percentage nodes done: 0.831373\n",
      "checked 9300 modules 487 were found significant.  Modules to check: 2432. Percentage nodes done: 0.839243\n",
      "checked 9400 modules 489 were found significant.  Modules to check: 2332. Percentage nodes done: 0.846265\n",
      "checked 9500 modules 490 were found significant.  Modules to check: 2232. Percentage nodes done: 0.853256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 9600 modules 490 were found significant.  Modules to check: 2132. Percentage nodes done: 0.86026\n",
      "checked 9700 modules 491 were found significant.  Modules to check: 2032. Percentage nodes done: 0.866994\n",
      "checked 9800 modules 494 were found significant.  Modules to check: 1932. Percentage nodes done: 0.874117\n",
      "checked 9900 modules 495 were found significant.  Modules to check: 1832. Percentage nodes done: 0.880839\n",
      "checked 10000 modules 500 were found significant.  Modules to check: 1732. Percentage nodes done: 0.889314\n",
      "checked 10100 modules 502 were found significant.  Modules to check: 1632. Percentage nodes done: 0.896246\n",
      "checked 10200 modules 503 were found significant.  Modules to check: 1532. Percentage nodes done: 0.903471\n",
      "checked 10300 modules 504 were found significant.  Modules to check: 1432. Percentage nodes done: 0.910659\n",
      "checked 10400 modules 508 were found significant.  Modules to check: 1332. Percentage nodes done: 0.917585\n",
      "checked 10500 modules 509 were found significant.  Modules to check: 1232. Percentage nodes done: 0.923775\n",
      "checked 10600 modules 513 were found significant.  Modules to check: 1132. Percentage nodes done: 0.929888\n",
      "checked 10700 modules 513 were found significant.  Modules to check: 1032. Percentage nodes done: 0.936592\n",
      "checked 10800 modules 518 were found significant.  Modules to check: 932. Percentage nodes done: 0.943171\n",
      "checked 10900 modules 520 were found significant.  Modules to check: 832. Percentage nodes done: 0.949235\n",
      "checked 11000 modules 520 were found significant.  Modules to check: 732. Percentage nodes done: 0.956634\n",
      "checked 11100 modules 521 were found significant.  Modules to check: 632. Percentage nodes done: 0.96274\n",
      "checked 11200 modules 521 were found significant.  Modules to check: 532. Percentage nodes done: 0.969379\n",
      "checked 11300 modules 523 were found significant.  Modules to check: 432. Percentage nodes done: 0.975509\n",
      "checked 11400 modules 523 were found significant.  Modules to check: 332. Percentage nodes done: 0.981083\n",
      "checked 11500 modules 523 were found significant.  Modules to check: 232. Percentage nodes done: 0.98643\n",
      "checked 11600 modules 523 were found significant.  Modules to check: 132. Percentage nodes done: 0.992404\n",
      "checked 11700 modules 525 were found significant.  Modules to check: 32. Percentage nodes done: 0.998307\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11207\n",
      "iteration: 0 number of modules: 5242\n",
      "iteration: 20 number of modules: 3813\n",
      "iteration: 40 number of modules: 3789\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1063\n",
      "iteration: 0 number of modules: 351\n",
      "iteration: 20 number of modules: 131\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 254 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12528\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11346\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checked 11300 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 14\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 241 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #10\n",
      "iteration: 0 number of modules: 12915\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 11736. Percentage nodes done: 0\n",
      "checked 100 modules 5 were found significant.  Modules to check: 11636. Percentage nodes done: 0.0152449\n",
      "checked 200 modules 11 were found significant.  Modules to check: 11536. Percentage nodes done: 0.0284445\n",
      "checked 300 modules 18 were found significant.  Modules to check: 11436. Percentage nodes done: 0.0402385\n",
      "checked 400 modules 26 were found significant.  Modules to check: 11336. Percentage nodes done: 0.0539285\n",
      "checked 500 modules 32 were found significant.  Modules to check: 11236. Percentage nodes done: 0.0648493\n",
      "checked 600 modules 39 were found significant.  Modules to check: 11136. Percentage nodes done: 0.0753635\n",
      "checked 700 modules 45 were found significant.  Modules to check: 11036. Percentage nodes done: 0.0886766\n",
      "checked 800 modules 48 were found significant.  Modules to check: 10936. Percentage nodes done: 0.100142\n",
      "checked 900 modules 53 were found significant.  Modules to check: 10836. Percentage nodes done: 0.10998\n",
      "checked 1000 modules 57 were found significant.  Modules to check: 10736. Percentage nodes done: 0.121296\n",
      "checked 1100 modules 67 were found significant.  Modules to check: 10636. Percentage nodes done: 0.133867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1200 modules 74 were found significant.  Modules to check: 10536. Percentage nodes done: 0.144094\n",
      "checked 1300 modules 82 were found significant.  Modules to check: 10436. Percentage nodes done: 0.154166\n",
      "checked 1400 modules 90 were found significant.  Modules to check: 10336. Percentage nodes done: 0.164226\n",
      "checked 1500 modules 93 were found significant.  Modules to check: 10236. Percentage nodes done: 0.173161\n",
      "checked 1600 modules 103 were found significant.  Modules to check: 10136. Percentage nodes done: 0.183077\n",
      "checked 1700 modules 110 were found significant.  Modules to check: 10036. Percentage nodes done: 0.1934\n",
      "checked 1800 modules 122 were found significant.  Modules to check: 9936. Percentage nodes done: 0.201205\n",
      "checked 1900 modules 133 were found significant.  Modules to check: 9836. Percentage nodes done: 0.21392\n",
      "checked 2000 modules 140 were found significant.  Modules to check: 9736. Percentage nodes done: 0.224332\n",
      "checked 2100 modules 150 were found significant.  Modules to check: 9636. Percentage nodes done: 0.234858\n",
      "checked 2200 modules 155 were found significant.  Modules to check: 9536. Percentage nodes done: 0.244386\n",
      "checked 2300 modules 161 were found significant.  Modules to check: 9436. Percentage nodes done: 0.253111\n",
      "checked 2400 modules 169 were found significant.  Modules to check: 9336. Percentage nodes done: 0.263494\n",
      "checked 2500 modules 179 were found significant.  Modules to check: 9236. Percentage nodes done: 0.27234\n",
      "checked 2600 modules 191 were found significant.  Modules to check: 9136. Percentage nodes done: 0.282465\n",
      "checked 2700 modules 193 were found significant.  Modules to check: 9036. Percentage nodes done: 0.290593\n",
      "checked 2800 modules 195 were found significant.  Modules to check: 8936. Percentage nodes done: 0.300054\n",
      "checked 2900 modules 205 were found significant.  Modules to check: 8836. Percentage nodes done: 0.310216\n",
      "checked 3000 modules 211 were found significant.  Modules to check: 8736. Percentage nodes done: 0.320628\n",
      "checked 3100 modules 217 were found significant.  Modules to check: 8636. Percentage nodes done: 0.330239\n",
      "checked 3200 modules 223 were found significant.  Modules to check: 8536. Percentage nodes done: 0.340042\n",
      "checked 3300 modules 224 were found significant.  Modules to check: 8436. Percentage nodes done: 0.347847\n",
      "checked 3400 modules 235 were found significant.  Modules to check: 8336. Percentage nodes done: 0.358187\n",
      "checked 3500 modules 244 were found significant.  Modules to check: 8236. Percentage nodes done: 0.366961\n",
      "checked 3600 modules 247 were found significant.  Modules to check: 8136. Percentage nodes done: 0.375532\n",
      "checked 3700 modules 252 were found significant.  Modules to check: 8036. Percentage nodes done: 0.38421\n",
      "checked 3800 modules 258 were found significant.  Modules to check: 7936. Percentage nodes done: 0.393946\n",
      "checked 3900 modules 260 were found significant.  Modules to check: 7836. Percentage nodes done: 0.402517\n",
      "checked 4000 modules 266 were found significant.  Modules to check: 7736. Percentage nodes done: 0.411027\n",
      "checked 4100 modules 270 were found significant.  Modules to check: 7636. Percentage nodes done: 0.420872\n",
      "checked 4200 modules 276 were found significant.  Modules to check: 7536. Percentage nodes done: 0.430279\n",
      "checked 4300 modules 284 were found significant.  Modules to check: 7436. Percentage nodes done: 0.438934\n",
      "checked 4400 modules 288 were found significant.  Modules to check: 7336. Percentage nodes done: 0.447815\n",
      "checked 4500 modules 294 were found significant.  Modules to check: 7236. Percentage nodes done: 0.455775\n",
      "checked 4600 modules 299 were found significant.  Modules to check: 7136. Percentage nodes done: 0.46376\n",
      "checked 4700 modules 306 were found significant.  Modules to check: 7036. Percentage nodes done: 0.473646\n",
      "checked 4800 modules 316 were found significant.  Modules to check: 6936. Percentage nodes done: 0.48288\n",
      "checked 4900 modules 322 were found significant.  Modules to check: 6836. Percentage nodes done: 0.492078\n",
      "checked 5000 modules 325 were found significant.  Modules to check: 6736. Percentage nodes done: 0.501325\n",
      "checked 5100 modules 329 were found significant.  Modules to check: 6636. Percentage nodes done: 0.510045\n",
      "checked 5200 modules 333 were found significant.  Modules to check: 6536. Percentage nodes done: 0.518137\n",
      "checked 5300 modules 338 were found significant.  Modules to check: 6436. Percentage nodes done: 0.527855\n",
      "checked 5400 modules 343 were found significant.  Modules to check: 6336. Percentage nodes done: 0.5352\n",
      "checked 5500 modules 346 were found significant.  Modules to check: 6236. Percentage nodes done: 0.543854\n",
      "checked 5600 modules 353 were found significant.  Modules to check: 6136. Percentage nodes done: 0.552024\n",
      "checked 5700 modules 356 were found significant.  Modules to check: 6036. Percentage nodes done: 0.559817\n",
      "checked 5800 modules 359 were found significant.  Modules to check: 5936. Percentage nodes done: 0.56801\n",
      "checked 5900 modules 365 were found significant.  Modules to check: 5836. Percentage nodes done: 0.576927\n",
      "checked 6000 modules 370 were found significant.  Modules to check: 5736. Percentage nodes done: 0.585755\n",
      "checked 6100 modules 375 were found significant.  Modules to check: 5636. Percentage nodes done: 0.592794\n",
      "checked 6200 modules 379 were found significant.  Modules to check: 5536. Percentage nodes done: 0.601413\n",
      "checked 6300 modules 379 were found significant.  Modules to check: 5436. Percentage nodes done: 0.60859\n",
      "checked 6400 modules 382 were found significant.  Modules to check: 5336. Percentage nodes done: 0.617028\n",
      "checked 6500 modules 384 were found significant.  Modules to check: 5236. Percentage nodes done: 0.624492\n",
      "checked 6600 modules 391 were found significant.  Modules to check: 5136. Percentage nodes done: 0.633954\n",
      "checked 6700 modules 397 were found significant.  Modules to check: 5036. Percentage nodes done: 0.642596\n",
      "checked 6800 modules 402 were found significant.  Modules to check: 4936. Percentage nodes done: 0.651322\n",
      "checked 6900 modules 409 were found significant.  Modules to check: 4836. Percentage nodes done: 0.658696\n",
      "checked 7000 modules 411 were found significant.  Modules to check: 4736. Percentage nodes done: 0.666406\n",
      "checked 7100 modules 418 were found significant.  Modules to check: 4636. Percentage nodes done: 0.674234\n",
      "checked 7200 modules 418 were found significant.  Modules to check: 4536. Percentage nodes done: 0.681806\n",
      "checked 7300 modules 422 were found significant.  Modules to check: 4436. Percentage nodes done: 0.689701\n",
      "checked 7400 modules 423 were found significant.  Modules to check: 4336. Percentage nodes done: 0.698331\n",
      "checked 7500 modules 426 were found significant.  Modules to check: 4236. Percentage nodes done: 0.705262\n",
      "checked 7600 modules 428 were found significant.  Modules to check: 4136. Percentage nodes done: 0.713564\n",
      "checked 7700 modules 430 were found significant.  Modules to check: 4036. Percentage nodes done: 0.722021\n",
      "checked 7800 modules 431 were found significant.  Modules to check: 3936. Percentage nodes done: 0.729191\n",
      "checked 7900 modules 435 were found significant.  Modules to check: 3836. Percentage nodes done: 0.738264\n",
      "checked 8000 modules 440 were found significant.  Modules to check: 3736. Percentage nodes done: 0.745872\n",
      "checked 8100 modules 442 were found significant.  Modules to check: 3636. Percentage nodes done: 0.75272\n",
      "checked 8200 modules 445 were found significant.  Modules to check: 3536. Percentage nodes done: 0.758724\n",
      "checked 8300 modules 447 were found significant.  Modules to check: 3436. Percentage nodes done: 0.766864\n",
      "checked 8400 modules 450 were found significant.  Modules to check: 3336. Percentage nodes done: 0.773814\n",
      "checked 8500 modules 456 were found significant.  Modules to check: 3236. Percentage nodes done: 0.782002\n",
      "checked 8600 modules 460 were found significant.  Modules to check: 3136. Percentage nodes done: 0.789753\n",
      "checked 8700 modules 462 were found significant.  Modules to check: 3036. Percentage nodes done: 0.796457\n",
      "checked 8800 modules 465 were found significant.  Modules to check: 2936. Percentage nodes done: 0.803514\n",
      "checked 8900 modules 470 were found significant.  Modules to check: 2836. Percentage nodes done: 0.810428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 9000 modules 475 were found significant.  Modules to check: 2736. Percentage nodes done: 0.817892\n",
      "checked 9100 modules 478 were found significant.  Modules to check: 2636. Percentage nodes done: 0.825368\n",
      "checked 9200 modules 482 were found significant.  Modules to check: 2536. Percentage nodes done: 0.832306\n",
      "checked 9300 modules 484 were found significant.  Modules to check: 2436. Percentage nodes done: 0.84032\n",
      "checked 9400 modules 486 were found significant.  Modules to check: 2336. Percentage nodes done: 0.847317\n",
      "checked 9500 modules 489 were found significant.  Modules to check: 2236. Percentage nodes done: 0.85444\n",
      "checked 9600 modules 490 were found significant.  Modules to check: 2136. Percentage nodes done: 0.861593\n",
      "checked 9700 modules 492 were found significant.  Modules to check: 2036. Percentage nodes done: 0.86828\n",
      "checked 9800 modules 494 were found significant.  Modules to check: 1936. Percentage nodes done: 0.875241\n",
      "checked 9900 modules 494 were found significant.  Modules to check: 1836. Percentage nodes done: 0.882436\n",
      "checked 10000 modules 499 were found significant.  Modules to check: 1736. Percentage nodes done: 0.890241\n",
      "checked 10100 modules 501 were found significant.  Modules to check: 1636. Percentage nodes done: 0.897484\n",
      "checked 10200 modules 504 were found significant.  Modules to check: 1536. Percentage nodes done: 0.904469\n",
      "checked 10300 modules 504 were found significant.  Modules to check: 1436. Percentage nodes done: 0.911724\n",
      "checked 10400 modules 509 were found significant.  Modules to check: 1336. Percentage nodes done: 0.918135\n",
      "checked 10500 modules 511 were found significant.  Modules to check: 1236. Percentage nodes done: 0.924774\n",
      "checked 10600 modules 512 were found significant.  Modules to check: 1136. Percentage nodes done: 0.931006\n",
      "checked 10700 modules 513 were found significant.  Modules to check: 1036. Percentage nodes done: 0.938183\n",
      "checked 10800 modules 515 were found significant.  Modules to check: 936. Percentage nodes done: 0.944098\n",
      "checked 10900 modules 516 were found significant.  Modules to check: 836. Percentage nodes done: 0.95015\n",
      "checked 11000 modules 518 were found significant.  Modules to check: 736. Percentage nodes done: 0.956927\n",
      "checked 11100 modules 520 were found significant.  Modules to check: 636. Percentage nodes done: 0.96286\n",
      "checked 11200 modules 521 were found significant.  Modules to check: 536. Percentage nodes done: 0.969408\n",
      "checked 11300 modules 521 were found significant.  Modules to check: 436. Percentage nodes done: 0.975455\n",
      "checked 11400 modules 521 were found significant.  Modules to check: 336. Percentage nodes done: 0.98137\n",
      "checked 11500 modules 522 were found significant.  Modules to check: 236. Percentage nodes done: 0.986346\n",
      "checked 11600 modules 522 were found significant.  Modules to check: 136. Percentage nodes done: 0.991776\n",
      "checked 11700 modules 524 were found significant.  Modules to check: 36. Percentage nodes done: 0.997799\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 11211\n",
      "iteration: 0 number of modules: 5185\n",
      "iteration: 20 number of modules: 3787\n",
      "iteration: 40 number of modules: 3756\n",
      "iteration: 60 number of modules: 3747\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1037\n",
      "iteration: 0 number of modules: 337\n",
      "iteration: 20 number of modules: 131\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 255 modules to check, run: 0\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 12372\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 11253\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checked 2500 unions. Fused: 0\n",
      "checked 2600 unions. Fused: 0\n",
      "checked 2700 unions. Fused: 0\n",
      "checked 2800 unions. Fused: 0\n",
      "checked 2900 unions. Fused: 0\n",
      "checked 3000 unions. Fused: 0\n",
      "checked 3100 unions. Fused: 0\n",
      "checked 3200 unions. Fused: 0\n",
      "checked 3300 unions. Fused: 0\n",
      "checked 3400 unions. Fused: 0\n",
      "checked 3500 unions. Fused: 0\n",
      "checked 3600 unions. Fused: 0\n",
      "checked 3700 unions. Fused: 0\n",
      "checked 3800 unions. Fused: 0\n",
      "checked 3900 unions. Fused: 0\n",
      "checked 4000 unions. Fused: 0\n",
      "checked 4100 unions. Fused: 0\n",
      "checked 4200 unions. Fused: 0\n",
      "checked 4300 unions. Fused: 0\n",
      "checked 4400 unions. Fused: 0\n",
      "checked 4500 unions. Fused: 0\n",
      "checked 4600 unions. Fused: 0\n",
      "checked 4700 unions. Fused: 0\n",
      "checked 4800 unions. Fused: 0\n",
      "checked 4900 unions. Fused: 0\n",
      "checked 5000 unions. Fused: 0\n",
      "checked 5100 unions. Fused: 0\n",
      "checked 5200 unions. Fused: 0\n",
      "checked 5300 unions. Fused: 0\n",
      "checked 5400 unions. Fused: 0\n",
      "checked 5500 unions. Fused: 0\n",
      "checked 5600 unions. Fused: 0\n",
      "checked 5700 unions. Fused: 0\n",
      "checked 5800 unions. Fused: 0\n",
      "checked 5900 unions. Fused: 0\n",
      "checked 6000 unions. Fused: 0\n",
      "checked 6100 unions. Fused: 0\n",
      "checked 6200 unions. Fused: 0\n",
      "checked 6300 unions. Fused: 0\n",
      "checked 6400 unions. Fused: 0\n",
      "checked 6500 unions. Fused: 0\n",
      "checked 6600 unions. Fused: 0\n",
      "checked 6700 unions. Fused: 0\n",
      "checked 6800 unions. Fused: 0\n",
      "checked 6900 unions. Fused: 0\n",
      "checked 7000 unions. Fused: 0\n",
      "checked 7100 unions. Fused: 0\n",
      "checked 7200 unions. Fused: 0\n",
      "checked 7300 unions. Fused: 0\n",
      "checked 7400 unions. Fused: 0\n",
      "checked 7500 unions. Fused: 0\n",
      "checked 7600 unions. Fused: 0\n",
      "checked 7700 unions. Fused: 0\n",
      "checked 7800 unions. Fused: 0\n",
      "checked 7900 unions. Fused: 0\n",
      "checked 8000 unions. Fused: 0\n",
      "checked 8100 unions. Fused: 0\n",
      "checked 8200 unions. Fused: 0\n",
      "checked 8300 unions. Fused: 0\n",
      "checked 8400 unions. Fused: 0\n",
      "checked 8500 unions. Fused: 0\n",
      "checked 8600 unions. Fused: 0\n",
      "checked 8700 unions. Fused: 0\n",
      "checked 8800 unions. Fused: 0\n",
      "checked 8900 unions. Fused: 0\n",
      "checked 9000 unions. Fused: 0\n",
      "checked 9100 unions. Fused: 0\n",
      "checked 9200 unions. Fused: 0\n",
      "checked 9300 unions. Fused: 0\n",
      "checked 9400 unions. Fused: 0\n",
      "checked 9500 unions. Fused: 0\n",
      "checked 9600 unions. Fused: 0\n",
      "checked 9700 unions. Fused: 0\n",
      "checked 9800 unions. Fused: 0\n",
      "checked 9900 unions. Fused: 0\n",
      "checked 10000 unions. Fused: 0\n",
      "checked 10100 unions. Fused: 0\n",
      "checked 10200 unions. Fused: 0\n",
      "checked 10300 unions. Fused: 0\n",
      "checked 10400 unions. Fused: 0\n",
      "checked 10500 unions. Fused: 0\n",
      "checked 10600 unions. Fused: 0\n",
      "checked 10700 unions. Fused: 0\n",
      "checked 10800 unions. Fused: 0\n",
      "checked 10900 unions. Fused: 0\n",
      "checked 11000 unions. Fused: 0\n",
      "checked 11100 unions. Fused: 0\n",
      "checked 11200 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 18\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 242 modules. writing... \n",
      "DONE   ****************************\n",
      "pruning all the modules collected. Partitions found: 10\n",
      "getting partition from tp-file: ../../results/papers/matrix/mentions/edges_mentions_weighted.csv_oslo_files/partitions_level_0\n",
      "2423 groups found\n",
      "2423 bss found\n",
      "checking similar modules\n",
      "\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 9\n",
      "pairs to check: 1\n",
      "checking homeless nodes\n",
      "assigning homeless nodes. Homeless at this point: 165256\n",
      "assigning homeless nodes. Homeless at this point: 147669\n",
      "assigning homeless nodes. Homeless at this point: 95536\n",
      "assigning homeless nodes. Homeless at this point: 50192\n",
      "assigning homeless nodes. Homeless at this point: 31488\n",
      "assigning homeless nodes. Homeless at this point: 25808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigning homeless nodes. Homeless at this point: 23785\n",
      "assigning homeless nodes. Homeless at this point: 23185\n",
      "assigning homeless nodes. Homeless at this point: 22942\n",
      "assigning homeless nodes. Homeless at this point: 22847\n",
      "assigning homeless nodes. Homeless at this point: 22802\n",
      "assigning homeless nodes. Homeless at this point: 22780\n",
      "assigning homeless nodes. Homeless at this point: 22770\n",
      "assigning homeless nodes. Homeless at this point: 22769\n",
      "assigning homeless nodes. Homeless at this point: 22761\n",
      "writing final solution in file ../../results/papers/matrix/mentions/edges_mentions_weighted.csv_oslo_files/tp\n",
      "******** module_collection ******** 249 modules. writing... \n",
      "DONE   ****************************\n",
      "network:: 23010 nodes and 42775 stubs;\t average degree = 1.85897\n",
      "STARTING! HIERARCHICAL LEVEL: 1\n",
      "***************************************************************** RUN: #1\n",
      "iteration: 0 number of modules: 2753\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0517166\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0936115\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.132681\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.179487\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.220991\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.259148\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.299174\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.33907\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.383399\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.424728\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.466015\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.504302\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.552542\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.592482\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.632942\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.672012\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.710691\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.750326\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.793003\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.833246\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871795\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.907127\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945502\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979487\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2673\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2458\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #2\n",
      "iteration: 0 number of modules: 2729\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2465. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2365. Percentage nodes done: 0.0510648\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2265. Percentage nodes done: 0.0923512\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2165. Percentage nodes done: 0.131769\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2065. Percentage nodes done: 0.176923\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1965. Percentage nodes done: 0.218253\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1865. Percentage nodes done: 0.255585\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1765. Percentage nodes done: 0.29535\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1665. Percentage nodes done: 0.337592\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1565. Percentage nodes done: 0.380269\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1465. Percentage nodes done: 0.419774\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1365. Percentage nodes done: 0.46206\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1265. Percentage nodes done: 0.501086\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1165. Percentage nodes done: 0.548935\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1065. Percentage nodes done: 0.590482\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 965. Percentage nodes done: 0.631247\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 865. Percentage nodes done: 0.6701\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 765. Percentage nodes done: 0.709518\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 665. Percentage nodes done: 0.748196\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 565. Percentage nodes done: 0.791786\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 465. Percentage nodes done: 0.831421\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 365. Percentage nodes done: 0.870404\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 265. Percentage nodes done: 0.906432\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 165. Percentage nodes done: 0.943155\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 65. Percentage nodes done: 0.978314\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2463\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 86\n",
      "iteration: 0 number of modules: 85\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2703\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #3\n",
      "iteration: 0 number of modules: 2749\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2465. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2365. Percentage nodes done: 0.0513255\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2265. Percentage nodes done: 0.0937853\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2165. Percentage nodes done: 0.133203\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2065. Percentage nodes done: 0.179835\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1965. Percentage nodes done: 0.220078\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1865. Percentage nodes done: 0.258149\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1765. Percentage nodes done: 0.298522\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1665. Percentage nodes done: 0.337245\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1565. Percentage nodes done: 0.380921\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1465. Percentage nodes done: 0.421686\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1365. Percentage nodes done: 0.46332\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1265. Percentage nodes done: 0.502608\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1165. Percentage nodes done: 0.550543\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1065. Percentage nodes done: 0.589396\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 965. Percentage nodes done: 0.630161\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 865. Percentage nodes done: 0.66997\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 765. Percentage nodes done: 0.708561\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 665. Percentage nodes done: 0.746719\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 565. Percentage nodes done: 0.789005\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 465. Percentage nodes done: 0.831073\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 365. Percentage nodes done: 0.870317\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 265. Percentage nodes done: 0.90578\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 165. Percentage nodes done: 0.943068\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 65. Percentage nodes done: 0.977879\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2463\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 86\n",
      "iteration: 0 number of modules: 85\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2690\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #4\n",
      "iteration: 0 number of modules: 2742\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0503259\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0919166\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.131943\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.179835\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.219339\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.257062\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.296827\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.337201\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.380748\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.421904\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.463885\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.501608\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.550543\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.591004\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.631551\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.67136\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.709605\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.747936\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.790309\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.83203\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870969\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906345\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.943764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978922\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2679\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #5\n",
      "iteration: 0 number of modules: 2728\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0510648\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0931334\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.132812\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.179835\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.220513\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.257931\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.297914\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.337201\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.381443\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.422295\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.464189\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.502173\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.550891\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.591917\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.632073\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.671925\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.710343\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.749761\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.791786\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.831725\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870882\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906302\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.943764\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978922\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2689\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #6\n",
      "iteration: 0 number of modules: 2716\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2460. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2360. Percentage nodes done: 0.0512386\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2260. Percentage nodes done: 0.093003\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2160. Percentage nodes done: 0.132725\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2060. Percentage nodes done: 0.178966\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1960. Percentage nodes done: 0.218253\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1860. Percentage nodes done: 0.25615\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1760. Percentage nodes done: 0.295611\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1660. Percentage nodes done: 0.337114\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1560. Percentage nodes done: 0.381052\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1460. Percentage nodes done: 0.421078\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1360. Percentage nodes done: 0.462408\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1260. Percentage nodes done: 0.501217\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1160. Percentage nodes done: 0.550109\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1060. Percentage nodes done: 0.590482\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 960. Percentage nodes done: 0.631769\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 860. Percentage nodes done: 0.671925\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 760. Percentage nodes done: 0.710604\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 660. Percentage nodes done: 0.748674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1900 modules 2 were found significant.  Modules to check: 560. Percentage nodes done: 0.791134\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 460. Percentage nodes done: 0.833464\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 360. Percentage nodes done: 0.872186\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 260. Percentage nodes done: 0.907345\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 160. Percentage nodes done: 0.945502\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 60. Percentage nodes done: 0.979791\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2458\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2693\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #7\n",
      "iteration: 0 number of modules: 2758\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0509344\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.0923512\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.13216\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.179835\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.219383\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.257627\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.298218\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.338288\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.381356\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.423816\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.465406\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.504954\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.551977\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.592308\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.632986\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.671969\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.710213\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.749848\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.791699\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.831856\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870926\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.906171\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.943633\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.978792\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #8\n",
      "iteration: 0 number of modules: 2734\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0508475\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0923946\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.132247\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.1794\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.220035\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.257497\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.297784\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.337419\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.381139\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.421817\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.463538\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.50213\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.551326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.590917\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.63216\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.671969\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.710734\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.749587\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.791699\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.832768\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871143\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.906867\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945024\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979618\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 81\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2715\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2458\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #9\n",
      "iteration: 0 number of modules: 2741\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0515863\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0936115\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.133898\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.179922\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.220904\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.258322\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.298131\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.338766\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.381834\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.422425\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.463798\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.502347\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.549587\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.589961\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.631421\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.671186\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.710865\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.749326\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.791917\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.832899\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.872186\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.907649\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945285\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979878\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2700\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #10\n",
      "iteration: 0 number of modules: 2745\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2460. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2360. Percentage nodes done: 0.0511082\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2260. Percentage nodes done: 0.093568\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2160. Percentage nodes done: 0.132986\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2060. Percentage nodes done: 0.179661\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1960. Percentage nodes done: 0.221121\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1860. Percentage nodes done: 0.258931\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1760. Percentage nodes done: 0.29887\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1660. Percentage nodes done: 0.339548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 900 modules 2 were found significant.  Modules to check: 1560. Percentage nodes done: 0.384094\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1460. Percentage nodes done: 0.423816\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1360. Percentage nodes done: 0.465971\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1260. Percentage nodes done: 0.504346\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1160. Percentage nodes done: 0.551543\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1060. Percentage nodes done: 0.591482\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 960. Percentage nodes done: 0.632334\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 860. Percentage nodes done: 0.672273\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 760. Percentage nodes done: 0.711256\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 660. Percentage nodes done: 0.749283\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 560. Percentage nodes done: 0.792003\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 460. Percentage nodes done: 0.83342\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 360. Percentage nodes done: 0.871969\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 260. Percentage nodes done: 0.907432\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 160. Percentage nodes done: 0.945502\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 60. Percentage nodes done: 0.980139\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2458\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2696\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2459\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #11\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0514993\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.094133\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.133551\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.180269\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.219948\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.257366\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.296827\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.338288\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.381704\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.422468\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.464798\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.502999\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.552238\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.591569\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.632421\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.671491\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.709735\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.747762\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.790526\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.832116\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870795\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.906041\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.943459\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.977966\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 84\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2671\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #12\n",
      "iteration: 0 number of modules: 2757\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2460. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2360. Percentage nodes done: 0.0515428\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2260. Percentage nodes done: 0.0933073\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2160. Percentage nodes done: 0.133942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 400 modules 2 were found significant.  Modules to check: 2060. Percentage nodes done: 0.179922\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1960. Percentage nodes done: 0.221469\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1860. Percentage nodes done: 0.259279\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1760. Percentage nodes done: 0.298827\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1660. Percentage nodes done: 0.339113\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1560. Percentage nodes done: 0.383138\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1460. Percentage nodes done: 0.423642\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1360. Percentage nodes done: 0.465667\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1260. Percentage nodes done: 0.503694\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1160. Percentage nodes done: 0.552021\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1060. Percentage nodes done: 0.59196\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 960. Percentage nodes done: 0.632942\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 860. Percentage nodes done: 0.672925\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 760. Percentage nodes done: 0.711821\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 660. Percentage nodes done: 0.7505\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 560. Percentage nodes done: 0.792916\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 460. Percentage nodes done: 0.834376\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 360. Percentage nodes done: 0.872099\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 260. Percentage nodes done: 0.907823\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 160. Percentage nodes done: 0.945893\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 60. Percentage nodes done: 0.979922\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2458\n",
      "iteration: 0 number of modules: 2368\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2714\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2459\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #13\n",
      "iteration: 0 number of modules: 2741\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.050804\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0926119\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.132421\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.178357\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.218079\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.256367\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.29535\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.335897\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.379878\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.42086\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.462147\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.500043\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.549674\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.589526\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.630248\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.669405\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.708301\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.747936\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.789657\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.830378\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.86997\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906128\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.943764\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978227\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2371\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 84\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2685\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE   ****************************\n",
      "***************************************************************** RUN: #14\n",
      "iteration: 0 number of modules: 2728\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0514993\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0938288\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.133333\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.178835\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.219252\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.256888\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.296436\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.337679\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.381704\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.420904\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.463277\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.501695\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.551152\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.592003\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.632334\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.672403\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.710561\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.749674\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.79196\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.833029\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.871838\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.907127\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.945415\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.979487\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2687\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #15\n",
      "iteration: 0 number of modules: 2742\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0514993\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0933073\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.132638\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.178488\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.218992\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.257627\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.297132\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.335984\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.381269\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.421512\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.463103\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.50213\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.550369\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.591047\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.631421\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.67123\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.709518\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.74824\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.790787\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.832203\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870752\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906606\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944633\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978661\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 84\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2691\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2462\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #16\n",
      "iteration: 0 number of modules: 2749\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0517166\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.093568\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.133333\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.178488\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.219817\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.257279\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.297262\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.338418\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.382095\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.422555\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.464841\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.502868\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.550239\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.59083\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.631378\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.670404\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.709996\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.74811\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.790265\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.831247\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870752\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.906084\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.943894\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.978357\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2707\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #17\n",
      "iteration: 0 number of modules: 2733\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0512386\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0928292\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.132986\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.178314\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.218209\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.25502\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.29435\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.335115\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.378705\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.418905\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.46106\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.499652\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.549413\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.589744\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.631073\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.670795\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.709518\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.74837\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.79083\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.831682\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870535\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906128\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944329\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978966\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 number of modules: 2701\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #18\n",
      "iteration: 0 number of modules: 2733\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2465. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2365. Percentage nodes done: 0.0510213\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2265. Percentage nodes done: 0.0921339\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2165. Percentage nodes done: 0.132595\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2065. Percentage nodes done: 0.177271\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1965. Percentage nodes done: 0.217949\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1865. Percentage nodes done: 0.255367\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1765. Percentage nodes done: 0.29422\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1665. Percentage nodes done: 0.33668\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1565. Percentage nodes done: 0.380574\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1465. Percentage nodes done: 0.42073\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1365. Percentage nodes done: 0.463016\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1265. Percentage nodes done: 0.501043\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1165. Percentage nodes done: 0.550543\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1065. Percentage nodes done: 0.591482\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 965. Percentage nodes done: 0.631595\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 865. Percentage nodes done: 0.670621\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 765. Percentage nodes done: 0.709605\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 665. Percentage nodes done: 0.748718\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 565. Percentage nodes done: 0.791091\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 465. Percentage nodes done: 0.831291\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 365. Percentage nodes done: 0.87023\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 265. Percentage nodes done: 0.906345\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 165. Percentage nodes done: 0.943329\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 65. Percentage nodes done: 0.977836\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2463\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 86\n",
      "iteration: 0 number of modules: 85\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2699\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #19\n",
      "iteration: 0 number of modules: 2735\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0508475\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0930465\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.132247\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.178705\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.218905\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.258105\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.297957\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.33681\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.381443\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.420904\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.462973\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.501347\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.549109\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.589352\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.6299\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.669752\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.708605\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.746762\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.789657\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.831595\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.870621\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.905824\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944198\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.978835\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2731\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #20\n",
      "iteration: 0 number of modules: 2709\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0511517\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.0928727\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.132247\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.178748\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.218427\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.255976\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.296002\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.334985\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.3794\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.419209\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.461495\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.499522\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.548544\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.589092\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.630204\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.670056\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.708909\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.747631\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.790004\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.831943\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870969\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.905997\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.944155\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.978748\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 86\n",
      "iteration: 0 number of modules: 85\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2716\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #21\n",
      "iteration: 0 number of modules: 2713\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0514124\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0930465\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.132247\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.178575\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.217862\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.256193\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.295089\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.335376\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.379661\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.419383\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.461669\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.500043\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.548761\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.588831\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.62977\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.669535\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.709083\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.748153\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.7907\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.83216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.870752\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.906128\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944502\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.978792\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2693\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #22\n",
      "iteration: 0 number of modules: 2728\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0511517\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.0933942\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.133246\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.179704\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.220991\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.258583\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.298175\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.338201\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.381486\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.422295\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.463581\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.503259\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.549761\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.589266\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.630595\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.670448\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.709344\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.748979\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.791047\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.831551\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870448\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.90565\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.944285\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.978357\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2692\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2462\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #23\n",
      "iteration: 0 number of modules: 2723\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2460. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2360. Percentage nodes done: 0.0516297\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2260. Percentage nodes done: 0.0931769\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2160. Percentage nodes done: 0.133116\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2060. Percentage nodes done: 0.178053\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1960. Percentage nodes done: 0.219339\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1860. Percentage nodes done: 0.256975\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1760. Percentage nodes done: 0.296002\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1660. Percentage nodes done: 0.337114\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1560. Percentage nodes done: 0.380617\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1460. Percentage nodes done: 0.41947\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1360. Percentage nodes done: 0.46219\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1260. Percentage nodes done: 0.500826\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1160. Percentage nodes done: 0.550282\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1060. Percentage nodes done: 0.590613\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 960. Percentage nodes done: 0.631725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1600 modules 2 were found significant.  Modules to check: 860. Percentage nodes done: 0.671664\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 760. Percentage nodes done: 0.710256\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 660. Percentage nodes done: 0.749109\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 560. Percentage nodes done: 0.791743\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 460. Percentage nodes done: 0.832768\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 360. Percentage nodes done: 0.87136\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 260. Percentage nodes done: 0.906953\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 160. Percentage nodes done: 0.945154\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 60. Percentage nodes done: 0.979748\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2458\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 81\n",
      "iteration: 0 number of modules: 80\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2687\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #24\n",
      "iteration: 0 number of modules: 2726\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2459. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2359. Percentage nodes done: 0.0506302\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2259. Percentage nodes done: 0.0923946\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2159. Percentage nodes done: 0.132986\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2059. Percentage nodes done: 0.177792\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1959. Percentage nodes done: 0.219339\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1859. Percentage nodes done: 0.256541\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1759. Percentage nodes done: 0.295567\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1659. Percentage nodes done: 0.337549\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1559. Percentage nodes done: 0.382225\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1459. Percentage nodes done: 0.421947\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1359. Percentage nodes done: 0.463972\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1259. Percentage nodes done: 0.502434\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1159. Percentage nodes done: 0.551543\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1059. Percentage nodes done: 0.592003\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 959. Percentage nodes done: 0.632595\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 859. Percentage nodes done: 0.672099\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 759. Percentage nodes done: 0.71043\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 659. Percentage nodes done: 0.749022\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 559. Percentage nodes done: 0.791221\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 459. Percentage nodes done: 0.832768\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 359. Percentage nodes done: 0.871664\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 259. Percentage nodes done: 0.907301\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 159. Percentage nodes done: 0.945676\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 59. Percentage nodes done: 0.980269\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2457\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 81\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2694\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #25\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0508475\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0926988\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.131943\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.177749\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.217949\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.256497\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.296045\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.335767\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.380052\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.420296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.462017\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.500261\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.549804\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.589657\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.631117\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.670882\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.709561\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.747327\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.790048\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.832203\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.87123\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906258\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944894\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978966\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2368\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2687\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #26\n",
      "iteration: 0 number of modules: 2764\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0502825\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0922642\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.131856\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.178748\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.218427\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.256019\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.295611\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.335637\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.380356\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.420382\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.462408\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.501608\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.550152\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.589917\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.631378\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.6711\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.71043\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.749196\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.79183\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.83329\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871621\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.907084\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945024\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979661\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2371\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2703\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #27\n",
      "iteration: 0 number of modules: 2733\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2459. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2359. Percentage nodes done: 0.0508475\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2259. Percentage nodes done: 0.0927857\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2159. Percentage nodes done: 0.133681\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2059. Percentage nodes done: 0.180748\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1959. Percentage nodes done: 0.220339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 600 modules 2 were found significant.  Modules to check: 1859. Percentage nodes done: 0.257453\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1759. Percentage nodes done: 0.297436\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1659. Percentage nodes done: 0.336723\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1559. Percentage nodes done: 0.382225\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1459. Percentage nodes done: 0.422468\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1359. Percentage nodes done: 0.464711\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1259. Percentage nodes done: 0.502608\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1159. Percentage nodes done: 0.55189\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1059. Percentage nodes done: 0.591178\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 959. Percentage nodes done: 0.631638\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 859. Percentage nodes done: 0.671621\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 759. Percentage nodes done: 0.710474\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 659. Percentage nodes done: 0.748588\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 559. Percentage nodes done: 0.791178\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 459. Percentage nodes done: 0.833507\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 359. Percentage nodes done: 0.871578\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 259. Percentage nodes done: 0.906867\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 159. Percentage nodes done: 0.945328\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 59. Percentage nodes done: 0.980139\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2457\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 81\n",
      "iteration: 0 number of modules: 80\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2726\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #28\n",
      "iteration: 0 number of modules: 2754\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0512386\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0934376\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.133073\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.180139\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.219948\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.257149\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.297306\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.336158\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.380748\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.421556\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.463451\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.501738\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.551456\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.591178\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.63203\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.671925\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.710561\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.748718\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.791178\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.832942\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.870708\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.906128\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944372\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.978922\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2721\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 4\n",
      "pairs to check: 4\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 4 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #29\n",
      "iteration: 0 number of modules: 2740\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0504563\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0923946\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.132595\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.178705\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.218383\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.256106\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.295611\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.334767\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.379704\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.420947\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.462364\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.500652\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.550326\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.590613\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.630595\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.670448\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.709213\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.748023\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.790482\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.83203\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871534\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.90678\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945024\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979053\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2458\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #30\n",
      "iteration: 0 number of modules: 2752\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0510213\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0929596\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.132942\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.180269\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.2196\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.259105\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.298305\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.338331\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.381182\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.422599\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.464363\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.503738\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.550847\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.590874\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.631204\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.670361\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.708996\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.749066\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.790787\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.831291\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870448\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.905737\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944024\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978575\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 84\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2694\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #31\n",
      "iteration: 0 number of modules: 2720\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0514993\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0927423\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.132638\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.178966\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.218557\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.255889\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.295958\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.335072\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.379444\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.420382\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.461886\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.500695\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.550196\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.589917\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.631247\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.671186\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.709909\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.748631\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.791352\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.832942\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871621\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.907345\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945328\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979313\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2693\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #32\n",
      "iteration: 0 number of modules: 2739\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0512386\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0926554\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.132421\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.179704\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.219383\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.25754\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.298218\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.338592\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.382877\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.422382\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.464537\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.502477\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.55163\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.59309\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.633029\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.671708\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.709648\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.74837\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.790656\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.831986\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870708\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.905997\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944372\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.97914\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2714\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #33\n",
      "iteration: 0 number of modules: 2735\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0512386\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0929161\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.132986\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.17814\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.219731\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.257801\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.296132\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.338157\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.381747\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.42186\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.463625\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.50239\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.550934\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.590309\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.631073\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.671056\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.708822\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.747849\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.789744\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.83216\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.870535\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.906302\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944502\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.978661\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2712\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 4\n",
      "pairs to check: 2\n",
      "pairs to check: 3\n",
      "pairs to check: 3\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 4 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #34\n",
      "iteration: 0 number of modules: 2764\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0504998\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.0927857\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.132942\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.179531\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.219687\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.256671\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.296914\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.335767\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.37914\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.420774\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.46306\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.501304\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.549587\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.589526\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.629944\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.669752\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.708648\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.747588\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.789657\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.830943\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870013\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.905693\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.943633\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.978401\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #35\n",
      "iteration: 0 number of modules: 2746\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0505432\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0923946\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.132551\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.178357\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.219339\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.257019\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.297088\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.335941\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.381312\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.421556\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.464276\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.502521\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.550978\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.591265\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.631551\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.67136\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.709909\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.748414\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.79083\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.831204\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870752\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.905997\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944372\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.979009\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 84\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2704\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #36\n",
      "iteration: 0 number of modules: 2715\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0511082\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0926554\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.131769\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.178618\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.218818\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.258105\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.298218\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.337897\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.380617\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.422425\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.463842\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.503346\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.550891\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.59083\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.630987\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.671186\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.710343\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.749631\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.791743\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.832681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.871317\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906345\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944807\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978879\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2700\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #37\n",
      "iteration: 0 number of modules: 2739\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0508909\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0920904\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.131769\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.178966\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.218948\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.257106\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.296219\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.335159\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.378575\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.419383\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.461017\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.49987\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.549153\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.589092\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.629857\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.669622\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.70904\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.74724\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.791873\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.831856\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870056\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906128\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.943764\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.978227\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2368\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #38\n",
      "iteration: 0 number of modules: 2756\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0515863\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0927423\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.132812\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.179357\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.220209\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.258453\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.297392\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.339635\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.383051\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.422773\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.464972\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.504389\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.551847\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.591569\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.632855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.671925\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.710952\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.750196\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.792786\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.833681\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871447\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.90691\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.944894\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979444\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 81\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2461\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #39\n",
      "iteration: 0 number of modules: 2757\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2460. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2360. Percentage nodes done: 0.0508909\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2260. Percentage nodes done: 0.0930465\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2160. Percentage nodes done: 0.13203\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2060. Percentage nodes done: 0.17814\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1960. Percentage nodes done: 0.218688\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1860. Percentage nodes done: 0.257497\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1760. Percentage nodes done: 0.297175\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1660. Percentage nodes done: 0.336767\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1560. Percentage nodes done: 0.381139\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1460. Percentage nodes done: 0.421425\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1360. Percentage nodes done: 0.46332\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1260. Percentage nodes done: 0.503129\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1160. Percentage nodes done: 0.551108\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1060. Percentage nodes done: 0.592134\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 960. Percentage nodes done: 0.632942\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 860. Percentage nodes done: 0.672881\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 760. Percentage nodes done: 0.711169\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 660. Percentage nodes done: 0.750847\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 560. Percentage nodes done: 0.79309\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 460. Percentage nodes done: 0.833594\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 360. Percentage nodes done: 0.872143\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 260. Percentage nodes done: 0.907649\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 160. Percentage nodes done: 0.945676\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 60. Percentage nodes done: 0.980226\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2458\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2700\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #40\n",
      "iteration: 0 number of modules: 2730\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0512821\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.0927423\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.133942\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.178618\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.219948\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.256888\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.29548\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.337419\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.380661\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.4206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.462668\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.502086\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.549674\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.590004\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.630639\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.670491\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.708953\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.748457\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.790395\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.830943\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870274\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.905693\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.943633\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.978096\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 86\n",
      "iteration: 0 number of modules: 85\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2710\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #41\n",
      "iteration: 0 number of modules: 2711\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0507605\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0931769\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.132768\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.178748\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.219122\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.256584\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.296089\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.33781\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.380965\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.421078\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.463494\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.501695\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.551282\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.59096\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.631899\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.670795\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.710083\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.748979\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.791786\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.832899\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.871056\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.906432\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944633\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.97914\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 84\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2684\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #42\n",
      "iteration: 0 number of modules: 2736\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0517166\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0931334\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.132812\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.179661\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.219904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.258105\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.297784\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.337288\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.381791\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.421947\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.464711\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.502999\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.551673\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.591265\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.631812\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.670926\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.710126\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.748283\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.790743\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.832899\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871578\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.907127\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945024\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979574\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 81\n",
      "iteration: 0 number of modules: 81\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2694\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2458\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #43\n",
      "iteration: 0 number of modules: 2750\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2465. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2365. Percentage nodes done: 0.0516297\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2265. Percentage nodes done: 0.093003\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2165. Percentage nodes done: 0.132377\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2065. Percentage nodes done: 0.179531\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1965. Percentage nodes done: 0.219731\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1865. Percentage nodes done: 0.256975\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1765. Percentage nodes done: 0.297479\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1665. Percentage nodes done: 0.336984\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1565. Percentage nodes done: 0.380183\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1465. Percentage nodes done: 0.420947\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1365. Percentage nodes done: 0.463233\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1265. Percentage nodes done: 0.501478\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1165. Percentage nodes done: 0.550282\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1065. Percentage nodes done: 0.589744\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 965. Percentage nodes done: 0.629987\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 865. Percentage nodes done: 0.669926\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 765. Percentage nodes done: 0.708779\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 665. Percentage nodes done: 0.748283\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 565. Percentage nodes done: 0.791134\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 465. Percentage nodes done: 0.83203\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 365. Percentage nodes done: 0.870491\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 265. Percentage nodes done: 0.90578\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 165. Percentage nodes done: 0.943894\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 65. Percentage nodes done: 0.978488\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2463\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 86\n",
      "iteration: 0 number of modules: 85\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2699\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #44\n",
      "iteration: 0 number of modules: 2740\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0518036\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0942199\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.133333\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.179096\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.22073\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.258322\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.29787\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.338288\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.382964\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.423816\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.465363\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.503607\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.551369\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.592568\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.633159\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.671838\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.710387\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.749761\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.791308\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.831812\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.870578\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906084\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944546\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.979096\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2690\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #45\n",
      "iteration: 0 number of modules: 2705\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2464. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2364. Percentage nodes done: 0.0515428\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2264. Percentage nodes done: 0.0933507\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2164. Percentage nodes done: 0.132812\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2064. Percentage nodes done: 0.177705\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1964. Percentage nodes done: 0.219904\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1864. Percentage nodes done: 0.256454\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1764. Percentage nodes done: 0.295958\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1664. Percentage nodes done: 0.337462\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1564. Percentage nodes done: 0.381704\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1464. Percentage nodes done: 0.421643\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1364. Percentage nodes done: 0.463364\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1264. Percentage nodes done: 0.501565\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1164. Percentage nodes done: 0.549457\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1064. Percentage nodes done: 0.590004\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 964. Percentage nodes done: 0.63116\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 864. Percentage nodes done: 0.671317\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 764. Percentage nodes done: 0.710213\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 664. Percentage nodes done: 0.748327\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 564. Percentage nodes done: 0.790135\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 464. Percentage nodes done: 0.831117\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 364. Percentage nodes done: 0.870491\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 264. Percentage nodes done: 0.906215\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 164. Percentage nodes done: 0.943503\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 64. Percentage nodes done: 0.978661\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2462\n",
      "iteration: 0 number of modules: 2371\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2698\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2459\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #46\n",
      "iteration: 0 number of modules: 2766\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2461. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2361. Percentage nodes done: 0.0508475\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2261. Percentage nodes done: 0.0926554\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2161. Percentage nodes done: 0.132377\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2061. Percentage nodes done: 0.17814\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1961. Percentage nodes done: 0.218731\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1861. Percentage nodes done: 0.256671\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1761. Percentage nodes done: 0.297045\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1661. Percentage nodes done: 0.33568\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1561. Percentage nodes done: 0.379748\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1461. Percentage nodes done: 0.420469\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1361. Percentage nodes done: 0.462103\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1261. Percentage nodes done: 0.500956\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1161. Percentage nodes done: 0.548892\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1061. Percentage nodes done: 0.58957\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 961. Percentage nodes done: 0.630856\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 861. Percentage nodes done: 0.670882\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 761. Percentage nodes done: 0.709474\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 661. Percentage nodes done: 0.748196\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 561. Percentage nodes done: 0.790569\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 461. Percentage nodes done: 0.832377\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 361. Percentage nodes done: 0.871578\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 261. Percentage nodes done: 0.907432\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 161. Percentage nodes done: 0.945458\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 61. Percentage nodes done: 0.979618\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2459\n",
      "iteration: 0 number of modules: 2370\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 82\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2679\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2462\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #47\n",
      "iteration: 0 number of modules: 2740\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0512386\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0927857\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.132812\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.177618\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.219644\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.258322\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.297566\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.338027\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.38166\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.42199\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.463277\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.502825\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.550456\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.590569\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.631856\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.671534\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.710039\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.749153\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.791221\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.833029\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.871317\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.906345\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944242\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.978792\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2701\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2463\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #48\n",
      "iteration: 0 number of modules: 2758\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0517166\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0933073\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.13329\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.179878\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.2196\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.258583\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.298044\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.33794\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.381399\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.422208\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.464276\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.502173\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.549848\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.590222\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.63116\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.67023\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.709691\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.748631\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.790743\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.832073\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.871143\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.906562\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944502\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.979096\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 83\n",
      "iteration: 0 number of modules: 82\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2677\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #49\n",
      "iteration: 0 number of modules: 2726\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2463. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2363. Percentage nodes done: 0.0508475\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2263. Percentage nodes done: 0.0929596\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2163. Percentage nodes done: 0.131899\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2063. Percentage nodes done: 0.177792\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1963. Percentage nodes done: 0.219209\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1863. Percentage nodes done: 0.256975\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1763. Percentage nodes done: 0.29648\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1663. Percentage nodes done: 0.338027\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1563. Percentage nodes done: 0.381747\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1463. Percentage nodes done: 0.422425\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1363. Percentage nodes done: 0.464841\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1263. Percentage nodes done: 0.50339\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1163. Percentage nodes done: 0.551065\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1063. Percentage nodes done: 0.590787\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 963. Percentage nodes done: 0.632247\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 863. Percentage nodes done: 0.67136\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 763. Percentage nodes done: 0.710256\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 663. Percentage nodes done: 0.748327\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 563. Percentage nodes done: 0.790526\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 463. Percentage nodes done: 0.83229\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 363. Percentage nodes done: 0.871621\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 263. Percentage nodes done: 0.906693\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 163. Percentage nodes done: 0.944676\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 63. Percentage nodes done: 0.979226\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2461\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 85\n",
      "iteration: 0 number of modules: 84\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2699\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2464\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #50\n",
      "iteration: 0 number of modules: 2741\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 2462. Percentage nodes done: 0\n",
      "checked 100 modules 2 were found significant.  Modules to check: 2362. Percentage nodes done: 0.0509344\n",
      "checked 200 modules 2 were found significant.  Modules to check: 2262. Percentage nodes done: 0.0931769\n",
      "checked 300 modules 2 were found significant.  Modules to check: 2162. Percentage nodes done: 0.13342\n",
      "checked 400 modules 2 were found significant.  Modules to check: 2062. Percentage nodes done: 0.179835\n",
      "checked 500 modules 2 were found significant.  Modules to check: 1962. Percentage nodes done: 0.219687\n",
      "checked 600 modules 2 were found significant.  Modules to check: 1862. Percentage nodes done: 0.257497\n",
      "checked 700 modules 2 were found significant.  Modules to check: 1762. Percentage nodes done: 0.297001\n",
      "checked 800 modules 2 were found significant.  Modules to check: 1662. Percentage nodes done: 0.337679\n",
      "checked 900 modules 2 were found significant.  Modules to check: 1562. Percentage nodes done: 0.380617\n",
      "checked 1000 modules 2 were found significant.  Modules to check: 1462. Percentage nodes done: 0.421208\n",
      "checked 1100 modules 2 were found significant.  Modules to check: 1362. Percentage nodes done: 0.463755\n",
      "checked 1200 modules 2 were found significant.  Modules to check: 1262. Percentage nodes done: 0.501651\n",
      "checked 1300 modules 2 were found significant.  Modules to check: 1162. Percentage nodes done: 0.55063\n",
      "checked 1400 modules 2 were found significant.  Modules to check: 1062. Percentage nodes done: 0.591134\n",
      "checked 1500 modules 2 were found significant.  Modules to check: 962. Percentage nodes done: 0.631291\n",
      "checked 1600 modules 2 were found significant.  Modules to check: 862. Percentage nodes done: 0.671404\n",
      "checked 1700 modules 2 were found significant.  Modules to check: 762. Percentage nodes done: 0.710691\n",
      "checked 1800 modules 2 were found significant.  Modules to check: 662. Percentage nodes done: 0.748631\n",
      "checked 1900 modules 2 were found significant.  Modules to check: 562. Percentage nodes done: 0.790874\n",
      "checked 2000 modules 2 were found significant.  Modules to check: 462. Percentage nodes done: 0.832899\n",
      "checked 2100 modules 2 were found significant.  Modules to check: 362. Percentage nodes done: 0.871534\n",
      "checked 2200 modules 2 were found significant.  Modules to check: 262. Percentage nodes done: 0.906953\n",
      "checked 2300 modules 2 were found significant.  Modules to check: 162. Percentage nodes done: 0.944894\n",
      "checked 2400 modules 2 were found significant.  Modules to check: 62. Percentage nodes done: 0.979531\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 2460\n",
      "iteration: 0 number of modules: 2369\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 84\n",
      "iteration: 0 number of modules: 83\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 2684\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 2460\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 0\n",
      "checked 300 unions. Fused: 0\n",
      "checked 400 unions. Fused: 0\n",
      "checked 500 unions. Fused: 0\n",
      "checked 600 unions. Fused: 0\n",
      "checked 700 unions. Fused: 0\n",
      "checked 800 unions. Fused: 0\n",
      "checked 900 unions. Fused: 0\n",
      "checked 1000 unions. Fused: 0\n",
      "checked 1100 unions. Fused: 0\n",
      "checked 1200 unions. Fused: 0\n",
      "checked 1300 unions. Fused: 0\n",
      "checked 1400 unions. Fused: 0\n",
      "checked 1500 unions. Fused: 0\n",
      "checked 1600 unions. Fused: 0\n",
      "checked 1700 unions. Fused: 0\n",
      "checked 1800 unions. Fused: 0\n",
      "checked 1900 unions. Fused: 0\n",
      "checked 2000 unions. Fused: 0\n",
      "checked 2100 unions. Fused: 0\n",
      "checked 2200 unions. Fused: 0\n",
      "checked 2300 unions. Fused: 0\n",
      "checked 2400 unions. Fused: 0\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 0\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 1 modules. writing... \n",
      "DONE   ****************************\n",
      "pruning all the modules collected. Partitions found: 50\n",
      "getting partition from tp-file: ../../results/papers/matrix/mentions/edges_mentions_weighted.csv_oslo_files/partitions_level_1\n",
      "56 groups found\n",
      "56 bss found\n",
      "checking similar modules\n",
      "\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 4\n",
      "checking homeless nodes\n",
      "writing final solution in file ../../results/papers/matrix/mentions/edges_mentions_weighted.csv_oslo_files/short_tp1\n",
      "******** module_collection ******** 4 modules. writing... \n",
      "DONE   ****************************\n",
      "hierarchies done ********* \n",
      "1282.4704468250275\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "!cd ../oslom/OSLOM2 && \\\n",
    "./oslom_dir -f ../../results/papers/matrix/mentions/edges_mentions_weighted.csv -w -r 10 -seed 430430 -cp 0.5\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "above-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.07510955505901\n"
     ]
    }
   ],
   "source": [
    "print((end - start)/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "liked-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, clusters = extract_oslom('../results/papers/matrix/mentions/edges_mentions_weighted.csv_oslo_files/tp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "original-bernard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167203</th>\n",
       "      <td>109433</td>\n",
       "      <td>23005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167204</th>\n",
       "      <td>137684</td>\n",
       "      <td>23006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167205</th>\n",
       "      <td>13040</td>\n",
       "      <td>23007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167206</th>\n",
       "      <td>143563</td>\n",
       "      <td>23008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167207</th>\n",
       "      <td>154893</td>\n",
       "      <td>23009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167208 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  cluster\n",
       "0         4592        0\n",
       "1         9452        0\n",
       "2        13208        0\n",
       "3        21829        0\n",
       "4        22921        0\n",
       "...        ...      ...\n",
       "167203  109433    23005\n",
       "167204  137684    23006\n",
       "167205   13040    23007\n",
       "167206  143563    23008\n",
       "167207  154893    23009\n",
       "\n",
       "[167208 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "regular-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_user_id(row):\n",
    "    return total_users[row[\"id\"]]\n",
    "\n",
    "train[\"real_user_id\"] = train.apply(get_original_user_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "enabling-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train_final = pd.merge(\n",
    "    left=train,\n",
    "    right=mahmud_mentions,\n",
    "    how='inner',\n",
    "    left_on=\"real_user_id\",\n",
    "    right_on=\"user_screen_name\",\n",
    "    validate=\"m:1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "determined-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>real_user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>mentions</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4592</td>\n",
       "      <td>0</td>\n",
       "      <td>PeterSchorschFL</td>\n",
       "      <td>PeterSchorschFL</td>\n",
       "      <td>[KirkPepper, brianjburgess, KirkPepper, brianj...</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9452</td>\n",
       "      <td>0</td>\n",
       "      <td>jen_vt</td>\n",
       "      <td>jen_vt</td>\n",
       "      <td>[FrancoRipple, FLGovScott, adamsmithtimes, new...</td>\n",
       "      <td>Tampa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>5</td>\n",
       "      <td>DCornelius_44</td>\n",
       "      <td>DCornelius_44</td>\n",
       "      <td>[JDbbs79, Cassa_Bear, Cassa_Bear, Cassa_Bear, ...</td>\n",
       "      <td>Glendale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2077</td>\n",
       "      <td>5</td>\n",
       "      <td>GPA_Athletics</td>\n",
       "      <td>GPA_Athletics</td>\n",
       "      <td>[BlondieSoBrazyy, dcclopton, _nataleeee, Jb_do...</td>\n",
       "      <td>Glendale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3098</td>\n",
       "      <td>6</td>\n",
       "      <td>K_Gonze</td>\n",
       "      <td>K_Gonze</td>\n",
       "      <td>[fuckingzu5, Issjackie, fuckingzu5, fuckingzu5...</td>\n",
       "      <td>Riverside</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  cluster     real_user_id user_screen_name  \\\n",
       "0  4592        0  PeterSchorschFL  PeterSchorschFL   \n",
       "1  9452        0           jen_vt           jen_vt   \n",
       "2  1359        5    DCornelius_44    DCornelius_44   \n",
       "3  2077        5    GPA_Athletics    GPA_Athletics   \n",
       "4  3098        6          K_Gonze          K_Gonze   \n",
       "\n",
       "                                            mentions              City  \n",
       "0  [KirkPepper, brianjburgess, KirkPepper, brianj...  Saint Petersburg  \n",
       "1  [FrancoRipple, FLGovScott, adamsmithtimes, new...             Tampa  \n",
       "2  [JDbbs79, Cassa_Bear, Cassa_Bear, Cassa_Bear, ...          Glendale  \n",
       "3  [BlondieSoBrazyy, dcclopton, _nataleeee, Jb_do...          Glendale  \n",
       "4  [fuckingzu5, Issjackie, fuckingzu5, fuckingzu5...         Riverside  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "removable-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train_final = users_train_final.loc[:, [\"real_user_id\", \"cluster\", \"City\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "christian-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train_final = users_train_final.groupby(\n",
    "        [\"real_user_id\", \"City\"]\n",
    "    )['cluster'].apply(list).reset_index(name='clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "communist-uncle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_user_id</th>\n",
       "      <th>City</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0305_adriana</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>[238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017leech</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>[291]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101SweetCandy</td>\n",
       "      <td>Madison</td>\n",
       "      <td>[81]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11SaraC</td>\n",
       "      <td>Madison</td>\n",
       "      <td>[306]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13sa25</td>\n",
       "      <td>Oxnard</td>\n",
       "      <td>[182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>zombiecomin4u</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>[192]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>zoswizard</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>[246]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5597</th>\n",
       "      <td>zrmoyers</td>\n",
       "      <td>Austin</td>\n",
       "      <td>[80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>ztbarr</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>[23001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>ztftw</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>[205]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5600 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       real_user_id         City clusters\n",
       "0      0305_adriana     San Jose    [238]\n",
       "1         1017leech     Columbus    [291]\n",
       "2     101SweetCandy      Madison     [81]\n",
       "3           11SaraC      Madison    [306]\n",
       "4            13sa25       Oxnard    [182]\n",
       "...             ...          ...      ...\n",
       "5595  zombiecomin4u    San Diego    [192]\n",
       "5596      zoswizard        Tampa    [246]\n",
       "5597       zrmoyers       Austin     [80]\n",
       "5598         ztbarr  Jersey City  [23001]\n",
       "5599          ztftw      Chicago    [205]\n",
       "\n",
       "[5600 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "choice-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_to_use = users_train_final.groupby(\"City\").count().sort_values('real_user_id', ascending=True).reset_index()\n",
    "cities_to_use = cities_to_use.loc[cities_to_use[\"real_user_id\"] >= 7, [\"City\"]]\n",
    "cities_to_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "incident-illness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5587, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final = pd.merge(\n",
    "    left=cities_to_use,\n",
    "    right=users_train_final,\n",
    "    how='inner',\n",
    "    on='City'\n",
    ")\n",
    "\n",
    "users_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "intelligent-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_city = users_train_final[\"City\"].values\n",
    "class_names = sorted(users_train_final['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "spectacular-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train_final[\"clusters\"] = users_train_final[\"clusters\"].apply(lambda l: list(map(str, l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "regulated-handbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5587x1211 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5582 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents=\"ascii\",\n",
    "    lowercase=False,\n",
    ")\n",
    "\n",
    "vector_of_clusters = vectorizer.fit_transform(users_train_final[\"clusters\"].apply(lambda x: ' '.join(x))).astype('bool').astype('int')\n",
    "vector_of_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "mighty-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    {\n",
    "        \"name\": \"LightGBM\",\n",
    "        \"estimator\": lgb.LGBMClassifier(n_jobs=1, objective=\"multiclass\", random_state=1500),\n",
    "        \"params_grid\": {'max_depth': [8, 80, 200, -1], 'class_weight': ['balanced']}\n",
    "    },    \n",
    "    {\n",
    "        \"name\": \"SVC\",\n",
    "        \"estimator\": SVC(kernel=\"rbf\", probability=True, random_state=1500),\n",
    "        \"params_grid\": {\"C\": [1, 10, 100], \"gamma\": [.01, .1], 'class_weight': ['balanced']}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DecisionTree\",\n",
    "        \"estimator\": DecisionTreeClassifier(random_state=1500),\n",
    "        \"params_grid\": {'max_depth': [8, 80, 200, 500, None], 'min_samples_leaf': [1], 'class_weight': ['balanced']}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RandomForest\",\n",
    "        \"estimator\": RandomForestClassifier(n_jobs=-1, random_state=1500),\n",
    "        \"params_grid\": {'max_depth': [8, 80, 200, 500, None], 'min_samples_leaf': [1], 'class_weight': ['balanced']}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "republican-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=44540570)\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=45405450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "consecutive-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "predictions = {}\n",
    "\n",
    "for estimator in estimators:\n",
    "    clf = GridSearchCV(\n",
    "        estimator=estimator[\"estimator\"],\n",
    "        param_grid=estimator[\"params_grid\"],\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo'],\n",
    "        refit='roc_auc_ovo'\n",
    "    )\n",
    "    \n",
    "    nested_score = cross_validate(\n",
    "        clf,\n",
    "        X=vector_of_clusters.astype('float'),\n",
    "        y=users_city,\n",
    "        cv=outer_cv,\n",
    "        n_jobs=-1,\n",
    "        scoring={\n",
    "            'accuracy': 'accuracy',\n",
    "            'balanced_accuracy': 'balanced_accuracy',\n",
    "            'roc_auc_ovo': 'roc_auc_ovo',\n",
    "           # 'accuracy@161': make_scorer(accuracy_161km, greater_is_better=True)            \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    nested_predict = cross_val_predict(\n",
    "        clf,\n",
    "        X=vector_of_clusters.astype('float'),\n",
    "        y=users_city,\n",
    "        cv=outer_cv,\n",
    "        n_jobs=-1,\n",
    "        method='predict'\n",
    "    )\n",
    "        \n",
    "    scores[estimator[\"name\"]] = nested_score\n",
    "    predictions[estimator[\"name\"]] = nested_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "composite-fisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LightGBM': {'fit_time': array([269.56962347, 271.62751508, 274.24053764, 272.31405616,\n",
       "         271.90705919]),\n",
       "  'score_time': array([10.10495472, 12.2074182 , 10.85857749, 10.40600538, 10.47162819]),\n",
       "  'test_accuracy': array([0.00447227, 0.00626118, 0.00626679, 0.00716204, 0.00447628]),\n",
       "  'test_balanced_accuracy': array([0.00559701, 0.00875681, 0.00746269, 0.00794243, 0.00621891]),\n",
       "  'test_roc_auc_ovo': array([0.52865718, 0.51618064, 0.5171967 , 0.52369961, 0.52737993])},\n",
       " 'SVC': {'fit_time': array([286.74503088, 287.5603354 , 290.43726778, 285.28668523,\n",
       "         295.26153445]),\n",
       "  'score_time': array([8.1479001 , 8.29206157, 7.97452235, 9.27672076, 7.82395244]),\n",
       "  'test_accuracy': array([0.02415027, 0.02415027, 0.01342883, 0.02238138, 0.02685765]),\n",
       "  'test_balanced_accuracy': array([0.02557432, 0.02476094, 0.01197584, 0.01968876, 0.02573765]),\n",
       "  'test_roc_auc_ovo': array([0.5226015 , 0.52648643, 0.52415862, 0.52031742, 0.52384439])},\n",
       " 'DecisionTree': {'fit_time': array([133.99841547, 139.01306534, 131.53511095, 132.62452173,\n",
       "         135.06324005]),\n",
       "  'score_time': array([6.45031381, 5.61978245, 7.3164413 , 7.25953674, 6.16303587]),\n",
       "  'test_accuracy': array([0.019678  , 0.02593918, 0.01253357, 0.02238138, 0.02148612]),\n",
       "  'test_balanced_accuracy': array([0.02097233, 0.02823168, 0.01371713, 0.02621861, 0.0226282 ]),\n",
       "  'test_roc_auc_ovo': array([0.53739502, 0.52462181, 0.51910763, 0.53563076, 0.53468957])},\n",
       " 'RandomForest': {'fit_time': array([158.16887903, 159.0862956 , 157.52235341, 160.16921401,\n",
       "         160.80133867]),\n",
       "  'score_time': array([8.58743572, 7.228549  , 7.66241693, 6.53038788, 6.12868547]),\n",
       "  'test_accuracy': array([0.019678  , 0.02415027, 0.01611459, 0.02238138, 0.02148612]),\n",
       "  'test_balanced_accuracy': array([0.0200272 , 0.0233233 , 0.01513052, 0.02208065, 0.02195847]),\n",
       "  'test_roc_auc_ovo': array([0.54312713, 0.53264481, 0.53073387, 0.54211158, 0.53785315])}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-buffer",
   "metadata": {},
   "source": [
    "# Twitter NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-threat",
   "metadata": {},
   "source": [
    "# TWITTER NA - Finding mentions and parsing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "reduced-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=[\"username\", \"latitude\", \"longitude\", \"all_tweets\"]\n",
    "usecols=[\"username\", \"latitude\", \"longitude\", \"all_tweets\"]\n",
    "\n",
    "dtypes = {\n",
    "    \"username\": str,\n",
    "    \"all_tweets\": str,\n",
    "    \"latitude\": np.longdouble,\n",
    "    \"longitude\": np.longdouble,\n",
    "}\n",
    "\n",
    "train_na = pd.read_csv(\"../../location/datasets/na/user_info.train\", sep=\"\\t\", names=colnames, usecols=usecols, dtype=dtypes)\n",
    "test_na = pd.read_csv(\"../../location/datasets/na/user_info.test\", sep=\"\\t\", names=colnames, usecols=usecols, dtype=dtypes)\n",
    "val_na = pd.read_csv(\"../../location/datasets/na/user_info.dev\", sep=\"\\t\", names=colnames, usecols=usecols, dtype=dtypes)\n",
    "\n",
    "twitter_na = pd.concat([train_na, val_na, test_na])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "turned-canadian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449650, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "turkish-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>I'm at Subway (327 N Main St, Frankenmuth) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164857</td>\n",
       "      <td>-79.055586</td>\n",
       "      <td>What's up, Tweet us let's chat! ||| Please lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarahset24</td>\n",
       "      <td>35.831288</td>\n",
       "      <td>-83.573236</td>\n",
       "      <td>These horses are wearing diapers.. and clearly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javeonthaprince</td>\n",
       "      <td>31.299422</td>\n",
       "      <td>-92.486251</td>\n",
       "      <td>@SlimGotDimples damn slim ya twin was on tha m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KushNMyTweet__</td>\n",
       "      <td>33.366996</td>\n",
       "      <td>-86.818111</td>\n",
       "      <td>If you see ian say nun the first time, why are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   latitude  longitude  \\\n",
       "0  DanielPPeterson  43.478622 -84.014946   \n",
       "1   530productions  43.164857 -79.055586   \n",
       "2       sarahset24  35.831288 -83.573236   \n",
       "3  Javeonthaprince  31.299422 -92.486251   \n",
       "4   KushNMyTweet__  33.366996 -86.818111   \n",
       "\n",
       "                                          all_tweets  \n",
       "0  I'm at Subway (327 N Main St, Frankenmuth) htt...  \n",
       "1  What's up, Tweet us let's chat! ||| Please lik...  \n",
       "2  These horses are wearing diapers.. and clearly...  \n",
       "3  @SlimGotDimples damn slim ya twin was on tha m...  \n",
       "4  If you see ian say nun the first time, why are...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-plymouth",
   "metadata": {},
   "source": [
    "Tenemos usuarios con username parecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cross-injection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227599</th>\n",
       "      <td>1DecAsh</td>\n",
       "      <td>36.779057</td>\n",
       "      <td>-121.669487</td>\n",
       "      <td>@_JuicyJenny I fb'd you my reply was too passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370193</th>\n",
       "      <td>1decash</td>\n",
       "      <td>36.698647</td>\n",
       "      <td>-121.652794</td>\n",
       "      <td>Damn that lady has a big ass! ||| @T_ROY01 lol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>2GuddaGoneWild</td>\n",
       "      <td>34.073830</td>\n",
       "      <td>-88.706757</td>\n",
       "      <td>Off work Finna go get the hair cut my ride jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22999</th>\n",
       "      <td>2Guddagonewild</td>\n",
       "      <td>34.105965</td>\n",
       "      <td>-88.859779</td>\n",
       "      <td>@townsendboi: Ion like skool 4 shitNIGGA STOP....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21925</th>\n",
       "      <td>4EVERUrsDarlene</td>\n",
       "      <td>40.842541</td>\n",
       "      <td>-73.937218</td>\n",
       "      <td>Funny shit is that the white ppl really be lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55442</th>\n",
       "      <td>4everUrsDarlene</td>\n",
       "      <td>40.842834</td>\n",
       "      <td>-73.938408</td>\n",
       "      <td>@spectacular172 wayy better thnx,give me a hin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129939</th>\n",
       "      <td>ABSOLUTELYkerr</td>\n",
       "      <td>34.065910</td>\n",
       "      <td>-118.195702</td>\n",
       "      <td>69? ||| ew. sorry but theres nothing i hate mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77215</th>\n",
       "      <td>AErnisse2</td>\n",
       "      <td>43.741806</td>\n",
       "      <td>-87.830482</td>\n",
       "      <td>Fuck why does everything bad happen when somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51923</th>\n",
       "      <td>AJ_Rotger</td>\n",
       "      <td>41.571053</td>\n",
       "      <td>-74.030800</td>\n",
       "      <td>@NickSwisher thanks for the DP was cool to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129652</th>\n",
       "      <td>ALEXACUSTODIOnj</td>\n",
       "      <td>39.403629</td>\n",
       "      <td>-74.659271</td>\n",
       "      <td>@Foboman this is a little creepy but I was jus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username   latitude   longitude  \\\n",
       "227599          1DecAsh  36.779057 -121.669487   \n",
       "370193          1decash  36.698647 -121.652794   \n",
       "7717     2GuddaGoneWild  34.073830  -88.706757   \n",
       "22999    2Guddagonewild  34.105965  -88.859779   \n",
       "21925   4EVERUrsDarlene  40.842541  -73.937218   \n",
       "55442   4everUrsDarlene  40.842834  -73.938408   \n",
       "129939   ABSOLUTELYkerr  34.065910 -118.195702   \n",
       "77215         AErnisse2  43.741806  -87.830482   \n",
       "51923         AJ_Rotger  41.571053  -74.030800   \n",
       "129652  ALEXACUSTODIOnj  39.403629  -74.659271   \n",
       "\n",
       "                                               all_tweets  \n",
       "227599  @_JuicyJenny I fb'd you my reply was too passi...  \n",
       "370193  Damn that lady has a big ass! ||| @T_ROY01 lol...  \n",
       "7717    Off work Finna go get the hair cut my ride jus...  \n",
       "22999   @townsendboi: Ion like skool 4 shitNIGGA STOP....  \n",
       "21925   Funny shit is that the white ppl really be lik...  \n",
       "55442   @spectacular172 wayy better thnx,give me a hin...  \n",
       "129939  69? ||| ew. sorry but theres nothing i hate mo...  \n",
       "77215   Fuck why does everything bad happen when somet...  \n",
       "51923   @NickSwisher thanks for the DP was cool to be ...  \n",
       "129652  @Foboman this is a little creepy but I was jus...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na[twitter_na[\"username\"].str.lower().duplicated(keep=False)].sort_values(\"username\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opponent-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_mentions(row):\n",
    "    if row[\"all_tweets\"] is None:\n",
    "        return None\n",
    "    \n",
    "    all_mentions = [x[1:] for x in re.findall(r'@\\w+', str(row[\"all_tweets\"]))]\n",
    "    \n",
    "    return [x for x in all_mentions if x != row[\"username\"]]\n",
    "\n",
    "twitter_na[\"mentions\"] = twitter_na.apply(retrieve_mentions, axis=1)\n",
    "\n",
    "def retrieve_hashtags(row):\n",
    "    if row[\"all_tweets\"] is None:\n",
    "        return None\n",
    "    \n",
    "    all_hashtags = [x[1:] for x in re.findall(r'#\\w+', str(row[\"all_tweets\"]))]\n",
    "    \n",
    "    return [x for x in all_hashtags]\n",
    "\n",
    "twitter_na[\"mentions\"] = twitter_na.apply(retrieve_mentions, axis=1)\n",
    "twitter_na[\"hashtags\"] = twitter_na.apply(retrieve_hashtags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "biblical-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>I'm at Subway (327 N Main St, Frankenmuth) htt...</td>\n",
       "      <td>[foursquare, foursquare, foursquare, foursquar...</td>\n",
       "      <td>[justsayin, fb, fb, fb, goblue, fb, rockandrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164856</td>\n",
       "      <td>-79.055588</td>\n",
       "      <td>What's up, Tweet us let's chat! ||| Please lik...</td>\n",
       "      <td>[lestackmusic]</td>\n",
       "      <td>[nowplaying, nobodyshero]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarahset24</td>\n",
       "      <td>35.831287</td>\n",
       "      <td>-83.573235</td>\n",
       "      <td>These horses are wearing diapers.. and clearly...</td>\n",
       "      <td>[taydillibar13, BrandonKIsaacs, drew_truitt, M...</td>\n",
       "      <td>[yum, ewww, yum, twitterless, ridiculous, smh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javeonthaprince</td>\n",
       "      <td>31.299423</td>\n",
       "      <td>-92.486252</td>\n",
       "      <td>@SlimGotDimples damn slim ya twin was on tha m...</td>\n",
       "      <td>[SlimGotDimples, Chyna_Doll_89, MR_YMCMB, Rec_...</td>\n",
       "      <td>[wetwetfarting, ihate, ItsokayToCheatif, zzzzz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KushNMyTweet__</td>\n",
       "      <td>33.366997</td>\n",
       "      <td>-86.818108</td>\n",
       "      <td>If you see ian say nun the first time, why are...</td>\n",
       "      <td>[uHO3S_EnvyMe]</td>\n",
       "      <td>[WhenIWasLittle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   latitude  longitude  \\\n",
       "0  DanielPPeterson  43.478622 -84.014946   \n",
       "1   530productions  43.164856 -79.055588   \n",
       "2       sarahset24  35.831287 -83.573235   \n",
       "3  Javeonthaprince  31.299423 -92.486252   \n",
       "4   KushNMyTweet__  33.366997 -86.818108   \n",
       "\n",
       "                                          all_tweets  \\\n",
       "0  I'm at Subway (327 N Main St, Frankenmuth) htt...   \n",
       "1  What's up, Tweet us let's chat! ||| Please lik...   \n",
       "2  These horses are wearing diapers.. and clearly...   \n",
       "3  @SlimGotDimples damn slim ya twin was on tha m...   \n",
       "4  If you see ian say nun the first time, why are...   \n",
       "\n",
       "                                            mentions  \\\n",
       "0  [foursquare, foursquare, foursquare, foursquar...   \n",
       "1                                     [lestackmusic]   \n",
       "2  [taydillibar13, BrandonKIsaacs, drew_truitt, M...   \n",
       "3  [SlimGotDimples, Chyna_Doll_89, MR_YMCMB, Rec_...   \n",
       "4                                     [uHO3S_EnvyMe]   \n",
       "\n",
       "                                            hashtags  \n",
       "0  [justsayin, fb, fb, fb, goblue, fb, rockandrol...  \n",
       "1                          [nowplaying, nobodyshero]  \n",
       "2     [yum, ewww, yum, twitterless, ridiculous, smh]  \n",
       "3  [wetwetfarting, ihate, ItsokayToCheatif, zzzzz...  \n",
       "4                                   [WhenIWasLittle]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amino-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = [\n",
    "    r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})',\n",
    "    r'@\\w+',\n",
    "    r'#\\w+',\n",
    "    r'[!\"$%&()*+,-./:;<=>?[\\]^_`{}~#@]',\n",
    "    r'(?<=[a-z])\\'(?=[a-z])'\n",
    "]\n",
    "\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "\n",
    "def parse_tweets(tweets):\n",
    "    try:\n",
    "        tweets = tweets.lower()\n",
    "\n",
    "        for replacement in replacements:\n",
    "            tweets = re.sub(replacement, '', tweets) \n",
    "        tweets = re.sub(emoji.get_emoji_regexp(), '', tweets)\n",
    "        tweets = re.sub(r'\\r\\n?|\\n', ' ', tweets)\n",
    "        tweets = tweets.replace('\\'', '')\n",
    "        tweets = pattern.sub('', tweets)\n",
    "        tweets = ' '.join(tweets.split())\n",
    "        \n",
    "        return tweets\n",
    "    except:\n",
    "        print(\"Exception\")\n",
    "        return tweets\n",
    "    \n",
    "def simple_parse(row):\n",
    "    tweets = row[\"all_tweets\"]\n",
    "    \n",
    "    return parse_tweets(tweets)\n",
    "\n",
    "twitter_na[\"all_tweets\"] = twitter_na.apply(simple_parse, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "junior-assault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       im subway 327 n main st frankenmuth ||| im ste...\n",
       "1       whats tweet us lets chat ||| please like us fa...\n",
       "2       horses wearing diapers clearly theyre full eww...\n",
       "3       damn slim ya twin tha move cummin tha schultz ...\n",
       "4       see ian say nun first time still trying ||| le...\n",
       "                              ...                        \n",
       "9995    mane ear still hurt ||| bit lol ||| cant tell ...\n",
       "9996    ||| could possibly want christmas dinner movie...\n",
       "9997    dont see room jesus ||| cant see ||| adam time...\n",
       "9998    taking one head ||| first tweet month ||| ahhh...\n",
       "9999    finally found car dunn loringmerrifield metro ...\n",
       "Name: all_tweets, Length: 449650, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na[\"all_tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brazilian-rough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>im subway 327 n main st frankenmuth ||| im ste...</td>\n",
       "      <td>[justsayin, fb, fb, fb, goblue, fb, rockandrol...</td>\n",
       "      <td>[clgray64, AntBlair4Real, AntBlair4Real, AntBl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164856</td>\n",
       "      <td>-79.055588</td>\n",
       "      <td>whats tweet us lets chat ||| please like us fa...</td>\n",
       "      <td>[nowplaying, nobodyshero]</td>\n",
       "      <td>[lestackmusic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarahset24</td>\n",
       "      <td>35.831287</td>\n",
       "      <td>-83.573235</td>\n",
       "      <td>horses wearing diapers clearly theyre full eww...</td>\n",
       "      <td>[yum, ewww, yum, twitterless, ridiculous, smh]</td>\n",
       "      <td>[taydillibar13, taydillibar13, taydillibar13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javeonthaprince</td>\n",
       "      <td>31.299423</td>\n",
       "      <td>-92.486252</td>\n",
       "      <td>damn slim ya twin tha move cummin tha schultz ...</td>\n",
       "      <td>[wetwetfarting, ihate, ItsokayToCheatif, zzzzz...</td>\n",
       "      <td>[SlimGotDimples, SlimGotDimples, Chyna_Doll_89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KushNMyTweet__</td>\n",
       "      <td>33.366997</td>\n",
       "      <td>-86.818108</td>\n",
       "      <td>see ian say nun first time still trying ||| le...</td>\n",
       "      <td>[WhenIWasLittle]</td>\n",
       "      <td>[uHO3S_EnvyMe]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   latitude  longitude  \\\n",
       "0  DanielPPeterson  43.478622 -84.014946   \n",
       "1   530productions  43.164856 -79.055588   \n",
       "2       sarahset24  35.831287 -83.573235   \n",
       "3  Javeonthaprince  31.299423 -92.486252   \n",
       "4   KushNMyTweet__  33.366997 -86.818108   \n",
       "\n",
       "                                          all_tweets  \\\n",
       "0  im subway 327 n main st frankenmuth ||| im ste...   \n",
       "1  whats tweet us lets chat ||| please like us fa...   \n",
       "2  horses wearing diapers clearly theyre full eww...   \n",
       "3  damn slim ya twin tha move cummin tha schultz ...   \n",
       "4  see ian say nun first time still trying ||| le...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [justsayin, fb, fb, fb, goblue, fb, rockandrol...   \n",
       "1                          [nowplaying, nobodyshero]   \n",
       "2     [yum, ewww, yum, twitterless, ridiculous, smh]   \n",
       "3  [wetwetfarting, ihate, ItsokayToCheatif, zzzzz...   \n",
       "4                                   [WhenIWasLittle]   \n",
       "\n",
       "                                            mentions  \n",
       "0  [clgray64, AntBlair4Real, AntBlair4Real, AntBl...  \n",
       "1                                     [lestackmusic]  \n",
       "2  [taydillibar13, taydillibar13, taydillibar13, ...  \n",
       "3  [SlimGotDimples, SlimGotDimples, Chyna_Doll_89...  \n",
       "4                                     [uHO3S_EnvyMe]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_unique_mentions = 20\n",
    "\n",
    "twitter_na_ex = twitter_na.explode(column=\"mentions\").loc[:, [\"username\", \"mentions\"]]\n",
    "count_mentions = twitter_na_ex.drop_duplicates()\n",
    "count_mentions = count_mentions.groupby(\"mentions\").count().reset_index()\n",
    "count_mentions = count_mentions[count_mentions[\"username\"] < max_unique_mentions].loc[:, [\"mentions\"]]\n",
    "\n",
    "twitter_na_ex = pd.merge(\n",
    "    left=twitter_na_ex,\n",
    "    right=count_mentions,\n",
    "    how='inner',\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "twitter_na_ex = twitter_na_ex.groupby(\n",
    "    [\"username\"]\n",
    ")['mentions'].apply(list).reset_index(name='mentions')\n",
    "\n",
    "twitter_na_co = pd.merge(\n",
    "    left=twitter_na.loc[:, [\"username\", \"latitude\", \"longitude\", \"all_tweets\", \"hashtags\"]],\n",
    "    right=twitter_na_ex,\n",
    "    how='left',\n",
    "    validate=\"1:m\"\n",
    ")\n",
    "\n",
    "twitter_na_co.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "complete-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_join(l):\n",
    "    try:\n",
    "        return '|||'.join(map(str, l))\n",
    "    except TypeError:\n",
    "        return np.nan\n",
    "\n",
    "twitter_na['mentions'] = [try_join(l) for l in twitter_na['mentions']]\n",
    "twitter_na_co['mentions'] = [try_join(l) for l in twitter_na_co['mentions']]\n",
    "twitter_na['hashtags'] = [try_join(l) for l in twitter_na['hashtags']]\n",
    "twitter_na_co['hashtags'] = [try_join(l) for l in twitter_na_co['hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ancient-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_na.to_csv(\"../../location/datasets/na/users_parsed.total\", index=False)\n",
    "twitter_na_co.to_csv(\"../../location/datasets/na/users_parsed_comentions.total\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-evolution",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "romance-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"username\": str,\n",
    "    \"all_tweets\": str,\n",
    "    \"latitude\": np.float32,\n",
    "    \"longitude\": np.float32,\n",
    "    \"mentions\": str,\n",
    "    \"hashtags\": str\n",
    "}\n",
    "\n",
    "twitter_na = pd.read_csv(\"../../location/datasets/na/users_parsed_comentions.total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "equal-violence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449650, 6)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "coated-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_mentions(row):\n",
    "    try:\n",
    "        return row[\"mentions\"].split('|||')\n",
    "    except:\n",
    "        return row[\"mentions\"]\n",
    "\n",
    "def string_to_hashtags(row):\n",
    "    try:\n",
    "        return row[\"hashtags\"].split('|||')\n",
    "    except:\n",
    "        return row[\"hashtags\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "federal-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_na['mentions'] = twitter_na.apply(string_to_mentions, axis=1)\n",
    "twitter_na['hashtags'] = twitter_na.apply(string_to_hashtags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ignored-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_na.loc[twitter_na['mentions'].isnull(), ['mentions']] = twitter_na.loc[twitter_na['mentions'].isnull(),'mentions'].apply(lambda x: [])\n",
    "twitter_na.loc[twitter_na['hashtags'].isnull(), ['hashtags']] = twitter_na.loc[twitter_na['hashtags'].isnull(),'hashtags'].apply(lambda x: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intensive-craps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>im subway 327 n main st frankenmuth ||| im ste...</td>\n",
       "      <td>[justsayin, fb, fb, fb, goblue, fb, rockandrol...</td>\n",
       "      <td>[clgray64, AntBlair4Real, AntBlair4Real, AntBl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164856</td>\n",
       "      <td>-79.055590</td>\n",
       "      <td>whats tweet us lets chat ||| please like us fa...</td>\n",
       "      <td>[nowplaying, nobodyshero]</td>\n",
       "      <td>[lestackmusic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarahset24</td>\n",
       "      <td>35.831287</td>\n",
       "      <td>-83.573235</td>\n",
       "      <td>horses wearing diapers clearly theyre full eww...</td>\n",
       "      <td>[yum, ewww, yum, twitterless, ridiculous, smh]</td>\n",
       "      <td>[taydillibar13, taydillibar13, taydillibar13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javeonthaprince</td>\n",
       "      <td>31.299423</td>\n",
       "      <td>-92.486250</td>\n",
       "      <td>damn slim ya twin tha move cummin tha schultz ...</td>\n",
       "      <td>[wetwetfarting, ihate, ItsokayToCheatif, zzzzz...</td>\n",
       "      <td>[SlimGotDimples, SlimGotDimples, Chyna_Doll_89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KushNMyTweet__</td>\n",
       "      <td>33.366997</td>\n",
       "      <td>-86.818110</td>\n",
       "      <td>see ian say nun first time still trying ||| le...</td>\n",
       "      <td>[WhenIWasLittle]</td>\n",
       "      <td>[uHO3S_EnvyMe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449645</th>\n",
       "      <td>Cbookie_225</td>\n",
       "      <td>32.413740</td>\n",
       "      <td>-93.779050</td>\n",
       "      <td>mane ear still hurt ||| bit lol ||| cant tell ...</td>\n",
       "      <td>[basketball4lyfe, np, Motorolawalkietalkie, wi...</td>\n",
       "      <td>[Hi_imTAYlORR, Hi_imTAYlORR, RichKidAjXXX, The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449646</th>\n",
       "      <td>jenii_babyy</td>\n",
       "      <td>29.420090</td>\n",
       "      <td>-98.497410</td>\n",
       "      <td>||| could possibly want christmas dinner movie...</td>\n",
       "      <td>[headshot, tacos, coleworld, WTF, johnstina, r...</td>\n",
       "      <td>[SweetAssSteph, Zombree2312, Zombree2312, Zomb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449647</th>\n",
       "      <td>haleyringo</td>\n",
       "      <td>32.902134</td>\n",
       "      <td>-96.984276</td>\n",
       "      <td>dont see room jesus ||| cant see ||| adam time...</td>\n",
       "      <td>[fog, isthatamaninthebackground, neverreallygo...</td>\n",
       "      <td>[michaelbleecker, ryan_polly, ryan_polly, ryan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449648</th>\n",
       "      <td>bummsayyo</td>\n",
       "      <td>34.084850</td>\n",
       "      <td>-117.383160</td>\n",
       "      <td>taking one head ||| first tweet month ||| ahhh...</td>\n",
       "      <td>[justSaying]</td>\n",
       "      <td>[DjWall_e, DjWall_e, CloserProds, CloserProds,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449649</th>\n",
       "      <td>d0uble_0_Saat</td>\n",
       "      <td>38.860294</td>\n",
       "      <td>-77.230250</td>\n",
       "      <td>finally found car dunn loringmerrifield metro ...</td>\n",
       "      <td>[Rockboyz, ftw, troublemaker, proudonlybrother...</td>\n",
       "      <td>[jasleenk, mhaque86, mhaque86, mhaque86, mhaqu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449650 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username   latitude   longitude  \\\n",
       "0       DanielPPeterson  43.478622  -84.014946   \n",
       "1        530productions  43.164856  -79.055590   \n",
       "2            sarahset24  35.831287  -83.573235   \n",
       "3       Javeonthaprince  31.299423  -92.486250   \n",
       "4        KushNMyTweet__  33.366997  -86.818110   \n",
       "...                 ...        ...         ...   \n",
       "449645      Cbookie_225  32.413740  -93.779050   \n",
       "449646      jenii_babyy  29.420090  -98.497410   \n",
       "449647       haleyringo  32.902134  -96.984276   \n",
       "449648        bummsayyo  34.084850 -117.383160   \n",
       "449649    d0uble_0_Saat  38.860294  -77.230250   \n",
       "\n",
       "                                               all_tweets  \\\n",
       "0       im subway 327 n main st frankenmuth ||| im ste...   \n",
       "1       whats tweet us lets chat ||| please like us fa...   \n",
       "2       horses wearing diapers clearly theyre full eww...   \n",
       "3       damn slim ya twin tha move cummin tha schultz ...   \n",
       "4       see ian say nun first time still trying ||| le...   \n",
       "...                                                   ...   \n",
       "449645  mane ear still hurt ||| bit lol ||| cant tell ...   \n",
       "449646  ||| could possibly want christmas dinner movie...   \n",
       "449647  dont see room jesus ||| cant see ||| adam time...   \n",
       "449648  taking one head ||| first tweet month ||| ahhh...   \n",
       "449649  finally found car dunn loringmerrifield metro ...   \n",
       "\n",
       "                                                 hashtags  \\\n",
       "0       [justsayin, fb, fb, fb, goblue, fb, rockandrol...   \n",
       "1                               [nowplaying, nobodyshero]   \n",
       "2          [yum, ewww, yum, twitterless, ridiculous, smh]   \n",
       "3       [wetwetfarting, ihate, ItsokayToCheatif, zzzzz...   \n",
       "4                                        [WhenIWasLittle]   \n",
       "...                                                   ...   \n",
       "449645  [basketball4lyfe, np, Motorolawalkietalkie, wi...   \n",
       "449646  [headshot, tacos, coleworld, WTF, johnstina, r...   \n",
       "449647  [fog, isthatamaninthebackground, neverreallygo...   \n",
       "449648                                       [justSaying]   \n",
       "449649  [Rockboyz, ftw, troublemaker, proudonlybrother...   \n",
       "\n",
       "                                                 mentions  \n",
       "0       [clgray64, AntBlair4Real, AntBlair4Real, AntBl...  \n",
       "1                                          [lestackmusic]  \n",
       "2       [taydillibar13, taydillibar13, taydillibar13, ...  \n",
       "3       [SlimGotDimples, SlimGotDimples, Chyna_Doll_89...  \n",
       "4                                          [uHO3S_EnvyMe]  \n",
       "...                                                   ...  \n",
       "449645  [Hi_imTAYlORR, Hi_imTAYlORR, RichKidAjXXX, The...  \n",
       "449646  [SweetAssSteph, Zombree2312, Zombree2312, Zomb...  \n",
       "449647  [michaelbleecker, ryan_polly, ryan_polly, ryan...  \n",
       "449648  [DjWall_e, DjWall_e, CloserProds, CloserProds,...  \n",
       "449649  [jasleenk, mhaque86, mhaque86, mhaque86, mhaqu...  \n",
       "\n",
       "[449650 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "second-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(row):\n",
    "    try:\n",
    "        return row[\"hashtags\"].lower()\n",
    "    except:\n",
    "        return row[\"hashtags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "marked-timer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47414, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags_used = twitter_na.loc[:, [\"username\", \"hashtags\"]]\n",
    "hashtags_used = hashtags_used.explode(\"hashtags\")\n",
    "hashtags_used[\"hashtags\"] = hashtags_used.apply(to_lower, axis=1)\n",
    "hashtags_used = hashtags_used.drop_duplicates()\n",
    "\n",
    "hashtags_count = hashtags_used.groupby(\"hashtags\").count().reset_index()\n",
    "hashtags_count = hashtags_count.loc[hashtags_count[\"username\"] > 10, [\"hashtags\"]]\n",
    "hashtags_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "chinese-liberty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6151442, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags_used = pd.merge(\n",
    "    left=hashtags_used,\n",
    "    right=hashtags_count,\n",
    "    how='left',\n",
    "    left_on='hashtags',\n",
    "    right_on='hashtags'\n",
    ")\n",
    "\n",
    "hashtags_used.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eleven-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_used = hashtags_used.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "narrow-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379661, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags_used = hashtags_used.groupby(\n",
    "    [\"username\"]\n",
    ")['hashtags'].apply(list).reset_index(name='hashtags')\n",
    "\n",
    "hashtags_used.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "featured-appraisal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449650, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del twitter_na[\"hashtags\"]\n",
    "\n",
    "twitter_na = pd.merge(\n",
    "    left=twitter_na,\n",
    "    right=hashtags_used,\n",
    "    how='left',\n",
    "    left_on='username',\n",
    "    right_on='username'\n",
    ")\n",
    "\n",
    "twitter_na.loc[twitter_na['hashtags'].isnull(), ['hashtags']] = twitter_na.loc[twitter_na['hashtags'].isnull(),'hashtags'].apply(lambda x: [])\n",
    "twitter_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sensitive-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_na.dropna(subset=[\"mentions\"], inplace=True)\n",
    "#twitter_na.reset_index(drop=True, inplace=True)\n",
    "#twitter_na.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-fishing",
   "metadata": {},
   "source": [
    "Armado matriz de menciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "compressed-abraham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449650, 13)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "vulnerable-thriller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4080831"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = twitter_na[\"username\"].unique()\n",
    "\n",
    "set_users = set(users_ids)\n",
    "\n",
    "for x in twitter_na[\"mentions\"].to_numpy():\n",
    "    set_users |= set(x)\n",
    "\n",
    "mentioned_users = list(set_users.difference(set(users_ids)))\n",
    "\n",
    "total_users = list(users_ids) + mentioned_users\n",
    "len(total_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "subject-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Verify order\n",
    "\n",
    "value = True\n",
    "\n",
    "for i in range(0, len(twitter_na[\"username\"])):\n",
    "    if total_users[i] != twitter_na[\"username\"][i]:\n",
    "        value = False\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "quantitative-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_mentions_dir = nx.DiGraph()\n",
    "\n",
    "graph_mentions_dir.add_nodes_from(users_ids)\n",
    "\n",
    "for user_id, users_mentioned in zip(users_ids, twitter_na[\"mentions\"].to_numpy()):\n",
    "    ocurrences = list(Counter(users_mentioned).items())\n",
    "            \n",
    "    graph_mentions_dir.add_weighted_edges_from(list(map(lambda x: (user_id, x[0], x[1]), ocurrences)))\n",
    "                    \n",
    "graph_mentions_dir.remove_edges_from(nx.selfloop_edges(graph_mentions_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "noted-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4080831x4080831 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 6477659 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_dir = nx.adjacency_matrix(graph_mentions_dir, nodelist=total_users).astype(np.uint8)\n",
    "vector_of_mentions_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "portable-paste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<449650x449650 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 451714 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_dir_local = vector_of_mentions_dir[0:len(users_ids), 0:len(users_ids)]\n",
    "vector_of_mentions_dir_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "boring-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<449650x449650 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 748308 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_undir_local = vector_of_mentions_dir_local + vector_of_mentions_dir_local.T\n",
    "vector_of_mentions_undir_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "educated-country",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<449650x3631181 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 6025945 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_dir_bip = vector_of_mentions_dir[:len(users_ids), len(users_ids):]\n",
    "# Convertimos a bool para que los pesos de las aristas pasen a ser todos 1\n",
    "vector_of_mentions_dir_bip = vector_of_mentions_dir_bip.astype(bool).astype(np.uint8)\n",
    "vector_of_mentions_dir_bip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ceramic-distribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<449650x449650 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 11255728 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_comentions_ext = vector_of_mentions_dir_bip.dot(vector_of_mentions_dir_bip.T)\n",
    "# Eliminamos la diagonal\n",
    "vector_of_comentions_ext.setdiag(0, k=0)\n",
    "vector_of_comentions_ext.eliminate_zeros()\n",
    "vector_of_comentions_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "operating-austria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<449650x449650 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 11688798 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_col_mentions = vector_of_mentions_undir_local + vector_of_comentions_ext\n",
    "vector_of_col_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "familiar-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_col_mentions.tocoo()\n",
    "edges = []\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_col_mentions.shape[0]):\n",
    "    already_passed[i] = []\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    if v <= 0:\n",
    "        continue\n",
    "    \n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "        \n",
    "    format_str = str(i) + \" \" + str(j) + \" \" + str(v)\n",
    "    edges.append(format_str)\n",
    "    \n",
    "    already_passed[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "institutional-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"edges\": edges})\n",
    "df.to_csv(\"../../results/papers/matrix/mentions/edges_colmentions_twitter_na.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-reminder",
   "metadata": {},
   "source": [
    "# Oslom runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-surfing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting -f\n",
      "setting -w\n",
      "setting -r\n",
      "setting -hr\n",
      "setting -seed\n",
      "setting -cp\n",
      "**************************************\n",
      "Threshold:\t\t\t0.1\n",
      "Network file:\t\t\t../../results/papers/matrix/mentions/edges_comentions_twitter_na.csv\n",
      "Weighted: yes\n",
      "First Level Runs:\t\t\t10\n",
      "Higher Level Runs:\t\t\t50\n",
      "-cp:\t\t\t0.5\n",
      "Random number generator seed:\t\t\t42\n",
      "**************************************\n",
      "\n",
      "allocating 12290698 factorials...\n",
      "done\n",
      "mkdir: cannot create directory ‚Äò../../results/papers/matrix/mentions/edges_comentions_twitter_na.csv_oslo_files‚Äô: File exists\n",
      "output files will be written in directory: ../../results/papers/matrix/mentions/edges_comentions_twitter_na.csv_oslo_files\n",
      "network:: 387205 nodes and 1.22907e+07 stubs;\t average degree = 31.7421\n",
      "STARTING! HIERARCHICAL LEVEL: 0\n",
      "***************************************************************** RUN: #1\n",
      "iteration: 0 number of modules: 81333\n",
      "iteration: 20 number of modules: 15633\n",
      "iteration: 40 number of modules: 15544\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 15887. Percentage nodes done: 0\n",
      "checked 100 modules 98 were found significant.  Modules to check: 15787. Percentage nodes done: 0.148601\n",
      "checked 200 modules 195 were found significant.  Modules to check: 15687. Percentage nodes done: 0.28809\n",
      "checked 300 modules 295 were found significant.  Modules to check: 15587. Percentage nodes done: 0.329154\n",
      "checked 400 modules 395 were found significant.  Modules to check: 15487. Percentage nodes done: 0.365047\n",
      "checked 500 modules 494 were found significant.  Modules to check: 15387. Percentage nodes done: 0.396338\n",
      "checked 600 modules 593 were found significant.  Modules to check: 15287. Percentage nodes done: 0.417107\n",
      "checked 700 modules 692 were found significant.  Modules to check: 15187. Percentage nodes done: 0.443086\n",
      "checked 800 modules 792 were found significant.  Modules to check: 15087. Percentage nodes done: 0.471358\n",
      "checked 900 modules 891 were found significant.  Modules to check: 14987. Percentage nodes done: 0.493578\n",
      "checked 1000 modules 991 were found significant.  Modules to check: 14887. Percentage nodes done: 0.510383\n",
      "checked 1100 modules 1089 were found significant.  Modules to check: 14787. Percentage nodes done: 0.525037\n",
      "checked 1200 modules 1189 were found significant.  Modules to check: 14687. Percentage nodes done: 0.542968\n",
      "checked 1300 modules 1289 were found significant.  Modules to check: 14587. Percentage nodes done: 0.558838\n",
      "checked 1400 modules 1388 were found significant.  Modules to check: 14487. Percentage nodes done: 0.573683\n",
      "checked 1500 modules 1488 were found significant.  Modules to check: 14387. Percentage nodes done: 0.586715\n",
      "checked 1600 modules 1588 were found significant.  Modules to check: 14287. Percentage nodes done: 0.599972\n",
      "checked 1700 modules 1688 were found significant.  Modules to check: 14187. Percentage nodes done: 0.609677\n",
      "checked 1800 modules 1788 were found significant.  Modules to check: 14087. Percentage nodes done: 0.61704\n",
      "checked 1900 modules 1887 were found significant.  Modules to check: 13987. Percentage nodes done: 0.629555\n",
      "checked 2000 modules 1985 were found significant.  Modules to check: 13887. Percentage nodes done: 0.638845\n",
      "checked 2100 modules 2085 were found significant.  Modules to check: 13787. Percentage nodes done: 0.64642\n",
      "checked 2200 modules 2185 were found significant.  Modules to check: 13687. Percentage nodes done: 0.655627\n",
      "checked 2300 modules 2285 were found significant.  Modules to check: 13587. Percentage nodes done: 0.663336\n",
      "checked 2400 modules 2384 were found significant.  Modules to check: 13487. Percentage nodes done: 0.671853\n",
      "checked 2500 modules 2484 were found significant.  Modules to check: 13387. Percentage nodes done: 0.682228\n",
      "checked 2600 modules 2584 were found significant.  Modules to check: 13287. Percentage nodes done: 0.690874\n",
      "checked 2700 modules 2684 were found significant.  Modules to check: 13187. Percentage nodes done: 0.699493\n",
      "checked 2800 modules 2780 were found significant.  Modules to check: 13087. Percentage nodes done: 0.705977\n",
      "checked 2900 modules 2879 were found significant.  Modules to check: 12987. Percentage nodes done: 0.711928\n",
      "checked 3000 modules 2978 were found significant.  Modules to check: 12887. Percentage nodes done: 0.719686\n",
      "checked 3100 modules 3077 were found significant.  Modules to check: 12787. Percentage nodes done: 0.725747\n",
      "checked 3200 modules 3177 were found significant.  Modules to check: 12687. Percentage nodes done: 0.731517\n",
      "checked 3300 modules 3277 were found significant.  Modules to check: 12587. Percentage nodes done: 0.737594\n",
      "checked 3400 modules 3376 were found significant.  Modules to check: 12487. Percentage nodes done: 0.743229\n",
      "checked 3500 modules 3474 were found significant.  Modules to check: 12387. Percentage nodes done: 0.748149\n",
      "checked 3600 modules 3574 were found significant.  Modules to check: 12287. Percentage nodes done: 0.754213\n",
      "checked 3700 modules 3672 were found significant.  Modules to check: 12187. Percentage nodes done: 0.760354\n",
      "checked 3800 modules 3772 were found significant.  Modules to check: 12087. Percentage nodes done: 0.765421\n",
      "checked 3900 modules 3872 were found significant.  Modules to check: 11987. Percentage nodes done: 0.770429\n",
      "checked 4000 modules 3971 were found significant.  Modules to check: 11887. Percentage nodes done: 0.776444\n",
      "checked 4100 modules 4071 were found significant.  Modules to check: 11787. Percentage nodes done: 0.781155\n",
      "checked 4200 modules 4171 were found significant.  Modules to check: 11687. Percentage nodes done: 0.786059\n",
      "checked 4300 modules 4271 were found significant.  Modules to check: 11587. Percentage nodes done: 0.790196\n",
      "checked 4400 modules 4371 were found significant.  Modules to check: 11487. Percentage nodes done: 0.794724\n",
      "checked 4500 modules 4471 were found significant.  Modules to check: 11387. Percentage nodes done: 0.799086\n",
      "checked 4600 modules 4571 were found significant.  Modules to check: 11287. Percentage nodes done: 0.802828\n",
      "checked 4700 modules 4671 were found significant.  Modules to check: 11187. Percentage nodes done: 0.807133\n",
      "checked 4800 modules 4771 were found significant.  Modules to check: 11087. Percentage nodes done: 0.811007\n",
      "checked 4900 modules 4870 were found significant.  Modules to check: 10987. Percentage nodes done: 0.81508\n",
      "checked 5000 modules 4968 were found significant.  Modules to check: 10887. Percentage nodes done: 0.819964\n",
      "checked 5100 modules 5066 were found significant.  Modules to check: 10787. Percentage nodes done: 0.823763\n",
      "checked 5200 modules 5165 were found significant.  Modules to check: 10687. Percentage nodes done: 0.8272\n",
      "checked 5300 modules 5265 were found significant.  Modules to check: 10587. Percentage nodes done: 0.830994\n",
      "checked 5400 modules 5363 were found significant.  Modules to check: 10487. Percentage nodes done: 0.834604\n",
      "checked 5500 modules 5461 were found significant.  Modules to check: 10387. Percentage nodes done: 0.838858\n",
      "checked 5600 modules 5559 were found significant.  Modules to check: 10287. Percentage nodes done: 0.8426\n",
      "checked 5700 modules 5658 were found significant.  Modules to check: 10187. Percentage nodes done: 0.846038\n",
      "checked 5800 modules 5758 were found significant.  Modules to check: 10087. Percentage nodes done: 0.848819\n",
      "checked 5900 modules 5856 were found significant.  Modules to check: 9987. Percentage nodes done: 0.85314\n",
      "checked 6000 modules 5954 were found significant.  Modules to check: 9887. Percentage nodes done: 0.856174\n",
      "checked 6100 modules 6053 were found significant.  Modules to check: 9787. Percentage nodes done: 0.859214\n",
      "checked 6200 modules 6153 were found significant.  Modules to check: 9687. Percentage nodes done: 0.86214\n",
      "checked 6300 modules 6252 were found significant.  Modules to check: 9587. Percentage nodes done: 0.865549\n",
      "checked 6400 modules 6350 were found significant.  Modules to check: 9487. Percentage nodes done: 0.869007\n",
      "checked 6500 modules 6448 were found significant.  Modules to check: 9387. Percentage nodes done: 0.871742\n",
      "checked 6600 modules 6545 were found significant.  Modules to check: 9287. Percentage nodes done: 0.874586\n",
      "checked 6700 modules 6642 were found significant.  Modules to check: 9187. Percentage nodes done: 0.877657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 6800 modules 6739 were found significant.  Modules to check: 9087. Percentage nodes done: 0.880348\n",
      "checked 6900 modules 6839 were found significant.  Modules to check: 8987. Percentage nodes done: 0.883111\n",
      "checked 7000 modules 6939 were found significant.  Modules to check: 8887. Percentage nodes done: 0.88622\n",
      "checked 7100 modules 7039 were found significant.  Modules to check: 8787. Percentage nodes done: 0.888713\n",
      "checked 7200 modules 7136 were found significant.  Modules to check: 8687. Percentage nodes done: 0.891329\n",
      "checked 7300 modules 7235 were found significant.  Modules to check: 8587. Percentage nodes done: 0.894087\n",
      "checked 7400 modules 7329 were found significant.  Modules to check: 8487. Percentage nodes done: 0.896329\n",
      "checked 7500 modules 7427 were found significant.  Modules to check: 8387. Percentage nodes done: 0.898914\n",
      "checked 7600 modules 7524 were found significant.  Modules to check: 8287. Percentage nodes done: 0.901215\n",
      "checked 7700 modules 7621 were found significant.  Modules to check: 8187. Percentage nodes done: 0.903377\n",
      "checked 7800 modules 7719 were found significant.  Modules to check: 8087. Percentage nodes done: 0.90574\n",
      "checked 7900 modules 7817 were found significant.  Modules to check: 7987. Percentage nodes done: 0.907876\n",
      "checked 8000 modules 7912 were found significant.  Modules to check: 7887. Percentage nodes done: 0.909993\n",
      "checked 8100 modules 8010 were found significant.  Modules to check: 7787. Percentage nodes done: 0.911964\n",
      "checked 8200 modules 8108 were found significant.  Modules to check: 7687. Percentage nodes done: 0.91442\n",
      "checked 8300 modules 8204 were found significant.  Modules to check: 7587. Percentage nodes done: 0.916502\n",
      "checked 8400 modules 8300 were found significant.  Modules to check: 7487. Percentage nodes done: 0.918408\n",
      "checked 8500 modules 8392 were found significant.  Modules to check: 7387. Percentage nodes done: 0.920115\n",
      "checked 8600 modules 8489 were found significant.  Modules to check: 7287. Percentage nodes done: 0.922101\n",
      "checked 8700 modules 8585 were found significant.  Modules to check: 7187. Percentage nodes done: 0.923831\n",
      "checked 8800 modules 8682 were found significant.  Modules to check: 7087. Percentage nodes done: 0.92592\n",
      "checked 8900 modules 8777 were found significant.  Modules to check: 6987. Percentage nodes done: 0.927705\n",
      "checked 9000 modules 8873 were found significant.  Modules to check: 6887. Percentage nodes done: 0.929422\n",
      "checked 9100 modules 8971 were found significant.  Modules to check: 6787. Percentage nodes done: 0.931096\n",
      "checked 9200 modules 9069 were found significant.  Modules to check: 6687. Percentage nodes done: 0.932891\n",
      "checked 9300 modules 9168 were found significant.  Modules to check: 6587. Percentage nodes done: 0.934619\n",
      "checked 9400 modules 9261 were found significant.  Modules to check: 6487. Percentage nodes done: 0.936486\n",
      "checked 9500 modules 9357 were found significant.  Modules to check: 6387. Percentage nodes done: 0.938159\n",
      "checked 9600 modules 9453 were found significant.  Modules to check: 6287. Percentage nodes done: 0.9399\n",
      "checked 9700 modules 9552 were found significant.  Modules to check: 6187. Percentage nodes done: 0.941478\n",
      "checked 9800 modules 9647 were found significant.  Modules to check: 6087. Percentage nodes done: 0.942999\n",
      "checked 9900 modules 9743 were found significant.  Modules to check: 5987. Percentage nodes done: 0.944544\n",
      "checked 10000 modules 9840 were found significant.  Modules to check: 5887. Percentage nodes done: 0.945876\n",
      "checked 10100 modules 9931 were found significant.  Modules to check: 5787. Percentage nodes done: 0.94749\n",
      "checked 10200 modules 10020 were found significant.  Modules to check: 5687. Percentage nodes done: 0.948774\n",
      "checked 10300 modules 10114 were found significant.  Modules to check: 5587. Percentage nodes done: 0.95029\n",
      "checked 10400 modules 10207 were found significant.  Modules to check: 5487. Percentage nodes done: 0.951602\n",
      "checked 10500 modules 10302 were found significant.  Modules to check: 5387. Percentage nodes done: 0.953015\n",
      "checked 10600 modules 10397 were found significant.  Modules to check: 5287. Percentage nodes done: 0.95437\n",
      "checked 10700 modules 10491 were found significant.  Modules to check: 5187. Percentage nodes done: 0.955592\n",
      "checked 10800 modules 10584 were found significant.  Modules to check: 5087. Percentage nodes done: 0.956832\n",
      "checked 10900 modules 10677 were found significant.  Modules to check: 4987. Percentage nodes done: 0.958082\n",
      "checked 11000 modules 10766 were found significant.  Modules to check: 4887. Percentage nodes done: 0.95935\n",
      "checked 11100 modules 10852 were found significant.  Modules to check: 4787. Percentage nodes done: 0.960447\n",
      "checked 11200 modules 10949 were found significant.  Modules to check: 4687. Percentage nodes done: 0.961653\n",
      "checked 11300 modules 11042 were found significant.  Modules to check: 4587. Percentage nodes done: 0.962808\n",
      "checked 11400 modules 11134 were found significant.  Modules to check: 4487. Percentage nodes done: 0.964058\n",
      "checked 11500 modules 11225 were found significant.  Modules to check: 4387. Percentage nodes done: 0.965261\n",
      "checked 11600 modules 11314 were found significant.  Modules to check: 4287. Percentage nodes done: 0.966377\n",
      "checked 11700 modules 11402 were found significant.  Modules to check: 4187. Percentage nodes done: 0.967611\n",
      "checked 11800 modules 11491 were found significant.  Modules to check: 4087. Percentage nodes done: 0.968694\n",
      "checked 11900 modules 11582 were found significant.  Modules to check: 3987. Percentage nodes done: 0.969786\n",
      "checked 12000 modules 11667 were found significant.  Modules to check: 3887. Percentage nodes done: 0.970801\n",
      "checked 12100 modules 11751 were found significant.  Modules to check: 3787. Percentage nodes done: 0.971837\n",
      "checked 12200 modules 11835 were found significant.  Modules to check: 3687. Percentage nodes done: 0.972795\n",
      "checked 12300 modules 11925 were found significant.  Modules to check: 3587. Percentage nodes done: 0.97381\n",
      "checked 12400 modules 12015 were found significant.  Modules to check: 3487. Percentage nodes done: 0.974776\n",
      "checked 12500 modules 12102 were found significant.  Modules to check: 3387. Percentage nodes done: 0.975811\n",
      "checked 12600 modules 12188 were found significant.  Modules to check: 3287. Percentage nodes done: 0.97671\n",
      "checked 12700 modules 12277 were found significant.  Modules to check: 3187. Percentage nodes done: 0.97772\n",
      "checked 12800 modules 12352 were found significant.  Modules to check: 3087. Percentage nodes done: 0.978637\n",
      "checked 12900 modules 12424 were found significant.  Modules to check: 2987. Percentage nodes done: 0.979507\n",
      "checked 13000 modules 12501 were found significant.  Modules to check: 2887. Percentage nodes done: 0.980426\n",
      "checked 13100 modules 12580 were found significant.  Modules to check: 2787. Percentage nodes done: 0.981312\n",
      "checked 13200 modules 12659 were found significant.  Modules to check: 2687. Percentage nodes done: 0.982175\n",
      "checked 13300 modules 12738 were found significant.  Modules to check: 2587. Percentage nodes done: 0.983071\n",
      "checked 13400 modules 12816 were found significant.  Modules to check: 2487. Percentage nodes done: 0.983869\n",
      "checked 13500 modules 12892 were found significant.  Modules to check: 2387. Percentage nodes done: 0.984652\n",
      "checked 13600 modules 12960 were found significant.  Modules to check: 2287. Percentage nodes done: 0.985452\n",
      "checked 13700 modules 13032 were found significant.  Modules to check: 2187. Percentage nodes done: 0.986201\n",
      "checked 13800 modules 13104 were found significant.  Modules to check: 2087. Percentage nodes done: 0.986914\n",
      "checked 13900 modules 13166 were found significant.  Modules to check: 1987. Percentage nodes done: 0.987645\n",
      "checked 14000 modules 13239 were found significant.  Modules to check: 1887. Percentage nodes done: 0.988399\n",
      "checked 14100 modules 13304 were found significant.  Modules to check: 1787. Percentage nodes done: 0.989125\n",
      "checked 14200 modules 13367 were found significant.  Modules to check: 1687. Percentage nodes done: 0.98984\n",
      "checked 14300 modules 13428 were found significant.  Modules to check: 1587. Percentage nodes done: 0.990555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 14400 modules 13486 were found significant.  Modules to check: 1487. Percentage nodes done: 0.991219\n",
      "checked 14500 modules 13536 were found significant.  Modules to check: 1387. Percentage nodes done: 0.991891\n",
      "checked 14600 modules 13591 were found significant.  Modules to check: 1287. Percentage nodes done: 0.992544\n",
      "checked 14700 modules 13638 were found significant.  Modules to check: 1187. Percentage nodes done: 0.993203\n",
      "checked 14800 modules 13686 were found significant.  Modules to check: 1087. Percentage nodes done: 0.993807\n",
      "checked 14900 modules 13741 were found significant.  Modules to check: 987. Percentage nodes done: 0.994419\n",
      "checked 15000 modules 13787 were found significant.  Modules to check: 887. Percentage nodes done: 0.995021\n",
      "checked 15100 modules 13830 were found significant.  Modules to check: 787. Percentage nodes done: 0.995617\n",
      "checked 15200 modules 13865 were found significant.  Modules to check: 687. Percentage nodes done: 0.996227\n",
      "checked 15300 modules 13900 were found significant.  Modules to check: 587. Percentage nodes done: 0.996813\n",
      "checked 15400 modules 13924 were found significant.  Modules to check: 487. Percentage nodes done: 0.997363\n",
      "checked 15500 modules 13955 were found significant.  Modules to check: 387. Percentage nodes done: 0.997926\n",
      "checked 15600 modules 13983 were found significant.  Modules to check: 287. Percentage nodes done: 0.998474\n",
      "checked 15700 modules 13997 were found significant.  Modules to check: 187. Percentage nodes done: 0.999019\n",
      "checked 15800 modules 14008 were found significant.  Modules to check: 87. Percentage nodes done: 0.999548\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1875\n",
      "iteration: 0 number of modules: 1870\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 5\n",
      "iteration: 0 number of modules: 5\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 12703 modules to check, run: 0\n",
      "minimality check: 4034 modules to check, run: 1\n",
      "minimality check: 107 modules to check, run: 2\n",
      "minimality check: 5 modules to check, run: 3\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19434\n",
      "iteration: 20 number of modules: 6290\n",
      "iteration: 40 number of modules: 6252\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 6845\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 4\n",
      "checked 200 unions. Fused: 9\n",
      "checked 300 unions. Fused: 18\n",
      "checked 400 unions. Fused: 25\n",
      "checked 500 unions. Fused: 31\n",
      "checked 600 unions. Fused: 44\n",
      "checked 700 unions. Fused: 51\n",
      "checked 800 unions. Fused: 63\n",
      "checked 900 unions. Fused: 78\n",
      "checked 1000 unions. Fused: 89\n",
      "checked 1100 unions. Fused: 102\n",
      "checked 1200 unions. Fused: 119\n",
      "checked 1300 unions. Fused: 131\n",
      "checked 1400 unions. Fused: 146\n",
      "checked 1500 unions. Fused: 164\n",
      "checked 1600 unions. Fused: 180\n",
      "checked 1700 unions. Fused: 200\n",
      "checked 1800 unions. Fused: 217\n",
      "checked 1900 unions. Fused: 229\n",
      "checked 2000 unions. Fused: 244\n",
      "checked 2200 unions. Fused: 276\n",
      "checked 2300 unions. Fused: 295\n",
      "checked 2500 unions. Fused: 329\n",
      "checked 2600 unions. Fused: 342\n",
      "checked 2700 unions. Fused: 361\n",
      "checked 2800 unions. Fused: 378\n",
      "checked 2900 unions. Fused: 390\n",
      "checked 3200 unions. Fused: 417\n",
      "checked 3300 unions. Fused: 425\n",
      "checked 3400 unions. Fused: 435\n",
      "checked 3500 unions. Fused: 445\n",
      "checked 3600 unions. Fused: 448\n",
      "checked 3700 unions. Fused: 454\n",
      "checked 3800 unions. Fused: 454\n",
      "checked 3900 unions. Fused: 456\n",
      "checked 4000 unions. Fused: 457\n",
      "checked 4100 unions. Fused: 459\n",
      "checked 4200 unions. Fused: 461\n",
      "checked 4300 unions. Fused: 465\n",
      "checked 4400 unions. Fused: 469\n",
      "checked 4600 unions. Fused: 474\n",
      "checked 4700 unions. Fused: 475\n",
      "checked 4800 unions. Fused: 476\n",
      "checked 5200 unions. Fused: 478\n",
      "checked 5300 unions. Fused: 478\n",
      "checked 5400 unions. Fused: 479\n",
      "checked 5500 unions. Fused: 479\n",
      "checked 5600 unions. Fused: 480\n",
      "checked 5700 unions. Fused: 481\n",
      "checked 6200 unions. Fused: 482\n",
      "checked 6500 unions. Fused: 482\n",
      "checked 6600 unions. Fused: 482\n",
      "checked 6700 unions. Fused: 482\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19079\n",
      "iteration: 20 number of modules: 6167\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 6556\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 2\n",
      "checked 200 unions. Fused: 3\n",
      "checked 300 unions. Fused: 6\n",
      "checked 400 unions. Fused: 10\n",
      "checked 500 unions. Fused: 13\n",
      "checked 600 unions. Fused: 17\n",
      "checked 700 unions. Fused: 21\n",
      "checked 800 unions. Fused: 27\n",
      "checked 900 unions. Fused: 38\n",
      "checked 1000 unions. Fused: 47\n",
      "checked 1100 unions. Fused: 54\n",
      "checked 1200 unions. Fused: 65\n",
      "checked 1300 unions. Fused: 77\n",
      "checked 1400 unions. Fused: 94\n",
      "checked 1500 unions. Fused: 106\n",
      "checked 1600 unions. Fused: 114\n",
      "checked 1700 unions. Fused: 128\n",
      "checked 1900 unions. Fused: 147\n",
      "checked 2000 unions. Fused: 154\n",
      "checked 2100 unions. Fused: 175\n",
      "checked 2200 unions. Fused: 205\n",
      "checked 2300 unions. Fused: 214\n",
      "checked 2400 unions. Fused: 222\n",
      "checked 2700 unions. Fused: 241\n",
      "checked 2900 unions. Fused: 251\n",
      "checked 3000 unions. Fused: 255\n",
      "checked 3100 unions. Fused: 258\n",
      "checked 3200 unions. Fused: 260\n",
      "checked 3300 unions. Fused: 265\n",
      "checked 3400 unions. Fused: 265\n",
      "checked 3500 unions. Fused: 266\n",
      "checked 3900 unions. Fused: 275\n",
      "checked 4000 unions. Fused: 275\n",
      "checked 4100 unions. Fused: 277\n",
      "checked 4200 unions. Fused: 277\n",
      "checked 4300 unions. Fused: 277\n",
      "checked 4600 unions. Fused: 277\n",
      "checked 4800 unions. Fused: 278\n",
      "checked 4900 unions. Fused: 278\n",
      "checked 5000 unions. Fused: 278\n",
      "checked 5100 unions. Fused: 278\n",
      "checked 5200 unions. Fused: 278\n",
      "checked 5400 unions. Fused: 278\n",
      "checked 5500 unions. Fused: 278\n",
      "checked 5700 unions. Fused: 278\n",
      "checked 6200 unions. Fused: 279\n",
      "checked 6500 unions. Fused: 279\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 40905\n",
      "minimality check: 12 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 46 modules to check, run: 1\n",
      "minimality check: 13 modules to check, run: 2\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 14 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 9 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 18 modules to check, run: 1\n",
      "minimality check: 11 modules to check, run: 1\n",
      "minimality check: 15 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 20 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 2\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 11 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 14 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "pairs to check: 11061\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 23 modules to check, run: 1\n",
      "minimality check: 17 modules to check, run: 1\n",
      "minimality check: 20 modules to check, run: 1\n",
      "minimality check: 26 modules to check, run: 1\n",
      "minimality check: 14 modules to check, run: 1\n",
      "minimality check: 18 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "pairs to check: 4499\n",
      "minimality check: 11 modules to check, run: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "pairs to check: 1641\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "pairs to check: 750\n",
      "minimality check: 15 modules to check, run: 1\n",
      "pairs to check: 409\n",
      "pairs to check: 378\n",
      "pairs to check: 20\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 12948 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #2\n",
      "iteration: 0 number of modules: 81530\n",
      "iteration: 20 number of modules: 15749\n",
      "iteration: 40 number of modules: 15524\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 15858. Percentage nodes done: 0\n",
      "checked 100 modules 96 were found significant.  Modules to check: 15758. Percentage nodes done: 0.165798\n",
      "checked 200 modules 193 were found significant.  Modules to check: 15658. Percentage nodes done: 0.292468\n",
      "checked 300 modules 292 were found significant.  Modules to check: 15558. Percentage nodes done: 0.336403\n",
      "checked 400 modules 392 were found significant.  Modules to check: 15458. Percentage nodes done: 0.373035\n",
      "checked 500 modules 492 were found significant.  Modules to check: 15358. Percentage nodes done: 0.405578\n",
      "checked 600 modules 591 were found significant.  Modules to check: 15258. Percentage nodes done: 0.426255\n",
      "checked 700 modules 691 were found significant.  Modules to check: 15158. Percentage nodes done: 0.445619\n",
      "checked 800 modules 791 were found significant.  Modules to check: 15058. Percentage nodes done: 0.469596\n",
      "checked 900 modules 891 were found significant.  Modules to check: 14958. Percentage nodes done: 0.489358\n",
      "checked 1000 modules 991 were found significant.  Modules to check: 14858. Percentage nodes done: 0.505962\n",
      "checked 1100 modules 1090 were found significant.  Modules to check: 14758. Percentage nodes done: 0.522292\n",
      "checked 1200 modules 1190 were found significant.  Modules to check: 14658. Percentage nodes done: 0.535863\n",
      "checked 1300 modules 1290 were found significant.  Modules to check: 14558. Percentage nodes done: 0.551424\n",
      "checked 1400 modules 1389 were found significant.  Modules to check: 14458. Percentage nodes done: 0.568836\n",
      "checked 1500 modules 1489 were found significant.  Modules to check: 14358. Percentage nodes done: 0.581754\n",
      "checked 1600 modules 1588 were found significant.  Modules to check: 14258. Percentage nodes done: 0.597856\n",
      "checked 1700 modules 1688 were found significant.  Modules to check: 14158. Percentage nodes done: 0.611376\n",
      "checked 1800 modules 1788 were found significant.  Modules to check: 14058. Percentage nodes done: 0.619308\n",
      "checked 1900 modules 1887 were found significant.  Modules to check: 13958. Percentage nodes done: 0.631534\n",
      "checked 2000 modules 1985 were found significant.  Modules to check: 13858. Percentage nodes done: 0.641776\n",
      "checked 2100 modules 2085 were found significant.  Modules to check: 13758. Percentage nodes done: 0.650116\n",
      "checked 2200 modules 2184 were found significant.  Modules to check: 13658. Percentage nodes done: 0.657561\n",
      "checked 2300 modules 2284 were found significant.  Modules to check: 13558. Percentage nodes done: 0.665756\n",
      "checked 2400 modules 2383 were found significant.  Modules to check: 13458. Percentage nodes done: 0.673839\n",
      "checked 2500 modules 2482 were found significant.  Modules to check: 13358. Percentage nodes done: 0.68488\n",
      "checked 2600 modules 2582 were found significant.  Modules to check: 13258. Percentage nodes done: 0.692667\n",
      "checked 2700 modules 2681 were found significant.  Modules to check: 13158. Percentage nodes done: 0.699895\n",
      "checked 2800 modules 2781 were found significant.  Modules to check: 13058. Percentage nodes done: 0.707338\n",
      "checked 2900 modules 2879 were found significant.  Modules to check: 12958. Percentage nodes done: 0.713671\n",
      "checked 3000 modules 2978 were found significant.  Modules to check: 12858. Percentage nodes done: 0.720001\n",
      "checked 3100 modules 3078 were found significant.  Modules to check: 12758. Percentage nodes done: 0.725476\n",
      "checked 3200 modules 3178 were found significant.  Modules to check: 12658. Percentage nodes done: 0.732059\n",
      "checked 3300 modules 3277 were found significant.  Modules to check: 12558. Percentage nodes done: 0.737917\n",
      "checked 3400 modules 3376 were found significant.  Modules to check: 12458. Percentage nodes done: 0.743748\n",
      "checked 3500 modules 3475 were found significant.  Modules to check: 12358. Percentage nodes done: 0.749024\n",
      "checked 3600 modules 3574 were found significant.  Modules to check: 12258. Percentage nodes done: 0.755158\n",
      "checked 3700 modules 3674 were found significant.  Modules to check: 12158. Percentage nodes done: 0.761217\n",
      "checked 3800 modules 3773 were found significant.  Modules to check: 12058. Percentage nodes done: 0.76716\n",
      "checked 3900 modules 3872 were found significant.  Modules to check: 11958. Percentage nodes done: 0.771615\n",
      "checked 4000 modules 3972 were found significant.  Modules to check: 11858. Percentage nodes done: 0.77694\n",
      "checked 4100 modules 4072 were found significant.  Modules to check: 11758. Percentage nodes done: 0.781888\n",
      "checked 4200 modules 4172 were found significant.  Modules to check: 11658. Percentage nodes done: 0.786426\n",
      "checked 4300 modules 4272 were found significant.  Modules to check: 11558. Percentage nodes done: 0.790731\n",
      "checked 4400 modules 4370 were found significant.  Modules to check: 11458. Percentage nodes done: 0.79499\n",
      "checked 4500 modules 4470 were found significant.  Modules to check: 11358. Percentage nodes done: 0.799295\n",
      "checked 4600 modules 4570 were found significant.  Modules to check: 11258. Percentage nodes done: 0.80407\n",
      "checked 4700 modules 4670 were found significant.  Modules to check: 11158. Percentage nodes done: 0.807756\n",
      "checked 4800 modules 4769 were found significant.  Modules to check: 11058. Percentage nodes done: 0.812001\n",
      "checked 4900 modules 4867 were found significant.  Modules to check: 10958. Percentage nodes done: 0.816203\n",
      "checked 5000 modules 4966 were found significant.  Modules to check: 10858. Percentage nodes done: 0.819357\n",
      "checked 5100 modules 5065 were found significant.  Modules to check: 10758. Percentage nodes done: 0.823887\n",
      "checked 5200 modules 5165 were found significant.  Modules to check: 10658. Percentage nodes done: 0.82774\n",
      "checked 5300 modules 5264 were found significant.  Modules to check: 10558. Percentage nodes done: 0.831758\n",
      "checked 5400 modules 5361 were found significant.  Modules to check: 10458. Percentage nodes done: 0.835818\n",
      "checked 5500 modules 5460 were found significant.  Modules to check: 10358. Percentage nodes done: 0.839201\n",
      "checked 5600 modules 5558 were found significant.  Modules to check: 10258. Percentage nodes done: 0.842502\n",
      "checked 5700 modules 5658 were found significant.  Modules to check: 10158. Percentage nodes done: 0.845857\n",
      "checked 5800 modules 5757 were found significant.  Modules to check: 10058. Percentage nodes done: 0.850069\n",
      "checked 5900 modules 5855 were found significant.  Modules to check: 9958. Percentage nodes done: 0.853375\n",
      "checked 6000 modules 5954 were found significant.  Modules to check: 9858. Percentage nodes done: 0.856717\n",
      "checked 6100 modules 6054 were found significant.  Modules to check: 9758. Percentage nodes done: 0.859622\n",
      "checked 6200 modules 6154 were found significant.  Modules to check: 9658. Percentage nodes done: 0.862807\n",
      "checked 6300 modules 6252 were found significant.  Modules to check: 9558. Percentage nodes done: 0.866363\n",
      "checked 6400 modules 6351 were found significant.  Modules to check: 9458. Percentage nodes done: 0.869532\n",
      "checked 6500 modules 6448 were found significant.  Modules to check: 9358. Percentage nodes done: 0.872646\n",
      "checked 6600 modules 6546 were found significant.  Modules to check: 9258. Percentage nodes done: 0.875877\n",
      "checked 6700 modules 6643 were found significant.  Modules to check: 9158. Percentage nodes done: 0.878783\n",
      "checked 6800 modules 6742 were found significant.  Modules to check: 9058. Percentage nodes done: 0.881825\n",
      "checked 6900 modules 6842 were found significant.  Modules to check: 8958. Percentage nodes done: 0.884666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 7000 modules 6941 were found significant.  Modules to check: 8858. Percentage nodes done: 0.887266\n",
      "checked 7100 modules 7039 were found significant.  Modules to check: 8758. Percentage nodes done: 0.889803\n",
      "checked 7200 modules 7136 were found significant.  Modules to check: 8658. Percentage nodes done: 0.892127\n",
      "checked 7300 modules 7232 were found significant.  Modules to check: 8558. Percentage nodes done: 0.894637\n",
      "checked 7400 modules 7329 were found significant.  Modules to check: 8458. Percentage nodes done: 0.896956\n",
      "checked 7500 modules 7425 were found significant.  Modules to check: 8358. Percentage nodes done: 0.899673\n",
      "checked 7600 modules 7524 were found significant.  Modules to check: 8258. Percentage nodes done: 0.901809\n",
      "checked 7700 modules 7624 were found significant.  Modules to check: 8158. Percentage nodes done: 0.904356\n",
      "checked 7800 modules 7722 were found significant.  Modules to check: 8058. Percentage nodes done: 0.906605\n",
      "checked 7900 modules 7819 were found significant.  Modules to check: 7958. Percentage nodes done: 0.908661\n",
      "checked 8000 modules 7913 were found significant.  Modules to check: 7858. Percentage nodes done: 0.91067\n",
      "checked 8100 modules 8011 were found significant.  Modules to check: 7758. Percentage nodes done: 0.912777\n",
      "checked 8200 modules 8107 were found significant.  Modules to check: 7658. Percentage nodes done: 0.915259\n",
      "checked 8300 modules 8202 were found significant.  Modules to check: 7558. Percentage nodes done: 0.917096\n",
      "checked 8400 modules 8299 were found significant.  Modules to check: 7458. Percentage nodes done: 0.919051\n",
      "checked 8500 modules 8393 were found significant.  Modules to check: 7358. Percentage nodes done: 0.92097\n",
      "checked 8600 modules 8491 were found significant.  Modules to check: 7258. Percentage nodes done: 0.922863\n",
      "checked 8700 modules 8589 were found significant.  Modules to check: 7158. Percentage nodes done: 0.925009\n",
      "checked 8800 modules 8684 were found significant.  Modules to check: 7058. Percentage nodes done: 0.926876\n",
      "checked 8900 modules 8781 were found significant.  Modules to check: 6958. Percentage nodes done: 0.928671\n",
      "checked 9000 modules 8877 were found significant.  Modules to check: 6858. Percentage nodes done: 0.930241\n",
      "checked 9100 modules 8975 were found significant.  Modules to check: 6758. Percentage nodes done: 0.931837\n",
      "checked 9200 modules 9073 were found significant.  Modules to check: 6658. Percentage nodes done: 0.933691\n",
      "checked 9300 modules 9169 were found significant.  Modules to check: 6558. Percentage nodes done: 0.935492\n",
      "checked 9400 modules 9265 were found significant.  Modules to check: 6458. Percentage nodes done: 0.937101\n",
      "checked 9500 modules 9361 were found significant.  Modules to check: 6358. Percentage nodes done: 0.938746\n",
      "checked 9600 modules 9458 were found significant.  Modules to check: 6258. Percentage nodes done: 0.940287\n",
      "checked 9700 modules 9553 were found significant.  Modules to check: 6158. Percentage nodes done: 0.94169\n",
      "checked 9800 modules 9649 were found significant.  Modules to check: 6058. Percentage nodes done: 0.943301\n",
      "checked 9900 modules 9748 were found significant.  Modules to check: 5958. Percentage nodes done: 0.944872\n",
      "checked 10000 modules 9842 were found significant.  Modules to check: 5858. Percentage nodes done: 0.946447\n",
      "checked 10100 modules 9934 were found significant.  Modules to check: 5758. Percentage nodes done: 0.947875\n",
      "checked 10200 modules 10029 were found significant.  Modules to check: 5658. Percentage nodes done: 0.949231\n",
      "checked 10300 modules 10121 were found significant.  Modules to check: 5558. Percentage nodes done: 0.950685\n",
      "checked 10400 modules 10212 were found significant.  Modules to check: 5458. Percentage nodes done: 0.952178\n",
      "checked 10500 modules 10305 were found significant.  Modules to check: 5358. Percentage nodes done: 0.953536\n",
      "checked 10600 modules 10399 were found significant.  Modules to check: 5258. Percentage nodes done: 0.954815\n",
      "checked 10700 modules 10492 were found significant.  Modules to check: 5158. Percentage nodes done: 0.956098\n",
      "checked 10800 modules 10589 were found significant.  Modules to check: 5058. Percentage nodes done: 0.957462\n",
      "checked 10900 modules 10678 were found significant.  Modules to check: 4958. Percentage nodes done: 0.958699\n",
      "checked 11000 modules 10769 were found significant.  Modules to check: 4858. Percentage nodes done: 0.959918\n",
      "checked 11100 modules 10859 were found significant.  Modules to check: 4758. Percentage nodes done: 0.961005\n",
      "checked 11200 modules 10953 were found significant.  Modules to check: 4658. Percentage nodes done: 0.962268\n",
      "checked 11300 modules 11046 were found significant.  Modules to check: 4558. Percentage nodes done: 0.963459\n",
      "checked 11400 modules 11139 were found significant.  Modules to check: 4458. Percentage nodes done: 0.964649\n",
      "checked 11500 modules 11228 were found significant.  Modules to check: 4358. Percentage nodes done: 0.965879\n",
      "checked 11600 modules 11318 were found significant.  Modules to check: 4258. Percentage nodes done: 0.96693\n",
      "checked 11700 modules 11407 were found significant.  Modules to check: 4158. Percentage nodes done: 0.968056\n",
      "checked 11800 modules 11493 were found significant.  Modules to check: 4058. Percentage nodes done: 0.969138\n",
      "checked 11900 modules 11586 were found significant.  Modules to check: 3958. Percentage nodes done: 0.970137\n",
      "checked 12000 modules 11670 were found significant.  Modules to check: 3858. Percentage nodes done: 0.971083\n",
      "checked 12100 modules 11759 were found significant.  Modules to check: 3758. Percentage nodes done: 0.972206\n",
      "checked 12200 modules 11845 were found significant.  Modules to check: 3658. Percentage nodes done: 0.973267\n",
      "checked 12300 modules 11932 were found significant.  Modules to check: 3558. Percentage nodes done: 0.974236\n",
      "checked 12400 modules 12019 were found significant.  Modules to check: 3458. Percentage nodes done: 0.975292\n",
      "checked 12500 modules 12105 were found significant.  Modules to check: 3358. Percentage nodes done: 0.97625\n",
      "checked 12600 modules 12192 were found significant.  Modules to check: 3258. Percentage nodes done: 0.977232\n",
      "checked 12700 modules 12275 were found significant.  Modules to check: 3158. Percentage nodes done: 0.978213\n",
      "checked 12800 modules 12352 were found significant.  Modules to check: 3058. Percentage nodes done: 0.979104\n",
      "checked 12900 modules 12432 were found significant.  Modules to check: 2958. Percentage nodes done: 0.979974\n",
      "checked 13000 modules 12513 were found significant.  Modules to check: 2858. Percentage nodes done: 0.98084\n",
      "checked 13100 modules 12586 were found significant.  Modules to check: 2758. Percentage nodes done: 0.981725\n",
      "checked 13200 modules 12659 were found significant.  Modules to check: 2658. Percentage nodes done: 0.982565\n",
      "checked 13300 modules 12735 were found significant.  Modules to check: 2558. Percentage nodes done: 0.983425\n",
      "checked 13400 modules 12813 were found significant.  Modules to check: 2458. Percentage nodes done: 0.984236\n",
      "checked 13500 modules 12884 were found significant.  Modules to check: 2358. Percentage nodes done: 0.985003\n",
      "checked 13600 modules 12952 were found significant.  Modules to check: 2258. Percentage nodes done: 0.985783\n",
      "checked 13700 modules 13025 were found significant.  Modules to check: 2158. Percentage nodes done: 0.986521\n",
      "checked 13800 modules 13091 were found significant.  Modules to check: 2058. Percentage nodes done: 0.987273\n",
      "checked 13900 modules 13163 were found significant.  Modules to check: 1958. Percentage nodes done: 0.988035\n",
      "checked 14000 modules 13226 were found significant.  Modules to check: 1858. Percentage nodes done: 0.988691\n",
      "checked 14100 modules 13287 were found significant.  Modules to check: 1758. Percentage nodes done: 0.989388\n",
      "checked 14200 modules 13347 were found significant.  Modules to check: 1658. Percentage nodes done: 0.99007\n",
      "checked 14300 modules 13411 were found significant.  Modules to check: 1558. Percentage nodes done: 0.990744\n",
      "checked 14400 modules 13472 were found significant.  Modules to check: 1458. Percentage nodes done: 0.991431\n",
      "checked 14500 modules 13529 were found significant.  Modules to check: 1358. Percentage nodes done: 0.992066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 14600 modules 13579 were found significant.  Modules to check: 1258. Percentage nodes done: 0.992714\n",
      "checked 14700 modules 13623 were found significant.  Modules to check: 1158. Percentage nodes done: 0.993339\n",
      "checked 14800 modules 13666 were found significant.  Modules to check: 1058. Percentage nodes done: 0.993946\n",
      "checked 14900 modules 13722 were found significant.  Modules to check: 958. Percentage nodes done: 0.994579\n",
      "checked 15000 modules 13764 were found significant.  Modules to check: 858. Percentage nodes done: 0.995168\n",
      "checked 15100 modules 13809 were found significant.  Modules to check: 758. Percentage nodes done: 0.995783\n",
      "checked 15200 modules 13844 were found significant.  Modules to check: 658. Percentage nodes done: 0.996364\n",
      "checked 15300 modules 13875 were found significant.  Modules to check: 558. Percentage nodes done: 0.996937\n",
      "checked 15400 modules 13912 were found significant.  Modules to check: 458. Percentage nodes done: 0.997526\n",
      "checked 15500 modules 13933 were found significant.  Modules to check: 358. Percentage nodes done: 0.998076\n",
      "checked 15600 modules 13962 were found significant.  Modules to check: 258. Percentage nodes done: 0.998634\n",
      "checked 15700 modules 13973 were found significant.  Modules to check: 158. Percentage nodes done: 0.999171\n",
      "checked 15800 modules 13983 were found significant.  Modules to check: 58. Percentage nodes done: 0.9997\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1872\n",
      "iteration: 0 number of modules: 1868\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 4\n",
      "iteration: 0 number of modules: 4\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 12650 modules to check, run: 0\n",
      "minimality check: 4168 modules to check, run: 1\n",
      "minimality check: 105 modules to check, run: 2\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19777\n",
      "iteration: 20 number of modules: 6686\n",
      "iteration: 40 number of modules: 6625\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 7054\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 1\n",
      "checked 200 unions. Fused: 7\n",
      "checked 300 unions. Fused: 13\n",
      "checked 400 unions. Fused: 21\n",
      "checked 500 unions. Fused: 31\n",
      "checked 600 unions. Fused: 41\n",
      "checked 700 unions. Fused: 54\n",
      "checked 800 unions. Fused: 68\n",
      "checked 900 unions. Fused: 85\n",
      "checked 1000 unions. Fused: 94\n",
      "checked 1100 unions. Fused: 106\n",
      "checked 1200 unions. Fused: 123\n",
      "checked 1300 unions. Fused: 146\n",
      "checked 1400 unions. Fused: 164\n",
      "checked 1500 unions. Fused: 177\n",
      "checked 1600 unions. Fused: 189\n",
      "checked 1700 unions. Fused: 202\n",
      "checked 1800 unions. Fused: 213\n",
      "checked 1900 unions. Fused: 224\n",
      "checked 2100 unions. Fused: 254\n",
      "checked 2200 unions. Fused: 282\n",
      "checked 2400 unions. Fused: 314\n",
      "checked 2500 unions. Fused: 328\n",
      "checked 2600 unions. Fused: 342\n",
      "checked 2800 unions. Fused: 364\n",
      "checked 3000 unions. Fused: 382\n",
      "checked 3100 unions. Fused: 391\n",
      "checked 3200 unions. Fused: 403\n",
      "checked 3300 unions. Fused: 409\n",
      "checked 3500 unions. Fused: 420\n",
      "checked 3600 unions. Fused: 424\n",
      "checked 3700 unions. Fused: 428\n",
      "checked 3800 unions. Fused: 429\n",
      "checked 3900 unions. Fused: 430\n",
      "checked 4000 unions. Fused: 432\n",
      "checked 4200 unions. Fused: 435\n",
      "checked 4300 unions. Fused: 437\n",
      "checked 4400 unions. Fused: 440\n",
      "checked 4500 unions. Fused: 441\n",
      "checked 4600 unions. Fused: 443\n",
      "checked 4800 unions. Fused: 446\n",
      "checked 4900 unions. Fused: 447\n",
      "checked 5000 unions. Fused: 448\n",
      "checked 5100 unions. Fused: 451\n",
      "checked 5200 unions. Fused: 452\n",
      "checked 5600 unions. Fused: 454\n",
      "checked 5700 unions. Fused: 454\n",
      "checked 5800 unions. Fused: 456\n",
      "checked 6000 unions. Fused: 456\n",
      "checked 6100 unions. Fused: 456\n",
      "checked 6200 unions. Fused: 457\n",
      "checked 6300 unions. Fused: 457\n",
      "checked 6400 unions. Fused: 457\n",
      "checked 6700 unions. Fused: 457\n",
      "checked 7000 unions. Fused: 457\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19305\n",
      "iteration: 20 number of modules: 6402\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 6866\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 1\n",
      "checked 300 unions. Fused: 5\n",
      "checked 400 unions. Fused: 8\n",
      "checked 500 unions. Fused: 11\n",
      "checked 600 unions. Fused: 19\n",
      "checked 700 unions. Fused: 21\n",
      "checked 800 unions. Fused: 27\n",
      "checked 900 unions. Fused: 31\n",
      "checked 1000 unions. Fused: 35\n",
      "checked 1100 unions. Fused: 47\n",
      "checked 1200 unions. Fused: 61\n",
      "checked 1300 unions. Fused: 76\n",
      "checked 1400 unions. Fused: 88\n",
      "checked 1500 unions. Fused: 103\n",
      "checked 1600 unions. Fused: 108\n",
      "checked 1700 unions. Fused: 121\n",
      "checked 1800 unions. Fused: 139\n",
      "checked 1900 unions. Fused: 147\n",
      "checked 2000 unions. Fused: 154\n",
      "checked 2100 unions. Fused: 176\n",
      "checked 2200 unions. Fused: 200\n",
      "checked 2300 unions. Fused: 209\n",
      "checked 2400 unions. Fused: 212\n",
      "checked 2500 unions. Fused: 214\n",
      "checked 2600 unions. Fused: 217\n",
      "checked 2700 unions. Fused: 221\n",
      "checked 2800 unions. Fused: 223\n",
      "checked 2900 unions. Fused: 229\n",
      "checked 3100 unions. Fused: 235\n",
      "checked 3300 unions. Fused: 239\n",
      "checked 3500 unions. Fused: 242\n",
      "checked 3600 unions. Fused: 244\n",
      "checked 3800 unions. Fused: 248\n",
      "checked 3900 unions. Fused: 249\n",
      "checked 4000 unions. Fused: 253\n",
      "checked 4200 unions. Fused: 256\n",
      "checked 4300 unions. Fused: 256\n",
      "checked 4500 unions. Fused: 257\n",
      "checked 4600 unions. Fused: 257\n",
      "checked 4800 unions. Fused: 258\n",
      "checked 4900 unions. Fused: 258\n",
      "checked 5000 unions. Fused: 258\n",
      "checked 5100 unions. Fused: 258\n",
      "checked 5300 unions. Fused: 259\n",
      "checked 5400 unions. Fused: 259\n",
      "checked 5500 unions. Fused: 259\n",
      "checked 5900 unions. Fused: 259\n",
      "checked 6000 unions. Fused: 259\n",
      "checked 6100 unions. Fused: 259\n",
      "checked 6400 unions. Fused: 259\n",
      "checked 6500 unions. Fused: 259\n",
      "checked 6600 unions. Fused: 259\n",
      "checked 6800 unions. Fused: 259\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 41216\n",
      "minimality check: 12 modules to check, run: 1\n",
      "minimality check: 18 modules to check, run: 1\n",
      "minimality check: 22 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 20 modules to check, run: 1\n",
      "minimality check: 21 modules to check, run: 1\n",
      "minimality check: 13 modules to check, run: 1\n",
      "minimality check: 17 modules to check, run: 1\n",
      "minimality check: 15 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 11 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 20 modules to check, run: 1\n",
      "minimality check: 32 modules to check, run: 1\n",
      "minimality check: 12 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 2\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 11 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimality check: 7 modules to check, run: 1\n",
      "pairs to check: 11179\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 11 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 18 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 2\n",
      "minimality check: 11 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 16 modules to check, run: 1\n",
      "minimality check: 13 modules to check, run: 1\n",
      "minimality check: 14 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 11 modules to check, run: 1\n",
      "pairs to check: 4607\n",
      "minimality check: 20 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 14 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 24 modules to check, run: 1\n",
      "pairs to check: 2281\n",
      "pairs to check: 929\n",
      "minimality check: 6 modules to check, run: 1\n",
      "pairs to check: 452\n",
      "pairs to check: 284\n",
      "pairs to check: 199\n",
      "pairs to check: 68\n",
      "pairs to check: 42\n",
      "pairs to check: 45\n",
      "pairs to check: 51\n",
      "pairs to check: 38\n",
      "pairs to check: 39\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 13140 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #3\n",
      "iteration: 0 number of modules: 81212\n",
      "iteration: 20 number of modules: 15872\n",
      "iteration: 40 number of modules: 15783\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 16095. Percentage nodes done: 0\n",
      "checked 100 modules 98 were found significant.  Modules to check: 15995. Percentage nodes done: 0.144068\n",
      "checked 200 modules 197 were found significant.  Modules to check: 15895. Percentage nodes done: 0.286226\n",
      "checked 300 modules 296 were found significant.  Modules to check: 15795. Percentage nodes done: 0.325807\n",
      "checked 400 modules 396 were found significant.  Modules to check: 15695. Percentage nodes done: 0.365122\n",
      "checked 500 modules 496 were found significant.  Modules to check: 15595. Percentage nodes done: 0.396415\n",
      "checked 600 modules 596 were found significant.  Modules to check: 15495. Percentage nodes done: 0.420175\n",
      "checked 700 modules 696 were found significant.  Modules to check: 15395. Percentage nodes done: 0.441934\n",
      "checked 800 modules 795 were found significant.  Modules to check: 15295. Percentage nodes done: 0.468023\n",
      "checked 900 modules 893 were found significant.  Modules to check: 15195. Percentage nodes done: 0.487527\n",
      "checked 1000 modules 992 were found significant.  Modules to check: 15095. Percentage nodes done: 0.503968\n",
      "checked 1100 modules 1088 were found significant.  Modules to check: 14995. Percentage nodes done: 0.517932\n",
      "checked 1200 modules 1188 were found significant.  Modules to check: 14895. Percentage nodes done: 0.53176\n",
      "checked 1300 modules 1287 were found significant.  Modules to check: 14795. Percentage nodes done: 0.549099\n",
      "checked 1400 modules 1386 were found significant.  Modules to check: 14695. Percentage nodes done: 0.562896\n",
      "checked 1500 modules 1486 were found significant.  Modules to check: 14595. Percentage nodes done: 0.578056\n",
      "checked 1600 modules 1586 were found significant.  Modules to check: 14495. Percentage nodes done: 0.592371\n",
      "checked 1700 modules 1686 were found significant.  Modules to check: 14395. Percentage nodes done: 0.603045\n",
      "checked 1800 modules 1786 were found significant.  Modules to check: 14295. Percentage nodes done: 0.611495\n",
      "checked 1900 modules 1886 were found significant.  Modules to check: 14195. Percentage nodes done: 0.623961\n",
      "checked 2000 modules 1985 were found significant.  Modules to check: 14095. Percentage nodes done: 0.635934\n",
      "checked 2100 modules 2084 were found significant.  Modules to check: 13995. Percentage nodes done: 0.644238\n",
      "checked 2200 modules 2184 were found significant.  Modules to check: 13895. Percentage nodes done: 0.652424\n",
      "checked 2300 modules 2283 were found significant.  Modules to check: 13795. Percentage nodes done: 0.662515\n",
      "checked 2400 modules 2382 were found significant.  Modules to check: 13695. Percentage nodes done: 0.669374\n",
      "checked 2500 modules 2482 were found significant.  Modules to check: 13595. Percentage nodes done: 0.679436\n",
      "checked 2600 modules 2582 were found significant.  Modules to check: 13495. Percentage nodes done: 0.688116\n",
      "checked 2700 modules 2682 were found significant.  Modules to check: 13395. Percentage nodes done: 0.694748\n",
      "checked 2800 modules 2779 were found significant.  Modules to check: 13295. Percentage nodes done: 0.700794\n",
      "checked 2900 modules 2878 were found significant.  Modules to check: 13195. Percentage nodes done: 0.707137\n",
      "checked 3000 modules 2976 were found significant.  Modules to check: 13095. Percentage nodes done: 0.713922\n",
      "checked 3100 modules 3075 were found significant.  Modules to check: 12995. Percentage nodes done: 0.720456\n",
      "checked 3200 modules 3175 were found significant.  Modules to check: 12895. Percentage nodes done: 0.727008\n",
      "checked 3300 modules 3275 were found significant.  Modules to check: 12795. Percentage nodes done: 0.732971\n",
      "checked 3400 modules 3374 were found significant.  Modules to check: 12695. Percentage nodes done: 0.739056\n",
      "checked 3500 modules 3473 were found significant.  Modules to check: 12595. Percentage nodes done: 0.744851\n",
      "checked 3600 modules 3571 were found significant.  Modules to check: 12495. Percentage nodes done: 0.750577\n",
      "checked 3700 modules 3671 were found significant.  Modules to check: 12395. Percentage nodes done: 0.756723\n",
      "checked 3800 modules 3770 were found significant.  Modules to check: 12295. Percentage nodes done: 0.76217\n",
      "checked 3900 modules 3868 were found significant.  Modules to check: 12195. Percentage nodes done: 0.766808\n",
      "checked 4000 modules 3968 were found significant.  Modules to check: 12095. Percentage nodes done: 0.772715\n",
      "checked 4100 modules 4067 were found significant.  Modules to check: 11995. Percentage nodes done: 0.77735\n",
      "checked 4200 modules 4167 were found significant.  Modules to check: 11895. Percentage nodes done: 0.782103\n",
      "checked 4300 modules 4267 were found significant.  Modules to check: 11795. Percentage nodes done: 0.787177\n",
      "checked 4400 modules 4366 were found significant.  Modules to check: 11695. Percentage nodes done: 0.791545\n",
      "checked 4500 modules 4466 were found significant.  Modules to check: 11595. Percentage nodes done: 0.795883\n",
      "checked 4600 modules 4566 were found significant.  Modules to check: 11495. Percentage nodes done: 0.800173\n",
      "checked 4700 modules 4666 were found significant.  Modules to check: 11395. Percentage nodes done: 0.804804\n",
      "checked 4800 modules 4766 were found significant.  Modules to check: 11295. Percentage nodes done: 0.808362\n",
      "checked 4900 modules 4864 were found significant.  Modules to check: 11195. Percentage nodes done: 0.812657\n",
      "checked 5000 modules 4962 were found significant.  Modules to check: 11095. Percentage nodes done: 0.816596\n",
      "checked 5100 modules 5061 were found significant.  Modules to check: 10995. Percentage nodes done: 0.820057\n",
      "checked 5200 modules 5161 were found significant.  Modules to check: 10895. Percentage nodes done: 0.824328\n",
      "checked 5300 modules 5261 were found significant.  Modules to check: 10795. Percentage nodes done: 0.828329\n",
      "checked 5400 modules 5360 were found significant.  Modules to check: 10695. Percentage nodes done: 0.832337\n",
      "checked 5500 modules 5458 were found significant.  Modules to check: 10595. Percentage nodes done: 0.836782\n",
      "checked 5600 modules 5554 were found significant.  Modules to check: 10495. Percentage nodes done: 0.840082\n",
      "checked 5700 modules 5654 were found significant.  Modules to check: 10395. Percentage nodes done: 0.843452\n",
      "checked 5800 modules 5754 were found significant.  Modules to check: 10295. Percentage nodes done: 0.846872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 5900 modules 5853 were found significant.  Modules to check: 10195. Percentage nodes done: 0.851043\n",
      "checked 6000 modules 5950 were found significant.  Modules to check: 10095. Percentage nodes done: 0.854119\n",
      "checked 6100 modules 6050 were found significant.  Modules to check: 9995. Percentage nodes done: 0.856978\n",
      "checked 6200 modules 6150 were found significant.  Modules to check: 9895. Percentage nodes done: 0.860756\n",
      "checked 6300 modules 6247 were found significant.  Modules to check: 9795. Percentage nodes done: 0.864431\n",
      "checked 6400 modules 6346 were found significant.  Modules to check: 9695. Percentage nodes done: 0.867318\n",
      "checked 6500 modules 6443 were found significant.  Modules to check: 9595. Percentage nodes done: 0.870079\n",
      "checked 6600 modules 6540 were found significant.  Modules to check: 9495. Percentage nodes done: 0.873018\n",
      "checked 6700 modules 6637 were found significant.  Modules to check: 9395. Percentage nodes done: 0.875851\n",
      "checked 6800 modules 6735 were found significant.  Modules to check: 9295. Percentage nodes done: 0.878819\n",
      "checked 6900 modules 6834 were found significant.  Modules to check: 9195. Percentage nodes done: 0.881391\n",
      "checked 7000 modules 6934 were found significant.  Modules to check: 9095. Percentage nodes done: 0.884395\n",
      "checked 7100 modules 7031 were found significant.  Modules to check: 8995. Percentage nodes done: 0.886773\n",
      "checked 7200 modules 7129 were found significant.  Modules to check: 8895. Percentage nodes done: 0.88917\n",
      "checked 7300 modules 7227 were found significant.  Modules to check: 8795. Percentage nodes done: 0.89167\n",
      "checked 7400 modules 7322 were found significant.  Modules to check: 8695. Percentage nodes done: 0.894141\n",
      "checked 7500 modules 7419 were found significant.  Modules to check: 8595. Percentage nodes done: 0.896507\n",
      "checked 7600 modules 7516 were found significant.  Modules to check: 8495. Percentage nodes done: 0.899152\n",
      "checked 7700 modules 7614 were found significant.  Modules to check: 8395. Percentage nodes done: 0.901145\n",
      "checked 7800 modules 7712 were found significant.  Modules to check: 8295. Percentage nodes done: 0.903599\n",
      "checked 7900 modules 7810 were found significant.  Modules to check: 8195. Percentage nodes done: 0.905972\n",
      "checked 8000 modules 7907 were found significant.  Modules to check: 8095. Percentage nodes done: 0.907927\n",
      "checked 8100 modules 8005 were found significant.  Modules to check: 7995. Percentage nodes done: 0.909926\n",
      "checked 8200 modules 8102 were found significant.  Modules to check: 7895. Percentage nodes done: 0.91207\n",
      "checked 8300 modules 8201 were found significant.  Modules to check: 7795. Percentage nodes done: 0.913955\n",
      "checked 8400 modules 8297 were found significant.  Modules to check: 7695. Percentage nodes done: 0.916083\n",
      "checked 8500 modules 8389 were found significant.  Modules to check: 7595. Percentage nodes done: 0.917896\n",
      "checked 8600 modules 8485 were found significant.  Modules to check: 7495. Percentage nodes done: 0.91972\n",
      "checked 8700 modules 8582 were found significant.  Modules to check: 7395. Percentage nodes done: 0.921708\n",
      "checked 8800 modules 8680 were found significant.  Modules to check: 7295. Percentage nodes done: 0.923733\n",
      "checked 8900 modules 8777 were found significant.  Modules to check: 7195. Percentage nodes done: 0.925608\n",
      "checked 9000 modules 8875 were found significant.  Modules to check: 7095. Percentage nodes done: 0.927263\n",
      "checked 9100 modules 8972 were found significant.  Modules to check: 6995. Percentage nodes done: 0.928986\n",
      "checked 9200 modules 9068 were found significant.  Modules to check: 6895. Percentage nodes done: 0.930528\n",
      "checked 9300 modules 9166 were found significant.  Modules to check: 6795. Percentage nodes done: 0.932274\n",
      "checked 9400 modules 9261 were found significant.  Modules to check: 6695. Percentage nodes done: 0.934058\n",
      "checked 9500 modules 9357 were found significant.  Modules to check: 6595. Percentage nodes done: 0.935683\n",
      "checked 9600 modules 9452 were found significant.  Modules to check: 6495. Percentage nodes done: 0.937183\n",
      "checked 9700 modules 9549 were found significant.  Modules to check: 6395. Percentage nodes done: 0.93879\n",
      "checked 9800 modules 9644 were found significant.  Modules to check: 6295. Percentage nodes done: 0.940362\n",
      "checked 9900 modules 9739 were found significant.  Modules to check: 6195. Percentage nodes done: 0.941853\n",
      "checked 10000 modules 9838 were found significant.  Modules to check: 6095. Percentage nodes done: 0.943335\n",
      "checked 10100 modules 9931 were found significant.  Modules to check: 5995. Percentage nodes done: 0.944996\n",
      "checked 10200 modules 10024 were found significant.  Modules to check: 5895. Percentage nodes done: 0.946535\n",
      "checked 10300 modules 10118 were found significant.  Modules to check: 5795. Percentage nodes done: 0.94786\n",
      "checked 10400 modules 10210 were found significant.  Modules to check: 5695. Percentage nodes done: 0.949303\n",
      "checked 10500 modules 10303 were found significant.  Modules to check: 5595. Percentage nodes done: 0.950719\n",
      "checked 10600 modules 10398 were found significant.  Modules to check: 5495. Percentage nodes done: 0.951966\n",
      "checked 10700 modules 10494 were found significant.  Modules to check: 5395. Percentage nodes done: 0.953467\n",
      "checked 10800 modules 10586 were found significant.  Modules to check: 5295. Percentage nodes done: 0.954729\n",
      "checked 10900 modules 10681 were found significant.  Modules to check: 5195. Percentage nodes done: 0.956124\n",
      "checked 11000 modules 10769 were found significant.  Modules to check: 5095. Percentage nodes done: 0.957426\n",
      "checked 11100 modules 10862 were found significant.  Modules to check: 4995. Percentage nodes done: 0.958699\n",
      "checked 11200 modules 10948 were found significant.  Modules to check: 4895. Percentage nodes done: 0.959696\n",
      "checked 11300 modules 11044 were found significant.  Modules to check: 4795. Percentage nodes done: 0.960954\n",
      "checked 11400 modules 11136 were found significant.  Modules to check: 4695. Percentage nodes done: 0.962067\n",
      "checked 11500 modules 11225 were found significant.  Modules to check: 4595. Percentage nodes done: 0.963293\n",
      "checked 11600 modules 11315 were found significant.  Modules to check: 4495. Percentage nodes done: 0.964507\n",
      "checked 11700 modules 11406 were found significant.  Modules to check: 4395. Percentage nodes done: 0.965708\n",
      "checked 11800 modules 11496 were found significant.  Modules to check: 4295. Percentage nodes done: 0.966754\n",
      "checked 11900 modules 11584 were found significant.  Modules to check: 4195. Percentage nodes done: 0.967818\n",
      "checked 12000 modules 11676 were found significant.  Modules to check: 4095. Percentage nodes done: 0.968859\n",
      "checked 12100 modules 11764 were found significant.  Modules to check: 3995. Percentage nodes done: 0.969923\n",
      "checked 12200 modules 11849 were found significant.  Modules to check: 3895. Percentage nodes done: 0.970948\n",
      "checked 12300 modules 11934 were found significant.  Modules to check: 3795. Percentage nodes done: 0.972025\n",
      "checked 12400 modules 12022 were found significant.  Modules to check: 3695. Percentage nodes done: 0.9731\n",
      "checked 12500 modules 12114 were found significant.  Modules to check: 3595. Percentage nodes done: 0.974068\n",
      "checked 12600 modules 12196 were found significant.  Modules to check: 3495. Percentage nodes done: 0.975073\n",
      "checked 12700 modules 12283 were found significant.  Modules to check: 3395. Percentage nodes done: 0.976002\n",
      "checked 12800 modules 12371 were found significant.  Modules to check: 3295. Percentage nodes done: 0.976994\n",
      "checked 12900 modules 12451 were found significant.  Modules to check: 3195. Percentage nodes done: 0.977888\n",
      "checked 13000 modules 12526 were found significant.  Modules to check: 3095. Percentage nodes done: 0.978774\n",
      "checked 13100 modules 12607 were found significant.  Modules to check: 2995. Percentage nodes done: 0.979706\n",
      "checked 13200 modules 12687 were found significant.  Modules to check: 2895. Percentage nodes done: 0.980587\n",
      "checked 13300 modules 12766 were found significant.  Modules to check: 2795. Percentage nodes done: 0.981452\n",
      "checked 13400 modules 12845 were found significant.  Modules to check: 2695. Percentage nodes done: 0.982317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 13500 modules 12929 were found significant.  Modules to check: 2595. Percentage nodes done: 0.983172\n",
      "checked 13600 modules 13005 were found significant.  Modules to check: 2495. Percentage nodes done: 0.983977\n",
      "checked 13700 modules 13077 were found significant.  Modules to check: 2395. Percentage nodes done: 0.984778\n",
      "checked 13800 modules 13146 were found significant.  Modules to check: 2295. Percentage nodes done: 0.985571\n",
      "checked 13900 modules 13224 were found significant.  Modules to check: 2195. Percentage nodes done: 0.986297\n",
      "checked 14000 modules 13296 were found significant.  Modules to check: 2095. Percentage nodes done: 0.987025\n",
      "checked 14100 modules 13374 were found significant.  Modules to check: 1995. Percentage nodes done: 0.987766\n",
      "checked 14200 modules 13444 were found significant.  Modules to check: 1895. Percentage nodes done: 0.988484\n",
      "checked 14300 modules 13507 were found significant.  Modules to check: 1795. Percentage nodes done: 0.989187\n",
      "checked 14400 modules 13570 were found significant.  Modules to check: 1695. Percentage nodes done: 0.98985\n",
      "checked 14500 modules 13632 were found significant.  Modules to check: 1595. Percentage nodes done: 0.990548\n",
      "checked 14600 modules 13692 were found significant.  Modules to check: 1495. Percentage nodes done: 0.991214\n",
      "checked 14700 modules 13740 were found significant.  Modules to check: 1395. Percentage nodes done: 0.991896\n",
      "checked 14800 modules 13792 were found significant.  Modules to check: 1295. Percentage nodes done: 0.992523\n",
      "checked 14900 modules 13841 were found significant.  Modules to check: 1195. Percentage nodes done: 0.993164\n",
      "checked 15000 modules 13883 were found significant.  Modules to check: 1095. Percentage nodes done: 0.993753\n",
      "checked 15100 modules 13942 were found significant.  Modules to check: 995. Percentage nodes done: 0.994362\n",
      "checked 15200 modules 13988 were found significant.  Modules to check: 895. Percentage nodes done: 0.994959\n",
      "checked 15300 modules 14029 were found significant.  Modules to check: 795. Percentage nodes done: 0.99556\n",
      "checked 15400 modules 14064 were found significant.  Modules to check: 695. Percentage nodes done: 0.996167\n",
      "checked 15500 modules 14091 were found significant.  Modules to check: 595. Percentage nodes done: 0.996743\n",
      "checked 15600 modules 14123 were found significant.  Modules to check: 495. Percentage nodes done: 0.997319\n",
      "checked 15700 modules 14155 were found significant.  Modules to check: 395. Percentage nodes done: 0.997877\n",
      "checked 15800 modules 14182 were found significant.  Modules to check: 295. Percentage nodes done: 0.998425\n",
      "checked 15900 modules 14200 were found significant.  Modules to check: 195. Percentage nodes done: 0.998972\n",
      "checked 16000 modules 14212 were found significant.  Modules to check: 95. Percentage nodes done: 0.999504\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1878\n",
      "iteration: 0 number of modules: 1873\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 5\n",
      "iteration: 0 number of modules: 5\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 12837 modules to check, run: 0\n",
      "minimality check: 4064 modules to check, run: 1\n",
      "minimality check: 87 modules to check, run: 2\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19758\n",
      "iteration: 20 number of modules: 6545\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 6873\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 4\n",
      "checked 300 unions. Fused: 11\n",
      "checked 400 unions. Fused: 16\n",
      "checked 500 unions. Fused: 25\n",
      "checked 600 unions. Fused: 33\n",
      "checked 700 unions. Fused: 44\n",
      "checked 800 unions. Fused: 56\n",
      "checked 900 unions. Fused: 72\n",
      "checked 1000 unions. Fused: 81\n",
      "checked 1100 unions. Fused: 94\n",
      "checked 1200 unions. Fused: 100\n",
      "checked 1300 unions. Fused: 115\n",
      "checked 1400 unions. Fused: 132\n",
      "checked 1500 unions. Fused: 152\n",
      "checked 1600 unions. Fused: 168\n",
      "checked 1700 unions. Fused: 181\n",
      "checked 1800 unions. Fused: 199\n",
      "checked 1900 unions. Fused: 216\n",
      "checked 2000 unions. Fused: 230\n",
      "checked 2200 unions. Fused: 258\n",
      "checked 2400 unions. Fused: 298\n",
      "checked 2500 unions. Fused: 306\n",
      "checked 2700 unions. Fused: 337\n",
      "checked 2800 unions. Fused: 349\n",
      "checked 2900 unions. Fused: 362\n",
      "checked 3000 unions. Fused: 369\n",
      "checked 3100 unions. Fused: 377\n",
      "checked 3200 unions. Fused: 384\n",
      "checked 3300 unions. Fused: 394\n",
      "checked 3400 unions. Fused: 401\n",
      "checked 3600 unions. Fused: 414\n",
      "checked 3700 unions. Fused: 416\n",
      "checked 3800 unions. Fused: 417\n",
      "checked 3900 unions. Fused: 418\n",
      "checked 4100 unions. Fused: 421\n",
      "checked 4200 unions. Fused: 427\n",
      "checked 4300 unions. Fused: 429\n",
      "checked 4400 unions. Fused: 435\n",
      "checked 4500 unions. Fused: 437\n",
      "checked 4600 unions. Fused: 439\n",
      "checked 4800 unions. Fused: 442\n",
      "checked 4900 unions. Fused: 443\n",
      "checked 5200 unions. Fused: 447\n",
      "checked 5300 unions. Fused: 448\n",
      "checked 5400 unions. Fused: 448\n",
      "checked 5500 unions. Fused: 449\n",
      "checked 5600 unions. Fused: 450\n",
      "checked 5700 unions. Fused: 450\n",
      "checked 5800 unions. Fused: 450\n",
      "checked 5900 unions. Fused: 450\n",
      "checked 6100 unions. Fused: 451\n",
      "checked 6200 unions. Fused: 451\n",
      "checked 6700 unions. Fused: 451\n",
      "checked 6800 unions. Fused: 451\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19458\n",
      "iteration: 20 number of modules: 6357\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 7422\n",
      "checked 0 unions. Fused: 0\n",
      "checked 200 unions. Fused: 1\n",
      "checked 600 unions. Fused: 1\n",
      "checked 700 unions. Fused: 4\n",
      "checked 800 unions. Fused: 8\n",
      "checked 900 unions. Fused: 11\n",
      "checked 1000 unions. Fused: 13\n",
      "checked 1100 unions. Fused: 17\n",
      "checked 1200 unions. Fused: 27\n",
      "checked 1300 unions. Fused: 35\n",
      "checked 1400 unions. Fused: 44\n",
      "checked 1500 unions. Fused: 48\n",
      "checked 1600 unions. Fused: 59\n",
      "checked 1700 unions. Fused: 71\n",
      "checked 1800 unions. Fused: 88\n",
      "checked 1900 unions. Fused: 99\n",
      "checked 2000 unions. Fused: 109\n",
      "checked 2100 unions. Fused: 125\n",
      "checked 2200 unions. Fused: 138\n",
      "checked 2300 unions. Fused: 153\n",
      "checked 2400 unions. Fused: 160\n",
      "checked 2500 unions. Fused: 175\n",
      "checked 2600 unions. Fused: 184\n",
      "checked 2700 unions. Fused: 188\n",
      "checked 2800 unions. Fused: 208\n",
      "checked 2900 unions. Fused: 241\n",
      "checked 3100 unions. Fused: 256\n",
      "checked 3300 unions. Fused: 273\n",
      "checked 3600 unions. Fused: 284\n",
      "checked 3800 unions. Fused: 289\n",
      "checked 3900 unions. Fused: 291\n",
      "checked 4000 unions. Fused: 292\n",
      "checked 4100 unions. Fused: 295\n",
      "checked 4200 unions. Fused: 295\n",
      "checked 4400 unions. Fused: 298\n",
      "checked 4500 unions. Fused: 299\n",
      "checked 4600 unions. Fused: 301\n",
      "checked 4700 unions. Fused: 302\n",
      "checked 4800 unions. Fused: 303\n",
      "checked 4900 unions. Fused: 305\n",
      "checked 5000 unions. Fused: 306\n",
      "checked 5100 unions. Fused: 307\n",
      "checked 5200 unions. Fused: 307\n",
      "checked 5300 unions. Fused: 307\n",
      "checked 5500 unions. Fused: 307\n",
      "checked 5700 unions. Fused: 307\n",
      "checked 5900 unions. Fused: 309\n",
      "checked 6500 unions. Fused: 309\n",
      "checked 6700 unions. Fused: 309\n",
      "checked 6800 unions. Fused: 309\n",
      "checked 6900 unions. Fused: 310\n",
      "checked 7100 unions. Fused: 310\n",
      "checked 7200 unions. Fused: 310\n",
      "checked 7400 unions. Fused: 310\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 41522\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 9 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 9 modules to check, run: 1\n",
      "minimality check: 19 modules to check, run: 1\n",
      "minimality check: 14 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 14 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 12 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 8 modules to check, run: 1\n",
      "pairs to check: 11851\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 21 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 12 modules to check, run: 1\n",
      "minimality check: 16 modules to check, run: 1\n",
      "minimality check: 11 modules to check, run: 1\n",
      "minimality check: 15 modules to check, run: 1\n",
      "minimality check: 13 modules to check, run: 1\n",
      "minimality check: 31 modules to check, run: 1\n",
      "minimality check: 26 modules to check, run: 1\n",
      "minimality check: 9 modules to check, run: 2\n",
      "minimality check: 6 modules to check, run: 1\n",
      "minimality check: 16 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "minimality check: 6 modules to check, run: 1\n",
      "pairs to check: 5581\n",
      "minimality check: 20 modules to check, run: 1\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 24 modules to check, run: 1\n",
      "minimality check: 20 modules to check, run: 1\n",
      "minimality check: 13 modules to check, run: 1\n",
      "minimality check: 23 modules to check, run: 1\n",
      "minimality check: 5 modules to check, run: 1\n",
      "pairs to check: 2336\n",
      "minimality check: 5 modules to check, run: 1\n",
      "minimality check: 27 modules to check, run: 1\n",
      "pairs to check: 988\n",
      "pairs to check: 572\n",
      "pairs to check: 392\n",
      "pairs to check: 263\n",
      "pairs to check: 124\n",
      "pairs to check: 166\n",
      "pairs to check: 67\n",
      "pairs to check: 45\n",
      "pairs to check: 62\n",
      "pairs to check: 57\n",
      "pairs to check: 70\n",
      "pairs to check: 27\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 13056 modules. writing... \n",
      "DONE   ****************************\n",
      "***************************************************************** RUN: #4\n",
      "iteration: 0 number of modules: 81092\n",
      "iteration: 20 number of modules: 15621\n",
      "iteration: 40 number of modules: 15476\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 15827. Percentage nodes done: 0\n",
      "checked 100 modules 96 were found significant.  Modules to check: 15727. Percentage nodes done: 0.124193\n",
      "checked 200 modules 195 were found significant.  Modules to check: 15627. Percentage nodes done: 0.301158\n",
      "checked 300 modules 294 were found significant.  Modules to check: 15527. Percentage nodes done: 0.340566\n",
      "checked 400 modules 393 were found significant.  Modules to check: 15427. Percentage nodes done: 0.367108\n",
      "checked 500 modules 493 were found significant.  Modules to check: 15327. Percentage nodes done: 0.4022\n",
      "checked 600 modules 592 were found significant.  Modules to check: 15227. Percentage nodes done: 0.422148\n",
      "checked 700 modules 691 were found significant.  Modules to check: 15127. Percentage nodes done: 0.448192\n",
      "checked 800 modules 789 were found significant.  Modules to check: 15027. Percentage nodes done: 0.476758\n",
      "checked 900 modules 889 were found significant.  Modules to check: 14927. Percentage nodes done: 0.498372\n",
      "checked 1000 modules 988 were found significant.  Modules to check: 14827. Percentage nodes done: 0.516894\n",
      "checked 1100 modules 1087 were found significant.  Modules to check: 14727. Percentage nodes done: 0.530812\n",
      "checked 1200 modules 1186 were found significant.  Modules to check: 14627. Percentage nodes done: 0.542292\n",
      "checked 1300 modules 1286 were found significant.  Modules to check: 14527. Percentage nodes done: 0.558332\n",
      "checked 1400 modules 1384 were found significant.  Modules to check: 14427. Percentage nodes done: 0.575424\n",
      "checked 1500 modules 1484 were found significant.  Modules to check: 14327. Percentage nodes done: 0.588603\n",
      "checked 1600 modules 1584 were found significant.  Modules to check: 14227. Percentage nodes done: 0.60304\n",
      "checked 1700 modules 1684 were found significant.  Modules to check: 14127. Percentage nodes done: 0.616919\n",
      "checked 1800 modules 1784 were found significant.  Modules to check: 14027. Percentage nodes done: 0.624393\n",
      "checked 1900 modules 1884 were found significant.  Modules to check: 13927. Percentage nodes done: 0.634488\n",
      "checked 2000 modules 1983 were found significant.  Modules to check: 13827. Percentage nodes done: 0.64455\n",
      "checked 2100 modules 2083 were found significant.  Modules to check: 13727. Percentage nodes done: 0.652461\n",
      "checked 2200 modules 2183 were found significant.  Modules to check: 13627. Percentage nodes done: 0.661037\n",
      "checked 2300 modules 2283 were found significant.  Modules to check: 13527. Percentage nodes done: 0.670733\n",
      "checked 2400 modules 2382 were found significant.  Modules to check: 13427. Percentage nodes done: 0.677272\n",
      "checked 2500 modules 2482 were found significant.  Modules to check: 13327. Percentage nodes done: 0.685771\n",
      "checked 2600 modules 2582 were found significant.  Modules to check: 13227. Percentage nodes done: 0.694265\n",
      "checked 2700 modules 2680 were found significant.  Modules to check: 13127. Percentage nodes done: 0.701432\n",
      "checked 2800 modules 2780 were found significant.  Modules to check: 13027. Percentage nodes done: 0.707708\n",
      "checked 2900 modules 2880 were found significant.  Modules to check: 12927. Percentage nodes done: 0.713942\n",
      "checked 3000 modules 2979 were found significant.  Modules to check: 12827. Percentage nodes done: 0.720463\n",
      "checked 3100 modules 3078 were found significant.  Modules to check: 12727. Percentage nodes done: 0.725814\n",
      "checked 3200 modules 3178 were found significant.  Modules to check: 12627. Percentage nodes done: 0.731674\n",
      "checked 3300 modules 3278 were found significant.  Modules to check: 12527. Percentage nodes done: 0.737307\n",
      "checked 3400 modules 3377 were found significant.  Modules to check: 12427. Percentage nodes done: 0.742418\n",
      "checked 3500 modules 3475 were found significant.  Modules to check: 12327. Percentage nodes done: 0.747384\n",
      "checked 3600 modules 3575 were found significant.  Modules to check: 12227. Percentage nodes done: 0.753769\n",
      "checked 3700 modules 3674 were found significant.  Modules to check: 12127. Percentage nodes done: 0.760019\n",
      "checked 3800 modules 3774 were found significant.  Modules to check: 12027. Percentage nodes done: 0.765762\n",
      "checked 3900 modules 3873 were found significant.  Modules to check: 11927. Percentage nodes done: 0.771059\n",
      "checked 4000 modules 3972 were found significant.  Modules to check: 11827. Percentage nodes done: 0.776746\n",
      "checked 4100 modules 4072 were found significant.  Modules to check: 11727. Percentage nodes done: 0.780984\n",
      "checked 4200 modules 4172 were found significant.  Modules to check: 11627. Percentage nodes done: 0.78571\n",
      "checked 4300 modules 4272 were found significant.  Modules to check: 11527. Percentage nodes done: 0.790196\n",
      "checked 4400 modules 4371 were found significant.  Modules to check: 11427. Percentage nodes done: 0.794429\n",
      "checked 4500 modules 4471 were found significant.  Modules to check: 11327. Percentage nodes done: 0.798466\n",
      "checked 4600 modules 4571 were found significant.  Modules to check: 11227. Percentage nodes done: 0.80328\n",
      "checked 4700 modules 4671 were found significant.  Modules to check: 11127. Percentage nodes done: 0.808233\n",
      "checked 4800 modules 4770 were found significant.  Modules to check: 11027. Percentage nodes done: 0.812084\n",
      "checked 4900 modules 4868 were found significant.  Modules to check: 10927. Percentage nodes done: 0.816418\n",
      "checked 5000 modules 4965 were found significant.  Modules to check: 10827. Percentage nodes done: 0.820718\n",
      "checked 5100 modules 5064 were found significant.  Modules to check: 10727. Percentage nodes done: 0.824695\n",
      "checked 5200 modules 5163 were found significant.  Modules to check: 10627. Percentage nodes done: 0.828657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 5300 modules 5261 were found significant.  Modules to check: 10527. Percentage nodes done: 0.832691\n",
      "checked 5400 modules 5359 were found significant.  Modules to check: 10427. Percentage nodes done: 0.836642\n",
      "checked 5500 modules 5458 were found significant.  Modules to check: 10327. Percentage nodes done: 0.840374\n",
      "checked 5600 modules 5556 were found significant.  Modules to check: 10227. Percentage nodes done: 0.844072\n",
      "checked 5700 modules 5655 were found significant.  Modules to check: 10127. Percentage nodes done: 0.846887\n",
      "checked 5800 modules 5755 were found significant.  Modules to check: 10027. Percentage nodes done: 0.850921\n",
      "checked 5900 modules 5853 were found significant.  Modules to check: 9927. Percentage nodes done: 0.85448\n",
      "checked 6000 modules 5952 were found significant.  Modules to check: 9827. Percentage nodes done: 0.857721\n",
      "checked 6100 modules 6052 were found significant.  Modules to check: 9727. Percentage nodes done: 0.860552\n",
      "checked 6200 modules 6152 were found significant.  Modules to check: 9627. Percentage nodes done: 0.864222\n",
      "checked 6300 modules 6250 were found significant.  Modules to check: 9527. Percentage nodes done: 0.867553\n",
      "checked 6400 modules 6349 were found significant.  Modules to check: 9427. Percentage nodes done: 0.870567\n",
      "checked 6500 modules 6444 were found significant.  Modules to check: 9327. Percentage nodes done: 0.873333\n",
      "checked 6600 modules 6544 were found significant.  Modules to check: 9227. Percentage nodes done: 0.87621\n",
      "checked 6700 modules 6641 were found significant.  Modules to check: 9127. Percentage nodes done: 0.879188\n",
      "checked 6800 modules 6740 were found significant.  Modules to check: 9027. Percentage nodes done: 0.882024\n",
      "checked 6900 modules 6840 were found significant.  Modules to check: 8927. Percentage nodes done: 0.884808\n",
      "checked 7000 modules 6940 were found significant.  Modules to check: 8827. Percentage nodes done: 0.887607\n",
      "checked 7100 modules 7038 were found significant.  Modules to check: 8727. Percentage nodes done: 0.890193\n",
      "checked 7200 modules 7135 were found significant.  Modules to check: 8627. Percentage nodes done: 0.892966\n",
      "checked 7300 modules 7234 were found significant.  Modules to check: 8527. Percentage nodes done: 0.895807\n",
      "checked 7400 modules 7329 were found significant.  Modules to check: 8427. Percentage nodes done: 0.898168\n",
      "checked 7500 modules 7425 were found significant.  Modules to check: 8327. Percentage nodes done: 0.900546\n",
      "checked 7600 modules 7522 were found significant.  Modules to check: 8227. Percentage nodes done: 0.902914\n",
      "checked 7700 modules 7622 were found significant.  Modules to check: 8127. Percentage nodes done: 0.905662\n",
      "checked 7800 modules 7720 were found significant.  Modules to check: 8027. Percentage nodes done: 0.907783\n",
      "checked 7900 modules 7814 were found significant.  Modules to check: 7927. Percentage nodes done: 0.909983\n",
      "checked 8000 modules 7912 were found significant.  Modules to check: 7827. Percentage nodes done: 0.912261\n",
      "checked 8100 modules 8010 were found significant.  Modules to check: 7727. Percentage nodes done: 0.914296\n",
      "checked 8200 modules 8107 were found significant.  Modules to check: 7627. Percentage nodes done: 0.916414\n",
      "checked 8300 modules 8203 were found significant.  Modules to check: 7527. Percentage nodes done: 0.918271\n",
      "checked 8400 modules 8298 were found significant.  Modules to check: 7427. Percentage nodes done: 0.920275\n",
      "checked 8500 modules 8391 were found significant.  Modules to check: 7327. Percentage nodes done: 0.92217\n",
      "checked 8600 modules 8488 were found significant.  Modules to check: 7227. Percentage nodes done: 0.92404\n",
      "checked 8700 modules 8586 were found significant.  Modules to check: 7127. Percentage nodes done: 0.925887\n",
      "checked 8800 modules 8681 were found significant.  Modules to check: 7027. Percentage nodes done: 0.927803\n",
      "checked 8900 modules 8779 were found significant.  Modules to check: 6927. Percentage nodes done: 0.929502\n",
      "checked 9000 modules 8875 were found significant.  Modules to check: 6827. Percentage nodes done: 0.931124\n",
      "checked 9100 modules 8972 were found significant.  Modules to check: 6727. Percentage nodes done: 0.93279\n",
      "checked 9200 modules 9070 were found significant.  Modules to check: 6627. Percentage nodes done: 0.934619\n",
      "checked 9300 modules 9165 were found significant.  Modules to check: 6527. Percentage nodes done: 0.936253\n",
      "checked 9400 modules 9261 were found significant.  Modules to check: 6427. Percentage nodes done: 0.93788\n",
      "checked 9500 modules 9355 were found significant.  Modules to check: 6327. Percentage nodes done: 0.939575\n",
      "checked 9600 modules 9454 were found significant.  Modules to check: 6227. Percentage nodes done: 0.941217\n",
      "checked 9700 modules 9550 were found significant.  Modules to check: 6127. Percentage nodes done: 0.942741\n",
      "checked 9800 modules 9646 were found significant.  Modules to check: 6027. Percentage nodes done: 0.9442\n",
      "checked 9900 modules 9745 were found significant.  Modules to check: 5927. Percentage nodes done: 0.945608\n",
      "checked 10000 modules 9838 were found significant.  Modules to check: 5827. Percentage nodes done: 0.947147\n",
      "checked 10100 modules 9931 were found significant.  Modules to check: 5727. Percentage nodes done: 0.948467\n",
      "checked 10200 modules 10022 were found significant.  Modules to check: 5627. Percentage nodes done: 0.949913\n",
      "checked 10300 modules 10113 were found significant.  Modules to check: 5527. Percentage nodes done: 0.951258\n",
      "checked 10400 modules 10210 were found significant.  Modules to check: 5427. Percentage nodes done: 0.95263\n",
      "checked 10500 modules 10307 were found significant.  Modules to check: 5327. Percentage nodes done: 0.954092\n",
      "checked 10600 modules 10400 were found significant.  Modules to check: 5227. Percentage nodes done: 0.955429\n",
      "checked 10700 modules 10493 were found significant.  Modules to check: 5127. Percentage nodes done: 0.956767\n",
      "checked 10800 modules 10590 were found significant.  Modules to check: 5027. Percentage nodes done: 0.958133\n",
      "checked 10900 modules 10679 were found significant.  Modules to check: 4927. Percentage nodes done: 0.959479\n",
      "checked 11000 modules 10767 were found significant.  Modules to check: 4827. Percentage nodes done: 0.960571\n",
      "checked 11100 modules 10861 were found significant.  Modules to check: 4727. Percentage nodes done: 0.961721\n",
      "checked 11200 modules 10952 were found significant.  Modules to check: 4627. Percentage nodes done: 0.962764\n",
      "checked 11300 modules 11045 were found significant.  Modules to check: 4527. Percentage nodes done: 0.963967\n",
      "checked 11400 modules 11134 were found significant.  Modules to check: 4427. Percentage nodes done: 0.96523\n",
      "checked 11500 modules 11225 were found significant.  Modules to check: 4327. Percentage nodes done: 0.966423\n",
      "checked 11600 modules 11311 were found significant.  Modules to check: 4227. Percentage nodes done: 0.96749\n",
      "checked 11700 modules 11400 were found significant.  Modules to check: 4127. Percentage nodes done: 0.968598\n",
      "checked 11800 modules 11492 were found significant.  Modules to check: 4027. Percentage nodes done: 0.969618\n",
      "checked 11900 modules 11579 were found significant.  Modules to check: 3927. Percentage nodes done: 0.970664\n",
      "checked 12000 modules 11664 were found significant.  Modules to check: 3827. Percentage nodes done: 0.9717\n",
      "checked 12100 modules 11751 were found significant.  Modules to check: 3727. Percentage nodes done: 0.972839\n",
      "checked 12200 modules 11836 were found significant.  Modules to check: 3627. Percentage nodes done: 0.973807\n",
      "checked 12300 modules 11925 were found significant.  Modules to check: 3527. Percentage nodes done: 0.974758\n",
      "checked 12400 modules 12011 were found significant.  Modules to check: 3427. Percentage nodes done: 0.975767\n",
      "checked 12500 modules 12096 were found significant.  Modules to check: 3327. Percentage nodes done: 0.976687\n",
      "checked 12600 modules 12178 were found significant.  Modules to check: 3227. Percentage nodes done: 0.977611\n",
      "checked 12700 modules 12256 were found significant.  Modules to check: 3127. Percentage nodes done: 0.978471\n",
      "checked 12800 modules 12335 were found significant.  Modules to check: 3027. Percentage nodes done: 0.979383\n",
      "checked 12900 modules 12414 were found significant.  Modules to check: 2927. Percentage nodes done: 0.980277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 13000 modules 12492 were found significant.  Modules to check: 2827. Percentage nodes done: 0.981147\n",
      "checked 13100 modules 12571 were found significant.  Modules to check: 2727. Percentage nodes done: 0.981958\n",
      "checked 13200 modules 12649 were found significant.  Modules to check: 2627. Percentage nodes done: 0.982867\n",
      "checked 13300 modules 12721 were found significant.  Modules to check: 2527. Percentage nodes done: 0.983693\n",
      "checked 13400 modules 12799 were found significant.  Modules to check: 2427. Percentage nodes done: 0.984445\n",
      "checked 13500 modules 12869 were found significant.  Modules to check: 2327. Percentage nodes done: 0.985282\n",
      "checked 13600 modules 12934 were found significant.  Modules to check: 2227. Percentage nodes done: 0.986033\n",
      "checked 13700 modules 13005 were found significant.  Modules to check: 2127. Percentage nodes done: 0.98679\n",
      "checked 13800 modules 13070 were found significant.  Modules to check: 2027. Percentage nodes done: 0.987541\n",
      "checked 13900 modules 13142 were found significant.  Modules to check: 1927. Percentage nodes done: 0.988288\n",
      "checked 14000 modules 13202 were found significant.  Modules to check: 1827. Percentage nodes done: 0.989003\n",
      "checked 14100 modules 13264 were found significant.  Modules to check: 1727. Percentage nodes done: 0.989672\n",
      "checked 14200 modules 13329 were found significant.  Modules to check: 1627. Percentage nodes done: 0.990344\n",
      "checked 14300 modules 13386 were found significant.  Modules to check: 1527. Percentage nodes done: 0.991033\n",
      "checked 14400 modules 13442 were found significant.  Modules to check: 1427. Percentage nodes done: 0.991697\n",
      "checked 14500 modules 13494 were found significant.  Modules to check: 1327. Percentage nodes done: 0.992312\n",
      "checked 14600 modules 13550 were found significant.  Modules to check: 1227. Percentage nodes done: 0.992968\n",
      "checked 14700 modules 13593 were found significant.  Modules to check: 1127. Percentage nodes done: 0.993556\n",
      "checked 14800 modules 13651 were found significant.  Modules to check: 1027. Percentage nodes done: 0.994187\n",
      "checked 14900 modules 13697 were found significant.  Modules to check: 927. Percentage nodes done: 0.994783\n",
      "checked 15000 modules 13743 were found significant.  Modules to check: 827. Percentage nodes done: 0.99539\n",
      "checked 15100 modules 13785 were found significant.  Modules to check: 727. Percentage nodes done: 0.995994\n",
      "checked 15200 modules 13820 were found significant.  Modules to check: 627. Percentage nodes done: 0.996578\n",
      "checked 15300 modules 13846 were found significant.  Modules to check: 527. Percentage nodes done: 0.997138\n",
      "checked 15400 modules 13879 were found significant.  Modules to check: 427. Percentage nodes done: 0.997701\n",
      "checked 15500 modules 13901 were found significant.  Modules to check: 327. Percentage nodes done: 0.998249\n",
      "checked 15600 modules 13922 were found significant.  Modules to check: 227. Percentage nodes done: 0.998797\n",
      "checked 15700 modules 13939 were found significant.  Modules to check: 127. Percentage nodes done: 0.999331\n",
      "checked 15800 modules 13949 were found significant.  Modules to check: 27. Percentage nodes done: 0.999861\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 1878\n",
      "iteration: 0 number of modules: 1871\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 7\n",
      "iteration: 0 number of modules: 7\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 12582 modules to check, run: 0\n",
      "minimality check: 4311 modules to check, run: 1\n",
      "minimality check: 158 modules to check, run: 2\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19815\n",
      "iteration: 20 number of modules: 6532\n",
      "iteration: 40 number of modules: 6466\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 6929\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 5\n",
      "checked 200 unions. Fused: 7\n",
      "checked 300 unions. Fused: 9\n",
      "checked 400 unions. Fused: 15\n",
      "checked 500 unions. Fused: 18\n",
      "checked 600 unions. Fused: 31\n",
      "checked 700 unions. Fused: 40\n",
      "checked 800 unions. Fused: 48\n",
      "checked 900 unions. Fused: 55\n",
      "checked 1000 unions. Fused: 76\n",
      "checked 1100 unions. Fused: 88\n",
      "checked 1200 unions. Fused: 100\n",
      "checked 1300 unions. Fused: 120\n",
      "checked 1400 unions. Fused: 136\n",
      "checked 1500 unions. Fused: 155\n",
      "checked 1600 unions. Fused: 171\n",
      "checked 1700 unions. Fused: 192\n",
      "checked 1800 unions. Fused: 208\n",
      "checked 1900 unions. Fused: 225\n",
      "checked 2000 unions. Fused: 237\n",
      "checked 2100 unions. Fused: 251\n",
      "checked 2200 unions. Fused: 273\n",
      "checked 2400 unions. Fused: 307\n",
      "checked 2500 unions. Fused: 319\n",
      "checked 2600 unions. Fused: 337\n",
      "checked 2800 unions. Fused: 358\n",
      "checked 2900 unions. Fused: 367\n",
      "checked 3000 unions. Fused: 373\n",
      "checked 3100 unions. Fused: 379\n",
      "checked 3300 unions. Fused: 398\n",
      "checked 3400 unions. Fused: 402\n",
      "checked 3600 unions. Fused: 414\n",
      "checked 3700 unions. Fused: 417\n",
      "checked 3800 unions. Fused: 423\n",
      "checked 4000 unions. Fused: 427\n",
      "checked 4100 unions. Fused: 429\n",
      "checked 4200 unions. Fused: 432\n",
      "checked 4300 unions. Fused: 432\n",
      "checked 4400 unions. Fused: 434\n",
      "checked 4500 unions. Fused: 436\n",
      "checked 4700 unions. Fused: 438\n",
      "checked 4800 unions. Fused: 439\n",
      "checked 4900 unions. Fused: 441\n",
      "checked 5000 unions. Fused: 441\n",
      "checked 5100 unions. Fused: 441\n",
      "checked 5200 unions. Fused: 442\n",
      "checked 5300 unions. Fused: 443\n",
      "checked 5400 unions. Fused: 443\n",
      "checked 5500 unions. Fused: 443\n",
      "checked 5600 unions. Fused: 444\n",
      "checked 5700 unions. Fused: 444\n",
      "checked 5800 unions. Fused: 444\n",
      "checked 6000 unions. Fused: 444\n",
      "checked 6100 unions. Fused: 444\n",
      "checked 6300 unions. Fused: 444\n",
      "checked 6400 unions. Fused: 444\n",
      "checked 6500 unions. Fused: 444\n",
      "checked 6800 unions. Fused: 444\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 19570\n",
      "iteration: 20 number of modules: 6198\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 6655\n",
      "checked 0 unions. Fused: 0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "!cd ../../oslom/OSLOM2 && \\\n",
    "./oslom_undir -f ../../results/papers/matrix/mentions/edges_colmentions_twitter_na.csv -w -r 10 -hr 50 -seed 42 -cp 0.5\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "seventh-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.46624074459076\n"
     ]
    }
   ],
   "source": [
    "print((end - start)/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "funky-galaxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net1  partitions_level_0  short_tp1\t\t  statistics_level_1.dat  tp1\r\n",
      "net2  partitions_level_1  short_tp2\t\t  statistics_level_2.dat  tp2\r\n",
      "net3  partitions_level_2  short_tp3\t\t  statistics_level_3.dat  tp3\r\n",
      "net4  partitions_level_3  statistics_level_0.dat  tp\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../results/papers/matrix/mentions/edges_mentions_twitter_na.csv_oslo_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-flooring",
   "metadata": {},
   "source": [
    "Guardemos datos temporalmente por consumo excesivo de RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "chief-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'vector_of_colmentions_twitter_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(vector_of_col_mentions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(tmp_save + 'vector_of_local_mentions_twitter_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(vector_of_mentions_undir_local, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(tmp_save + 'vector_of_comentions_ext_twitter_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(vector_of_comentions_ext, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(tmp_save + 'total_users_twitter_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(total_users, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(tmp_save + 'twitter_na.pickle', 'wb') as handle:\n",
    "    pickle.dump(twitter_na.loc[:, [\"username\", \"latitude\", \"longitude\", \"all_tweets\", \"hashtags\"]], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "suburban-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tokenizer(row):\n",
    "    tweets = row[\"all_tweets\"].lower()\n",
    "    \n",
    "    tweets = re.sub('|||', ' ', tweets)\n",
    "    \n",
    "    return TweetTokenizer(reduce_len=3).tokenize(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_na[\"all_tweets\"] = twitter_na.apply(apply_tokenizer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exact-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tweets(row):\n",
    "    return ' '.join(row[\"all_tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reflected-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_na[\"all_tweets\"] = twitter_na.apply(split_tweets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "certain-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_na = twitter_na.loc[:, [\"username\", \"latitude\", \"longitude\", \"all_tweets\", \"hashtags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "successful-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'twitter_na_tweets_tokenized.pickle', 'wb') as handle:\n",
    "    pickle.dump(twitter_na.loc[:, [\"username\", \"latitude\", \"longitude\", \"all_tweets\", \"hashtags\"]], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-measurement",
   "metadata": {},
   "source": [
    "Cargamos todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "neither-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'vector_of_colmentions_twitter_us.pickle', 'rb') as handle:\n",
    "    vector_of_col_mentions = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'total_users_twitter_us.pickle', 'rb') as handle:\n",
    "    total_users = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'twitter_na.pickle', 'rb') as handle:\n",
    "    twitter_na = pickle.load(handle)\n",
    "#with open(tmp_save + 'twitter_na_tweets_tokenized.pickle', 'rb') as handle:\n",
    "#    twitter_na = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "postal-child",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>im subway 327 n main st frankenmuth ||| im ste...</td>\n",
       "      <td>[justsayin, fb, goblue, rockandroll, longlivet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164856</td>\n",
       "      <td>-79.055590</td>\n",
       "      <td>whats tweet us lets chat ||| please like us fa...</td>\n",
       "      <td>[nowplaying, nobodyshero]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarahset24</td>\n",
       "      <td>35.831287</td>\n",
       "      <td>-83.573235</td>\n",
       "      <td>horses wearing diapers clearly theyre full eww...</td>\n",
       "      <td>[yum, ewww, twitterless, ridiculous, smh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javeonthaprince</td>\n",
       "      <td>31.299423</td>\n",
       "      <td>-92.486250</td>\n",
       "      <td>damn slim ya twin tha move cummin tha schultz ...</td>\n",
       "      <td>[wetwetfarting, ihate, itsokaytocheatif, zzzzz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KushNMyTweet__</td>\n",
       "      <td>33.366997</td>\n",
       "      <td>-86.818110</td>\n",
       "      <td>see ian say nun first time still trying ||| le...</td>\n",
       "      <td>[wheniwaslittle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   latitude  longitude  \\\n",
       "0  DanielPPeterson  43.478622 -84.014946   \n",
       "1   530productions  43.164856 -79.055590   \n",
       "2       sarahset24  35.831287 -83.573235   \n",
       "3  Javeonthaprince  31.299423 -92.486250   \n",
       "4   KushNMyTweet__  33.366997 -86.818110   \n",
       "\n",
       "                                          all_tweets  \\\n",
       "0  im subway 327 n main st frankenmuth ||| im ste...   \n",
       "1  whats tweet us lets chat ||| please like us fa...   \n",
       "2  horses wearing diapers clearly theyre full eww...   \n",
       "3  damn slim ya twin tha move cummin tha schultz ...   \n",
       "4  see ian say nun first time still trying ||| le...   \n",
       "\n",
       "                                            hashtags  \n",
       "0  [justsayin, fb, goblue, rockandroll, longlivet...  \n",
       "1                          [nowplaying, nobodyshero]  \n",
       "2          [yum, ewww, twitterless, ridiculous, smh]  \n",
       "3  [wetwetfarting, ihate, itsokaytocheatif, zzzzz...  \n",
       "4                                   [wheniwaslittle]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "linear-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ids = twitter_na[\"username\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-lawrence",
   "metadata": {},
   "source": [
    "# Class generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "multiple-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 256\n"
     ]
    }
   ],
   "source": [
    "leaves = kdtree_class_gen(twitter_na, 1200)\n",
    "print(\"Total classes:\", len(leaves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "given-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves_df = gpd.GeoDataFrame(leaves)\n",
    "\n",
    "def create_regions(row):\n",
    "    return box(row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"])\n",
    "\n",
    "def create_mid_point(row):\n",
    "    return Point(row[\"x_med_points\"], row[\"y_med_points\"])\n",
    "\n",
    "leaves_df[\"region\"] = leaves_df.apply(create_regions, axis=1)\n",
    "leaves_df[\"mid_point\"] = leaves_df.apply(create_mid_point, axis=1)\n",
    "\n",
    "region_df = gpd.GeoDataFrame(leaves_df, geometry='region')\n",
    "med_df = gpd.GeoDataFrame(leaves_df, geometry='mid_point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "induced-respect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "world = gpd.read_file(\n",
    "    gpd.datasets.get_path('naturalearth_lowres')\n",
    ")\n",
    "\n",
    "usa = world.query('continent == \"North America\"')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "usa.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "region_df.plot(ax=ax, cmap=\"tab20b\", alpha=0.3, linewidth=2, linestyle='-', edgecolor=\"black\")\n",
    "med_df.plot(ax=ax, marker='o', markersize=120, cmap=\"tab20b\", alpha=1.0)\n",
    "\n",
    "ax.set_xlim(-135, -40)\n",
    "ax.set_ylim(20, 60)\n",
    "\n",
    "fig.savefig(figuresPath + 'twitter_us/kdtree_twitter_us.pdf', bbox_inches = 'tight')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "joint-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25298, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = [\n",
    "    \"geonameid\",\n",
    "    \"name\",\n",
    "    \"asciiname\",\n",
    "    \"alternatenames\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"feature class\",\n",
    "    \"feature code\",\n",
    "    \"country code\",\n",
    "    \"cc2\",\n",
    "    \"admin1 code\",\n",
    "    \"admin2 code\",\n",
    "    \"admin3 code\",\n",
    "    \"admin4 code\",\n",
    "    \"population\",\n",
    "    \"elevation\",\n",
    "    \"dem\",\n",
    "    \"timezone\",\n",
    "    \"modification date\"\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "    \"geonameid\": np.int32,\n",
    "    \"name\": str,\n",
    "    \"asciiname\": str,\n",
    "    \"alternatenames\": str,\n",
    "    \"latitude\": np.float32,\n",
    "    \"longitude\": np.float32,\n",
    "    \"feature class\": str,\n",
    "    \"feature code\": str,\n",
    "    \"country code\": str,\n",
    "    \"cc2\": str,\n",
    "    \"admin1 code\": str,\n",
    "    \"admin2 code\": str,\n",
    "    \"admin3 code\": str,\n",
    "    \"admin4 code\": str,\n",
    "    \"population\": np.uint64,\n",
    "    \"elevation\": np.float32,\n",
    "    \"dem\": str,\n",
    "    \"timezone\": str,\n",
    "    \"modification date\": str    \n",
    "}\n",
    "\n",
    "geonames = pd.read_csv(\n",
    "    unTPath + 'geonames_us/cities15000.txt',\n",
    "    sep=\"\\t\",\n",
    "    names=colnames,\n",
    "    dtype=dtypes\n",
    ")\n",
    "\n",
    "geonames = geonames.rename(columns={\"asciiname\": \"city_name\"})\n",
    "geonames = geonames.fillna(\"\")\n",
    "geonames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "taken-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "def admin2_codes_filter(row):\n",
    "    if len(row[\"admin2 code\"]) > 4 or len(row[\"admin2 code\"]) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    return \"-\" + row[\"admin2 code\"]\n",
    "    \n",
    "geonames[\"admin2 code\"] = geonames.apply(admin2_codes_filter, axis=1)\n",
    "geonames[\"unified_name\"] = geonames[\"city_name\"] + \"-\" + geonames[\"admin1 code\"] + geonames[\"admin2 code\"] + \"-\" + geonames[\"country code\"]\n",
    "geonames[\"unique_code\"] = geonames[\"admin1 code\"] + geonames[\"admin2 code\"] + \"-\" + geonames[\"country code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beautiful-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>feature class</th>\n",
       "      <th>feature code</th>\n",
       "      <th>country code</th>\n",
       "      <th>cc2</th>\n",
       "      <th>...</th>\n",
       "      <th>admin2 code</th>\n",
       "      <th>admin3 code</th>\n",
       "      <th>admin4 code</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>dem</th>\n",
       "      <th>timezone</th>\n",
       "      <th>modification date</th>\n",
       "      <th>unified_name</th>\n",
       "      <th>unique_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3040051</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15853</td>\n",
       "      <td></td>\n",
       "      <td>1033</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-10-15</td>\n",
       "      <td>les Escaldes-08-AD</td>\n",
       "      <td>08-AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3041563</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20430</td>\n",
       "      <td></td>\n",
       "      <td>1037</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>Andorra la Vella-07-AD</td>\n",
       "      <td>07-AD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid              name         city_name  \\\n",
       "0    3040051      les Escaldes      les Escaldes   \n",
       "1    3041563  Andorra la Vella  Andorra la Vella   \n",
       "\n",
       "                                      alternatenames  latitude  longitude  \\\n",
       "0  Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...  42.50729    1.53414   \n",
       "1  ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...  42.50779    1.52109   \n",
       "\n",
       "  feature class feature code country code cc2  ... admin2 code admin3 code  \\\n",
       "0             P         PPLA           AD      ...                           \n",
       "1             P         PPLC           AD      ...                           \n",
       "\n",
       "  admin4 code population  elevation   dem        timezone modification date  \\\n",
       "0                  15853             1033  Europe/Andorra        2008-10-15   \n",
       "1                  20430             1037  Europe/Andorra        2020-03-03   \n",
       "\n",
       "             unified_name unique_code  \n",
       "0      les Escaldes-08-AD       08-AD  \n",
       "1  Andorra la Vella-07-AD       07-AD  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geonames.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expired-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geonames size after finding biggest C cities per region:  17805\n",
      "Geonames size after collapsing:  (6091, 21)\n",
      "Geonames size after finding biggest C cities per region:  4778\n",
      "Geonames size after collapsing:  (3538, 21)\n",
      "Geonames size after finding biggest C cities per region:  2915\n",
      "Geonames size after collapsing:  (2433, 21)\n",
      "Geonames size after finding biggest C cities per region:  2096\n",
      "Geonames size after collapsing:  (1847, 21)\n",
      "Geonames size after finding biggest C cities per region:  1656\n",
      "Geonames size after collapsing:  (1494, 21)\n",
      "Geonames size after finding biggest C cities per region:  1365\n",
      "Geonames size after collapsing:  (1283, 21)\n",
      "Geonames size after finding biggest C cities per region:  1191\n",
      "Geonames size after collapsing:  (1109, 21)\n",
      "Geonames size after finding biggest C cities per region:  1032\n",
      "Geonames size after collapsing:  (953, 21)\n",
      "Geonames size after finding biggest C cities per region:  888\n",
      "Geonames size after collapsing:  (845, 21)\n",
      "Geonames size after finding biggest C cities per region:  785\n",
      "Geonames size after collapsing:  (752, 21)\n",
      "Geonames size after finding biggest C cities per region:  705\n",
      "Geonames size after collapsing:  (668, 21)\n",
      "Geonames size after finding biggest C cities per region:  631\n",
      "Geonames size after collapsing:  (611, 21)\n",
      "Geonames size after finding biggest C cities per region:  582\n",
      "Geonames size after collapsing:  (554, 21)\n",
      "Geonames size after finding biggest C cities per region:  528\n",
      "Geonames size after collapsing:  (506, 21)\n",
      "Geonames size after finding biggest C cities per region:  484\n",
      "Geonames size after collapsing:  (463, 21)\n",
      "Geonames size after finding biggest C cities per region:  442\n",
      "Geonames size after collapsing:  (419, 21)\n",
      "Geonames size after finding biggest C cities per region:  399\n",
      "Geonames size after collapsing:  (390, 21)\n",
      "Geonames size after finding biggest C cities per region:  375\n",
      "Geonames size after collapsing:  (365, 21)\n",
      "Geonames size after finding biggest C cities per region:  350\n",
      "Geonames size after collapsing:  (337, 21)\n",
      "Geonames size after finding biggest C cities per region:  324\n",
      "Geonames size after collapsing:  (316, 21)\n",
      "Geonames size after finding biggest C cities per region:  303\n",
      "Geonames size after collapsing:  (290, 21)\n",
      "Geonames size after finding biggest C cities per region:  278\n",
      "Geonames size after collapsing:  (270, 21)\n",
      "Geonames size after finding biggest C cities per region:  258\n",
      "Geonames size after collapsing:  (252, 21)\n",
      "Geonames size after finding biggest C cities per region:  243\n",
      "Geonames size after collapsing:  (232, 21)\n",
      "Geonames size after finding biggest C cities per region:  223\n",
      "Geonames size after collapsing:  (215, 21)\n",
      "Geonames size after finding biggest C cities per region:  207\n",
      "Geonames size after collapsing:  (202, 21)\n",
      "Geonames size after finding biggest C cities per region:  194\n",
      "Geonames size after collapsing:  (188, 21)\n",
      "Geonames size after finding biggest C cities per region:  181\n",
      "Geonames size after collapsing:  (177, 21)\n",
      "Geonames size after finding biggest C cities per region:  170\n",
      "Geonames size after collapsing:  (161, 21)\n",
      "Geonames size after finding biggest C cities per region:  155\n",
      "Geonames size after collapsing:  (150, 21)\n",
      "Geonames size after finding biggest C cities per region:  145\n",
      "Geonames size after collapsing:  (144, 21)\n",
      "Geonames size after finding biggest C cities per region:  139\n",
      "Geonames size after collapsing:  (133, 21)\n",
      "Geonames size after finding biggest C cities per region:  128\n",
      "Geonames size after collapsing:  (125, 21)\n",
      "Geonames size after finding biggest C cities per region:  120\n",
      "Geonames size after collapsing:  (115, 21)\n",
      "Geonames size after finding biggest C cities per region:  110\n",
      "Geonames size after collapsing:  (102, 21)\n",
      "Geonames size after finding biggest C cities per region:  97\n",
      "Geonames size after collapsing:  (94, 21)\n",
      "Geonames size after finding biggest C cities per region:  90\n",
      "Geonames size after collapsing:  (88, 21)\n",
      "Geonames size after finding biggest C cities per region:  84\n",
      "Geonames size after collapsing:  (80, 21)\n",
      "Geonames size after finding biggest C cities per region:  76\n",
      "Geonames size after collapsing:  (74, 21)\n",
      "Geonames size after finding biggest C cities per region:  70\n",
      "Geonames size after collapsing:  (66, 21)\n",
      "Geonames size after finding biggest C cities per region:  62\n",
      "Geonames size after collapsing:  (60, 21)\n",
      "Geonames size after finding biggest C cities per region:  56\n",
      "Geonames size after collapsing:  (55, 21)\n",
      "Geonames size after finding biggest C cities per region:  51\n",
      "Geonames size after collapsing:  (51, 21)\n",
      "Geonames size after finding biggest C cities per region:  47\n",
      "Geonames size after collapsing:  (45, 21)\n",
      "Geonames size after finding biggest C cities per region:  41\n",
      "Geonames size after collapsing:  (41, 21)\n",
      "Geonames size after finding biggest C cities per region:  37\n",
      "Geonames size after collapsing:  (37, 21)\n",
      "Geonames size after finding biggest C cities per region:  35\n",
      "Geonames size after collapsing:  (34, 21)\n",
      "Geonames size after finding biggest C cities per region:  32\n",
      "Geonames size after collapsing:  (32, 21)\n",
      "Geonames size after finding biggest C cities per region:  30\n",
      "Geonames size after collapsing:  (30, 21)\n",
      "Geonames size after finding biggest C cities per region:  28\n",
      "Geonames size after collapsing:  (28, 21)\n",
      "Geonames size after finding biggest C cities per region:  27\n",
      "Geonames size after collapsing:  (26, 21)\n",
      "Geonames size after finding biggest C cities per region:  25\n",
      "Geonames size after collapsing:  (25, 21)\n",
      "Geonames size after finding biggest C cities per region:  24\n",
      "Geonames size after collapsing:  (24, 21)\n",
      "Geonames size after finding biggest C cities per region:  23\n",
      "Geonames size after collapsing:  (22, 21)\n",
      "Geonames size after finding biggest C cities per region:  21\n",
      "Geonames size after collapsing:  (21, 21)\n",
      "Geonames size after finding biggest C cities per region:  20\n",
      "Geonames size after collapsing:  (20, 21)\n",
      "Geonames size after finding biggest C cities per region:  19\n",
      "Geonames size after collapsing:  (19, 21)\n",
      "Geonames size after finding biggest C cities per region:  18\n",
      "Geonames size after collapsing:  (18, 21)\n",
      "Geonames size after finding biggest C cities per region:  17\n",
      "Geonames size after collapsing:  (17, 21)\n",
      "Geonames size after finding biggest C cities per region:  16\n",
      "Geonames size after collapsing:  (16, 21)\n",
      "Geonames size after finding biggest C cities per region:  15\n",
      "Geonames size after collapsing:  (14, 21)\n",
      "Geonames size after finding biggest C cities per region:  13\n",
      "Geonames size after collapsing:  (13, 21)\n",
      "Geonames size after finding biggest C cities per region:  12\n",
      "Geonames size after collapsing:  (11, 21)\n",
      "Geonames size after finding biggest C cities per region:  10\n",
      "Geonames size after collapsing:  (10, 21)\n",
      "Geonames size after finding biggest C cities per region:  9\n",
      "Geonames size after collapsing:  (8, 21)\n",
      "Geonames size after finding biggest C cities per region:  7\n",
      "Geonames size after collapsing:  (7, 21)\n",
      "Geonames size after finding biggest C cities per region:  6\n",
      "Geonames size after collapsing:  (6, 21)\n",
      "Geonames size after finding biggest C cities per region:  5\n",
      "Geonames size after collapsing:  (5, 21)\n",
      "Geonames size after finding biggest C cities per region:  4\n",
      "Geonames size after collapsing:  (4, 21)\n",
      "Geonames size after finding biggest C cities per region:  3\n",
      "Geonames size after collapsing:  (3, 21)\n",
      "Geonames size after finding biggest C cities per region:  2\n",
      "Geonames size after collapsing:  (2, 21)\n",
      "Geonames size after finding biggest C cities per region:  1\n",
      "Geonames size after collapsing:  (1, 21)\n",
      "Geonames size after finding biggest C cities per region:  0\n",
      "Geonames size after collapsing:  (0, 21)\n"
     ]
    }
   ],
   "source": [
    "biggest_cities_list = []\n",
    "\n",
    "def collapse_cities(row, biggest_cities):\n",
    "    city_to_check = biggest_cities.loc[biggest_cities[\"unique_code\"] == row[\"unique_code\"]].iloc[0]\n",
    "    dist = haversine_distance(row[\"latitude\"], row[\"longitude\"], city_to_check[\"latitude\"], city_to_check[\"longitude\"])\n",
    "    \n",
    "    if dist <= 50.0:\n",
    "        biggest_cities.loc[biggest_cities[\"unique_code\"] == row[\"unique_code\"], [\"population\"]] += row[\"population\"]\n",
    "        return -1\n",
    "    \n",
    "    return row[\"population\"]\n",
    "\n",
    "while geonames.shape[0] > 0:\n",
    "    biggest_cities = geonames.loc[:, [\n",
    "        \"unique_code\", \"population\",\n",
    "    ]].groupby(\"unique_code\").max().reset_index()\n",
    "\n",
    "    biggest_cities = pd.merge(\n",
    "        left=geonames.loc[:, [\"city_name\", \"latitude\", \"longitude\", \"admin1 code\", \"admin2 code\", \"country code\", \"unified_name\", \"unique_code\", \"population\"]],\n",
    "        right=biggest_cities,\n",
    "        how='inner',\n",
    "        on=[\"unique_code\", \"population\"]\n",
    "    )\n",
    "\n",
    "    geonames = geonames[~geonames['unified_name'].isin(biggest_cities[\"unified_name\"].to_numpy())]\n",
    "    \n",
    "    print(\"Geonames size after finding biggest C cities per region: \", geonames.shape[0])\n",
    "\n",
    "    geonames[\"population\"] = geonames.apply(collapse_cities, axis=1, biggest_cities=biggest_cities)   \n",
    "    geonames = geonames[geonames[\"population\"] > -1]\n",
    "    \n",
    "    print(\"Geonames size after collapsing: \", geonames.shape)\n",
    "    \n",
    "    biggest_cities_list.append(biggest_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prompt-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities = biggest_cities_list[0]\n",
    "\n",
    "for i in range(1, len(biggest_cities_list)):\n",
    "    top_cities = pd.concat((top_cities, biggest_cities_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coated-integer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4145, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cities = top_cities[top_cities[\"population\"] >= 100000]\n",
    "top_cities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "married-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'top_cities.pickle', 'wb') as handle:\n",
    "    pickle.dump(top_cities, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "according-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'top_cities.pickle', 'rb') as handle:\n",
    "    top_cities = pickle.load(handle)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aware-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_geonames = top_cities.unified_name.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "integrated-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = BallTree(top_cities[[\"latitude\", \"longitude\"]])              \n",
    "\n",
    "dist, ind = tree.query(twitter_na[[\"latitude\", \"longitude\"]].to_numpy(), k=1)\n",
    "\n",
    "twitter_na[\"closest_city\"] = cities_geonames[ind].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "scheduled-reliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na[\"closest_city\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "serial-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449650, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "similar-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>class</th>\n",
       "      <th>closest_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>im subway 327 n main st frankenmuth ||| im ste...</td>\n",
       "      <td>[justsayin, fb, goblue, rockandroll, longlivet...</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Flint-MI-049-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164856</td>\n",
       "      <td>-79.055590</td>\n",
       "      <td>whats tweet us lets chat ||| please like us fa...</td>\n",
       "      <td>[nowplaying, nobodyshero]</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Niagara Falls-08-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarahset24</td>\n",
       "      <td>35.831287</td>\n",
       "      <td>-83.573235</td>\n",
       "      <td>horses wearing diapers clearly theyre full eww...</td>\n",
       "      <td>[yum, ewww, twitterless, ridiculous, smh]</td>\n",
       "      <td>151.0</td>\n",
       "      <td>Knoxville-TN-093-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javeonthaprince</td>\n",
       "      <td>31.299423</td>\n",
       "      <td>-92.486250</td>\n",
       "      <td>damn slim ya twin tha move cummin tha schultz ...</td>\n",
       "      <td>[wetwetfarting, ihate, itsokaytocheatif, zzzzz...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Lafayette-LA-055-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KushNMyTweet__</td>\n",
       "      <td>33.366997</td>\n",
       "      <td>-86.818110</td>\n",
       "      <td>see ian say nun first time still trying ||| le...</td>\n",
       "      <td>[wheniwaslittle]</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Birmingham-AL-073-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   latitude  longitude  \\\n",
       "0  DanielPPeterson  43.478622 -84.014946   \n",
       "1   530productions  43.164856 -79.055590   \n",
       "2       sarahset24  35.831287 -83.573235   \n",
       "3  Javeonthaprince  31.299423 -92.486250   \n",
       "4   KushNMyTweet__  33.366997 -86.818110   \n",
       "\n",
       "                                          all_tweets  \\\n",
       "0  im subway 327 n main st frankenmuth ||| im ste...   \n",
       "1  whats tweet us lets chat ||| please like us fa...   \n",
       "2  horses wearing diapers clearly theyre full eww...   \n",
       "3  damn slim ya twin tha move cummin tha schultz ...   \n",
       "4  see ian say nun first time still trying ||| le...   \n",
       "\n",
       "                                            hashtags  class  \\\n",
       "0  [justsayin, fb, goblue, rockandroll, longlivet...  186.0   \n",
       "1                          [nowplaying, nobodyshero]  188.0   \n",
       "2          [yum, ewww, twitterless, ridiculous, smh]  151.0   \n",
       "3  [wetwetfarting, ihate, itsokaytocheatif, zzzzz...   74.0   \n",
       "4                                   [wheniwaslittle]   86.0   \n",
       "\n",
       "           closest_city  \n",
       "0       Flint-MI-049-US  \n",
       "1   Niagara Falls-08-CA  \n",
       "2   Knoxville-TN-093-US  \n",
       "3   Lafayette-LA-055-US  \n",
       "4  Birmingham-AL-073-US  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "viral-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_split(row):\n",
    "    return row[\"all_tweets\"].split('|||')[:100]\n",
    "\n",
    "#twitter_na_txt = twitter_na.loc[:, [\"username\", \"latitude\", \"longitude\", \"all_tweets\", \"class\", \"closest_city\"]]\n",
    "#twitter_na_txt[\"all_tweets\"] = twitter_na_txt.apply(tweets_split, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "missing-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_na_txt = twitter_na_txt.explode(\"all_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "express-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_na_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "engaged-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'twitter_na_explode_txt.pickle', 'wb') as handle:\n",
    "#    pickle.dump(twitter_na_txt, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "color-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'twitter_na_explode_txt.pickle', 'rb') as handle:\n",
    "#    twitter_na_txt = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "meaningful-shanghai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median: 7.0 Mean: 8.006623190337454 Max: 62 Min: 1\n"
     ]
    }
   ],
   "source": [
    "#txt_dist = twitter_na_txt[\"all_tweets\"].apply(lambda x: x.split(' ')).str.len()\n",
    "\n",
    "#print(\n",
    "#    \"Median:\", txt_dist.median(),\n",
    "#    \"Mean:\", txt_dist.mean(),\n",
    "#    \"Max:\", txt_dist.max(),\n",
    "#    \"Min:\", txt_dist.min()\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-algebra",
   "metadata": {},
   "source": [
    "# Predictions run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-whale",
   "metadata": {},
   "source": [
    "# Co-mentions prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acknowledged-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, clusters = extract_all_oslom('../../results/papers/matrix/mentions/edges_comentions_twitter_na.csv_oslo_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "attended-explanation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clusters</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "      <th>clusters_4</th>\n",
       "      <th>clusters_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[5802, 11449]</td>\n",
       "      <td>[2239]</td>\n",
       "      <td>[186]</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[15133]</td>\n",
       "      <td>[2917]</td>\n",
       "      <td>[243]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       clusters clusters_1 clusters_2 clusters_3 clusters_4 clusters_5\n",
       "0   0  [5802, 11449]     [2239]      [186]       [25]        [0]        [0]\n",
       "1   3        [15133]     [2917]      [243]       [46]        [0]        [0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "political-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_clusters_lvls = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "funky-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387205"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "working-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "placed-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_user_id(row):\n",
    "    return total_users[row[\"id\"]]\n",
    "\n",
    "train[\"id\"] = train.apply(get_original_user_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sunset-services",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>class</th>\n",
       "      <th>closest_city</th>\n",
       "      <th>clusters</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "      <th>clusters_4</th>\n",
       "      <th>clusters_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>im subway 327 n main st frankenmuth ||| im ste...</td>\n",
       "      <td>[justsayin, fb, goblue, rockandroll, longlivet...</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Flint-MI-049-US</td>\n",
       "      <td>[5802, 11449]</td>\n",
       "      <td>[2239]</td>\n",
       "      <td>[186]</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164856</td>\n",
       "      <td>-79.055590</td>\n",
       "      <td>whats tweet us lets chat ||| please like us fa...</td>\n",
       "      <td>[nowplaying, nobodyshero]</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Niagara Falls-08-CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   latitude  longitude  \\\n",
       "0  DanielPPeterson  43.478622 -84.014946   \n",
       "1   530productions  43.164856 -79.055590   \n",
       "\n",
       "                                          all_tweets  \\\n",
       "0  im subway 327 n main st frankenmuth ||| im ste...   \n",
       "1  whats tweet us lets chat ||| please like us fa...   \n",
       "\n",
       "                                            hashtags  class  \\\n",
       "0  [justsayin, fb, goblue, rockandroll, longlivet...  186.0   \n",
       "1                          [nowplaying, nobodyshero]  188.0   \n",
       "\n",
       "          closest_city       clusters clusters_1 clusters_2 clusters_3  \\\n",
       "0      Flint-MI-049-US  [5802, 11449]     [2239]      [186]       [25]   \n",
       "1  Niagara Falls-08-CA            NaN        NaN        NaN        NaN   \n",
       "\n",
       "  clusters_4 clusters_5  \n",
       "0        [0]        [0]  \n",
       "1        NaN        NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na = pd.merge(\n",
    "    left=twitter_na,\n",
    "    right=train,\n",
    "    how='left',\n",
    "    left_on='username',\n",
    "    right_on='id',\n",
    "    validate=\"1:m\"\n",
    ")\n",
    "\n",
    "del twitter_na[\"id\"]\n",
    "\n",
    "twitter_na.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "choice-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_na = twitter_na.rename(columns={\n",
    "    \"clusters\": \"clusters_mentions_0\",\n",
    "    \"clusters_1\": \"clusters_mentions_1\",\n",
    "    \"clusters_2\": \"clusters_mentions_2\",\n",
    "    \"clusters_3\": \"clusters_mentions_3\",\n",
    "    \"clusters_4\": \"clusters_mentions_4\",\n",
    "    \"clusters_5\": \"clusters_mentions_5\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "hybrid-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(total_clusters_lvls):\n",
    "    ind = str(i)\n",
    "    twitter_na.loc[twitter_na['clusters_mentions_' + ind].isnull(), ['clusters_mentions_' + ind]] = twitter_na.loc[twitter_na['clusters_mentions_' + ind].isnull(),'clusters_mentions_' + ind].apply(lambda x: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "enhanced-broadway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>class</th>\n",
       "      <th>closest_city</th>\n",
       "      <th>clusters_mentions_0</th>\n",
       "      <th>clusters_mentions_1</th>\n",
       "      <th>clusters_mentions_2</th>\n",
       "      <th>clusters_mentions_3</th>\n",
       "      <th>clusters_mentions_4</th>\n",
       "      <th>clusters_mentions_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanielPPeterson</td>\n",
       "      <td>43.478622</td>\n",
       "      <td>-84.014946</td>\n",
       "      <td>im subway 327 n main st frankenmuth ||| im ste...</td>\n",
       "      <td>[justsayin, fb, goblue, rockandroll, longlivet...</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Flint-MI-049-US</td>\n",
       "      <td>[5802, 11449]</td>\n",
       "      <td>[2239]</td>\n",
       "      <td>[186]</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530productions</td>\n",
       "      <td>43.164856</td>\n",
       "      <td>-79.055590</td>\n",
       "      <td>whats tweet us lets chat ||| please like us fa...</td>\n",
       "      <td>[nowplaying, nobodyshero]</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Niagara Falls-08-CA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   latitude  longitude  \\\n",
       "0  DanielPPeterson  43.478622 -84.014946   \n",
       "1   530productions  43.164856 -79.055590   \n",
       "\n",
       "                                          all_tweets  \\\n",
       "0  im subway 327 n main st frankenmuth ||| im ste...   \n",
       "1  whats tweet us lets chat ||| please like us fa...   \n",
       "\n",
       "                                            hashtags  class  \\\n",
       "0  [justsayin, fb, goblue, rockandroll, longlivet...  186.0   \n",
       "1                          [nowplaying, nobodyshero]  188.0   \n",
       "\n",
       "          closest_city clusters_mentions_0 clusters_mentions_1  \\\n",
       "0      Flint-MI-049-US       [5802, 11449]              [2239]   \n",
       "1  Niagara Falls-08-CA                  []                  []   \n",
       "\n",
       "  clusters_mentions_2 clusters_mentions_3 clusters_mentions_4  \\\n",
       "0               [186]                [25]                 [0]   \n",
       "1                  []                  []                  []   \n",
       "\n",
       "  clusters_mentions_5  \n",
       "0                 [0]  \n",
       "1                  []  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_na.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fewer-healing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429652, 13) (9998, 13) (10000, 13)\n"
     ]
    }
   ],
   "source": [
    "colnames=[\"username\"]\n",
    "usecols=[\"username\"]\n",
    "\n",
    "dtypes = {\n",
    "    \"username\": str,\n",
    "}\n",
    "\n",
    "train_na = pd.read_csv(\"../../location/datasets/na/user_info.train\", sep=\"\\t\", names=colnames, usecols=usecols, dtype=dtypes)\n",
    "test_na = pd.read_csv(\"../../location/datasets/na/user_info.test\", sep=\"\\t\", names=colnames, usecols=usecols, dtype=dtypes)\n",
    "val_na = pd.read_csv(\"../../location/datasets/na/user_info.dev\", sep=\"\\t\", names=colnames, usecols=usecols, dtype=dtypes)\n",
    "\n",
    "train_na = pd.merge(\n",
    "    left=train_na,\n",
    "    right=twitter_na,\n",
    "    how='inner',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "         \n",
    "test_na = pd.merge(\n",
    "    left=test_na,\n",
    "    right=twitter_na,\n",
    "    how='inner',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "\n",
    "val_na = pd.merge(\n",
    "    left=val_na,\n",
    "    right=twitter_na,\n",
    "    how='inner',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "\n",
    "print(train_na.shape, val_na.shape, test_na.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "skilled-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = train_na.groupby(\"closest_city\").count().reset_index().loc[:, [\"closest_city\", \"username\"]]\n",
    "count = count.loc[count[\"username\"] >= 10, [\"closest_city\"]]\n",
    "\n",
    "train_na_cities = pd.merge(\n",
    "    left=train_na,\n",
    "    right=count,\n",
    "    how='inner',\n",
    "    on=\"closest_city\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "floral-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na[\"index\"] = train_na.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "stopped-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = train_na.groupby(\"closest_city\").count().reset_index().loc[:, [\"closest_city\", \"username\"]]\n",
    "count = count.loc[count[\"username\"] >= 10, [\"closest_city\"]]\n",
    "\n",
    "train_na_cities = pd.merge(\n",
    "    left=train_na,\n",
    "    right=count,\n",
    "    how='inner',\n",
    "    on=\"closest_city\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "behavioral-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_regions = train_na[\"class\"].astype(\"int\").to_numpy()\n",
    "val_regions = val_na[\"class\"].astype(\"int\").to_numpy()\n",
    "test_regions = test_na[\"class\"].astype(\"int\").to_numpy()\n",
    "\n",
    "encoder = LabelBinarizer()#sparse_output=True)\n",
    "\n",
    "train_regions_enc = encoder.fit_transform(train_regions)\n",
    "val_regions_enc = encoder.transform(val_regions)\n",
    "test_regions_enc = encoder.transform(test_regions)\n",
    "\n",
    "train_cities = train_na_cities[\"closest_city\"].to_numpy()\n",
    "val_cities = val_na[\"closest_city\"].to_numpy()\n",
    "test_cities = test_na[\"closest_city\"].to_numpy()\n",
    "\n",
    "encoder_city = LabelBinarizer()\n",
    "\n",
    "train_cities_enc = encoder_city.fit_transform(train_cities)\n",
    "val_cities_enc = encoder_city.transform(val_cities)\n",
    "test_cities_enc = encoder_city.transform(test_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "compliant-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = train_na[\"all_tweets\"].to_numpy()\n",
    "train_cities_tweets = train_na_cities[\"all_tweets\"].to_numpy()\n",
    "val_tweets = val_na[\"all_tweets\"].to_numpy()\n",
    "test_tweets = test_na[\"all_tweets\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "narrow-reach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36.731544</td>\n",
       "      <td>-121.656166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>36.731190</td>\n",
       "      <td>-119.733500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class   latitude   longitude\n",
       "0     0  36.731544 -121.656166\n",
       "1     1  36.731190 -119.733500"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_with_coords = (pd.DataFrame(leaves)\n",
    "                      .rename(columns={\"y_med_points\": 'latitude', \"x_med_points\": \"longitude\"})\n",
    "                      .loc[:, [\"class\", \"latitude\", \"longitude\"]])\n",
    "\n",
    "places_with_coords = places_with_coords.astype({\"class\": str})\n",
    "\n",
    "places_with_coords.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "premium-battery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras Al Khaimah City-05-AE</td>\n",
       "      <td>25.78953</td>\n",
       "      <td>55.943199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dubai-03-AE</td>\n",
       "      <td>25.07725</td>\n",
       "      <td>55.309269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       class  latitude  longitude\n",
       "3  Ras Al Khaimah City-05-AE  25.78953  55.943199\n",
       "5                Dubai-03-AE  25.07725  55.309269"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_with_coords = top_cities.loc[:, [\"unified_name\", \"latitude\", \"longitude\"]].rename(columns={\"unified_name\": \"class\"})\n",
    "cities_with_coords.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "revised-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_regions = places_with_coords[\"class\"].nunique()\n",
    "total_cities = cities_with_coords[\"class\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "wound-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_coords = train_na[[\"latitude\", \"longitude\"]].to_numpy()\n",
    "users_cities_coords = train_na_cities[[\"latitude\", \"longitude\"]].to_numpy()\n",
    "users_coords_test = test_na[[\"latitude\", \"longitude\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "circular-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_kd, test_kd_idxs = FoldGen().create_folds(train_na, train_regions)\n",
    "folds_cities, test_cities_idxs = FoldGen().create_folds(train_na_cities, train_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "standing-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New saves\n",
    "\n",
    "#regions = [train_regions, val_regions, test_regions, encoder]\n",
    "\n",
    "#with open(tmp_save + 'regions_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(regions, handle, protocol=4)\n",
    "    \n",
    "#cities = [train_cities, val_cities, test_cities, encoder_city]\n",
    "\n",
    "#with open(tmp_save + 'cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(cities, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'train_na_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(train_na, handle, protocol=4)\n",
    "        \n",
    "#with open(tmp_save + 'train_na_cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(train_na_cities, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'val_na_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(val_na, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'test_na_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(test_na, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "italian-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'folds_kd_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(folds_kd, handle, protocol=4) \n",
    "    \n",
    "#with open(tmp_save + 'test_kd_idxs_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(test_kd_idxs, handle, protocol=4)  \n",
    "    \n",
    "#with open(tmp_save + 'folds_cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(folds_cities, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'test_cities_idxs_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(test_cities_idxs, handle, protocol=4)\n",
    "\n",
    "#regions = [train_regions, val_regions, test_regions, train_regions_enc, val_regions_enc, test_regions_enc]\n",
    "#cities = [train_cities, val_cities, test_cities, train_cities_enc, val_cities_enc, test_cities_enc]\n",
    "\n",
    "#with open(tmp_save + 'train_na_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(train_na, handle, protocol=4)\n",
    "        \n",
    "#with open(tmp_save + 'train_na_cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(train_na_cities, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'val_na_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(val_na, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'test_na_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(test_na, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'regions_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(regions, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(cities, handle, protocol=4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-grammar",
   "metadata": {},
   "source": [
    "# Entrenamiento TWITTER-US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-zealand",
   "metadata": {},
   "source": [
    "# Chi2 T√©rminos/Hashtags m√°s significativos (LIW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "white-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChiSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocab, k=50):\n",
    "        self.vocab = vocab\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        features_sel = np.array([])\n",
    "        \n",
    "        #print(\"Finding chi2 most significative terms\")\n",
    "        \n",
    "        for target in np.unique(y):\n",
    "            chi, p = chi2(X, y==target)\n",
    "            \n",
    "            idxs = np.argsort(chi)[-self.k:]\n",
    "            \n",
    "            features_sel = np.concatenate([features_sel, idxs])\n",
    "        \n",
    "        #print(\"Found chi2 most significative terms\")\n",
    "        \n",
    "        features_sel = np.unique(features_sel)\n",
    "        \n",
    "        self.features_selected = features_sel\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X[:, self.features_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "comparable-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index.copy()\n",
    "\n",
    "for i in vocab.keys():\n",
    "    vocab[i] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-rider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary of size:  2487232\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        #strip_accents='unicode',\n",
    "        strip_accents='ascii',\n",
    "        lowercase=True,\n",
    "        max_df=0.1,\n",
    "        min_df=10,\n",
    "        #vocabulary=vocab\n",
    "        #ngram_range=(1, 3)\n",
    "    )\n",
    "    \n",
    "    tweets_train = X_train[\"all_tweets\"]\n",
    "    hashtags_train = X_train[\"hashtags\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    content_train = tweets_train + hashtags_train\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(content_train.to_numpy()).astype(np.uint8)\n",
    "    \n",
    "    print(\"Using vocabulary of size: \", X_train.shape[1])\n",
    "    \n",
    "    tweets_test = X_test[\"all_tweets\"]\n",
    "    hashtags_test = X_test[\"hashtags\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    content_test = tweets_test + hashtags_test\n",
    "    \n",
    "    X_test = vectorizer.transform(content_test).astype(np.uint8)\n",
    "    \n",
    "    estimator = Pipeline(\n",
    "        [\n",
    "            (\"chi2\", ChiSelector(np.array(vectorizer.get_feature_names()), k=60)),\n",
    "            #(\"naive_bayes\", LogisticRegression(n_jobs=-1, solver='sag'))\n",
    "            (\"naive_bayes\", MultinomialNB(alpha=0.5 if i == 0 else 0.05))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    clf = estimator\n",
    "    \n",
    "    '''clf=GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid={\n",
    "            #\"naive_bayes__alpha\": [0.05, 0.1, 0.5],\n",
    "            \"naive_bayes__alpha\": [0.05, 0.1, 0.5],\n",
    "            \"chi2__k\": [50, 100, 150, 300, 400]\n",
    "            #\"chi2__k\": [100]\n",
    "        },\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )'''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Contenido Chi2 + Naive Bayes\",\n",
    ")\n",
    "\n",
    "content_preds = cn_cross_val.cross_predict(\n",
    "    folds_kd,\n",
    "    test_kd_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, content_preds, cn_cross_val.classes_order(), places_with_coords, users_coords)\n",
    "\n",
    "content_preds_city = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(train_cities_enc, content_preds_city, cn_cross_val.classes_order(), cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "introductory-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20207284034520961        \n",
      "Acc@161: 0.41835019969649856        \n",
      "Balanced Acc: 0.20208758621513906        \n",
      "ROC AUC Ovo: 0.7790261486278383        \n",
      "Mean Dist Err: 775.7295151684808        \n",
      "Median Dist Err: 303.94527033106993\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "arctic-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2616010185295097        \n",
      "Acc@161: 0.4415939893724732        \n",
      "Balanced Acc: 0.19200079068974996        \n",
      "ROC AUC Ovo: 0.7934797385514943        \n",
      "Mean Dist Err: 797.8659883064074        \n",
      "Median Dist Err: 278.86803590592933\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "characteristic-jordan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary of size:  1175445\n",
      "Using vocabulary of size:  1172333\n",
      "Using vocabulary of size:  1177745\n",
      "Using vocabulary of size:  1171066\n",
      "Using vocabulary of size:  1171663\n",
      "Using vocabulary of size:  1170430\n",
      "Using vocabulary of size:  1172026\n",
      "Using vocabulary of size:  1179861\n",
      "Using vocabulary of size:  1172867\n",
      "Using vocabulary of size:  1172804\n"
     ]
    }
   ],
   "source": [
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        #strip_accents='unicode',\n",
    "        strip_accents='ascii',\n",
    "        lowercase=True,\n",
    "        analyzer=lambda x: x,\n",
    "        binary=True\n",
    "        #max_df=0.1,\n",
    "        #min_df=10,\n",
    "        #vocabulary=vocab\n",
    "        #ngram_range=(1, 3)\n",
    "    )\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train[\"hashtags\"].to_numpy()).astype(np.uint8)\n",
    "    \n",
    "    print(\"Using vocabulary of size: \", X_train.shape[1])\n",
    "        \n",
    "    X_test = vectorizer.transform(X_test[\"hashtags\"].to_numpy()).astype(np.uint8)\n",
    "    \n",
    "    estimator = Pipeline(\n",
    "        [\n",
    "            (\"chi2\", ChiSelector(np.array(vectorizer.get_feature_names()), k=100)),\n",
    "            (\"naive_bayes\", MultinomialNB(alpha=0.05))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    clf = estimator\n",
    "    \n",
    "    '''clf=GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid={\n",
    "            \"naive_bayes__alpha\": [0.05, 0.1],\n",
    "            \"chi2__k\": [50, 100, 150, 300, 400]\n",
    "        },\n",
    "        cv=3,\n",
    "        #n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )'''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Contenido Chi2 + Naive Bayes\",\n",
    ")\n",
    "\n",
    "hashtag_preds = cn_cross_val.cross_predict(\n",
    "    folds_kd,\n",
    "    test_kd_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, hashtag_preds, cn_cross_val.classes_order(), places_with_coords, users_coords)\n",
    "\n",
    "hashtag_city_preds = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(train_cities_enc, hashtag_city_preds, cn_cross_val.classes_order(), cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "invalid-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1025046608897237        \n",
      "Acc@161: 0.19248485356310763        \n",
      "Balanced Acc: 0.04331205656768197        \n",
      "ROC AUC Ovo: 0.6539821249006317        \n",
      "Mean Dist Err: 1916.7212807788549        \n",
      "Median Dist Err: 1977.58671681972\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "operating-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'content_preds_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(content_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "white-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'content_preds_cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(content_preds_city, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "decent-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'hashtag_preds_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(hashtag_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "creative-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'hashtag_preds_city_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(hashtag_city_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "nuclear-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'content_preds_twitter_us.pickle', 'rb') as handle:\n",
    "    content_preds = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "pacific-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'content_preds_cities_twitter_us.pickle', 'rb') as handle:\n",
    "    content_preds_city = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "distant-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'hashtag_preds_twitter_us.pickle', 'rb') as handle:\n",
    "    hashtag_preds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "indian-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'hashtag_preds_city_twitter_us.pickle', 'rb') as handle:\n",
    "    hashtag_city_preds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-fortune",
   "metadata": {},
   "source": [
    "Chi2 fit sobre todo el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "industrial-happiness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('chi2',\n",
       "                 ChiSelector(k=60,\n",
       "                             vocab=array(['00', '000', '000000', ..., 'zzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzz',\n",
       "       'zzzzzzzzzzzzzzzz'], dtype='<U80'))),\n",
       "                ('naive_bayes', MultinomialNB(alpha=0.05))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    #strip_accents='unicode',\n",
    "    strip_accents='ascii',\n",
    "    lowercase=True,\n",
    "    max_df=0.1,\n",
    "    min_df=10,\n",
    "    #ngram_range=(1, 3)\n",
    ")\n",
    "\n",
    "tweets_train = train_na[\"all_tweets\"]\n",
    "hashtags_train = train_na[\"hashtags\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "content_train = tweets_train + hashtags_train\n",
    "\n",
    "X_train = vectorizer.fit_transform(content_train.to_numpy()).astype(np.uint8)\n",
    "\n",
    "clf = Pipeline(\n",
    "    [\n",
    "        (\"chi2\", ChiSelector(np.array(vectorizer.get_feature_names()), k=60)),\n",
    "        (\"naive_bayes\", MultinomialNB(alpha=0.5))\n",
    "    ]\n",
    ")\n",
    "    \n",
    "clf.fit(X_train, train_regions)\n",
    "\n",
    "vectorizer_city = CountVectorizer(\n",
    "    #strip_accents='unicode',\n",
    "    strip_accents='ascii',\n",
    "    lowercase=True,\n",
    "    max_df=0.1,\n",
    "    min_df=10,\n",
    "    #ngram_range=(1, 3)\n",
    ")\n",
    "\n",
    "tweets_train = train_na_cities[\"all_tweets\"]\n",
    "hashtags_train = train_na_cities[\"hashtags\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "content_train = tweets_train + hashtags_train\n",
    "\n",
    "X_train = vectorizer_city.fit_transform(content_train.to_numpy()).astype(np.uint8)\n",
    "\n",
    "clf_city = Pipeline(\n",
    "    [\n",
    "        (\"chi2\", ChiSelector(np.array(vectorizer.get_feature_names()), k=60)),\n",
    "        (\"naive_bayes\", MultinomialNB(alpha=0.05))\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf_city.fit(X_train, train_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "labeled-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = test_na[\"all_tweets\"]\n",
    "hashtags_test = test_na[\"hashtags\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "content_test = tweets_test + hashtags_test\n",
    "\n",
    "tweets_val = val_na[\"all_tweets\"]\n",
    "hashtags_val = val_na[\"hashtags\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "content_val = tweets_val + hashtags_val\n",
    "\n",
    "X_test = vectorizer.transform(content_test.to_numpy())\n",
    "X_val = vectorizer.transform(content_val.to_numpy())\n",
    "\n",
    "content_preds_fit = clf.predict_proba(\n",
    "    X_test\n",
    ")\n",
    "\n",
    "content_preds_fit_val = clf.predict_proba(\n",
    "    X_val\n",
    ")\n",
    "\n",
    "X_test = vectorizer_city.transform(content_test.to_numpy())\n",
    "X_val = vectorizer_city.transform(content_val.to_numpy())\n",
    "\n",
    "content_preds_city_fit = clf_city.predict_proba(\n",
    "    X_test\n",
    ")\n",
    "\n",
    "content_preds_city_fit_val = clf_city.predict_proba(\n",
    "    X_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "collaborative-advantage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2131        \n",
      "Acc@161: 0.4301        \n",
      "Balanced Acc: 0.2134299265261612        \n",
      "ROC AUC Ovo: 0.7861470169728951        \n",
      "Mean Dist Err: 739.4797613811702        \n",
      "Median Dist Err: 270.88745378747774\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_regions_enc, content_preds_fit, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "hidden-maple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.252        \n",
      "Acc@161: 0.4386        \n",
      "Balanced Acc: 0.20136787679149645        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 780.1000322312422        \n",
      "Median Dist Err: 270.77995747252766\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_cities_enc, content_preds_city_fit, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "innocent-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'content_preds_fit_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(content_preds_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open(tmp_save + 'content_preds_fit_twitter_us_val.pickle', 'wb') as handle:\n",
    "#    pickle.dump(content_preds_fit_val, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "#with open(tmp_save + 'content_predscities_fit_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(content_preds_city_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open(tmp_save + 'content_predscities_fit_twitter_us_val.pickle', 'wb') as handle:\n",
    "#    pickle.dump(content_preds_city_fit_val, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sharing-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'content_preds_fit_twitter_us.pickle', 'rb') as handle:\n",
    "    content_preds_fit = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'content_preds_fit_twitter_us_val.pickle', 'rb') as handle:\n",
    "    content_preds_fit_val = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'content_predscities_fit_twitter_us.pickle', 'rb') as handle:\n",
    "    content_preds_city_fit = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'content_predscities_fit_twitter_us_val.pickle', 'rb') as handle:\n",
    "    content_preds_city_fit_val = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-cinema",
   "metadata": {},
   "source": [
    "Solo hashtags fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "female-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('chi2',\n",
       "                 ChiSelector(k=100,\n",
       "                             vocab=array(['0', '00', '000', ..., 'ÔΩíÔΩÖÔΩîÔΩóÔΩÖÔΩÖÔΩî', 'ÔΩíÔΩî', 'Ôæü–¥Ôæü'], dtype='<U139'))),\n",
       "                ('naive_bayes', MultinomialNB(alpha=0.05))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='ascii',\n",
    "    lowercase=True,\n",
    "    analyzer=lambda x: x,\n",
    "    binary=True\n",
    ")\n",
    "        \n",
    "X_train = vectorizer.fit_transform(train_na[\"hashtags\"].to_numpy()).astype(np.uint8)\n",
    "        \n",
    "estimator = Pipeline(\n",
    "    [\n",
    "        (\"chi2\", ChiSelector(np.array(vectorizer.get_feature_names()), k=100)),\n",
    "        (\"naive_bayes\", MultinomialNB(alpha=0.05))\n",
    "    ]\n",
    ")\n",
    "    \n",
    "clf = estimator\n",
    "\n",
    "clf.fit(X_train, train_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "suffering-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_na[\"hashtags\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "informal-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_preds_fit = clf.predict_proba(\n",
    "    X_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "rubber-stupid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('chi2',\n",
       "                 ChiSelector(k=100,\n",
       "                             vocab=array(['0', '00', '000', ..., 'ÔΩíÔΩÖÔΩîÔΩóÔΩÖÔΩÖÔΩî', 'ÔΩíÔΩî', 'Ôæü–¥Ôæü'], dtype='<U139'))),\n",
       "                ('naive_bayes', MultinomialNB(alpha=0.05))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='ascii',\n",
    "    lowercase=True,\n",
    "    analyzer=lambda x: x,\n",
    "    binary=True\n",
    ")\n",
    "        \n",
    "X_train = vectorizer.fit_transform(train_na_cities[\"hashtags\"].to_numpy()).astype(np.uint8)\n",
    "        \n",
    "estimator = Pipeline(\n",
    "    [\n",
    "        (\"chi2\", ChiSelector(np.array(vectorizer.get_feature_names()), k=100)),\n",
    "        (\"naive_bayes\", MultinomialNB(alpha=0.05))\n",
    "    ]\n",
    ")\n",
    "    \n",
    "clf = estimator\n",
    "\n",
    "clf.fit(X_train, train_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "expired-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_na[\"hashtags\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "chief-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_preds_city_fit = clf.predict_proba(\n",
    "    X_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "alleged-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'hashtags_kd_fit_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(hashtag_preds_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#with open(tmp_save + 'hashtags_cities_fit_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(hashtag_preds_city_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-victory",
   "metadata": {},
   "source": [
    "word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "regional-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "sequence_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caring-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stopwords(row, av_words):\n",
    "    tweets = row[\"all_tweets\"].lower()\n",
    "\n",
    "    return ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words])\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    #strip_accents='unicode',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    max_df=0.05,\n",
    "    min_df=10\n",
    ")\n",
    "\n",
    "vector_of_words = vectorizer.fit_transform(train_tweets).astype(np.uint8)\n",
    "    \n",
    "av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "tweets_filtered = train_na.apply(parse_stopwords, axis=1, av_words=av_words).to_numpy()\n",
    "\n",
    "tweets_filtered_list = list(map(lambda x: x.split(' '), tweets_filtered))\n",
    "    \n",
    "bigrams_detector = Phrases(tweets_filtered_list, \n",
    "            delimiter=' ', min_count=10, threshold=10)\n",
    "\n",
    "bigrams_detector = Phraser(bigrams_detector)\n",
    "    \n",
    "trigrams_detector = Phrases(bigrams_detector[tweets_filtered_list], \n",
    "            delimiter=' ', min_count=10, threshold=10)\n",
    "\n",
    "trigrams_detector = Phraser(trigrams_detector)\n",
    "    \n",
    "tweets_filtered_list = list(bigrams_detector[tweets_filtered_list])\n",
    "tweets_filtered_list = list(trigrams_detector[tweets_filtered_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "covered-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'vocabulary_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(tweets_filtered_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "consistent-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'vocabulary_twitter_us.pickle', 'rb') as handle:\n",
    "    tweets_filtered_list = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "brazilian-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "strong-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 493051\n",
      "Embedding dim recomendado:  26.498601923258857\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(tweets_filtered_list)\n",
    "print('Tokens unicos %s' % len(tokenizer.word_index))\n",
    "print('Embedding dim recomendado: ', len(tokenizer.word_index)**(1/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "smart-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(\n",
    "    tweets_filtered_list,\n",
    "    vector_size=embedding_dim,\n",
    "    window=5,\n",
    "    min_count=0,\n",
    "    sg=1,\n",
    "    workers=7,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baking-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 dim\n",
    "#with open(tmp_save + 'word2vec_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(word2vec, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "egyptian-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300 dim\n",
    "#with open(tmp_save + 'word2vec_twitter_us_300dim.pickle', 'wb') as handle:\n",
    "#    pickle.dump(word2vec, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "increased-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'word2vec_twitter_us.pickle', 'rb') as handle:\n",
    "    word2vec = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "derived-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de embeddings con +1 por el elemento agregado por el Tokenizer\n",
    "embeddings = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embeddings[idx] =  word2vec.wv[word]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "occasional-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nlp_model(\n",
    "    optimizer, num_classes, input_text_length, embeddings_text, words_dim, embedding_text_dim\n",
    "):\n",
    "    clear_session()\n",
    "    \n",
    "    nlp_input = Input(shape=(input_text_length, ))\n",
    "    nlp_emb = Embedding(words_dim, embedding_text_dim, input_length=input_text_length, \n",
    "                    weights=[embeddings_text],trainable=False)(nlp_input)\n",
    "    sdrop = SpatialDropout1D(0.4)(nlp_emb)\n",
    "    nlp_output = Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2))(sdrop)\n",
    "    #nlp_output = Attention(use_scale=True)([nlp_output, nlp_output])\n",
    "    \n",
    "    #nlp_output = MultiHeadAttention(num_heads=6, key_dim=6)(nlp_output, nlp_output)\n",
    "        \n",
    "    #nlp_output = Flatten()(nlp_output)\n",
    "            \n",
    "    output = Dense(num_classes, activation='softmax')(nlp_output)\n",
    "\n",
    "    model = Model(inputs=[nlp_input], outputs=[output])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlp = tokenizer.texts_to_sequences(train_tweets)\n",
    "train_nlp = pad_sequences(train_nlp, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "val_nlp = tokenizer.texts_to_sequences(val_tweets)\n",
    "val_nlp = pad_sequences(val_nlp, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "test_nlp = tokenizer.texts_to_sequences(test_tweets)\n",
    "test_nlp = pad_sequences(test_nlp, maxlen=sequence_length, truncating='post', padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "adequate-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 256, 64)           31555328  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200)               132000    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               25728     \n",
      "=================================================================\n",
      "Total params: 31,713,056\n",
      "Trainable params: 157,728\n",
      "Non-trainable params: 31,555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nlp_model = create_nlp_model(\n",
    "    num_classes=total_regions,\n",
    "    \n",
    "    input_text_length=sequence_length,\n",
    "    embeddings_text=embeddings,\n",
    "    embedding_text_dim=embedding_dim,\n",
    "    words_dim=len(tokenizer.word_index) + 1,\n",
    "\n",
    "    optimizer=\"adam\",\n",
    ")\n",
    "\n",
    "nlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "removed-child",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6714/6714 [==============================] - 1292s 192ms/step - loss: 3.7715 - accuracy: 0.1435 - val_loss: 3.5796 - val_accuracy: 0.1730\n",
      "Epoch 2/30\n",
      "5083/6714 [=====================>........] - ETA: 5:10 - loss: 3.7181 - accuracy: 0.1527"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-5d82db9608a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nlp_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_nlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_cities_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_cities_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlp_model.fit(\n",
    "    train_nlp,\n",
    "    train_regions_enc,\n",
    "    validation_data=(val_nlp, val_regions_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=30,\n",
    "    batch_size=64   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-somalia",
   "metadata": {},
   "source": [
    "# Transformador con pre-embeddings GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_100d = load_glove_model(tmp_save + 'glove_100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "authorized-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "regulation-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "incorporate-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer_model(optimizer, num_classes, input_length, vocab_size, emb_dim, num_heads, ff_dim):\n",
    "    inputs = layers.Input(shape=(input_length,))\n",
    "    \n",
    "    embedding_layer = TokenAndPositionEmbedding(input_length, vocab_size, emb_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(emb_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    #x = layers.Dense(20, activation=\"relu\")(x)\n",
    "    #x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "integral-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 256, 32)           1608192   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 256, 32)           27424     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               8448      \n",
      "=================================================================\n",
      "Total params: 1,644,064\n",
      "Trainable params: 1,644,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_transformer_model(\"adam\", 256, 256, 50000, 32, 6, 32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "painful-brain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 2997590\n",
      "Embedding dim recomendado:  41.609553719274416\n",
      "Epoch 1/30\n",
      "4834/4834 [==============================] - 1693s 350ms/step - loss: 4.5115 - accuracy: 0.0942 - val_loss: 3.9463 - val_accuracy: 0.1650\n",
      "Epoch 2/30\n",
      "4834/4834 [==============================] - 1691s 350ms/step - loss: 3.7062 - accuracy: 0.1902 - val_loss: 3.8595 - val_accuracy: 0.1874\n",
      "Epoch 3/30\n",
      "4076/4834 [========================>.....] - ETA: 4:12 - loss: 3.3465 - accuracy: 0.2362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-3158f73cf0c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m transformer_preds = cn_cross_val.cross_predict(\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mfolds_kd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtest_kd_idxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-97085e467fa9>\u001b[0m in \u001b[0;36mcross_predict\u001b[0;34m(self, folds, test_idx, outer_cv, predict_proba, random_state, preprocess, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-3158f73cf0c6>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     clf.fit(\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "train_regions_unique = len(np.unique(train_regions))\n",
    "train_cities_unique = len(np.unique(train_cities))\n",
    "\n",
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = fold.unpack(val_split=0.1)\n",
    "    \n",
    "    train_tweets = X_train[\"all_tweets\"].to_numpy()\n",
    "    val_tweets = X_val[\"all_tweets\"].to_numpy()\n",
    "    test_tweets = X_test[\"all_tweets\"].to_numpy()\n",
    "    \n",
    "    sequence_length = 512\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        #strip_accents='unicode',\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        max_df=0.7,\n",
    "        min_df=10,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "\n",
    "    vectorizer.fit(train_tweets)\n",
    "\n",
    "    av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "    train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(train_tweets)\n",
    "    \n",
    "    print('Tokens unicos %s' % len(tokenizer.word_index))\n",
    "    print('Embedding dim recomendado: ', len(tokenizer.word_index)**(1/4))\n",
    "    \n",
    "    X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "    X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "    X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "    X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "    X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "    X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "    clf = create_transformer_model(\n",
    "        optimizer=\"adam\",\n",
    "        num_classes=train_regions_unique if i == 0 else train_cities_unique,\n",
    "        input_length=sequence_length,\n",
    "        vocab_size=max_features,\n",
    "        emb_dim=32,\n",
    "        num_heads=6,\n",
    "        ff_dim=32\n",
    "    )\n",
    "    \n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0001, restore_best_weights=True)],\n",
    "        epochs=30,\n",
    "        batch_size=64        \n",
    "    )\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = KerasCrossValidator(\n",
    "    name=\"Contenido Mutual information + Naive Bayes\",\n",
    "    encoder=LabelBinarizer()\n",
    ")\n",
    "\n",
    "transformer_preds = cn_cross_val.cross_predict(\n",
    "    folds_kd,\n",
    "    test_kd_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, transformer_preds, cn_cross_val.classes_order(), places_with_coords, users_coords)\n",
    "\n",
    "i += 1\n",
    "\n",
    "transformer_preds_city = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(train_cities_enc, transformer_preds_city, cn_cross_val.classes_order(), cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'transformer_kd_preds_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(transformer_preds, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "other-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'transformer_kd_preds_twitter_us.pickle', 'rb') as handle:\n",
    "    transformer_preds = pickle.load(handle)\n",
    "    \n",
    "count_score_kd = get_all_metrics(train_regions_enc, transformer_preds, encoder.classes_, places_with_coords, users_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_preds = []\n",
    "\n",
    "with open(tmp_save + 'transformer_kd_preds_twitter_us_1.pickle', 'rb') as handle:\n",
    "    transformer_preds = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_twitter_us_2.pickle', 'rb') as handle:\n",
    "    transformer_preds = np.concatenate((transformer_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_twitter_us_3.pickle', 'rb') as handle:\n",
    "    transformer_preds = np.concatenate((transformer_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_twitter_us_4.pickle', 'rb') as handle:\n",
    "    transformer_preds = np.concatenate((transformer_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_twitter_us_5.pickle', 'rb') as handle:\n",
    "    transformer_preds = np.concatenate((transformer_preds, pickle.load(handle)))\n",
    "    \n",
    "transformer_preds = transformer_preds[test_kd_idxs.argsort()]\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, transformer_preds, encoder.classes_, places_with_coords, users_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "conditional-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20818476348300485        \n",
      "Acc@161: 0.4790155753959018        \n",
      "Balanced Acc: 0.20819323595821745        \n",
      "ROC AUC Ovo: 0.9139434020863897        \n",
      "Mean Dist Err: 648.5760456450319        \n",
      "Median Dist Err: 184.2255573209216\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "meaning-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_city_preds = []\n",
    "\n",
    "with open(tmp_save + 'transformer_city_preds_fit_1_v2.pickle', 'rb') as handle:\n",
    "    transformer_city_preds = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_fit_2_v2.pickle', 'rb') as handle:\n",
    "    transformer_city_preds = np.concatenate((transformer_city_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_fit_3_v2.pickle', 'rb') as handle:\n",
    "    transformer_city_preds = np.concatenate((transformer_city_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_fit_4_v2.pickle', 'rb') as handle:\n",
    "    transformer_city_preds = np.concatenate((transformer_city_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_fit_5_v2.pickle', 'rb') as handle:\n",
    "    transformer_city_preds = np.concatenate((transformer_city_preds, pickle.load(handle)))\n",
    "    \n",
    "transformer_city_preds = transformer_city_preds[test_cities_idxs.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "third-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score_kd = get_all_metrics(train_cities_enc, transformer_city_preds, encoder_city.classes_, cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "missing-employment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28711313451525583        \n",
      "Acc@161: 0.5001896941385675        \n",
      "Balanced Acc: 0.18893769445987432        \n",
      "ROC AUC Ovo: 0.9174775059241199        \n",
      "Mean Dist Err: 656.6197173344874        \n",
      "Median Dist Err: 160.73637918344866\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-aircraft",
   "metadata": {},
   "source": [
    "Transformer fit preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000\n",
    "sequence_length = 512\n",
    "    \n",
    "train_tweets = train_na[\"all_tweets\"].to_numpy()\n",
    "val_tweets = val_na[\"all_tweets\"].to_numpy()\n",
    "test_tweets = test_na[\"all_tweets\"].to_numpy()\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "clf = create_transformer_model(\n",
    "    optimizer=\"adam\",\n",
    "    num_classes=total_regions,\n",
    "    input_length=sequence_length,\n",
    "    vocab_size=max_features,\n",
    "    emb_dim=128,\n",
    "    num_heads=8,\n",
    "    ff_dim=128\n",
    ")\n",
    "    \n",
    "clf.fit(\n",
    "    X_train,\n",
    "    train_regions_enc,\n",
    "    validation_data=(X_val, val_regions_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=300,\n",
    "    batch_size=64        \n",
    ")\n",
    "\n",
    "transformer_kd_fit_preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000\n",
    "sequence_length = 512\n",
    "    \n",
    "train_tweets = train_na_cities[\"all_tweets\"].to_numpy()\n",
    "val_tweets = val_na[\"all_tweets\"].to_numpy()\n",
    "test_tweets = test_na[\"all_tweets\"].to_numpy()\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "    \n",
    "clf = create_transformer_model(\n",
    "    optimizer=\"adam\",\n",
    "    num_classes=total_cities,\n",
    "    input_length=sequence_length,\n",
    "    vocab_size=max_features,\n",
    "    emb_dim=128,\n",
    "    num_heads=8,\n",
    "    ff_dim=128\n",
    ")\n",
    "    \n",
    "clf.fit(\n",
    "    X_train,\n",
    "    train_cities_enc,\n",
    "    validation_data=(X_val, val_cities_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=300,\n",
    "    batch_size=64        \n",
    ")\n",
    "\n",
    "transformer_city_fit_preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/kaggle/working/transformer_kd_preds_fit3.pickle', 'wb') as handle:\n",
    "#    pickle.dump(transformer_kd_fit_preds, handle, protocol=4)\n",
    "\n",
    "#with open('/kaggle/working/transformer_cities_preds_fit.pickle', 'wb') as handle:\n",
    "#    pickle.dump(transformer_city_fit_preds, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fixed-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'transformer_kd_preds_fit6.pickle', 'rb') as handle:\n",
    "    transformer_kd_fit_preds = pickle.load(handle)\n",
    "    \n",
    "count_score_kd = get_all_metrics(test_regions_enc, transformer_kd_fit_preds, encoder.classes_, places_with_coords, users_coords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "lined-parent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2324        \n",
      "Acc@161: 0.5024        \n",
      "Balanced Acc: 0.23130255126037558        \n",
      "ROC AUC Ovo: 0.9201757732932739        \n",
      "Mean Dist Err: 605.9041769364449        \n",
      "Median Dist Err: 158.5066796031915\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "molecular-setting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "with open(tmp_save + 'transformer_cities_preds_fit3.pickle', 'rb') as handle:\n",
    "    transformer_city_fit_preds = pickle.load(handle)\n",
    "    \n",
    "count_score_city = get_all_metrics(test_cities_enc, transformer_city_fit_preds, encoder_city.classes_, cities_with_coords, users_coords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "coordinate-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3009        \n",
      "Acc@161: 0.5156        \n",
      "Balanced Acc: 0.20538400784994076        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 625.2429502368356        \n",
      "Median Dist Err: 141.51207091696287\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-student",
   "metadata": {},
   "source": [
    "# BiLSTM con pre-embeddings GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bilstm_model(optimizer, num_classes, input_length, vocab_size, emb_dim, weights):\n",
    "    inputs = layers.Input(shape=(input_length,))\n",
    "    \n",
    "    emb = Embedding(input_dim=vocab_size, output_dim=emb_dim, weights=[weights], trainable=True)(inputs)\n",
    "    \n",
    "    sdrop = SpatialDropout1D(0.3)(emb)\n",
    "    \n",
    "    nlp_output = Bidirectional(LSTM(50, dropout=0.2))(sdrop)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(nlp_output)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        #loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "train_regions_unique = len(np.unique(train_regions))\n",
    "train_cities_unique = len(np.unique(train_cities))\n",
    "\n",
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = fold.unpack(val_split=0.1)\n",
    "    \n",
    "    train_tweets = X_train[\"all_tweets\"].to_numpy()\n",
    "    val_tweets = X_val[\"all_tweets\"].to_numpy()\n",
    "    test_tweets = X_test[\"all_tweets\"].to_numpy()\n",
    "    \n",
    "    sequence_length = 256\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        #strip_accents='unicode',\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        max_df=0.7,\n",
    "        min_df=10,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "\n",
    "    vectorizer.fit(train_tweets)\n",
    "\n",
    "    av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "    train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(train_tweets)\n",
    "    \n",
    "    print('Tokens unicos %s' % len(tokenizer.word_index))\n",
    "    print('Embedding dim recomendado: ', len(tokenizer.word_index)**(1/4))\n",
    "    \n",
    "    X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "    X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "    X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "    X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "    X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "    X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "    clf = create_bilstm_model(\n",
    "        optimizer=\"adam\",#Adam(learning_rate=3e-4),\n",
    "        num_classes=train_regions_unique if i == 0 else train_cities_unique,\n",
    "        input_length=sequence_length,\n",
    "        vocab_size=embeddings.shape[0],\n",
    "        emb_dim=100,\n",
    "        weights=embeddings\n",
    "    )\n",
    "    \n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0001, restore_best_weights=True)],\n",
    "        epochs=30,\n",
    "        batch_size=64        \n",
    "    )\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = KerasCrossValidator(\n",
    "    name=\"Contenido Mutual information + Naive Bayes\",\n",
    "    encoder=LabelBinarizer()\n",
    ")\n",
    "\n",
    "bilstm_preds = cn_cross_val.cross_predict(\n",
    "    folds_kd,\n",
    "    test_kd_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, bilstm_preds, cn_cross_val.classes_order(), places_with_coords, users_coords)\n",
    "\n",
    "i += 1\n",
    "\n",
    "bilstm_preds_city = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(train_cities_enc, bilstm_preds_city, cn_cross_val.classes_order(), cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "elementary-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_preds = []\n",
    "\n",
    "with open(tmp_save + 'transformer_kd_preds_bilstm_0.pickle', 'rb') as handle:\n",
    "    bilstm_preds = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_bilstm_1.pickle', 'rb') as handle:\n",
    "    bilstm_preds = np.concatenate((bilstm_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_bilstm_2.pickle', 'rb') as handle:\n",
    "    bilstm_preds = np.concatenate((bilstm_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_bilstm_3.pickle', 'rb') as handle:\n",
    "    bilstm_preds = np.concatenate((bilstm_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_kd_preds_bilstm_4.pickle', 'rb') as handle:\n",
    "    bilstm_preds = np.concatenate((bilstm_preds, pickle.load(handle)))\n",
    "    \n",
    "bilstm_preds = bilstm_preds[test_kd_idxs.argsort()]\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, bilstm_preds, encoder.classes_, places_with_coords, users_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "veterinary-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17731094001657155        \n",
      "Acc@161: 0.4605773975217152        \n",
      "Balanced Acc: 0.1773291810353812        \n",
      "ROC AUC Ovo: 0.904492955853263        \n",
      "Mean Dist Err: 649.0542979610854        \n",
      "Median Dist Err: 205.01431949052858\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "skilled-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_city_preds = []\n",
    "\n",
    "with open(tmp_save + 'transformer_city_preds_bilstm_0.pickle', 'rb') as handle:\n",
    "    bilstm_city_preds = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_bilstm_1.pickle', 'rb') as handle:\n",
    "    bilstm_city_preds = np.concatenate((bilstm_city_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_bilstm_2.pickle', 'rb') as handle:\n",
    "    bilstm_city_preds = np.concatenate((bilstm_city_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_bilstm_3.pickle', 'rb') as handle:\n",
    "    bilstm_city_preds = np.concatenate((bilstm_city_preds, pickle.load(handle)))\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_bilstm_4.pickle', 'rb') as handle:\n",
    "    bilstm_city_preds = np.concatenate((bilstm_city_preds, pickle.load(handle)))\n",
    "    \n",
    "bilstm_city_preds = bilstm_city_preds[test_cities_idxs.argsort()]\n",
    "\n",
    "count_score_city = get_all_metrics(train_cities_enc, bilstm_city_preds, encoder_city.classes_, cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "happy-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2516554595835108        \n",
      "Acc@161: 0.4781712088520828        \n",
      "Balanced Acc: 0.13285696165251556        \n",
      "ROC AUC Ovo: 0.9051042791422996        \n",
      "Mean Dist Err: 662.0017805450656        \n",
      "Median Dist Err: 189.85365616980877\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-hundred",
   "metadata": {},
   "source": [
    "BiLstm fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 512\n",
    "    \n",
    "vectorizer = CountVectorizer(\n",
    "    #strip_accents='unicode',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    max_df=0.7,\n",
    "    min_df=10,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "    \n",
    "train_tweets = train_na[\"all_tweets\"].to_numpy()\n",
    "val_tweets = val_na[\"all_tweets\"].to_numpy()\n",
    "test_tweets = test_na[\"all_tweets\"].to_numpy()\n",
    "\n",
    "vectorizer.fit(train_tweets)\n",
    "\n",
    "av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "clf = create_bilstm_model(\n",
    "    optimizer=\"adam\",#Adam(learning_rate=3e-4),\n",
    "    num_classes=train_regions_unique,\n",
    "    input_length=sequence_length,\n",
    "    vocab_size=embeddings.shape[0],\n",
    "    emb_dim=100,\n",
    "    weights=embeddings\n",
    ")\n",
    "    \n",
    "clf.fit(\n",
    "    X_train,\n",
    "    train_regions_enc,\n",
    "    validation_data=(X_val, val_regions_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=300,\n",
    "    batch_size=64        \n",
    ")\n",
    "\n",
    "bilstm_kd_fit_preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 512\n",
    "    \n",
    "vectorizer = CountVectorizer(\n",
    "    #strip_accents='unicode',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    max_df=0.7,\n",
    "    min_df=10,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "    \n",
    "train_tweets = train_na[\"all_tweets\"].to_numpy()\n",
    "val_tweets = val_na[\"all_tweets\"].to_numpy()\n",
    "test_tweets = test_na[\"all_tweets\"].to_numpy()\n",
    "\n",
    "vectorizer.fit(train_tweets)\n",
    "\n",
    "av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "clf = create_bilstm_model(\n",
    "    optimizer=\"adam\",#Adam(learning_rate=3e-4),\n",
    "    num_classes=train_cities_unique,\n",
    "    input_length=sequence_length,\n",
    "    vocab_size=embeddings.shape[0],\n",
    "    emb_dim=100,\n",
    "    weights=embeddings\n",
    ")\n",
    "    \n",
    "clf.fit(\n",
    "    X_train,\n",
    "    train_cities_enc,\n",
    "    validation_data=(X_val, val_cities_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=300,\n",
    "    batch_size=64        \n",
    ")\n",
    "\n",
    "bilstm_city_fit_preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "italian-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'transformer_kd_preds_fit_test_bisltm.pickle', 'rb') as handle:\n",
    "    bilstm_kd_fit_preds = pickle.load(handle)\n",
    "    \n",
    "count_score_kd = get_all_metrics(test_regions_enc, bilstm_kd_fit_preds, encoder.classes_, places_with_coords, users_coords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "metropolitan-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2052        \n",
      "Acc@161: 0.4857        \n",
      "Balanced Acc: 0.20504714629943815        \n",
      "ROC AUC Ovo: 0.9151819853320103        \n",
      "Mean Dist Err: 610.0084401204205        \n",
      "Median Dist Err: 173.3988824390015\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "taken-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'transformer_city_preds_fit_test_bilstm.pickle', 'rb') as handle:\n",
    "    bilstm_city_fit_preds = pickle.load(handle)\n",
    "    \n",
    "count_score_city = get_all_metrics(test_cities_enc, bilstm_city_fit_preds, encoder_city.classes_, cities_with_coords, users_coords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "consolidated-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2724        \n",
      "Acc@161: 0.4925        \n",
      "Balanced Acc: 0.1691649546331077        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 609.4443256283739        \n",
      "Median Dist Err: 170.1343971536699\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-stopping",
   "metadata": {},
   "source": [
    "node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "closing-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node2vec_pecanpy(\n",
    "    adj_mat, out_dim=128, p=1.0, q=1.0, num_walks=10, length_walks=100\n",
    "):    \n",
    "    tmp_fold = tmp_save\n",
    "    \n",
    "    cx = adj_mat.tocoo()\n",
    "\n",
    "    edges = []\n",
    "\n",
    "    already_passed = {}\n",
    "\n",
    "    for i in range(adj_mat.shape[0]):\n",
    "        already_passed[i] = []\n",
    "\n",
    "    for i,j,v in zip(cx.row, cx.col, cx.data):    \n",
    "        if i in already_passed[j]:\n",
    "            continue\n",
    "\n",
    "        #edges.append(str(users_ids[i]) + \"\\t\" + str(users_ids[j]) + \"\\t\" + str(v))\n",
    "        edges.append(str(i) + \"\\t\" + str(j) + \"\\t\" + str(v))\n",
    "\n",
    "        already_passed[i].append(j)    \n",
    "        \n",
    "    edges = pd.DataFrame({\"edges\": edges})\n",
    "    \n",
    "    save_in = tmp_fold + \"edges_node2vec_twitter_us.edg\"\n",
    "    emb_save_in = tmp_fold + \"edges_node2vec_twitter_us.emb\"\n",
    "    \n",
    "    edges.to_csv(save_in, header=False, index=False)\n",
    "    \n",
    "    !pecanpy --input $save_in --output $emb_save_in --mode SparseOTF\\\n",
    "    --dimensions $out_dim --walk-length $length_walks --num-walks $num_walks --p $p --q $q --weighted\n",
    "    \n",
    "    df = pd.read_csv(emb_save_in, header=None,  skiprows=[0], sep=\" \")\n",
    "    \n",
    "    all_users_ids = set(np.arange(len(users_ids)))\n",
    "    users_embedded = set(df[0].to_numpy())\n",
    "    missing_users = np.array(list(all_users_ids.difference(users_embedded)))\n",
    "    missing_embs = [np.append(np.array([int(x)]), np.zeros(shape=(1, out_dim))) for x in missing_users]\n",
    "    \n",
    "    return df.append(missing_embs).sort_values(0).to_numpy()[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "alien-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 00:00:14.20 to load graph\n",
      "Took 00:00:00.00 to pre-compute transition probabilities\n",
      "Took 00:19:39.12 to generate walks\n",
      "Took 00:53:46.01 to train embeddings\n"
     ]
    }
   ],
   "source": [
    "node2vec_pec_embs = node2vec_pecanpy(vector_of_col_mentions, num_walks=20, length_walks=100, p=1.0, q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "administrative-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'node2vec_pec_embs_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(node2vec_pec_embs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "champion-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'node2vec_pec_embs_twitter_us.pickle', 'rb') as handle:\n",
    "    node2vec_pec_embs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "previous-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.1}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.1}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.1}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.1}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.1}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.5}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.5}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.5}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.5}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params:  {'C': 0.5}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    if i == 0:\n",
    "        X_train = node2vec_pec_embs[X_train.index.to_numpy()]\n",
    "        X_test = node2vec_pec_embs[X_test.index.to_numpy()]\n",
    "    else:\n",
    "        X_train = node2vec_pec_embs[X_train[\"index\"].to_numpy()]\n",
    "        X_test = node2vec_pec_embs[X_test[\"index\"].to_numpy()] \n",
    "        \n",
    "    clf=GridSearchCV(\n",
    "        estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "        param_grid={'C': [0.05, 0.1, 0.5, 1.0]},\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Node2vec\",\n",
    ")\n",
    "\n",
    "node2vec_preds = cn_cross_val.cross_predict(\n",
    "    folds_kd,\n",
    "    test_kd_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, content_preds, cn_cross_val.classes_order(), places_with_coords, users_coords)\n",
    "\n",
    "i += 1\n",
    "\n",
    "node2vec_preds_city = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(train_cities_enc, content_preds_city, cn_cross_val.classes_order(), cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "optional-worse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2074027352368894        \n",
      "Acc@161: 0.42946384515840724        \n",
      "Balanced Acc: 0.20741793935188663        \n",
      "ROC AUC Ovo: 0.7823325558809547        \n",
      "Mean Dist Err: 756.8087896267816        \n",
      "Median Dist Err: 276.3998853806887\n"
     ]
    }
   ],
   "source": [
    "print(count_score_kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "complicated-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2616010185295097        \n",
      "Acc@161: 0.4415939893724732        \n",
      "Balanced Acc: 0.19200079068974996        \n",
      "ROC AUC Ovo: 0.7934797385514943        \n",
      "Mean Dist Err: 797.8659883064074        \n",
      "Median Dist Err: 278.86803590592933\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "antique-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'node2vec_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(node2vec_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open(tmp_save + 'node2vec_cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(node2vec_preds_city, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "sought-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'node2vec_twitter_us.pickle', 'rb') as handle:\n",
    "    node2vec_preds = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'node2vec_cities_twitter_us.pickle', 'rb') as handle:\n",
    "    node2vec_preds_city = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-edition",
   "metadata": {},
   "source": [
    "node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "worthy-apparatus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, n_jobs=-1, random_state=35)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.05, 0.1, 0.5, 1.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")'''\n",
    "    \n",
    "clf.fit(node2vec_pec_embs[0:train_na.shape[0]], train_regions)\n",
    "#print(clf.best_params_)\n",
    "\n",
    "clf_city = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.05, 0.1, 0.5, 1.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")'''\n",
    "    \n",
    "clf_city.fit(node2vec_pec_embs[train_na_cities[\"index\"].to_numpy()], train_cities)\n",
    "#print(clf_city.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "practical-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_preds_fit = clf.predict_proba(\n",
    "    node2vec_pec_embs[train_na.shape[0]+val_na.shape[0]:train_na.shape[0]+val_na.shape[0]+test_na.shape[0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "accepting-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_preds_city_fit = clf_city.predict_proba(\n",
    "    node2vec_pec_embs[train_na.shape[0]+val_na.shape[0]:train_na.shape[0]+val_na.shape[0]+test_na.shape[0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "otherwise-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2688        \n",
      "Acc@161: 0.527        \n",
      "Balanced Acc: 0.26856159035948346        \n",
      "ROC AUC Ovo: 0.900126530747339        \n",
      "Mean Dist Err: 710.698924564338        \n",
      "Median Dist Err: 132.7133415824623\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_regions_enc, node2vec_preds_fit, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "everyday-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.351        \n",
      "Acc@161: 0.5516        \n",
      "Balanced Acc: 0.24268734554874039        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 797.9439286637597        \n",
      "Median Dist Err: 98.58094198840173\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_cities_enc, node2vec_preds_city_fit, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "smoking-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'node2vec_fit_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(node2vec_preds_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open(tmp_save + 'node2vec_fit_cities_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(node2vec_preds_city_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bright-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'node2vec_fit_twitter_us.pickle', 'rb') as handle:\n",
    "    node2vec_preds_fit = pickle.load(handle)  \n",
    "    \n",
    "with open(tmp_save + 'node2vec_fit_cities_twitter_us.pickle', 'rb') as handle:\n",
    "    node2vec_preds_city_fit = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-valentine",
   "metadata": {},
   "source": [
    "meta transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "original-ethnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3654        \n",
      "Acc@161: 0.6697        \n",
      "Balanced Acc: 0.3649315850557562        \n",
      "ROC AUC Ovo: 0.9465524792089199        \n",
      "Mean Dist Err: 394.7647035785224        \n",
      "Median Dist Err: 57.03704247894968\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.1, 0.5, 1.0, 2.0, 4.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")\n",
    "'''\n",
    "total_preds_train = transformer_preds\n",
    "\n",
    "total_preds_train = np.concatenate((total_preds_train, node2vec_preds, content_preds), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_regions)\n",
    "\n",
    "total_fit_preds = transformer_kd_fit_preds\n",
    "\n",
    "total_fit_preds = np.concatenate((total_fit_preds, node2vec_preds_fit, content_preds_fit), axis=1)\n",
    "\n",
    "meta_preds = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_regions_enc, meta_preds, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "frozen-director",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4539        \n",
      "Acc@161: 0.6895        \n",
      "Balanced Acc: 0.3220070970984957        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 420.9880071124519        \n",
      "Median Dist Err: 35.30875964530681\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.1, 0.5, 1.0, 2.0, 4.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")\n",
    "'''\n",
    "total_preds_train = transformer_city_preds\n",
    "\n",
    "total_preds_train = np.concatenate((total_preds_train, node2vec_preds_city, content_preds_city), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_cities)\n",
    "\n",
    "total_fit_preds = transformer_city_fit_preds\n",
    "\n",
    "total_fit_preds = np.concatenate((total_fit_preds, node2vec_preds_city_fit, content_preds_city_fit), axis=1)\n",
    "\n",
    "meta_preds = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_cities_enc, meta_preds, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-provision",
   "metadata": {},
   "source": [
    "meta bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "organized-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3578        \n",
      "Acc@161: 0.6622        \n",
      "Balanced Acc: 0.3576174049719897        \n",
      "ROC AUC Ovo: 0.945872977548834        \n",
      "Mean Dist Err: 401.67027369837325        \n",
      "Median Dist Err: 59.472865948290696\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.1, 0.5, 1.0, 2.0, 4.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")\n",
    "'''\n",
    "total_preds_train = bilstm_preds\n",
    "\n",
    "total_preds_train = np.concatenate((total_preds_train, node2vec_preds, content_preds), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_regions)\n",
    "\n",
    "total_fit_preds = bilstm_kd_fit_preds\n",
    "\n",
    "total_fit_preds = np.concatenate((total_fit_preds, node2vec_preds_fit, content_preds_fit), axis=1)\n",
    "\n",
    "meta_preds = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_regions_enc, meta_preds, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "sophisticated-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4467        \n",
      "Acc@161: 0.6837        \n",
      "Balanced Acc: 0.31840855161547993        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 429.60436219527907        \n",
      "Median Dist Err: 36.84941798517585\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.1, 0.5, 1.0, 2.0, 4.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")\n",
    "'''\n",
    "total_preds_train = bilstm_city_preds\n",
    "\n",
    "total_preds_train = np.concatenate((total_preds_train, node2vec_preds_city, content_preds_city), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_cities)\n",
    "\n",
    "total_fit_preds = bilstm_city_fit_preds\n",
    "\n",
    "total_fit_preds = np.concatenate((total_fit_preds, node2vec_preds_city_fit, content_preds_city_fit), axis=1)\n",
    "\n",
    "meta_preds = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_cities_enc, meta_preds, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-reggae",
   "metadata": {},
   "source": [
    "Contenido Bilstm + Chi2 LIW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "accredited-grace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2365        \n",
      "Acc@161: 0.4998        \n",
      "Balanced Acc: 0.23671503340282193        \n",
      "ROC AUC Ovo: 0.9060077218383252        \n",
      "Mean Dist Err: 603.1308882614716        \n",
      "Median Dist Err: 161.68581954508255\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "total_preds_train = bilstm_preds\n",
    "\n",
    "total_preds_train = np.concatenate((total_preds_train, content_preds), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_regions)\n",
    "\n",
    "total_fit_preds = bilstm_kd_fit_preds\n",
    "\n",
    "total_fit_preds = np.concatenate((total_fit_preds, content_preds_fit), axis=1)\n",
    "\n",
    "meta_preds = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_regions_enc, meta_preds, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "obvious-requirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.298        \n",
      "Acc@161: 0.5082        \n",
      "Balanced Acc: 0.20505344423313143        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 638.9427238997065        \n",
      "Median Dist Err: 150.82402772433073\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "total_preds_train = bilstm_city_preds\n",
    "\n",
    "total_preds_train = np.concatenate((total_preds_train, content_preds_city), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_cities)\n",
    "\n",
    "total_fit_preds = bilstm_city_fit_preds\n",
    "\n",
    "total_fit_preds = np.concatenate((total_fit_preds, content_preds_city_fit), axis=1)\n",
    "\n",
    "meta_preds = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_cities_enc, meta_preds, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-entry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "coupled-associate",
   "metadata": {},
   "source": [
    "Modelo completo NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "boolean-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complete_model(\n",
    "    optimizer, num_classes, input_text_length, embeddings_text, words_dim, embedding_text_dim, input_mentions_length,\n",
    "    embeddings_mentions, mentions_dim, embeddings_mentions_dim\n",
    "):\n",
    "    clear_session()\n",
    "    \n",
    "    nlp_input = Input(shape=(input_text_length, ))\n",
    "    nlp_emb = Embedding(words_dim, embedding_text_dim, input_length=input_text_length, \n",
    "                    weights=[embeddings_text],trainable=False)(nlp_input)\n",
    "    sdrop = SpatialDropout1D(0.4)(nlp_emb)\n",
    "    nlp_output = Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(sdrop)\n",
    "    #nlp_output = Attention(use_scale=True)([nlp_output, nlp_output])\n",
    "    \n",
    "    nlp_output = MultiHeadAttention(num_heads=6, key_dim=6)(nlp_output, nlp_output)\n",
    "        \n",
    "    nlp_output = Flatten()(nlp_output)\n",
    "    \n",
    "    mentions_input = Input(shape=(input_mentions_length, ))\n",
    "    mentions_emb = Embedding(input_dim=mentions_dim, output_dim=embeddings_mentions_dim, \n",
    "                    weights=[embeddings_mentions],trainable=False)(mentions_input)\n",
    "    \n",
    "    mentions_sdrop = SpatialDropout1D(0.2)(mentions_emb)\n",
    "    \n",
    "    mentions_output = MultiHeadAttention(num_heads=6, key_dim=6)(mentions_sdrop, mentions_sdrop)\n",
    "    \n",
    "    mentions_output = Flatten()(mentions_output)\n",
    "            \n",
    "    concat = Concatenate()([nlp_output, mentions_output])\n",
    "    output = Dense(num_classes, activation='softmax')(concat)\n",
    "\n",
    "    model = Model(inputs=[nlp_input, mentions_input], outputs=[output])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "under-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlp = tokenizer.texts_to_sequences(train_tweets)\n",
    "train_nlp = pad_sequences(train_nlp, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "val_nlp = tokenizer.texts_to_sequences(val_tweets)\n",
    "val_nlp = pad_sequences(val_nlp, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "test_nlp = tokenizer.texts_to_sequences(test_tweets)\n",
    "test_nlp = pad_sequences(test_nlp, maxlen=sequence_length, truncating='post', padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-jewel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "better-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = twitter_na.index.to_numpy()\n",
    "train_mentions = idxs[0:train_na.shape[0]]\n",
    "val_mentions = idxs[train_na.shape[0]:train_na.shape[0]+val_na.shape[0]]\n",
    "test_mentions = idxs[train_na.shape[0]+val_na.shape[0]:train_na.shape[0]+val_na.shape[0]+test_na.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "proof-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1024, 300)    147915600   input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 128)       57555200    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 1024, 300)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 128)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 1024, 300)    43608       spatial_dropout1d[0][0]          \n",
      "                                                                 spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 1, 128)       18668       spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 307200)       0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 307328)       0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          39338112    concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 244,871,188\n",
      "Trainable params: 39,400,388\n",
      "Non-trainable params: 205,470,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_complete_model(\n",
    "    num_classes=total_regions,\n",
    "    \n",
    "    input_text_length=sequence_length,\n",
    "    embeddings_text=embeddings,\n",
    "    embedding_text_dim=embedding_dim,\n",
    "    words_dim=len(tokenizer.word_index) + 1,\n",
    "    \n",
    "    input_mentions_length=1,\n",
    "    embeddings_mentions=node2vec_pec_embs,\n",
    "    mentions_dim=node2vec_pec_embs.shape[0],\n",
    "    embeddings_mentions_dim=node2vec_pec_embs.shape[1],\n",
    "    \n",
    "    optimizer=\"adam\",\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "victorian-webster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  10/6714 [..............................] - ETA: 6:25:00 - loss: 4.8846 - accuracy: 0.0109"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-042fb865671e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtrain_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_cities_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_cities_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_nlp, train_mentions],\n",
    "    train_regions_enc,\n",
    "    validation_data=([val_nlp, val_mentions], val_regions_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=30,\n",
    "    batch_size=64   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adult-picnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../../../../unT/ffunes/tmp_saves/complete_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../../../../unT/ffunes/tmp_saves/complete_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(tmp_save + 'complete_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "traditional-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(tmp_save + 'complete_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "alert-november",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c33dd7edc5e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds = model.predict([test_nlp, test_mentions]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "psychological-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3055        \n",
      "Acc@161: 0.5633        \n",
      "Balanced Acc: 0.30461478900107375        \n",
      "ROC AUC Ovo: 0.9127358482497752        \n",
      "Mean Dist Err: 726.3917146537316        \n",
      "Median Dist Err: 298.4483665219399\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_regions_enc, preds, encoder.classes_, places_with_coords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-surprise",
   "metadata": {},
   "source": [
    "Modelo completo transformador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "appointed-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "specialized-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "hungarian-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complete_transformer_model(\n",
    "    optimizer, num_classes, input_text_length, vocab_size, embed_text_dim, ff_dim, num_heads, input_mentions_length,\n",
    "    embeddings_mentions, mentions_dim, embeddings_mentions_dim\n",
    "):\n",
    "    clear_session()\n",
    "    \n",
    "    nlp_input = Input(shape=(input_text_length, ))\n",
    "    \n",
    "    nlp_emb = TokenAndPositionEmbedding(input_text_length, vocab_size, embed_text_dim)(nlp_input)\n",
    "        \n",
    "    nlp_transformer = TransformerBlock(embed_text_dim, num_heads, ff_dim)(nlp_emb)\n",
    "    \n",
    "    nlp_gap = layers.GlobalAveragePooling1D()(nlp_transformer)\n",
    "    nlp_output = Dropout(0.1)(nlp_gap)\n",
    "        \n",
    "    mentions_input = Input(shape=(input_mentions_length, ))\n",
    "    mentions_emb = Embedding(input_dim=mentions_dim, output_dim=embeddings_mentions_dim, \n",
    "                    weights=[embeddings_mentions],trainable=False)(mentions_input)\n",
    "    \n",
    "    mentions_sdrop = SpatialDropout1D(0.2)(mentions_emb)\n",
    "    \n",
    "    mentions_output = MultiHeadAttention(num_heads=num_heads, key_dim=embeddings_mentions_dim)(mentions_sdrop, mentions_sdrop)\n",
    "    \n",
    "    mentions_output = Flatten()(mentions_output)\n",
    "            \n",
    "    concat = Concatenate()([nlp_output, mentions_output])\n",
    "        \n",
    "    output = Dense(num_classes, activation='softmax')(concat)\n",
    "\n",
    "    model = Model(inputs=[nlp_input, mentions_input], outputs=[output])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "suitable-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 3801899\n",
      "Embedding dim recomendado:  44.15705936026863\n"
     ]
    }
   ],
   "source": [
    "#embedding_dim = 300\n",
    "sequence_length = 256\n",
    "max_features = 50000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "print('Tokens unicos %s' % len(tokenizer.word_index))\n",
    "print('Embedding dim recomendado: ', len(tokenizer.word_index)**(1/4))\n",
    "\n",
    "train_nlp = tokenizer.texts_to_sequences(train_tweets)\n",
    "train_nlp = pad_sequences(train_nlp, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "val_nlp = tokenizer.texts_to_sequences(val_tweets)\n",
    "val_nlp = pad_sequences(val_nlp, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "test_nlp = tokenizer.texts_to_sequences(test_tweets)\n",
    "test_nlp = pad_sequences(test_nlp, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "idxs = twitter_na.index.to_numpy()\n",
    "train_mentions = idxs[0:train_na.shape[0]]\n",
    "val_mentions = idxs[train_na.shape[0]:train_na.shape[0]+val_na.shape[0]]\n",
    "test_mentions = idxs[train_na.shape[0]+val_na.shape[0]:train_na.shape[0]+val_na.shape[0]+test_na.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "opposite-observer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_and_position_embedding (T (None, 256, 32)      1608192     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 128)       57555200    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 256, 32)      27424       token_and_position_embedding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 1, 128)       0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 1, 128)       395648      spatial_dropout1d[0][0]          \n",
      "                                                                 spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 160)          0           dropout_2[0][0]                  \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          20608       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 59,607,072\n",
      "Trainable params: 2,051,872\n",
      "Non-trainable params: 57,555,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_complete_transformer_model(\n",
    "    num_classes=total_regions,\n",
    "    \n",
    "    input_text_length=sequence_length,\n",
    "    vocab_size=max_features,\n",
    "    embed_text_dim=32,\n",
    "    ff_dim=32,\n",
    "    num_heads=6,\n",
    "    \n",
    "    input_mentions_length=1,\n",
    "    embeddings_mentions=node2vec_pec_embs,\n",
    "    mentions_dim=node2vec_pec_embs.shape[0],\n",
    "    embeddings_mentions_dim=node2vec_pec_embs.shape[1],\n",
    "    \n",
    "    optimizer=\"adam\",\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "conceptual-filing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   6/6714 [..............................] - ETA: 47:44 - loss: 1.1814 - accuracy: 0.6536"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f597a3093ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtrain_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_cities_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_cities_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_nlp, train_mentions],\n",
    "    train_regions_enc,\n",
    "    validation_data=([val_nlp, val_mentions], val_regions_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=100,\n",
    "    batch_size=64   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "empirical-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([test_nlp, test_mentions]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "prostate-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3177        \n",
      "Acc@161: 0.5321        \n",
      "Balanced Acc: 0.3171330181212956        \n",
      "ROC AUC Ovo: 0.8982573946897142        \n",
      "Mean Dist Err: 571.022640962184        \n",
      "Median Dist Err: 128.51433232104438\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_regions_enc, preds, encoder.classes_, places_with_coords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-virgin",
   "metadata": {},
   "source": [
    "# RGCN and GraphSage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "tired-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'transformer_kd_preds_fit_val2.pickle', 'rb') as handle:\n",
    "    transformer_kd_fit_val_preds = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'transformer_city_preds_fit_val.pickle', 'rb') as handle:\n",
    "    transformer_city_fit_val_preds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "living-federation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold\n",
      "Processing fold\n",
      "Processing fold\n",
      "Processing fold\n",
      "Processing fold\n"
     ]
    }
   ],
   "source": [
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    train_idxs = X_train.index.to_numpy()\n",
    "    test_idxs = X_test.index.to_numpy()\n",
    "        \n",
    "    X_train = np.concatenate((transformer_preds[train_idxs], content_preds[train_idxs]), axis=1)\n",
    "        \n",
    "    X_test = np.concatenate((transformer_preds[test_idxs], content_preds[test_idxs]), axis=1)\n",
    "    \n",
    "    print(\"Processing fold\")\n",
    "\n",
    "    clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "    \n",
    "    '''clf=GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid={\n",
    "            \"naive_bayes__alpha\": [0.05, 0.1],\n",
    "            \"chi2__k\": [50, 100, 150, 300, 400]\n",
    "        },\n",
    "        cv=3,\n",
    "        #n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )'''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Contenido Chi2 + Naive Bayes\",\n",
    ")\n",
    "\n",
    "meta_content_preds = cn_cross_val.cross_predict(\n",
    "    folds_kd,\n",
    "    test_kd_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_kd = get_all_metrics(train_regions_enc, meta_content_preds, cn_cross_val.classes_order(), places_with_coords, users_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "frozen-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'meta_content_kd_preds_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(meta_content_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "alternate-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'meta_content_kd_preds_twitter_us.pickle', 'rb') as handle:\n",
    "    meta_content_preds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "descending-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold\n",
      "Processing fold\n",
      "Processing fold\n",
      "Processing fold\n",
      "Processing fold\n"
     ]
    }
   ],
   "source": [
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    train_idxs = X_train.index.to_numpy()\n",
    "    test_idxs = X_test.index.to_numpy()\n",
    "        \n",
    "    X_train = np.concatenate((transformer_city_preds[train_idxs], content_preds_city[train_idxs]), axis=1)\n",
    "        \n",
    "    X_test = np.concatenate((transformer_city_preds[test_idxs], content_preds_city[test_idxs]), axis=1)\n",
    "    \n",
    "    print(\"Processing fold\")\n",
    "\n",
    "    clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "    \n",
    "    '''clf=GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid={\n",
    "            \"naive_bayes__alpha\": [0.05, 0.1],\n",
    "            \"chi2__k\": [50, 100, 150, 300, 400]\n",
    "        },\n",
    "        cv=3,\n",
    "        #n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )'''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Contenido Chi2 + Naive Bayes\",\n",
    ")\n",
    "\n",
    "meta_content_preds_city = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(train_cities_enc, meta_content_preds_city, cn_cross_val.classes_order(), cities_with_coords, users_cities_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "affecting-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'meta_content_city_preds_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(meta_content_preds_city, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "international-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'meta_content_city_preds_twitter_us.pickle', 'rb') as handle:\n",
    "    meta_content_preds_city = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "israeli-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2479        \n",
      "Acc@161: 0.5134        \n",
      "Balanced Acc: 0.24760498627282154        \n",
      "ROC AUC Ovo: 0.909377958713395        \n",
      "Mean Dist Err: 589.2626470141195        \n",
      "Median Dist Err: 146.65646587738257\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.1, 0.5, 1.0, 2.0, 4.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")\n",
    "'''\n",
    "total_preds_train = np.concatenate((transformer_preds, content_preds), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_regions)\n",
    "\n",
    "total_fit_preds = np.concatenate((transformer_kd_fit_preds, content_preds_fit), axis=1)\n",
    "total_fit_preds_val = np.concatenate((transformer_kd_fit_val_preds, content_preds_fit_val), axis=1)\n",
    "\n",
    "meta_content_preds_fit = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "meta_content_preds_fit_val = clf.predict_proba(\n",
    "    total_fit_preds_val\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_regions_enc, meta_content_preds_fit, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "directed-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'meta_content_kd_preds_twitter_us_fit.pickle', 'wb') as handle:\n",
    "#    pickle.dump(meta_content_preds_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#with open(tmp_save + 'meta_content_kd_preds_twitter_us_fit_val.pickle', 'wb') as handle:\n",
    "#    pickle.dump(meta_content_preds_fit_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(tmp_save + 'meta_content_kd_preds_twitter_us_fit.pickle', 'rb') as handle:\n",
    "    meta_content_preds_fit = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'meta_content_kd_preds_twitter_us_fit_val.pickle', 'rb') as handle:\n",
    "    meta_content_preds_fit_val = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "stock-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3158        \n",
      "Acc@161: 0.5234        \n",
      "Balanced Acc: 0.2127675601814523        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 653.5852183745282        \n",
      "Median Dist Err: 132.4119860238718\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=35, n_jobs=-1)\n",
    "\n",
    "'''GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "    param_grid={'C': [0.1, 0.5, 1.0, 2.0, 4.0]},\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    verbose=3\n",
    ")\n",
    "'''\n",
    "total_preds_train = np.concatenate((transformer_city_preds, content_preds_city), axis=1)\n",
    "\n",
    "clf.fit(total_preds_train, train_cities)\n",
    "\n",
    "total_fit_preds = np.concatenate((transformer_city_fit_preds, content_preds_city_fit), axis=1)\n",
    "total_fit_preds_val = np.concatenate((transformer_city_fit_val_preds, content_preds_city_fit_val), axis=1)\n",
    "\n",
    "meta_content_preds_city_fit = clf.predict_proba(\n",
    "    total_fit_preds\n",
    ")\n",
    "\n",
    "meta_content_preds_city_fit_val = clf.predict_proba(\n",
    "    total_fit_preds_val\n",
    ")\n",
    "\n",
    "print(get_all_metrics(test_cities_enc, meta_content_preds_city_fit, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "personal-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'meta_content_city_preds_twitter_us_fit.pickle', 'wb') as handle:\n",
    "#    pickle.dump(meta_content_preds_city_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#with open(tmp_save + 'meta_content_city_preds_twitter_us_fit_val.pickle', 'wb') as handle:\n",
    "#    pickle.dump(meta_content_preds_city_fit_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(tmp_save + 'meta_content_city_preds_twitter_us_fit.pickle', 'rb') as handle:\n",
    "    meta_content_preds_city_fit = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'meta_content_city_preds_twitter_us_fit_val.pickle', 'rb') as handle:\n",
    "    meta_content_preds_city_fit_val = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "solved-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_mentions_undir_local.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_mentions_undir_local.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "        \n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "selected-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>13940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  weight\n",
       "0       0   44831       1\n",
       "1       3   13940       1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_edges = pd.DataFrame(\n",
    "    {\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight}\n",
    ")\n",
    "\n",
    "mentions_edges.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fatty-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_comentions_ext.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_comentions_ext.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "        \n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "colonial-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "comentions_edges_ext = pd.DataFrame(\n",
    "    {\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight},\n",
    "    index=np.arange(len(mentions_edges), len(edges_tails) + len(mentions_edges))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_col_mentions.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_col_mentions.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "        \n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dietary-contrast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>349011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>431150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  weight\n",
       "0       0  349011       1\n",
       "1       0  431150       1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colmentions_edges = pd.DataFrame(\n",
    "    {\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight}\n",
    ")\n",
    "\n",
    "colmentions_edges.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "female-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_meta_kd_preds = np.concatenate((meta_content_preds, meta_content_preds_fit_val, meta_content_preds_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "restricted-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_content_preds_city_shift = np.zeros(shape=(train_na.shape[0], 403))\n",
    "meta_content_preds_city_shift[train_na_cities[\"index\"].to_numpy()] = meta_content_preds_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sudden-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_meta_city_preds = np.concatenate((meta_content_preds_city_shift, meta_content_preds_city_fit_val, meta_content_preds_city_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "deadly-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_content_preds = sg.IndexedArray(total_meta_kd_preds, index=np.arange(len(users_ids)))\n",
    "nodes_content_preds_city = sg.IndexedArray(total_meta_city_preds, index=np.arange(len(users_ids)))\n",
    "nodes_content_preds_city_lowres = sg.IndexedArray(total_meta_city_preds.astype(np.float16), index=np.arange(len(users_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "alpine-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 449650, Edges: 6002018\n",
      "\n",
      " Node types:\n",
      "  default: [449650]\n",
      "    Features: float64 vector, length 256\n",
      "    Edge types: default-co_mentions_ext->default, default-mentions->default\n",
      "\n",
      " Edge types:\n",
      "    default-co_mentions_ext->default: [5627864]\n",
      "        Weights: range=[1, 99], mean=1.17331, std=0.866246\n",
      "        Features: none\n",
      "    default-mentions->default: [374154]\n",
      "        Weights: range=[1, 255], mean=4.18197, std=8.83395\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "multilayer_graph = sg.StellarGraph(\n",
    "    nodes_content_preds, {\n",
    "        \"mentions\": mentions_edges,\n",
    "        \"co_mentions_ext\": comentions_edges_ext,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(multilayer_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "equipped-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 449650, Edges: 6002018\n",
      "\n",
      " Node types:\n",
      "  default: [449650]\n",
      "    Features: float64 vector, length 403\n",
      "    Edge types: default-co_mentions_ext->default, default-mentions->default\n",
      "\n",
      " Edge types:\n",
      "    default-co_mentions_ext->default: [5627864]\n",
      "        Weights: range=[1, 99], mean=1.17331, std=0.866246\n",
      "        Features: none\n",
      "    default-mentions->default: [374154]\n",
      "        Weights: range=[1, 255], mean=4.18197, std=8.83395\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "multilayer_graph_city = sg.StellarGraph(\n",
    "    nodes_content_preds_city, {\n",
    "        \"mentions\": mentions_edges,\n",
    "        \"co_mentions_ext\": comentions_edges_ext,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(multilayer_graph_city.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "handy-particle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 449650, Edges: 5844399\n",
      "\n",
      " Node types:\n",
      "  default: [449650]\n",
      "    Features: float64 vector, length 256\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [5844399]\n",
      "        Weights: range=[1, 255], mean=1.39726, std=2.74505\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "colmentions_graph = sg.StellarGraph(\n",
    "    nodes_content_preds,\n",
    "    colmentions_edges\n",
    ")\n",
    "\n",
    "print(colmentions_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "arabic-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 449650, Edges: 5844399\n",
      "\n",
      " Node types:\n",
      "  default: [449650]\n",
      "    Features: float64 vector, length 403\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [5844399]\n",
      "        Weights: range=[1, 255], mean=1.39726, std=2.74505\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "colmentions_graph_city = sg.StellarGraph(\n",
    "    nodes_content_preds_city,\n",
    "    colmentions_edges\n",
    ")\n",
    "\n",
    "print(colmentions_graph_city.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "breathing-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 449650, Edges: 5844399\n",
      "\n",
      " Node types:\n",
      "  default: [449650]\n",
      "    Features: float16 vector, length 403\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [5844399]\n",
      "        Weights: range=[1, 255], mean=1.39726, std=2.74505\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "colmentions_graph_city_lowres = sg.StellarGraph(\n",
    "    nodes_content_preds_city_lowres,\n",
    "    colmentions_edges\n",
    ")\n",
    "\n",
    "print(colmentions_graph_city_lowres.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dramatic-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'colmentions_graph_twitter_us_kd.pickle', 'wb') as handle:\n",
    "#    pickle.dump(colmentions_graph, handle, protocol=4)\n",
    "\n",
    "#with open(tmp_save + 'colmentions_graph_twitter_us_city.pickle', 'wb') as handle:\n",
    "#    pickle.dump(colmentions_graph_city, handle, protocol=4)\n",
    "\n",
    "#with open(tmp_save + 'colmentions_graph_twitter_us_city_lowres.pickle', 'wb') as handle:\n",
    "#    pickle.dump(colmentions_graph_city_lowres, handle, protocol=4)\n",
    "\n",
    "#with open(tmp_save + 'multilayer_graph_kd_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(multilayer_graph, handle, protocol=4)\n",
    "\n",
    "#with open(tmp_save + 'multilayer_graph_city_twitter_us.pickle', 'wb') as handle:\n",
    "#    pickle.dump(multilayer_graph_city, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aboriginal-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'colmentions_graph_twitter_us_kd.pickle', 'rb') as handle:\n",
    "#    colmentions_graph = pickle.load(handle)  \n",
    "    \n",
    "#with open(tmp_save + 'colmentions_graph_twitter_us_city.pickle', 'rb') as handle:\n",
    "#    colmentions_graph_city = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'colmentions_graph_twitter_us_city_lowres.pickle', 'rb') as handle:\n",
    "    colmentions_graph_city_lowres = pickle.load(handle)\n",
    "    \n",
    "#with open(tmp_save + 'multilayer_graph_kd_twitter_us.pickle', 'rb') as handle:\n",
    "#    multilayer_graph = pickle.load(handle)  \n",
    "\n",
    "#with open(tmp_save + 'multilayer_graph_city_twitter_us.pickle', 'rb') as handle:\n",
    "#    multilayer_graph_city = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "gentle-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na_shape = train_na.shape[0]\n",
    "test_na_shape = test_na.shape[0]\n",
    "val_na_shape = val_na.shape[0]\n",
    "\n",
    "t_cities = len(np.unique(train_cities))\n",
    "total_regions = len(np.unique(train_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "interracial-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rgcn_model(optimizer, num_classes, generator):\n",
    "    clear_session()\n",
    "    \n",
    "    rgcn = sg.layer.RGCN(\n",
    "        layer_sizes=[128, 64, num_classes],\n",
    "        activations=[\"relu\", \"relu\", \"softmax\"],\n",
    "        generator=generator,\n",
    "        num_bases=2,\n",
    "        dropout=0.2,\n",
    "        bias=True,\n",
    "        #kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "    )\n",
    "    \n",
    "    x_inp, x_out = rgcn.in_out_tensors()\n",
    "    \n",
    "    #x_out = tf.keras.layers.Dense(units=num_classes, activation=\"softmax\")(x_out)\n",
    "\n",
    "    model = tf.keras.Model(inputs=x_inp, outputs=x_out)\n",
    "\n",
    "    model.compile(optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "positive-enough",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/240000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 5.5452 - accuracy: 0.0035 - val_loss: 5.5864 - val_accuracy: 0.0078\n",
      "Epoch 2/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 5.5988 - accuracy: 0.0084 - val_loss: 5.4988 - val_accuracy: 0.0152\n",
      "Epoch 3/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 5.5061 - accuracy: 0.0123 - val_loss: 5.2677 - val_accuracy: 0.0417\n",
      "Epoch 4/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 5.2917 - accuracy: 0.0308 - val_loss: 4.8122 - val_accuracy: 0.0787\n",
      "Epoch 5/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4.9088 - accuracy: 0.0590 - val_loss: 4.3183 - val_accuracy: 0.1057\n",
      "Epoch 6/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4.5388 - accuracy: 0.0851 - val_loss: 4.3034 - val_accuracy: 0.1152\n",
      "Epoch 7/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4.5867 - accuracy: 0.0904 - val_loss: 4.1095 - val_accuracy: 0.1322\n",
      "Epoch 8/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4.3229 - accuracy: 0.1035 - val_loss: 3.9999 - val_accuracy: 0.1407\n",
      "Epoch 9/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4.1999 - accuracy: 0.1136 - val_loss: 3.8902 - val_accuracy: 0.1584\n",
      "Epoch 10/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4.0928 - accuracy: 0.1276 - val_loss: 3.7765 - val_accuracy: 0.1671\n",
      "Epoch 11/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.9760 - accuracy: 0.1380 - val_loss: 3.6579 - val_accuracy: 0.1864\n",
      "Epoch 12/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.8513 - accuracy: 0.1551 - val_loss: 3.5766 - val_accuracy: 0.2011\n",
      "Epoch 13/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.7558 - accuracy: 0.1665 - val_loss: 3.5246 - val_accuracy: 0.2076\n",
      "Epoch 14/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.6954 - accuracy: 0.1726 - val_loss: 3.4842 - val_accuracy: 0.2084\n",
      "Epoch 15/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.6539 - accuracy: 0.1774 - val_loss: 3.4302 - val_accuracy: 0.2211\n",
      "Epoch 16/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.6050 - accuracy: 0.1862 - val_loss: 3.3825 - val_accuracy: 0.2309\n",
      "Epoch 17/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.5617 - accuracy: 0.1917 - val_loss: 3.3566 - val_accuracy: 0.2375\n",
      "Epoch 18/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.5299 - accuracy: 0.1970 - val_loss: 3.3336 - val_accuracy: 0.2430\n",
      "Epoch 19/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.5023 - accuracy: 0.2028 - val_loss: 3.3138 - val_accuracy: 0.2458\n",
      "Epoch 20/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.4855 - accuracy: 0.2087 - val_loss: 3.2975 - val_accuracy: 0.2519\n",
      "Epoch 21/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.4637 - accuracy: 0.2137 - val_loss: 3.2730 - val_accuracy: 0.2592\n",
      "Epoch 22/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.4418 - accuracy: 0.2186 - val_loss: 3.2560 - val_accuracy: 0.2651\n",
      "Epoch 23/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.4223 - accuracy: 0.2226 - val_loss: 3.2402 - val_accuracy: 0.2687\n",
      "Epoch 24/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.4029 - accuracy: 0.2268 - val_loss: 3.2229 - val_accuracy: 0.2719\n",
      "Epoch 25/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.3875 - accuracy: 0.2304 - val_loss: 3.2044 - val_accuracy: 0.2759\n",
      "Epoch 26/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.3732 - accuracy: 0.2344 - val_loss: 3.1877 - val_accuracy: 0.2784\n",
      "Epoch 27/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.3588 - accuracy: 0.2377 - val_loss: 3.1755 - val_accuracy: 0.2829\n",
      "Epoch 28/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.3444 - accuracy: 0.2409 - val_loss: 3.1619 - val_accuracy: 0.2867\n",
      "Epoch 29/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.3308 - accuracy: 0.2437 - val_loss: 3.1461 - val_accuracy: 0.2897\n",
      "Epoch 30/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.3137 - accuracy: 0.2478 - val_loss: 3.1452 - val_accuracy: 0.2877\n",
      "Epoch 31/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.3107 - accuracy: 0.2482 - val_loss: 3.1389 - val_accuracy: 0.2883\n",
      "Epoch 32/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.3027 - accuracy: 0.2496 - val_loss: 3.1278 - val_accuracy: 0.2913\n",
      "Epoch 33/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2919 - accuracy: 0.2520 - val_loss: 3.1109 - val_accuracy: 0.2931\n",
      "Epoch 34/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2778 - accuracy: 0.2547 - val_loss: 3.1014 - val_accuracy: 0.2935\n",
      "Epoch 35/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2703 - accuracy: 0.2564 - val_loss: 3.1056 - val_accuracy: 0.2988\n",
      "Epoch 36/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2658 - accuracy: 0.2573 - val_loss: 3.0878 - val_accuracy: 0.2965\n",
      "Epoch 37/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2539 - accuracy: 0.2588 - val_loss: 3.0852 - val_accuracy: 0.3007\n",
      "Epoch 38/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2469 - accuracy: 0.2583 - val_loss: 3.0821 - val_accuracy: 0.3033\n",
      "Epoch 39/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2517 - accuracy: 0.2589 - val_loss: 3.0987 - val_accuracy: 0.2986\n",
      "Epoch 40/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2520 - accuracy: 0.2591 - val_loss: 3.0807 - val_accuracy: 0.2988\n",
      "Epoch 41/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.2428 - accuracy: 0.2613 - val_loss: 3.0650 - val_accuracy: 0.3021\n",
      "Epoch 42/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2196 - accuracy: 0.2640 - val_loss: 3.0697 - val_accuracy: 0.3011\n",
      "Epoch 43/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2279 - accuracy: 0.2632 - val_loss: 3.0516 - val_accuracy: 0.3025\n",
      "Epoch 44/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2098 - accuracy: 0.2659 - val_loss: 3.0517 - val_accuracy: 0.3081\n",
      "Epoch 45/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.2080 - accuracy: 0.2664 - val_loss: 3.0430 - val_accuracy: 0.3096\n",
      "Epoch 46/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1956 - accuracy: 0.2685 - val_loss: 3.0397 - val_accuracy: 0.3092\n",
      "Epoch 47/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1974 - accuracy: 0.2678 - val_loss: 3.0256 - val_accuracy: 0.3136\n",
      "Epoch 48/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1827 - accuracy: 0.2705 - val_loss: 3.0266 - val_accuracy: 0.3128\n",
      "Epoch 49/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1800 - accuracy: 0.2717 - val_loss: 3.0218 - val_accuracy: 0.3097\n",
      "Epoch 50/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1750 - accuracy: 0.2713 - val_loss: 3.0214 - val_accuracy: 0.3094\n",
      "Epoch 51/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1743 - accuracy: 0.2728 - val_loss: 3.0181 - val_accuracy: 0.3136\n",
      "Epoch 52/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1706 - accuracy: 0.2732 - val_loss: 3.0047 - val_accuracy: 0.3154\n",
      "Epoch 53/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1552 - accuracy: 0.2748 - val_loss: 3.0058 - val_accuracy: 0.3145\n",
      "Epoch 54/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1561 - accuracy: 0.2748 - val_loss: 3.0027 - val_accuracy: 0.3127\n",
      "Epoch 55/240000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 20s 20s/step - loss: 3.1536 - accuracy: 0.2762 - val_loss: 2.9940 - val_accuracy: 0.3163\n",
      "Epoch 56/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1455 - accuracy: 0.2770 - val_loss: 2.9934 - val_accuracy: 0.3157\n",
      "Epoch 57/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1420 - accuracy: 0.2785 - val_loss: 2.9912 - val_accuracy: 0.3157\n",
      "Epoch 58/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1379 - accuracy: 0.2792 - val_loss: 2.9905 - val_accuracy: 0.3185\n",
      "Epoch 59/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1338 - accuracy: 0.2785 - val_loss: 2.9868 - val_accuracy: 0.3160\n",
      "Epoch 60/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1297 - accuracy: 0.2801 - val_loss: 2.9818 - val_accuracy: 0.3143\n",
      "Epoch 61/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1271 - accuracy: 0.2809 - val_loss: 2.9770 - val_accuracy: 0.3183\n",
      "Epoch 62/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1218 - accuracy: 0.2815 - val_loss: 2.9748 - val_accuracy: 0.3218\n",
      "Epoch 63/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1192 - accuracy: 0.2825 - val_loss: 2.9730 - val_accuracy: 0.3203\n",
      "Epoch 64/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1163 - accuracy: 0.2832 - val_loss: 2.9689 - val_accuracy: 0.3232\n",
      "Epoch 65/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1129 - accuracy: 0.2829 - val_loss: 2.9673 - val_accuracy: 0.3219\n",
      "Epoch 66/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1106 - accuracy: 0.2836 - val_loss: 2.9633 - val_accuracy: 0.3198\n",
      "Epoch 67/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1065 - accuracy: 0.2837 - val_loss: 2.9630 - val_accuracy: 0.3203\n",
      "Epoch 68/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1033 - accuracy: 0.2853 - val_loss: 2.9577 - val_accuracy: 0.3203\n",
      "Epoch 69/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0986 - accuracy: 0.2852 - val_loss: 2.9551 - val_accuracy: 0.3187\n",
      "Epoch 70/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0985 - accuracy: 0.2846 - val_loss: 2.9551 - val_accuracy: 0.3213\n",
      "Epoch 71/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0962 - accuracy: 0.2866 - val_loss: 2.9592 - val_accuracy: 0.3231\n",
      "Epoch 72/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0999 - accuracy: 0.2851 - val_loss: 2.9664 - val_accuracy: 0.3193\n",
      "Epoch 73/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1100 - accuracy: 0.2847 - val_loss: 2.9663 - val_accuracy: 0.3217\n",
      "Epoch 74/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.1063 - accuracy: 0.2850 - val_loss: 2.9596 - val_accuracy: 0.3225\n",
      "Epoch 75/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.0963 - accuracy: 0.2868 - val_loss: 2.9512 - val_accuracy: 0.3228\n",
      "Epoch 76/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0871 - accuracy: 0.2876 - val_loss: 2.9596 - val_accuracy: 0.3218\n",
      "Epoch 77/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0934 - accuracy: 0.2863 - val_loss: 2.9495 - val_accuracy: 0.3233\n",
      "Epoch 78/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0854 - accuracy: 0.2882 - val_loss: 2.9485 - val_accuracy: 0.3239\n",
      "Epoch 79/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0849 - accuracy: 0.2872 - val_loss: 2.9501 - val_accuracy: 0.3257\n",
      "Epoch 80/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0838 - accuracy: 0.2893 - val_loss: 2.9536 - val_accuracy: 0.3217\n",
      "Epoch 81/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0843 - accuracy: 0.2882 - val_loss: 2.9412 - val_accuracy: 0.3252\n",
      "Epoch 82/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0750 - accuracy: 0.2892 - val_loss: 2.9451 - val_accuracy: 0.3256\n",
      "Epoch 83/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0771 - accuracy: 0.2896 - val_loss: 2.9436 - val_accuracy: 0.3249\n",
      "Epoch 84/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0750 - accuracy: 0.2888 - val_loss: 2.9438 - val_accuracy: 0.3219\n",
      "Epoch 85/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.0758 - accuracy: 0.2899 - val_loss: 2.9520 - val_accuracy: 0.3250\n",
      "Epoch 86/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0812 - accuracy: 0.2899 - val_loss: 2.9556 - val_accuracy: 0.3226\n",
      "Epoch 87/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0879 - accuracy: 0.2882 - val_loss: 2.9567 - val_accuracy: 0.3245\n",
      "Epoch 88/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0841 - accuracy: 0.2878 - val_loss: 2.9475 - val_accuracy: 0.3257\n",
      "Epoch 89/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0757 - accuracy: 0.2899 - val_loss: 2.9418 - val_accuracy: 0.3255\n",
      "Epoch 90/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0774 - accuracy: 0.2887 - val_loss: 2.9494 - val_accuracy: 0.3210\n",
      "Epoch 91/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0728 - accuracy: 0.2903 - val_loss: 2.9355 - val_accuracy: 0.3272\n",
      "Epoch 92/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0679 - accuracy: 0.2912 - val_loss: 2.9363 - val_accuracy: 0.3256\n",
      "Epoch 93/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0679 - accuracy: 0.2899 - val_loss: 2.9366 - val_accuracy: 0.3262\n",
      "Epoch 94/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.0611 - accuracy: 0.2930 - val_loss: 2.9342 - val_accuracy: 0.3272\n",
      "Epoch 95/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0617 - accuracy: 0.2933 - val_loss: 2.9307 - val_accuracy: 0.3291\n",
      "Epoch 96/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.0568 - accuracy: 0.2932 - val_loss: 2.9265 - val_accuracy: 0.3259\n",
      "Epoch 97/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0499 - accuracy: 0.2931 - val_loss: 2.9283 - val_accuracy: 0.3254\n",
      "Epoch 98/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0530 - accuracy: 0.2924 - val_loss: 2.9285 - val_accuracy: 0.3255\n",
      "Epoch 99/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0503 - accuracy: 0.2943 - val_loss: 2.9246 - val_accuracy: 0.3257\n",
      "Epoch 100/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0482 - accuracy: 0.2949 - val_loss: 2.9231 - val_accuracy: 0.3302\n",
      "Epoch 101/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0470 - accuracy: 0.2957 - val_loss: 2.9202 - val_accuracy: 0.3271\n",
      "Epoch 102/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0427 - accuracy: 0.2960 - val_loss: 2.9174 - val_accuracy: 0.3278\n",
      "Epoch 103/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0400 - accuracy: 0.2963 - val_loss: 2.9133 - val_accuracy: 0.3268\n",
      "Epoch 104/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0386 - accuracy: 0.2970 - val_loss: 2.9124 - val_accuracy: 0.3322\n",
      "Epoch 105/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0373 - accuracy: 0.2961 - val_loss: 2.9118 - val_accuracy: 0.3316\n",
      "Epoch 106/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0347 - accuracy: 0.2968 - val_loss: 2.9137 - val_accuracy: 0.3312\n",
      "Epoch 107/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0364 - accuracy: 0.2966 - val_loss: 2.9088 - val_accuracy: 0.3310\n",
      "Epoch 108/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0323 - accuracy: 0.2970 - val_loss: 2.9079 - val_accuracy: 0.3317\n",
      "Epoch 109/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0317 - accuracy: 0.2984 - val_loss: 2.9066 - val_accuracy: 0.3311\n",
      "Epoch 110/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0290 - accuracy: 0.2980 - val_loss: 2.9077 - val_accuracy: 0.3329\n",
      "Epoch 111/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0286 - accuracy: 0.2978 - val_loss: 2.9077 - val_accuracy: 0.3327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0280 - accuracy: 0.2985 - val_loss: 2.9047 - val_accuracy: 0.3327\n",
      "Epoch 113/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0239 - accuracy: 0.2993 - val_loss: 2.9023 - val_accuracy: 0.3336\n",
      "Epoch 114/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0246 - accuracy: 0.2994 - val_loss: 2.9047 - val_accuracy: 0.3333\n",
      "Epoch 115/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0231 - accuracy: 0.2991 - val_loss: 2.9041 - val_accuracy: 0.3312\n",
      "Epoch 116/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0228 - accuracy: 0.2992 - val_loss: 2.9002 - val_accuracy: 0.3335\n",
      "Epoch 117/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0205 - accuracy: 0.2996 - val_loss: 2.9001 - val_accuracy: 0.3341\n",
      "Epoch 118/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0214 - accuracy: 0.2987 - val_loss: 2.8990 - val_accuracy: 0.3352\n",
      "Epoch 119/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0178 - accuracy: 0.3004 - val_loss: 2.8993 - val_accuracy: 0.3348\n",
      "Epoch 120/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0152 - accuracy: 0.3004 - val_loss: 2.8978 - val_accuracy: 0.3337\n",
      "Epoch 121/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0150 - accuracy: 0.3005 - val_loss: 2.8996 - val_accuracy: 0.3324\n",
      "Epoch 122/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0178 - accuracy: 0.3009 - val_loss: 2.8975 - val_accuracy: 0.3323\n",
      "Epoch 123/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0168 - accuracy: 0.3009 - val_loss: 2.9005 - val_accuracy: 0.3316\n",
      "Epoch 124/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0171 - accuracy: 0.3007 - val_loss: 2.9035 - val_accuracy: 0.3337\n",
      "Epoch 125/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0228 - accuracy: 0.2993 - val_loss: 2.9124 - val_accuracy: 0.3309\n",
      "Epoch 126/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0293 - accuracy: 0.3001 - val_loss: 2.9089 - val_accuracy: 0.3314\n",
      "Epoch 127/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0298 - accuracy: 0.2982 - val_loss: 2.9079 - val_accuracy: 0.3328\n",
      "Epoch 128/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0206 - accuracy: 0.2998 - val_loss: 2.8983 - val_accuracy: 0.3353\n",
      "Epoch 129/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0175 - accuracy: 0.3010 - val_loss: 2.9008 - val_accuracy: 0.3332\n",
      "Epoch 130/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0212 - accuracy: 0.3005 - val_loss: 2.9067 - val_accuracy: 0.3327\n",
      "Epoch 131/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0183 - accuracy: 0.3006 - val_loss: 2.8933 - val_accuracy: 0.3359\n",
      "Epoch 132/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0097 - accuracy: 0.3011 - val_loss: 2.8944 - val_accuracy: 0.3355\n",
      "Epoch 133/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0126 - accuracy: 0.3022 - val_loss: 2.9033 - val_accuracy: 0.3345\n",
      "Epoch 134/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0127 - accuracy: 0.3024 - val_loss: 2.8957 - val_accuracy: 0.3353\n",
      "Epoch 135/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0089 - accuracy: 0.3019 - val_loss: 2.8926 - val_accuracy: 0.3350\n",
      "Epoch 136/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0113 - accuracy: 0.3017 - val_loss: 2.8961 - val_accuracy: 0.3354\n",
      "Epoch 137/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0106 - accuracy: 0.3022 - val_loss: 2.8954 - val_accuracy: 0.3355\n",
      "Epoch 138/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0120 - accuracy: 0.3012 - val_loss: 2.8902 - val_accuracy: 0.3370\n",
      "Epoch 139/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0070 - accuracy: 0.3031 - val_loss: 2.8956 - val_accuracy: 0.3354\n",
      "Epoch 140/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0092 - accuracy: 0.3025 - val_loss: 2.8919 - val_accuracy: 0.3352\n",
      "Epoch 141/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0050 - accuracy: 0.3026 - val_loss: 2.8911 - val_accuracy: 0.3333\n",
      "Epoch 142/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0055 - accuracy: 0.3019 - val_loss: 2.8939 - val_accuracy: 0.3336\n",
      "Epoch 143/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0086 - accuracy: 0.3023 - val_loss: 2.8898 - val_accuracy: 0.3352\n",
      "Epoch 144/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0006 - accuracy: 0.3029 - val_loss: 2.8867 - val_accuracy: 0.3362\n",
      "Epoch 145/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0009 - accuracy: 0.3037 - val_loss: 2.8890 - val_accuracy: 0.3339\n",
      "Epoch 146/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.0002 - accuracy: 0.3040 - val_loss: 2.8840 - val_accuracy: 0.3334\n",
      "Epoch 147/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9977 - accuracy: 0.3031 - val_loss: 2.8837 - val_accuracy: 0.3357\n",
      "Epoch 148/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9924 - accuracy: 0.3045 - val_loss: 2.8845 - val_accuracy: 0.3367\n",
      "Epoch 149/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9940 - accuracy: 0.3038 - val_loss: 2.8831 - val_accuracy: 0.3336\n",
      "Epoch 150/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9950 - accuracy: 0.3048 - val_loss: 2.8828 - val_accuracy: 0.3370\n",
      "Epoch 151/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9932 - accuracy: 0.3048 - val_loss: 2.8802 - val_accuracy: 0.3383\n",
      "Epoch 152/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9889 - accuracy: 0.3052 - val_loss: 2.8812 - val_accuracy: 0.3364\n",
      "Epoch 153/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9908 - accuracy: 0.3054 - val_loss: 2.8789 - val_accuracy: 0.3354\n",
      "Epoch 154/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9865 - accuracy: 0.3064 - val_loss: 2.8766 - val_accuracy: 0.3382\n",
      "Epoch 155/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9863 - accuracy: 0.3067 - val_loss: 2.8773 - val_accuracy: 0.3393\n",
      "Epoch 156/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9861 - accuracy: 0.3069 - val_loss: 2.8772 - val_accuracy: 0.3395\n",
      "Epoch 157/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9875 - accuracy: 0.3057 - val_loss: 2.8746 - val_accuracy: 0.3388\n",
      "Epoch 158/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9836 - accuracy: 0.3069 - val_loss: 2.8733 - val_accuracy: 0.3392\n",
      "Epoch 159/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9828 - accuracy: 0.3066 - val_loss: 2.8729 - val_accuracy: 0.3390\n",
      "Epoch 160/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9819 - accuracy: 0.3065 - val_loss: 2.8737 - val_accuracy: 0.3396\n",
      "Epoch 161/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9826 - accuracy: 0.3067 - val_loss: 2.8724 - val_accuracy: 0.3386\n",
      "Epoch 162/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9805 - accuracy: 0.3072 - val_loss: 2.8727 - val_accuracy: 0.3396\n",
      "Epoch 163/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9806 - accuracy: 0.3071 - val_loss: 2.8717 - val_accuracy: 0.3394\n",
      "Epoch 164/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9778 - accuracy: 0.3072 - val_loss: 2.8708 - val_accuracy: 0.3411\n",
      "Epoch 165/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9790 - accuracy: 0.3065 - val_loss: 2.8708 - val_accuracy: 0.3384\n",
      "Epoch 166/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9758 - accuracy: 0.3081 - val_loss: 2.8702 - val_accuracy: 0.3398\n",
      "Epoch 167/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9766 - accuracy: 0.3083 - val_loss: 2.8682 - val_accuracy: 0.3426\n",
      "Epoch 168/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9769 - accuracy: 0.3077 - val_loss: 2.8695 - val_accuracy: 0.3418\n",
      "Epoch 169/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9771 - accuracy: 0.3085 - val_loss: 2.8671 - val_accuracy: 0.3424\n",
      "Epoch 170/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9749 - accuracy: 0.3079 - val_loss: 2.8675 - val_accuracy: 0.3392\n",
      "Epoch 171/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9731 - accuracy: 0.3078 - val_loss: 2.8701 - val_accuracy: 0.3398\n",
      "Epoch 172/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9736 - accuracy: 0.3081 - val_loss: 2.8665 - val_accuracy: 0.3405\n",
      "Epoch 173/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9721 - accuracy: 0.3096 - val_loss: 2.8663 - val_accuracy: 0.3419\n",
      "Epoch 174/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9721 - accuracy: 0.3081 - val_loss: 2.8679 - val_accuracy: 0.3394\n",
      "Epoch 175/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9728 - accuracy: 0.3087 - val_loss: 2.8664 - val_accuracy: 0.3412\n",
      "Epoch 176/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9722 - accuracy: 0.3084 - val_loss: 2.8671 - val_accuracy: 0.3417\n",
      "Epoch 177/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9713 - accuracy: 0.3095 - val_loss: 2.8651 - val_accuracy: 0.3430\n",
      "Epoch 178/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9697 - accuracy: 0.3089 - val_loss: 2.8646 - val_accuracy: 0.3417\n",
      "Epoch 179/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9687 - accuracy: 0.3093 - val_loss: 2.8663 - val_accuracy: 0.3396\n",
      "Epoch 180/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9695 - accuracy: 0.3091 - val_loss: 2.8667 - val_accuracy: 0.3391\n",
      "Epoch 181/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9714 - accuracy: 0.3095 - val_loss: 2.8688 - val_accuracy: 0.3376\n",
      "Epoch 182/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9734 - accuracy: 0.3084 - val_loss: 2.8777 - val_accuracy: 0.3393\n",
      "Epoch 183/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9813 - accuracy: 0.3091 - val_loss: 2.8925 - val_accuracy: 0.3379\n",
      "Epoch 184/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.0019 - accuracy: 0.3066 - val_loss: 2.8937 - val_accuracy: 0.3358\n",
      "Epoch 185/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9979 - accuracy: 0.3056 - val_loss: 2.8789 - val_accuracy: 0.3398\n",
      "Epoch 186/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9824 - accuracy: 0.3085 - val_loss: 2.8681 - val_accuracy: 0.3405\n",
      "Epoch 187/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9716 - accuracy: 0.3088 - val_loss: 2.8820 - val_accuracy: 0.3393\n",
      "Epoch 188/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9821 - accuracy: 0.3093 - val_loss: 2.8799 - val_accuracy: 0.3395\n",
      "Epoch 189/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9808 - accuracy: 0.3077 - val_loss: 2.8689 - val_accuracy: 0.3412\n",
      "Epoch 190/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9702 - accuracy: 0.3099 - val_loss: 2.8845 - val_accuracy: 0.3402\n",
      "Epoch 191/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9831 - accuracy: 0.3091 - val_loss: 2.8752 - val_accuracy: 0.3428\n",
      "Epoch 192/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9757 - accuracy: 0.3090 - val_loss: 2.8681 - val_accuracy: 0.3422\n",
      "Epoch 193/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9709 - accuracy: 0.3094 - val_loss: 2.8772 - val_accuracy: 0.3401\n",
      "Epoch 194/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9742 - accuracy: 0.3103 - val_loss: 2.8752 - val_accuracy: 0.3378\n",
      "Epoch 195/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9779 - accuracy: 0.3075 - val_loss: 2.8668 - val_accuracy: 0.3417\n",
      "Epoch 196/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9699 - accuracy: 0.3093 - val_loss: 2.8746 - val_accuracy: 0.3398\n",
      "Epoch 197/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9739 - accuracy: 0.3087 - val_loss: 2.8694 - val_accuracy: 0.3383\n",
      "Epoch 198/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9689 - accuracy: 0.3092 - val_loss: 2.8692 - val_accuracy: 0.3395\n",
      "Epoch 199/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9678 - accuracy: 0.3089 - val_loss: 2.8724 - val_accuracy: 0.3404\n",
      "Epoch 200/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9688 - accuracy: 0.3095 - val_loss: 2.8659 - val_accuracy: 0.3409\n",
      "Epoch 201/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9672 - accuracy: 0.3097 - val_loss: 2.8641 - val_accuracy: 0.3422\n",
      "Epoch 202/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9626 - accuracy: 0.3106 - val_loss: 2.8671 - val_accuracy: 0.3422\n",
      "Epoch 203/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9632 - accuracy: 0.3109 - val_loss: 2.8650 - val_accuracy: 0.3442\n",
      "Epoch 204/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9615 - accuracy: 0.3103 - val_loss: 2.8626 - val_accuracy: 0.3402\n",
      "Epoch 205/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9608 - accuracy: 0.3103 - val_loss: 2.8631 - val_accuracy: 0.3396\n",
      "Epoch 206/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9604 - accuracy: 0.3110 - val_loss: 2.8625 - val_accuracy: 0.3426\n",
      "Epoch 207/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9577 - accuracy: 0.3122 - val_loss: 2.8622 - val_accuracy: 0.3447\n",
      "Epoch 208/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9552 - accuracy: 0.3121 - val_loss: 2.8613 - val_accuracy: 0.3439\n",
      "Epoch 209/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9574 - accuracy: 0.3116 - val_loss: 2.8611 - val_accuracy: 0.3417\n",
      "Epoch 210/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9563 - accuracy: 0.3115 - val_loss: 2.8601 - val_accuracy: 0.3435\n",
      "Epoch 211/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9552 - accuracy: 0.3115 - val_loss: 2.8597 - val_accuracy: 0.3418\n",
      "Epoch 212/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9546 - accuracy: 0.3124 - val_loss: 2.8589 - val_accuracy: 0.3425\n",
      "Epoch 213/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9540 - accuracy: 0.3117 - val_loss: 2.8582 - val_accuracy: 0.3413\n",
      "Epoch 214/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9548 - accuracy: 0.3122 - val_loss: 2.8574 - val_accuracy: 0.3420\n",
      "Epoch 215/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9523 - accuracy: 0.3125 - val_loss: 2.8556 - val_accuracy: 0.3454\n",
      "Epoch 216/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9521 - accuracy: 0.3122 - val_loss: 2.8569 - val_accuracy: 0.3450\n",
      "Epoch 217/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9511 - accuracy: 0.3126 - val_loss: 2.8568 - val_accuracy: 0.3460\n",
      "Epoch 218/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9504 - accuracy: 0.3122 - val_loss: 2.8549 - val_accuracy: 0.3445\n",
      "Epoch 219/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9509 - accuracy: 0.3134 - val_loss: 2.8545 - val_accuracy: 0.3441\n",
      "Epoch 220/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9508 - accuracy: 0.3131 - val_loss: 2.8565 - val_accuracy: 0.3447\n",
      "Epoch 221/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9507 - accuracy: 0.3130 - val_loss: 2.8544 - val_accuracy: 0.3442\n",
      "Epoch 222/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9488 - accuracy: 0.3130 - val_loss: 2.8559 - val_accuracy: 0.3441\n",
      "Epoch 223/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9495 - accuracy: 0.3135 - val_loss: 2.8544 - val_accuracy: 0.3445\n",
      "Epoch 224/240000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 20s 20s/step - loss: 2.9471 - accuracy: 0.3132 - val_loss: 2.8539 - val_accuracy: 0.3428\n",
      "Epoch 225/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9458 - accuracy: 0.3130 - val_loss: 2.8543 - val_accuracy: 0.3436\n",
      "Epoch 226/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9471 - accuracy: 0.3125 - val_loss: 2.8535 - val_accuracy: 0.3442\n",
      "Epoch 227/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9470 - accuracy: 0.3138 - val_loss: 2.8532 - val_accuracy: 0.3456\n",
      "Epoch 228/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9440 - accuracy: 0.3139 - val_loss: 2.8533 - val_accuracy: 0.3437\n",
      "Epoch 229/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9452 - accuracy: 0.3139 - val_loss: 2.8516 - val_accuracy: 0.3430\n",
      "Epoch 230/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9460 - accuracy: 0.3134 - val_loss: 2.8517 - val_accuracy: 0.3438\n",
      "Epoch 231/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9458 - accuracy: 0.3136 - val_loss: 2.8512 - val_accuracy: 0.3437\n",
      "Epoch 232/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9424 - accuracy: 0.3136 - val_loss: 2.8519 - val_accuracy: 0.3444\n",
      "Epoch 233/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9447 - accuracy: 0.3136 - val_loss: 2.8506 - val_accuracy: 0.3451\n",
      "Epoch 234/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9416 - accuracy: 0.3145 - val_loss: 2.8509 - val_accuracy: 0.3452\n",
      "Epoch 235/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9452 - accuracy: 0.3134 - val_loss: 2.8506 - val_accuracy: 0.3439\n",
      "Epoch 236/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9425 - accuracy: 0.3144 - val_loss: 2.8502 - val_accuracy: 0.3436\n",
      "Epoch 237/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9431 - accuracy: 0.3140 - val_loss: 2.8519 - val_accuracy: 0.3435\n",
      "Epoch 238/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9418 - accuracy: 0.3141 - val_loss: 2.8509 - val_accuracy: 0.3463\n",
      "Epoch 239/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9413 - accuracy: 0.3146 - val_loss: 2.8502 - val_accuracy: 0.3470\n",
      "Epoch 240/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9431 - accuracy: 0.3139 - val_loss: 2.8498 - val_accuracy: 0.3468\n",
      "Epoch 241/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9399 - accuracy: 0.3150 - val_loss: 2.8497 - val_accuracy: 0.3438\n",
      "Epoch 242/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9409 - accuracy: 0.3146 - val_loss: 2.8491 - val_accuracy: 0.3441\n",
      "Epoch 243/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9390 - accuracy: 0.3148 - val_loss: 2.8482 - val_accuracy: 0.3431\n",
      "Epoch 244/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9390 - accuracy: 0.3159 - val_loss: 2.8476 - val_accuracy: 0.3457\n",
      "Epoch 245/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9406 - accuracy: 0.3136 - val_loss: 2.8472 - val_accuracy: 0.3480\n",
      "Epoch 246/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9374 - accuracy: 0.3154 - val_loss: 2.8478 - val_accuracy: 0.3489\n",
      "Epoch 247/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9400 - accuracy: 0.3144 - val_loss: 2.8481 - val_accuracy: 0.3478\n",
      "Epoch 248/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9397 - accuracy: 0.3140 - val_loss: 2.8471 - val_accuracy: 0.3463\n",
      "Epoch 249/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9372 - accuracy: 0.3151 - val_loss: 2.8488 - val_accuracy: 0.3454\n",
      "Epoch 250/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9371 - accuracy: 0.3154 - val_loss: 2.8473 - val_accuracy: 0.3462\n",
      "Epoch 251/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9387 - accuracy: 0.3142 - val_loss: 2.8465 - val_accuracy: 0.3461\n",
      "Epoch 252/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9357 - accuracy: 0.3152 - val_loss: 2.8469 - val_accuracy: 0.3472\n",
      "Epoch 253/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9359 - accuracy: 0.3150 - val_loss: 2.8461 - val_accuracy: 0.3488\n",
      "Epoch 254/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9365 - accuracy: 0.3150 - val_loss: 2.8454 - val_accuracy: 0.3479\n",
      "Epoch 255/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9336 - accuracy: 0.3160 - val_loss: 2.8479 - val_accuracy: 0.3452\n",
      "Epoch 256/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9342 - accuracy: 0.3152 - val_loss: 2.8464 - val_accuracy: 0.3459\n",
      "Epoch 257/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9347 - accuracy: 0.3153 - val_loss: 2.8459 - val_accuracy: 0.3451\n",
      "Epoch 258/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9333 - accuracy: 0.3157 - val_loss: 2.8469 - val_accuracy: 0.3470\n",
      "Epoch 259/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9340 - accuracy: 0.3158 - val_loss: 2.8462 - val_accuracy: 0.3457\n",
      "Epoch 260/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9331 - accuracy: 0.3161 - val_loss: 2.8454 - val_accuracy: 0.3452\n",
      "Epoch 261/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9340 - accuracy: 0.3156 - val_loss: 2.8451 - val_accuracy: 0.3468\n",
      "Epoch 262/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9318 - accuracy: 0.3168 - val_loss: 2.8454 - val_accuracy: 0.3470\n",
      "Epoch 263/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9327 - accuracy: 0.3157 - val_loss: 2.8457 - val_accuracy: 0.3448\n",
      "Epoch 264/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9324 - accuracy: 0.3164 - val_loss: 2.8458 - val_accuracy: 0.3448\n",
      "Epoch 265/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9336 - accuracy: 0.3146 - val_loss: 2.8454 - val_accuracy: 0.3452\n",
      "Epoch 266/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9314 - accuracy: 0.3157 - val_loss: 2.8456 - val_accuracy: 0.3458\n",
      "Epoch 267/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9331 - accuracy: 0.3164 - val_loss: 2.8449 - val_accuracy: 0.3467\n",
      "Epoch 268/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9294 - accuracy: 0.3161 - val_loss: 2.8442 - val_accuracy: 0.3461\n",
      "Epoch 269/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9305 - accuracy: 0.3156 - val_loss: 2.8452 - val_accuracy: 0.3465\n",
      "Epoch 270/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9323 - accuracy: 0.3155 - val_loss: 2.8450 - val_accuracy: 0.3498\n",
      "Epoch 271/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9270 - accuracy: 0.3163 - val_loss: 2.8447 - val_accuracy: 0.3476\n",
      "Epoch 272/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9288 - accuracy: 0.3161 - val_loss: 2.8456 - val_accuracy: 0.3469\n",
      "Epoch 273/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9293 - accuracy: 0.3166 - val_loss: 2.8449 - val_accuracy: 0.3466\n",
      "Epoch 274/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9292 - accuracy: 0.3170 - val_loss: 2.8444 - val_accuracy: 0.3465\n",
      "Epoch 275/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9311 - accuracy: 0.3159 - val_loss: 2.8459 - val_accuracy: 0.3456\n",
      "Epoch 276/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9301 - accuracy: 0.3163 - val_loss: 2.8442 - val_accuracy: 0.3475\n",
      "Epoch 277/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9287 - accuracy: 0.3168 - val_loss: 2.8428 - val_accuracy: 0.3476\n",
      "Epoch 278/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9267 - accuracy: 0.3177 - val_loss: 2.8445 - val_accuracy: 0.3465\n",
      "Epoch 279/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9279 - accuracy: 0.3167 - val_loss: 2.8434 - val_accuracy: 0.3471\n",
      "Epoch 280/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9275 - accuracy: 0.3167 - val_loss: 2.8426 - val_accuracy: 0.3468\n",
      "Epoch 281/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9270 - accuracy: 0.3168 - val_loss: 2.8444 - val_accuracy: 0.3475\n",
      "Epoch 282/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9290 - accuracy: 0.3159 - val_loss: 2.8425 - val_accuracy: 0.3467\n",
      "Epoch 283/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9288 - accuracy: 0.3165 - val_loss: 2.8444 - val_accuracy: 0.3460\n",
      "Epoch 284/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9248 - accuracy: 0.3174 - val_loss: 2.8441 - val_accuracy: 0.3467\n",
      "Epoch 285/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9252 - accuracy: 0.3175 - val_loss: 2.8433 - val_accuracy: 0.3463\n",
      "Epoch 286/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9239 - accuracy: 0.3177 - val_loss: 2.8443 - val_accuracy: 0.3468\n",
      "Epoch 287/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9251 - accuracy: 0.3171 - val_loss: 2.8439 - val_accuracy: 0.3473\n",
      "Epoch 288/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9249 - accuracy: 0.3169 - val_loss: 2.8428 - val_accuracy: 0.3475\n",
      "Epoch 289/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9259 - accuracy: 0.3161 - val_loss: 2.8438 - val_accuracy: 0.3442\n",
      "Epoch 290/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9236 - accuracy: 0.3171 - val_loss: 2.8446 - val_accuracy: 0.3443\n",
      "Epoch 291/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9239 - accuracy: 0.3176 - val_loss: 2.8439 - val_accuracy: 0.3467\n",
      "Epoch 292/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9255 - accuracy: 0.3178 - val_loss: 2.8434 - val_accuracy: 0.3462\n",
      "Epoch 293/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9249 - accuracy: 0.3171 - val_loss: 2.8433 - val_accuracy: 0.3449\n",
      "Epoch 294/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9239 - accuracy: 0.3178 - val_loss: 2.8434 - val_accuracy: 0.3459\n",
      "Epoch 295/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9241 - accuracy: 0.3168 - val_loss: 2.8430 - val_accuracy: 0.3450\n",
      "Epoch 296/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9231 - accuracy: 0.3175 - val_loss: 2.8442 - val_accuracy: 0.3445\n",
      "Epoch 297/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9240 - accuracy: 0.3171 - val_loss: 2.8447 - val_accuracy: 0.3445\n",
      "Epoch 298/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9241 - accuracy: 0.3175 - val_loss: 2.8439 - val_accuracy: 0.3459\n",
      "Epoch 299/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9240 - accuracy: 0.3173 - val_loss: 2.8439 - val_accuracy: 0.3464\n",
      "Epoch 300/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9237 - accuracy: 0.3168 - val_loss: 2.8450 - val_accuracy: 0.3452\n",
      "Epoch 301/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9226 - accuracy: 0.3178 - val_loss: 2.8434 - val_accuracy: 0.3463\n",
      "Epoch 302/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9218 - accuracy: 0.3186 - val_loss: 2.8426 - val_accuracy: 0.3460\n",
      "Epoch 303/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9205 - accuracy: 0.3181 - val_loss: 2.8424 - val_accuracy: 0.3457\n",
      "Epoch 304/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9216 - accuracy: 0.3180 - val_loss: 2.8430 - val_accuracy: 0.3450\n",
      "Epoch 305/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9212 - accuracy: 0.3175 - val_loss: 2.8419 - val_accuracy: 0.3471\n",
      "Epoch 306/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9193 - accuracy: 0.3188 - val_loss: 2.8411 - val_accuracy: 0.3464\n",
      "Epoch 307/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9194 - accuracy: 0.3181 - val_loss: 2.8412 - val_accuracy: 0.3473\n",
      "Epoch 308/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9193 - accuracy: 0.3175 - val_loss: 2.8415 - val_accuracy: 0.3465\n",
      "Epoch 309/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9178 - accuracy: 0.3186 - val_loss: 2.8404 - val_accuracy: 0.3480\n",
      "Epoch 310/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9192 - accuracy: 0.3180 - val_loss: 2.8408 - val_accuracy: 0.3483\n",
      "Epoch 311/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9193 - accuracy: 0.3187 - val_loss: 2.8418 - val_accuracy: 0.3460\n",
      "Epoch 312/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9184 - accuracy: 0.3182 - val_loss: 2.8410 - val_accuracy: 0.3470\n",
      "Epoch 313/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9187 - accuracy: 0.3185 - val_loss: 2.8409 - val_accuracy: 0.3451\n",
      "Epoch 314/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9191 - accuracy: 0.3180 - val_loss: 2.8419 - val_accuracy: 0.3462\n",
      "Epoch 315/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9182 - accuracy: 0.3182 - val_loss: 2.8412 - val_accuracy: 0.3471\n",
      "Epoch 316/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9179 - accuracy: 0.3180 - val_loss: 2.8423 - val_accuracy: 0.3472\n",
      "Epoch 317/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9164 - accuracy: 0.3183 - val_loss: 2.8431 - val_accuracy: 0.3456\n",
      "Epoch 318/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9185 - accuracy: 0.3184 - val_loss: 2.8404 - val_accuracy: 0.3464\n",
      "Epoch 319/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9164 - accuracy: 0.3193 - val_loss: 2.8400 - val_accuracy: 0.3481\n",
      "Epoch 320/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9163 - accuracy: 0.3185 - val_loss: 2.8407 - val_accuracy: 0.3474\n",
      "Epoch 321/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9176 - accuracy: 0.3188 - val_loss: 2.8389 - val_accuracy: 0.3459\n",
      "Epoch 322/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9196 - accuracy: 0.3187 - val_loss: 2.8390 - val_accuracy: 0.3473\n",
      "Epoch 323/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9171 - accuracy: 0.3190 - val_loss: 2.8405 - val_accuracy: 0.3481\n",
      "Epoch 324/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9140 - accuracy: 0.3199 - val_loss: 2.8397 - val_accuracy: 0.3473\n",
      "Epoch 325/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9156 - accuracy: 0.3183 - val_loss: 2.8398 - val_accuracy: 0.3494\n",
      "Epoch 326/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9167 - accuracy: 0.3193 - val_loss: 2.8403 - val_accuracy: 0.3484\n",
      "Epoch 327/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9137 - accuracy: 0.3192 - val_loss: 2.8395 - val_accuracy: 0.3477\n",
      "Epoch 328/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9159 - accuracy: 0.3196 - val_loss: 2.8397 - val_accuracy: 0.3483\n",
      "Epoch 329/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9144 - accuracy: 0.3193 - val_loss: 2.8403 - val_accuracy: 0.3452\n",
      "Epoch 330/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9167 - accuracy: 0.3188 - val_loss: 2.8391 - val_accuracy: 0.3479\n",
      "Epoch 331/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9167 - accuracy: 0.3178 - val_loss: 2.8388 - val_accuracy: 0.3481\n",
      "Epoch 332/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9148 - accuracy: 0.3184 - val_loss: 2.8399 - val_accuracy: 0.3459\n",
      "Epoch 333/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9130 - accuracy: 0.3190 - val_loss: 2.8393 - val_accuracy: 0.3466\n",
      "Epoch 334/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9140 - accuracy: 0.3192 - val_loss: 2.8389 - val_accuracy: 0.3468\n",
      "Epoch 335/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9123 - accuracy: 0.3195 - val_loss: 2.8381 - val_accuracy: 0.3468\n",
      "Epoch 336/240000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 20s 20s/step - loss: 2.9153 - accuracy: 0.3182 - val_loss: 2.8378 - val_accuracy: 0.3469\n",
      "Epoch 337/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9130 - accuracy: 0.3194 - val_loss: 2.8379 - val_accuracy: 0.3442\n",
      "Epoch 338/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9146 - accuracy: 0.3185 - val_loss: 2.8390 - val_accuracy: 0.3468\n",
      "Epoch 339/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9143 - accuracy: 0.3193 - val_loss: 2.8392 - val_accuracy: 0.3460\n",
      "Epoch 340/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9148 - accuracy: 0.3187 - val_loss: 2.8382 - val_accuracy: 0.3476\n",
      "Epoch 341/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9119 - accuracy: 0.3185 - val_loss: 2.8387 - val_accuracy: 0.3486\n",
      "Epoch 342/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9118 - accuracy: 0.3190 - val_loss: 2.8377 - val_accuracy: 0.3488\n",
      "Epoch 343/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9128 - accuracy: 0.3194 - val_loss: 2.8366 - val_accuracy: 0.3503\n",
      "Epoch 344/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9125 - accuracy: 0.3200 - val_loss: 2.8372 - val_accuracy: 0.3497\n",
      "Epoch 345/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9122 - accuracy: 0.3201 - val_loss: 2.8365 - val_accuracy: 0.3483\n",
      "Epoch 346/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9123 - accuracy: 0.3193 - val_loss: 2.8377 - val_accuracy: 0.3474\n",
      "Epoch 347/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9124 - accuracy: 0.3192 - val_loss: 2.8385 - val_accuracy: 0.3474\n",
      "Epoch 348/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9143 - accuracy: 0.3189 - val_loss: 2.8365 - val_accuracy: 0.3498\n",
      "Epoch 349/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9104 - accuracy: 0.3199 - val_loss: 2.8368 - val_accuracy: 0.3500\n",
      "Epoch 350/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9118 - accuracy: 0.3196 - val_loss: 2.8375 - val_accuracy: 0.3483\n",
      "Epoch 351/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9120 - accuracy: 0.3202 - val_loss: 2.8357 - val_accuracy: 0.3506\n",
      "Epoch 352/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9102 - accuracy: 0.3204 - val_loss: 2.8357 - val_accuracy: 0.3493\n",
      "Epoch 353/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9109 - accuracy: 0.3200 - val_loss: 2.8361 - val_accuracy: 0.3484\n",
      "Epoch 354/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9113 - accuracy: 0.3208 - val_loss: 2.8351 - val_accuracy: 0.3491\n",
      "Epoch 355/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9096 - accuracy: 0.3200 - val_loss: 2.8354 - val_accuracy: 0.3491\n",
      "Epoch 356/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9103 - accuracy: 0.3205 - val_loss: 2.8360 - val_accuracy: 0.3495\n",
      "Epoch 357/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9086 - accuracy: 0.3205 - val_loss: 2.8361 - val_accuracy: 0.3476\n",
      "Epoch 358/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9084 - accuracy: 0.3187 - val_loss: 2.8356 - val_accuracy: 0.3478\n",
      "Epoch 359/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9079 - accuracy: 0.3202 - val_loss: 2.8357 - val_accuracy: 0.3474\n",
      "Epoch 360/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9082 - accuracy: 0.3201 - val_loss: 2.8361 - val_accuracy: 0.3482\n",
      "Epoch 361/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9080 - accuracy: 0.3201 - val_loss: 2.8355 - val_accuracy: 0.3478\n",
      "Epoch 362/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9095 - accuracy: 0.3195 - val_loss: 2.8347 - val_accuracy: 0.3495\n",
      "Epoch 363/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9087 - accuracy: 0.3199 - val_loss: 2.8352 - val_accuracy: 0.3477\n",
      "Epoch 364/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9077 - accuracy: 0.3205 - val_loss: 2.8360 - val_accuracy: 0.3466\n",
      "Epoch 365/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9085 - accuracy: 0.3203 - val_loss: 2.8353 - val_accuracy: 0.3479\n",
      "Epoch 366/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9094 - accuracy: 0.3201 - val_loss: 2.8347 - val_accuracy: 0.3478\n",
      "Epoch 367/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9094 - accuracy: 0.3204 - val_loss: 2.8350 - val_accuracy: 0.3477\n",
      "Epoch 368/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9092 - accuracy: 0.3199 - val_loss: 2.8341 - val_accuracy: 0.3463\n",
      "Epoch 369/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9067 - accuracy: 0.3208 - val_loss: 2.8345 - val_accuracy: 0.3456\n",
      "Epoch 370/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9081 - accuracy: 0.3207 - val_loss: 2.8356 - val_accuracy: 0.3469\n",
      "Epoch 371/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9088 - accuracy: 0.3200 - val_loss: 2.8342 - val_accuracy: 0.3474\n",
      "Epoch 372/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9092 - accuracy: 0.3202 - val_loss: 2.8347 - val_accuracy: 0.3470\n",
      "Epoch 373/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9058 - accuracy: 0.3204 - val_loss: 2.8348 - val_accuracy: 0.3490\n",
      "Epoch 374/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9075 - accuracy: 0.3205 - val_loss: 2.8343 - val_accuracy: 0.3484\n",
      "Epoch 375/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9085 - accuracy: 0.3201 - val_loss: 2.8348 - val_accuracy: 0.3480\n",
      "Epoch 376/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9048 - accuracy: 0.3208 - val_loss: 2.8347 - val_accuracy: 0.3484\n",
      "Epoch 377/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9075 - accuracy: 0.3207 - val_loss: 2.8339 - val_accuracy: 0.3478\n",
      "Epoch 378/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9050 - accuracy: 0.3209 - val_loss: 2.8341 - val_accuracy: 0.3461\n",
      "Epoch 379/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9057 - accuracy: 0.3202 - val_loss: 2.8334 - val_accuracy: 0.3471\n",
      "Epoch 380/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9062 - accuracy: 0.3208 - val_loss: 2.8335 - val_accuracy: 0.3490\n",
      "Epoch 381/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9077 - accuracy: 0.3197 - val_loss: 2.8336 - val_accuracy: 0.3480\n",
      "Epoch 382/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9073 - accuracy: 0.3204 - val_loss: 2.8337 - val_accuracy: 0.3493\n",
      "Epoch 383/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9054 - accuracy: 0.3214 - val_loss: 2.8334 - val_accuracy: 0.3482\n",
      "Epoch 384/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9060 - accuracy: 0.3201 - val_loss: 2.8325 - val_accuracy: 0.3488\n",
      "Epoch 385/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9066 - accuracy: 0.3205 - val_loss: 2.8333 - val_accuracy: 0.3486\n",
      "Epoch 386/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9071 - accuracy: 0.3202 - val_loss: 2.8345 - val_accuracy: 0.3469\n",
      "Epoch 387/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9050 - accuracy: 0.3207 - val_loss: 2.8341 - val_accuracy: 0.3484\n",
      "Epoch 388/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9058 - accuracy: 0.3205 - val_loss: 2.8331 - val_accuracy: 0.3495\n",
      "Epoch 389/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9036 - accuracy: 0.3203 - val_loss: 2.8332 - val_accuracy: 0.3497\n",
      "Epoch 390/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9053 - accuracy: 0.3206 - val_loss: 2.8331 - val_accuracy: 0.3502\n",
      "Epoch 391/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9047 - accuracy: 0.3204 - val_loss: 2.8329 - val_accuracy: 0.3497\n",
      "Epoch 392/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9033 - accuracy: 0.3209 - val_loss: 2.8336 - val_accuracy: 0.3466\n",
      "Epoch 393/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9048 - accuracy: 0.3209 - val_loss: 2.8334 - val_accuracy: 0.3469\n",
      "Epoch 394/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9061 - accuracy: 0.3204 - val_loss: 2.8328 - val_accuracy: 0.3472\n",
      "Epoch 395/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9040 - accuracy: 0.3201 - val_loss: 2.8335 - val_accuracy: 0.3484\n",
      "Epoch 396/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9052 - accuracy: 0.3204 - val_loss: 2.8338 - val_accuracy: 0.3492\n",
      "Epoch 397/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9046 - accuracy: 0.3210 - val_loss: 2.8330 - val_accuracy: 0.3486\n",
      "Epoch 398/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9042 - accuracy: 0.3209 - val_loss: 2.8329 - val_accuracy: 0.3478\n",
      "Epoch 399/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9028 - accuracy: 0.3213 - val_loss: 2.8338 - val_accuracy: 0.3483\n",
      "Epoch 400/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.9030 - accuracy: 0.3216 - val_loss: 2.8335 - val_accuracy: 0.3502\n",
      "Epoch 401/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9029 - accuracy: 0.3210 - val_loss: 2.8327 - val_accuracy: 0.3491\n",
      "Epoch 402/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9018 - accuracy: 0.3209 - val_loss: 2.8333 - val_accuracy: 0.3472\n",
      "Epoch 403/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9008 - accuracy: 0.3219 - val_loss: 2.8336 - val_accuracy: 0.3494\n",
      "Epoch 404/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9023 - accuracy: 0.3217 - val_loss: 2.8322 - val_accuracy: 0.3514\n",
      "Epoch 405/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9033 - accuracy: 0.3202 - val_loss: 2.8318 - val_accuracy: 0.3514\n",
      "Epoch 406/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9014 - accuracy: 0.3212 - val_loss: 2.8331 - val_accuracy: 0.3505\n",
      "Epoch 407/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9034 - accuracy: 0.3213 - val_loss: 2.8333 - val_accuracy: 0.3506\n",
      "Epoch 408/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9017 - accuracy: 0.3212 - val_loss: 2.8321 - val_accuracy: 0.3514\n",
      "Epoch 409/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8987 - accuracy: 0.3214 - val_loss: 2.8316 - val_accuracy: 0.3504\n",
      "Epoch 410/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9033 - accuracy: 0.3217 - val_loss: 2.8322 - val_accuracy: 0.3495\n",
      "Epoch 411/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9019 - accuracy: 0.3216 - val_loss: 2.8321 - val_accuracy: 0.3500\n",
      "Epoch 412/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9035 - accuracy: 0.3204 - val_loss: 2.8315 - val_accuracy: 0.3486\n",
      "Epoch 413/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9028 - accuracy: 0.3218 - val_loss: 2.8310 - val_accuracy: 0.3490\n",
      "Epoch 414/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9008 - accuracy: 0.3215 - val_loss: 2.8320 - val_accuracy: 0.3491\n",
      "Epoch 415/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9036 - accuracy: 0.3212 - val_loss: 2.8317 - val_accuracy: 0.3482\n",
      "Epoch 416/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8997 - accuracy: 0.3212 - val_loss: 2.8317 - val_accuracy: 0.3491\n",
      "Epoch 417/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9003 - accuracy: 0.3210 - val_loss: 2.8321 - val_accuracy: 0.3490\n",
      "Epoch 418/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9022 - accuracy: 0.3213 - val_loss: 2.8320 - val_accuracy: 0.3516\n",
      "Epoch 419/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9017 - accuracy: 0.3214 - val_loss: 2.8318 - val_accuracy: 0.3514\n",
      "Epoch 420/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9007 - accuracy: 0.3217 - val_loss: 2.8322 - val_accuracy: 0.3497\n",
      "Epoch 421/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9028 - accuracy: 0.3205 - val_loss: 2.8332 - val_accuracy: 0.3500\n",
      "Epoch 422/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9028 - accuracy: 0.3208 - val_loss: 2.8330 - val_accuracy: 0.3477\n",
      "Epoch 423/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9023 - accuracy: 0.3212 - val_loss: 2.8318 - val_accuracy: 0.3478\n",
      "Epoch 424/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8991 - accuracy: 0.3215 - val_loss: 2.8320 - val_accuracy: 0.3488\n",
      "Epoch 425/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8976 - accuracy: 0.3225 - val_loss: 2.8326 - val_accuracy: 0.3490\n",
      "Epoch 426/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8975 - accuracy: 0.3227 - val_loss: 2.8326 - val_accuracy: 0.3477\n",
      "Epoch 427/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9010 - accuracy: 0.3209 - val_loss: 2.8314 - val_accuracy: 0.3493\n",
      "Epoch 428/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8984 - accuracy: 0.3217 - val_loss: 2.8311 - val_accuracy: 0.3490\n",
      "Epoch 429/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8997 - accuracy: 0.3223 - val_loss: 2.8320 - val_accuracy: 0.3495\n",
      "Epoch 430/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9019 - accuracy: 0.3214 - val_loss: 2.8322 - val_accuracy: 0.3498\n",
      "Epoch 431/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8973 - accuracy: 0.3229 - val_loss: 2.8323 - val_accuracy: 0.3487\n",
      "Epoch 432/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.9007 - accuracy: 0.3213 - val_loss: 2.8316 - val_accuracy: 0.3486\n",
      "Epoch 433/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8989 - accuracy: 0.3225 - val_loss: 2.8318 - val_accuracy: 0.3503\n",
      "Epoch 434/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8967 - accuracy: 0.3224 - val_loss: 2.8315 - val_accuracy: 0.3511\n",
      "Epoch 435/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8976 - accuracy: 0.3221 - val_loss: 2.8304 - val_accuracy: 0.3500\n",
      "Epoch 436/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8980 - accuracy: 0.3215 - val_loss: 2.8311 - val_accuracy: 0.3495\n",
      "Epoch 437/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8994 - accuracy: 0.3220 - val_loss: 2.8320 - val_accuracy: 0.3490\n",
      "Epoch 438/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8966 - accuracy: 0.3224 - val_loss: 2.8316 - val_accuracy: 0.3500\n",
      "Epoch 439/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8990 - accuracy: 0.3219 - val_loss: 2.8307 - val_accuracy: 0.3519\n",
      "Epoch 440/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8985 - accuracy: 0.3221 - val_loss: 2.8307 - val_accuracy: 0.3515\n",
      "Epoch 441/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8963 - accuracy: 0.3220 - val_loss: 2.8313 - val_accuracy: 0.3516\n",
      "Epoch 442/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8978 - accuracy: 0.3209 - val_loss: 2.8301 - val_accuracy: 0.3519\n",
      "Epoch 443/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8976 - accuracy: 0.3215 - val_loss: 2.8301 - val_accuracy: 0.3494\n",
      "Epoch 444/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8999 - accuracy: 0.3216 - val_loss: 2.8303 - val_accuracy: 0.3497\n",
      "Epoch 445/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8992 - accuracy: 0.3219 - val_loss: 2.8310 - val_accuracy: 0.3505\n",
      "Epoch 446/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8989 - accuracy: 0.3214 - val_loss: 2.8301 - val_accuracy: 0.3509\n",
      "Epoch 447/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8983 - accuracy: 0.3222 - val_loss: 2.8301 - val_accuracy: 0.3518\n",
      "Epoch 448/240000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 20s 20s/step - loss: 2.8983 - accuracy: 0.3224 - val_loss: 2.8313 - val_accuracy: 0.3514\n",
      "Epoch 449/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8993 - accuracy: 0.3224 - val_loss: 2.8304 - val_accuracy: 0.3515\n",
      "Epoch 450/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8985 - accuracy: 0.3221 - val_loss: 2.8305 - val_accuracy: 0.3512\n",
      "Epoch 451/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8988 - accuracy: 0.3213 - val_loss: 2.8306 - val_accuracy: 0.3497\n",
      "Epoch 452/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8956 - accuracy: 0.3219 - val_loss: 2.8308 - val_accuracy: 0.3511\n",
      "Epoch 453/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8975 - accuracy: 0.3216 - val_loss: 2.8305 - val_accuracy: 0.3517\n",
      "Epoch 454/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8959 - accuracy: 0.3219 - val_loss: 2.8303 - val_accuracy: 0.3508\n",
      "Epoch 455/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8950 - accuracy: 0.3224 - val_loss: 2.8303 - val_accuracy: 0.3502\n",
      "Epoch 456/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8954 - accuracy: 0.3224 - val_loss: 2.8303 - val_accuracy: 0.3490\n",
      "Epoch 457/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8956 - accuracy: 0.3230 - val_loss: 2.8299 - val_accuracy: 0.3482\n",
      "Epoch 458/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8957 - accuracy: 0.3229 - val_loss: 2.8296 - val_accuracy: 0.3504\n",
      "Epoch 459/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8969 - accuracy: 0.3224 - val_loss: 2.8298 - val_accuracy: 0.3514\n",
      "Epoch 460/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8970 - accuracy: 0.3231 - val_loss: 2.8302 - val_accuracy: 0.3517\n",
      "Epoch 461/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8956 - accuracy: 0.3231 - val_loss: 2.8301 - val_accuracy: 0.3511\n",
      "Epoch 462/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8971 - accuracy: 0.3223 - val_loss: 2.8296 - val_accuracy: 0.3504\n",
      "Epoch 463/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8964 - accuracy: 0.3222 - val_loss: 2.8297 - val_accuracy: 0.3484\n",
      "Epoch 464/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8957 - accuracy: 0.3230 - val_loss: 2.8296 - val_accuracy: 0.3493\n",
      "Epoch 465/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8942 - accuracy: 0.3220 - val_loss: 2.8295 - val_accuracy: 0.3498\n",
      "Epoch 466/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8967 - accuracy: 0.3224 - val_loss: 2.8298 - val_accuracy: 0.3511\n",
      "Epoch 467/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8978 - accuracy: 0.3220 - val_loss: 2.8298 - val_accuracy: 0.3516\n",
      "Epoch 468/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8982 - accuracy: 0.3221 - val_loss: 2.8293 - val_accuracy: 0.3507\n",
      "Epoch 469/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8965 - accuracy: 0.3216 - val_loss: 2.8296 - val_accuracy: 0.3509\n",
      "Epoch 470/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8950 - accuracy: 0.3223 - val_loss: 2.8297 - val_accuracy: 0.3495\n",
      "Epoch 471/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8951 - accuracy: 0.3225 - val_loss: 2.8296 - val_accuracy: 0.3500\n",
      "Epoch 472/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8953 - accuracy: 0.3224 - val_loss: 2.8296 - val_accuracy: 0.3511\n",
      "Epoch 473/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8968 - accuracy: 0.3221 - val_loss: 2.8295 - val_accuracy: 0.3514\n",
      "Epoch 474/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8953 - accuracy: 0.3219 - val_loss: 2.8294 - val_accuracy: 0.3521\n",
      "Epoch 475/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8942 - accuracy: 0.3214 - val_loss: 2.8296 - val_accuracy: 0.3514\n",
      "Epoch 476/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8934 - accuracy: 0.3230 - val_loss: 2.8292 - val_accuracy: 0.3509\n",
      "Epoch 477/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8938 - accuracy: 0.3216 - val_loss: 2.8291 - val_accuracy: 0.3523\n",
      "Epoch 478/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8945 - accuracy: 0.3227 - val_loss: 2.8288 - val_accuracy: 0.3515\n",
      "Epoch 479/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8929 - accuracy: 0.3232 - val_loss: 2.8287 - val_accuracy: 0.3524\n",
      "Epoch 480/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8955 - accuracy: 0.3234 - val_loss: 2.8291 - val_accuracy: 0.3521\n",
      "Epoch 481/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8940 - accuracy: 0.3233 - val_loss: 2.8293 - val_accuracy: 0.3532\n",
      "Epoch 482/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8963 - accuracy: 0.3222 - val_loss: 2.8285 - val_accuracy: 0.3521\n",
      "Epoch 483/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8964 - accuracy: 0.3225 - val_loss: 2.8289 - val_accuracy: 0.3506\n",
      "Epoch 484/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8946 - accuracy: 0.3228 - val_loss: 2.8304 - val_accuracy: 0.3495\n",
      "Epoch 485/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8957 - accuracy: 0.3227 - val_loss: 2.8299 - val_accuracy: 0.3506\n",
      "Epoch 486/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8957 - accuracy: 0.3220 - val_loss: 2.8283 - val_accuracy: 0.3507\n",
      "Epoch 487/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8930 - accuracy: 0.3230 - val_loss: 2.8284 - val_accuracy: 0.3519\n",
      "Epoch 488/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8944 - accuracy: 0.3223 - val_loss: 2.8293 - val_accuracy: 0.3505\n",
      "Epoch 489/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8937 - accuracy: 0.3233 - val_loss: 2.8291 - val_accuracy: 0.3513\n",
      "Epoch 490/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8932 - accuracy: 0.3230 - val_loss: 2.8289 - val_accuracy: 0.3524\n",
      "Epoch 491/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8933 - accuracy: 0.3228 - val_loss: 2.8291 - val_accuracy: 0.3516\n",
      "Epoch 492/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8932 - accuracy: 0.3228 - val_loss: 2.8287 - val_accuracy: 0.3526\n",
      "Epoch 493/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8918 - accuracy: 0.3229 - val_loss: 2.8288 - val_accuracy: 0.3540\n",
      "Epoch 494/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8919 - accuracy: 0.3229 - val_loss: 2.8295 - val_accuracy: 0.3528\n",
      "Epoch 495/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8930 - accuracy: 0.3226 - val_loss: 2.8297 - val_accuracy: 0.3524\n",
      "Epoch 496/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8943 - accuracy: 0.3228 - val_loss: 2.8290 - val_accuracy: 0.3520\n",
      "Epoch 497/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8916 - accuracy: 0.3233 - val_loss: 2.8285 - val_accuracy: 0.3517\n",
      "Epoch 498/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8938 - accuracy: 0.3225 - val_loss: 2.8285 - val_accuracy: 0.3523\n",
      "Epoch 499/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8944 - accuracy: 0.3229 - val_loss: 2.8280 - val_accuracy: 0.3513\n",
      "Epoch 500/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8956 - accuracy: 0.3229 - val_loss: 2.8283 - val_accuracy: 0.3508\n",
      "Epoch 501/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8923 - accuracy: 0.3231 - val_loss: 2.8286 - val_accuracy: 0.3518\n",
      "Epoch 502/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8921 - accuracy: 0.3223 - val_loss: 2.8289 - val_accuracy: 0.3531\n",
      "Epoch 503/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8939 - accuracy: 0.3233 - val_loss: 2.8278 - val_accuracy: 0.3524\n",
      "Epoch 504/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8916 - accuracy: 0.3229 - val_loss: 2.8280 - val_accuracy: 0.3518\n",
      "Epoch 505/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8937 - accuracy: 0.3217 - val_loss: 2.8287 - val_accuracy: 0.3509\n",
      "Epoch 506/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8916 - accuracy: 0.3236 - val_loss: 2.8292 - val_accuracy: 0.3503\n",
      "Epoch 507/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8922 - accuracy: 0.3223 - val_loss: 2.8285 - val_accuracy: 0.3507\n",
      "Epoch 508/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8938 - accuracy: 0.3222 - val_loss: 2.8278 - val_accuracy: 0.3511\n",
      "Epoch 509/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8935 - accuracy: 0.3229 - val_loss: 2.8279 - val_accuracy: 0.3512\n",
      "Epoch 510/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8912 - accuracy: 0.3233 - val_loss: 2.8289 - val_accuracy: 0.3505\n",
      "Epoch 511/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8944 - accuracy: 0.3227 - val_loss: 2.8289 - val_accuracy: 0.3524\n",
      "Epoch 512/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8912 - accuracy: 0.3235 - val_loss: 2.8281 - val_accuracy: 0.3508\n",
      "Epoch 513/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8929 - accuracy: 0.3223 - val_loss: 2.8278 - val_accuracy: 0.3514\n",
      "Epoch 514/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8916 - accuracy: 0.3234 - val_loss: 2.8278 - val_accuracy: 0.3517\n",
      "Epoch 515/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8904 - accuracy: 0.3232 - val_loss: 2.8277 - val_accuracy: 0.3508\n",
      "Epoch 516/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8941 - accuracy: 0.3221 - val_loss: 2.8273 - val_accuracy: 0.3519\n",
      "Epoch 517/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8913 - accuracy: 0.3231 - val_loss: 2.8270 - val_accuracy: 0.3518\n",
      "Epoch 518/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8898 - accuracy: 0.3244 - val_loss: 2.8270 - val_accuracy: 0.3526\n",
      "Epoch 519/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8913 - accuracy: 0.3235 - val_loss: 2.8272 - val_accuracy: 0.3522\n",
      "Epoch 520/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8904 - accuracy: 0.3229 - val_loss: 2.8281 - val_accuracy: 0.3513\n",
      "Epoch 521/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8908 - accuracy: 0.3228 - val_loss: 2.8282 - val_accuracy: 0.3511\n",
      "Epoch 522/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8903 - accuracy: 0.3234 - val_loss: 2.8279 - val_accuracy: 0.3508\n",
      "Epoch 523/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8898 - accuracy: 0.3227 - val_loss: 2.8279 - val_accuracy: 0.3513\n",
      "Epoch 524/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8899 - accuracy: 0.3238 - val_loss: 2.8280 - val_accuracy: 0.3512\n",
      "Epoch 525/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8911 - accuracy: 0.3233 - val_loss: 2.8279 - val_accuracy: 0.3517\n",
      "Epoch 526/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8906 - accuracy: 0.3228 - val_loss: 2.8277 - val_accuracy: 0.3530\n",
      "Epoch 527/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8909 - accuracy: 0.3232 - val_loss: 2.8272 - val_accuracy: 0.3528\n",
      "Epoch 528/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8910 - accuracy: 0.3234 - val_loss: 2.8269 - val_accuracy: 0.3525\n",
      "Epoch 529/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8915 - accuracy: 0.3230 - val_loss: 2.8271 - val_accuracy: 0.3511\n",
      "Epoch 530/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8909 - accuracy: 0.3229 - val_loss: 2.8276 - val_accuracy: 0.3507\n",
      "Epoch 531/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8882 - accuracy: 0.3238 - val_loss: 2.8278 - val_accuracy: 0.3501\n",
      "Epoch 532/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8900 - accuracy: 0.3229 - val_loss: 2.8275 - val_accuracy: 0.3504\n",
      "Epoch 533/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8927 - accuracy: 0.3232 - val_loss: 2.8271 - val_accuracy: 0.3512\n",
      "Epoch 534/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8886 - accuracy: 0.3241 - val_loss: 2.8270 - val_accuracy: 0.3521\n",
      "Epoch 535/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8881 - accuracy: 0.3241 - val_loss: 2.8267 - val_accuracy: 0.3531\n",
      "Epoch 536/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8903 - accuracy: 0.3239 - val_loss: 2.8271 - val_accuracy: 0.3524\n",
      "Epoch 537/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8903 - accuracy: 0.3228 - val_loss: 2.8280 - val_accuracy: 0.3513\n",
      "Epoch 538/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8878 - accuracy: 0.3245 - val_loss: 2.8284 - val_accuracy: 0.3518\n",
      "Epoch 539/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8910 - accuracy: 0.3233 - val_loss: 2.8274 - val_accuracy: 0.3514\n",
      "Epoch 540/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8899 - accuracy: 0.3231 - val_loss: 2.8275 - val_accuracy: 0.3500\n",
      "Epoch 541/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8889 - accuracy: 0.3240 - val_loss: 2.8282 - val_accuracy: 0.3504\n",
      "Epoch 542/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8892 - accuracy: 0.3239 - val_loss: 2.8286 - val_accuracy: 0.3516\n",
      "Epoch 543/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8896 - accuracy: 0.3240 - val_loss: 2.8275 - val_accuracy: 0.3525\n",
      "Epoch 544/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8904 - accuracy: 0.3236 - val_loss: 2.8265 - val_accuracy: 0.3519\n",
      "Epoch 545/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8898 - accuracy: 0.3249 - val_loss: 2.8267 - val_accuracy: 0.3528\n",
      "Epoch 546/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8877 - accuracy: 0.3238 - val_loss: 2.8276 - val_accuracy: 0.3508\n",
      "Epoch 547/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8898 - accuracy: 0.3234 - val_loss: 2.8278 - val_accuracy: 0.3510\n",
      "Epoch 548/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8904 - accuracy: 0.3235 - val_loss: 2.8268 - val_accuracy: 0.3496\n",
      "Epoch 549/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8879 - accuracy: 0.3238 - val_loss: 2.8263 - val_accuracy: 0.3501\n",
      "Epoch 550/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8900 - accuracy: 0.3238 - val_loss: 2.8264 - val_accuracy: 0.3496\n",
      "Epoch 551/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8885 - accuracy: 0.3240 - val_loss: 2.8262 - val_accuracy: 0.3491\n",
      "Epoch 552/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8909 - accuracy: 0.3223 - val_loss: 2.8267 - val_accuracy: 0.3500\n",
      "Epoch 553/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8894 - accuracy: 0.3232 - val_loss: 2.8270 - val_accuracy: 0.3499\n",
      "Epoch 554/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8884 - accuracy: 0.3240 - val_loss: 2.8267 - val_accuracy: 0.3505\n",
      "Epoch 555/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8866 - accuracy: 0.3239 - val_loss: 2.8268 - val_accuracy: 0.3515\n",
      "Epoch 556/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8899 - accuracy: 0.3233 - val_loss: 2.8267 - val_accuracy: 0.3505\n",
      "Epoch 557/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8858 - accuracy: 0.3245 - val_loss: 2.8269 - val_accuracy: 0.3508\n",
      "Epoch 558/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8871 - accuracy: 0.3247 - val_loss: 2.8271 - val_accuracy: 0.3507\n",
      "Epoch 559/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8877 - accuracy: 0.3245 - val_loss: 2.8266 - val_accuracy: 0.3513\n",
      "Epoch 560/240000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 20s 20s/step - loss: 2.8859 - accuracy: 0.3236 - val_loss: 2.8263 - val_accuracy: 0.3512\n",
      "Epoch 561/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8897 - accuracy: 0.3232 - val_loss: 2.8264 - val_accuracy: 0.3521\n",
      "Epoch 562/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8877 - accuracy: 0.3240 - val_loss: 2.8265 - val_accuracy: 0.3518\n",
      "Epoch 563/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8873 - accuracy: 0.3244 - val_loss: 2.8268 - val_accuracy: 0.3507\n",
      "Epoch 564/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8905 - accuracy: 0.3233 - val_loss: 2.8264 - val_accuracy: 0.3514\n",
      "Epoch 565/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8890 - accuracy: 0.3241 - val_loss: 2.8260 - val_accuracy: 0.3504\n",
      "Epoch 566/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8885 - accuracy: 0.3231 - val_loss: 2.8260 - val_accuracy: 0.3511\n",
      "Epoch 567/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8890 - accuracy: 0.3232 - val_loss: 2.8259 - val_accuracy: 0.3508\n",
      "Epoch 568/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8862 - accuracy: 0.3247 - val_loss: 2.8258 - val_accuracy: 0.3519\n",
      "Epoch 569/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8881 - accuracy: 0.3231 - val_loss: 2.8255 - val_accuracy: 0.3523\n",
      "Epoch 570/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8855 - accuracy: 0.3243 - val_loss: 2.8254 - val_accuracy: 0.3519\n",
      "Epoch 571/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8873 - accuracy: 0.3235 - val_loss: 2.8255 - val_accuracy: 0.3519\n",
      "Epoch 572/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8879 - accuracy: 0.3233 - val_loss: 2.8260 - val_accuracy: 0.3525\n",
      "Epoch 573/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8883 - accuracy: 0.3229 - val_loss: 2.8263 - val_accuracy: 0.3520\n",
      "Epoch 574/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8890 - accuracy: 0.3236 - val_loss: 2.8258 - val_accuracy: 0.3516\n",
      "Epoch 575/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8868 - accuracy: 0.3238 - val_loss: 2.8255 - val_accuracy: 0.3513\n",
      "Epoch 576/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8882 - accuracy: 0.3237 - val_loss: 2.8256 - val_accuracy: 0.3505\n",
      "Epoch 577/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8872 - accuracy: 0.3233 - val_loss: 2.8256 - val_accuracy: 0.3509\n",
      "Epoch 578/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8889 - accuracy: 0.3242 - val_loss: 2.8254 - val_accuracy: 0.3524\n",
      "Epoch 579/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8890 - accuracy: 0.3242 - val_loss: 2.8252 - val_accuracy: 0.3513\n",
      "Epoch 580/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8878 - accuracy: 0.3234 - val_loss: 2.8252 - val_accuracy: 0.3525\n",
      "Epoch 581/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8881 - accuracy: 0.3237 - val_loss: 2.8251 - val_accuracy: 0.3526\n",
      "Epoch 582/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8878 - accuracy: 0.3228 - val_loss: 2.8252 - val_accuracy: 0.3521\n",
      "Epoch 583/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8871 - accuracy: 0.3242 - val_loss: 2.8258 - val_accuracy: 0.3519\n",
      "Epoch 584/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8870 - accuracy: 0.3238 - val_loss: 2.8256 - val_accuracy: 0.3524\n",
      "Epoch 585/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8872 - accuracy: 0.3237 - val_loss: 2.8252 - val_accuracy: 0.3526\n",
      "Epoch 586/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8881 - accuracy: 0.3243 - val_loss: 2.8251 - val_accuracy: 0.3520\n",
      "Epoch 587/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8864 - accuracy: 0.3248 - val_loss: 2.8258 - val_accuracy: 0.3510\n",
      "Epoch 588/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8875 - accuracy: 0.3240 - val_loss: 2.8261 - val_accuracy: 0.3494\n",
      "Epoch 589/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8881 - accuracy: 0.3236 - val_loss: 2.8252 - val_accuracy: 0.3508\n",
      "Epoch 590/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8852 - accuracy: 0.3239 - val_loss: 2.8244 - val_accuracy: 0.3520\n",
      "Epoch 591/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8860 - accuracy: 0.3239 - val_loss: 2.8243 - val_accuracy: 0.3522\n",
      "Epoch 592/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8874 - accuracy: 0.3239 - val_loss: 2.8251 - val_accuracy: 0.3515\n",
      "Epoch 593/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8858 - accuracy: 0.3237 - val_loss: 2.8257 - val_accuracy: 0.3508\n",
      "Epoch 594/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8870 - accuracy: 0.3237 - val_loss: 2.8255 - val_accuracy: 0.3501\n",
      "Epoch 595/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8868 - accuracy: 0.3237 - val_loss: 2.8254 - val_accuracy: 0.3508\n",
      "Epoch 596/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8871 - accuracy: 0.3236 - val_loss: 2.8256 - val_accuracy: 0.3515\n",
      "Epoch 597/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8859 - accuracy: 0.3243 - val_loss: 2.8258 - val_accuracy: 0.3524\n",
      "Epoch 598/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8865 - accuracy: 0.3244 - val_loss: 2.8255 - val_accuracy: 0.3518\n",
      "Epoch 599/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8888 - accuracy: 0.3236 - val_loss: 2.8249 - val_accuracy: 0.3525\n",
      "Epoch 600/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8838 - accuracy: 0.3248 - val_loss: 2.8247 - val_accuracy: 0.3516\n",
      "Epoch 601/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8876 - accuracy: 0.3240 - val_loss: 2.8244 - val_accuracy: 0.3520\n",
      "Epoch 602/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8888 - accuracy: 0.3234 - val_loss: 2.8248 - val_accuracy: 0.3505\n",
      "Epoch 603/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8873 - accuracy: 0.3244 - val_loss: 2.8249 - val_accuracy: 0.3501\n",
      "Epoch 604/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8859 - accuracy: 0.3241 - val_loss: 2.8246 - val_accuracy: 0.3490\n",
      "Epoch 605/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8846 - accuracy: 0.3249 - val_loss: 2.8242 - val_accuracy: 0.3508\n",
      "Epoch 606/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8855 - accuracy: 0.3242 - val_loss: 2.8244 - val_accuracy: 0.3520\n",
      "Epoch 607/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8858 - accuracy: 0.3241 - val_loss: 2.8248 - val_accuracy: 0.3520\n",
      "Epoch 608/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8855 - accuracy: 0.3239 - val_loss: 2.8247 - val_accuracy: 0.3517\n",
      "Epoch 609/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8857 - accuracy: 0.3232 - val_loss: 2.8241 - val_accuracy: 0.3528\n",
      "Epoch 610/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8857 - accuracy: 0.3238 - val_loss: 2.8241 - val_accuracy: 0.3539\n",
      "Epoch 611/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8837 - accuracy: 0.3253 - val_loss: 2.8243 - val_accuracy: 0.3533\n",
      "Epoch 612/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8869 - accuracy: 0.3236 - val_loss: 2.8250 - val_accuracy: 0.3520\n",
      "Epoch 613/240000\n",
      "1/1 [==============================] - 41s 41s/step - loss: 2.8876 - accuracy: 0.3235 - val_loss: 2.8252 - val_accuracy: 0.3520\n",
      "Epoch 614/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8862 - accuracy: 0.3237 - val_loss: 2.8247 - val_accuracy: 0.3522\n",
      "Epoch 615/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8868 - accuracy: 0.3241 - val_loss: 2.8242 - val_accuracy: 0.3516\n",
      "Epoch 616/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8859 - accuracy: 0.3239 - val_loss: 2.8242 - val_accuracy: 0.3512\n",
      "Epoch 617/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8877 - accuracy: 0.3245 - val_loss: 2.8248 - val_accuracy: 0.3520\n",
      "Epoch 618/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8860 - accuracy: 0.3247 - val_loss: 2.8256 - val_accuracy: 0.3522\n",
      "Epoch 619/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8838 - accuracy: 0.3247 - val_loss: 2.8259 - val_accuracy: 0.3533\n",
      "Epoch 620/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8845 - accuracy: 0.3245 - val_loss: 2.8251 - val_accuracy: 0.3523\n",
      "Epoch 621/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8847 - accuracy: 0.3245 - val_loss: 2.8241 - val_accuracy: 0.3520\n",
      "Epoch 622/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8826 - accuracy: 0.3254 - val_loss: 2.8239 - val_accuracy: 0.3521\n",
      "Epoch 623/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8837 - accuracy: 0.3241 - val_loss: 2.8242 - val_accuracy: 0.3516\n",
      "Epoch 624/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8856 - accuracy: 0.3242 - val_loss: 2.8248 - val_accuracy: 0.3522\n",
      "Epoch 625/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8850 - accuracy: 0.3238 - val_loss: 2.8248 - val_accuracy: 0.3522\n",
      "Epoch 626/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8832 - accuracy: 0.3248 - val_loss: 2.8244 - val_accuracy: 0.3518\n",
      "Epoch 627/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8866 - accuracy: 0.3240 - val_loss: 2.8243 - val_accuracy: 0.3525\n",
      "Epoch 628/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8871 - accuracy: 0.3241 - val_loss: 2.8243 - val_accuracy: 0.3520\n",
      "Epoch 629/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8869 - accuracy: 0.3233 - val_loss: 2.8244 - val_accuracy: 0.3512\n",
      "Epoch 630/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8868 - accuracy: 0.3245 - val_loss: 2.8242 - val_accuracy: 0.3505\n",
      "Epoch 631/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8838 - accuracy: 0.3245 - val_loss: 2.8241 - val_accuracy: 0.3521\n",
      "Epoch 632/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8833 - accuracy: 0.3247 - val_loss: 2.8247 - val_accuracy: 0.3510\n",
      "Epoch 633/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8830 - accuracy: 0.3242 - val_loss: 2.8248 - val_accuracy: 0.3520\n",
      "Epoch 634/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8830 - accuracy: 0.3243 - val_loss: 2.8242 - val_accuracy: 0.3518\n",
      "Epoch 635/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8864 - accuracy: 0.3238 - val_loss: 2.8237 - val_accuracy: 0.3522\n",
      "Epoch 636/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8865 - accuracy: 0.3249 - val_loss: 2.8236 - val_accuracy: 0.3502\n",
      "Epoch 637/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8843 - accuracy: 0.3245 - val_loss: 2.8240 - val_accuracy: 0.3518\n",
      "Epoch 638/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8841 - accuracy: 0.3244 - val_loss: 2.8244 - val_accuracy: 0.3511\n",
      "Epoch 639/240000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.8835 - accuracy: 0.3241 - val_loss: 2.8245 - val_accuracy: 0.3510\n",
      "Epoch 640/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8864 - accuracy: 0.3235 - val_loss: 2.8242 - val_accuracy: 0.3513\n",
      "Epoch 641/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8850 - accuracy: 0.3242 - val_loss: 2.8239 - val_accuracy: 0.3513\n",
      "Epoch 642/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8847 - accuracy: 0.3240 - val_loss: 2.8238 - val_accuracy: 0.3508\n",
      "Epoch 643/240000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.8863 - accuracy: 0.3236 - val_loss: 2.8240 - val_accuracy: 0.3518\n",
      "Epoch 644/240000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-30b6d982eb0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m clf.fit(\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_idxs = np.arange(train_na_shape)\n",
    "val_idxs = np.arange(train_na_shape, train_na_shape + val_na_shape)\n",
    "test_idxs = np.arange(train_na_shape + val_na_shape, train_na_shape + val_na_shape + test_na_shape)\n",
    "\n",
    "gcn_generator = sg.mapper.RelationalFullBatchNodeGenerator(multilayer_graph, weighted=True)\n",
    "\n",
    "lr = ExponentialDecay(\n",
    "        0.1,\n",
    "        decay_steps=50,\n",
    "        decay_rate=0.8,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "clf = create_rgcn_model(\n",
    "    Adam(learning_rate=lr),\n",
    "    total_regions,\n",
    "    gcn_generator\n",
    ")\n",
    "\n",
    "X_train, y_train = gcn_generator.flow(train_idxs, train_regions_enc)[0]\n",
    "X_val, y_val = gcn_generator.flow(val_idxs, val_regions_enc)[0]\n",
    "\n",
    "X_test = gcn_generator.flow(test_idxs)\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=30, min_delta=0.0001, restore_best_weights=True),\n",
    "    ],\n",
    "    epochs=240000,\n",
    "    shuffle=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "failing-pixel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../../../../unT/ffunes/tmp_saves/rgcn_kd_twitter_us/assets\n"
     ]
    }
   ],
   "source": [
    "clf.save(tmp_save + 'rgcn_kd_twitter_us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "naked-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "transparent-seattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3475        \n",
      "Acc@161: 0.6696        \n",
      "Balanced Acc: 0.3464065875169393        \n",
      "ROC AUC Ovo: 0.9498181992421548        \n",
      "Mean Dist Err: 384.040675218766        \n",
      "Median Dist Err: 57.233993176535144\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_regions_enc, preds, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "opening-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_sage_tmp_save = [\n",
    "#    train_na_shape, val_na_shape, test_na_shape, colmentions_graph,\n",
    "#    train_regions_enc, val_regions_enc, test_regions_enc,\n",
    "#    places_with_coords, users_coords_test, encoder\n",
    "#]\n",
    "\n",
    "#with open(tmp_save + 'graph_sage_tmp_save.pickle', 'wb') as handle:\n",
    "#    pickle.dump(graph_sage_tmp_save, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "decreased-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'graph_sage_tmp_save.pickle', 'rb') as handle:\n",
    "    train_na_shape, val_na_shape, test_na_shape, colmentions_graph,\\\n",
    "    train_regions_enc, val_regions_enc, test_regions_enc,\\\n",
    "    places_with_coords, users_coords_test, encoder = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "identified-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graphsage_model(optimizer, num_classes, generator):\n",
    "    clear_session()\n",
    "    \n",
    "    graphsage_model = sg.layer.GraphSAGE(\n",
    "        layer_sizes=[64, 32],\n",
    "        activations=[\"relu\", \"relu\"],\n",
    "        generator=generator,\n",
    "        bias=True,\n",
    "        dropout=0.2,\n",
    "        aggregator=sg.layer.MeanAggregator,#sg.layer.AttentionalAggregator,\n",
    "        normalize=\"l2\",\n",
    "        #kernel_regularizer=tf.keras.regularizers.l2(0.2)\n",
    "    )\n",
    "    \n",
    "    x_inp, x_out = graphsage_model.in_out_tensors()\n",
    "    \n",
    "    x_out = Dense(units=num_classes, activation=\"softmax\")(x_out)\n",
    "    \n",
    "    model = Model(inputs=x_inp, outputs=x_out)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "answering-grocery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 28.6 GiB for an array with shape (15000000, 256) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-480de243e0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_regions_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_regions_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/stellargraph/mapper/sequences.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, batch_num)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Get features for nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mbatch_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/stellargraph/mapper/sampled_node_generators.py\u001b[0m in \u001b[0;36msample_features\u001b[0;34m(self, head_nodes, batch_num)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# Get features for sampled nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         batch_feats = [\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ilocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer_nodes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_per_hop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/stellargraph/mapper/sampled_node_generators.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# Get features for sampled nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         batch_feats = [\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ilocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer_nodes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_per_hop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         ]\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/stellargraph/core/graph.py\u001b[0m in \u001b[0;36mnode_features\u001b[0;34m(self, nodes, node_type, use_ilocs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrequested\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \"\"\"\n\u001b[0;32m-> 1258\u001b[0;31m         return extract_element_features(\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_node_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"node\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ilocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         )\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/stellargraph/core/graph.py\u001b[0m in \u001b[0;36mextract_element_features\u001b[0;34m(element_data, unique, name, ids, type, use_ilocs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0msampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ilocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 28.6 GiB for an array with shape (15000000, 256) and data type float64"
     ]
    }
   ],
   "source": [
    "train_idxs = np.arange(train_na_shape)\n",
    "val_idxs = np.arange(train_na_shape, train_na_shape + val_na_shape)\n",
    "test_idxs = np.arange(train_na_shape + val_na_shape, train_na_shape + val_na_shape + test_na_shape)\n",
    "\n",
    "gcn_generator = sg.mapper.GraphSAGENodeGenerator(colmentions_graph, 300000, [10, 5], weighted=True)\n",
    "\n",
    "lr = ExponentialDecay(\n",
    "        0.001,\n",
    "        decay_steps=10,\n",
    "        decay_rate=0.5,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "clf = create_graphsage_model(\n",
    "    \"adam\",#Adam(learning_rate=lr),\n",
    "    256,\n",
    "    gcn_generator\n",
    ")\n",
    "\n",
    "X_train, y_train = gcn_generator.flow(train_idxs, train_regions_enc, shuffle=True)[0]\n",
    "X_val, y_val = gcn_generator.flow(val_idxs, val_regions_enc)[0]\n",
    "\n",
    "X_test = gcn_generator.flow(test_idxs)\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=30, min_delta=0.0001, restore_best_weights=True),\n",
    "    ],\n",
    "    epochs=600000,\n",
    "    shuffle=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "worldwide-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "available-programmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2831        \n",
      "Acc@161: 0.6084        \n",
      "Balanced Acc: 0.28277668036743553        \n",
      "ROC AUC Ovo: 0.9339401753738049        \n",
      "Mean Dist Err: 452.9050297290141        \n",
      "Median Dist Err: 81.68434789956949\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_regions_enc, preds, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "liked-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3075        \n",
      "Acc@161: 0.6316        \n",
      "Balanced Acc: 0.3077790092605436        \n",
      "ROC AUC Ovo: 0.9399307298083368        \n",
      "Mean Dist Err: 424.3100382227857        \n",
      "Median Dist Err: 70.17875064308582\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_regions_enc, preds, encoder.classes_, places_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "connected-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na_shape = 429652\n",
    "test_na_shape = 10000\n",
    "val_na_shape = 9998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "internal-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cities_rgcn = encoder_city.transform(train_cities[np.argsort(train_na_cities[\"index\"].to_numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "loved-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cities = len(np.unique(train_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-portable",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0435 - accuracy: 0.3633"
     ]
    }
   ],
   "source": [
    "train_idxs = train_na_cities[\"index\"].to_numpy()#np.arange(train_na_shape)\n",
    "val_idxs = np.arange(train_na_shape, train_na_shape + val_na_shape)\n",
    "test_idxs = np.arange(train_na_shape + val_na_shape, train_na_shape + val_na_shape + test_na_shape)\n",
    "\n",
    "gcn_generator = sg.mapper.RelationalFullBatchNodeGenerator(multilayer_graph_city, weighted=True)\n",
    "\n",
    "lr = ExponentialDecay(\n",
    "        0.1,\n",
    "        decay_steps=50,\n",
    "        decay_rate=0.8,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "'''clf = create_rgcn_model(\n",
    "    Adam(learning_rate=lr),\n",
    "    t_cities,\n",
    "    gcn_generator\n",
    ")'''\n",
    "\n",
    "X_train, y_train = gcn_generator.flow(train_idxs, train_cities_enc)[0]\n",
    "X_val, y_val = gcn_generator.flow(val_idxs, val_cities_enc)[0]\n",
    "\n",
    "X_test = gcn_generator.flow(test_idxs)\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=30, min_delta=0.0001, restore_best_weights=True),\n",
    "    ],\n",
    "    epochs=500,\n",
    "    shuffle=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "existing-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../../../../unT/ffunes/tmp_saves/rgcn_city_twitter_us/assets\n"
     ]
    }
   ],
   "source": [
    "clf.save(tmp_save + 'rgcn_city_twitter_us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "blessed-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "general-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4006        \n",
      "Acc@161: 0.6664        \n",
      "Balanced Acc: 0.25238152894021193        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 408.70556651908726        \n",
      "Median Dist Err: 43.262819544147234\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_cities_enc, preds, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "secondary-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_sage_tmp_save = [\n",
    "#    train_na_cities[\"index\"].to_numpy(), train_na_shape, val_na_shape, test_na_shape,\n",
    "#    colmentions_graph_city,\n",
    "#    train_cities_enc, val_cities_enc, test_cities_enc,\n",
    "#    cities_with_coords, users_coords_test, encoder_city\n",
    "#]\n",
    "\n",
    "#with open(tmp_save + 'graph_sage_tmp_save_city.pickle', 'wb') as handle:\n",
    "#    pickle.dump(graph_sage_tmp_save, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "heard-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'graph_sage_tmp_save_city.pickle', 'rb') as handle:\n",
    "    train_na_idxs, train_na_shape, val_na_shape, test_na_shape, colmentions_graph_city,\\\n",
    "    train_cities_enc, val_cities_enc, test_cities_enc,\\\n",
    "    cities_with_coords, users_coords_test, encoder_city = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "natural-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cities_enc = train_cities_enc.astype(np.uint8)\n",
    "val_cities_enc = val_cities_enc.astype(np.uint8)\n",
    "test_cities_enc = test_cities_enc.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mysterious-airline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240000\n",
      "2188/2188 [==============================] - 11s 5ms/step - loss: 4.7910 - accuracy: 0.1486 - val_loss: 4.1383 - val_accuracy: 0.2166\n",
      "Epoch 2/240000\n",
      "2188/2188 [==============================] - 12s 5ms/step - loss: 3.8101 - accuracy: 0.2575 - val_loss: 3.5761 - val_accuracy: 0.2806\n",
      "Epoch 3/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 3.4124 - accuracy: 0.2999 - val_loss: 3.3252 - val_accuracy: 0.3109\n",
      "Epoch 4/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 3.2136 - accuracy: 0.3230 - val_loss: 3.1941 - val_accuracy: 0.3285\n",
      "Epoch 5/240000\n",
      "2188/2188 [==============================] - 14s 6ms/step - loss: 3.0968 - accuracy: 0.3393 - val_loss: 3.1168 - val_accuracy: 0.3428\n",
      "Epoch 6/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 3.0156 - accuracy: 0.3498 - val_loss: 3.0686 - val_accuracy: 0.3520\n",
      "Epoch 7/240000\n",
      "2188/2188 [==============================] - 12s 6ms/step - loss: 2.9579 - accuracy: 0.3590 - val_loss: 3.0362 - val_accuracy: 0.3577\n",
      "Epoch 8/240000\n",
      "2188/2188 [==============================] - 13s 6ms/step - loss: 2.9157 - accuracy: 0.3649 - val_loss: 3.0115 - val_accuracy: 0.3617\n",
      "Epoch 9/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 2.8794 - accuracy: 0.3719 - val_loss: 2.9952 - val_accuracy: 0.3679\n",
      "Epoch 10/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.8506 - accuracy: 0.3763 - val_loss: 2.9822 - val_accuracy: 0.3728\n",
      "Epoch 11/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.8222 - accuracy: 0.3817 - val_loss: 2.9758 - val_accuracy: 0.3766\n",
      "Epoch 12/240000\n",
      "2188/2188 [==============================] - 12s 5ms/step - loss: 2.8000 - accuracy: 0.3859 - val_loss: 2.9689 - val_accuracy: 0.3803\n",
      "Epoch 13/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 2.7840 - accuracy: 0.3876 - val_loss: 2.9673 - val_accuracy: 0.3797\n",
      "Epoch 14/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.7651 - accuracy: 0.3897 - val_loss: 2.9615 - val_accuracy: 0.3829\n",
      "Epoch 15/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.7490 - accuracy: 0.3925 - val_loss: 2.9616 - val_accuracy: 0.3821\n",
      "Epoch 16/240000\n",
      "2188/2188 [==============================] - 11s 5ms/step - loss: 2.7348 - accuracy: 0.3940 - val_loss: 2.9627 - val_accuracy: 0.3851\n",
      "Epoch 17/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 2.7211 - accuracy: 0.3951 - val_loss: 2.9634 - val_accuracy: 0.3846\n",
      "Epoch 18/240000\n",
      "2188/2188 [==============================] - 10s 5ms/step - loss: 2.7101 - accuracy: 0.3974 - val_loss: 2.9645 - val_accuracy: 0.3854\n",
      "Epoch 19/240000\n",
      "2188/2188 [==============================] - 12s 6ms/step - loss: 2.6944 - accuracy: 0.4003 - val_loss: 2.9677 - val_accuracy: 0.3856\n",
      "Epoch 20/240000\n",
      "2188/2188 [==============================] - 12s 6ms/step - loss: 2.6838 - accuracy: 0.4015 - val_loss: 2.9660 - val_accuracy: 0.3874\n",
      "Epoch 21/240000\n",
      "2188/2188 [==============================] - 13s 6ms/step - loss: 2.6751 - accuracy: 0.4022 - val_loss: 2.9693 - val_accuracy: 0.3853\n",
      "Epoch 22/240000\n",
      "2188/2188 [==============================] - 10s 5ms/step - loss: 2.6666 - accuracy: 0.4032 - val_loss: 2.9700 - val_accuracy: 0.3880\n",
      "Epoch 23/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.6574 - accuracy: 0.4044 - val_loss: 2.9731 - val_accuracy: 0.3857\n",
      "Epoch 24/240000\n",
      "2188/2188 [==============================] - 14s 6ms/step - loss: 2.6522 - accuracy: 0.4047 - val_loss: 2.9755 - val_accuracy: 0.3854\n",
      "Epoch 25/240000\n",
      "2188/2188 [==============================] - 14s 6ms/step - loss: 2.6409 - accuracy: 0.4062 - val_loss: 2.9762 - val_accuracy: 0.3863\n",
      "Epoch 26/240000\n",
      "2188/2188 [==============================] - 12s 5ms/step - loss: 2.6344 - accuracy: 0.4062 - val_loss: 2.9824 - val_accuracy: 0.3860\n",
      "Epoch 27/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 2.6252 - accuracy: 0.4074 - val_loss: 2.9812 - val_accuracy: 0.3868\n",
      "Epoch 28/240000\n",
      "2188/2188 [==============================] - 14s 6ms/step - loss: 2.6184 - accuracy: 0.4089 - val_loss: 2.9839 - val_accuracy: 0.3853\n",
      "Epoch 29/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.6111 - accuracy: 0.4092 - val_loss: 2.9889 - val_accuracy: 0.3836\n",
      "Epoch 30/240000\n",
      "2188/2188 [==============================] - 11s 5ms/step - loss: 2.6048 - accuracy: 0.4106 - val_loss: 2.9919 - val_accuracy: 0.3848\n",
      "Epoch 31/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 2.6000 - accuracy: 0.4098 - val_loss: 2.9927 - val_accuracy: 0.3838\n",
      "Epoch 32/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.5927 - accuracy: 0.4118 - val_loss: 2.9980 - val_accuracy: 0.3832\n",
      "Epoch 33/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.5863 - accuracy: 0.4112 - val_loss: 2.9990 - val_accuracy: 0.3828\n",
      "Epoch 34/240000\n",
      "2188/2188 [==============================] - 13s 6ms/step - loss: 2.5787 - accuracy: 0.4137 - val_loss: 3.0013 - val_accuracy: 0.3835\n",
      "Epoch 35/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 2.5719 - accuracy: 0.4128 - val_loss: 3.0070 - val_accuracy: 0.3833\n",
      "Epoch 36/240000\n",
      "2188/2188 [==============================] - 14s 6ms/step - loss: 2.5678 - accuracy: 0.4144 - val_loss: 3.0107 - val_accuracy: 0.3812\n",
      "Epoch 37/240000\n",
      "2188/2188 [==============================] - 14s 7ms/step - loss: 2.5601 - accuracy: 0.4153 - val_loss: 3.0123 - val_accuracy: 0.3828\n",
      "Epoch 38/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.5573 - accuracy: 0.4155 - val_loss: 3.0131 - val_accuracy: 0.3818\n",
      "Epoch 39/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.5528 - accuracy: 0.4162 - val_loss: 3.0171 - val_accuracy: 0.3812\n",
      "Epoch 40/240000\n",
      "2188/2188 [==============================] - 15s 7ms/step - loss: 2.5474 - accuracy: 0.4172 - val_loss: 3.0209 - val_accuracy: 0.3803\n",
      "Epoch 41/240000\n",
      "2188/2188 [==============================] - 11s 5ms/step - loss: 2.5415 - accuracy: 0.4179 - val_loss: 3.0254 - val_accuracy: 0.3798\n",
      "Epoch 42/240000\n",
      "2188/2188 [==============================] - 14s 6ms/step - loss: 2.5371 - accuracy: 0.4184 - val_loss: 3.0290 - val_accuracy: 0.3799\n",
      "Epoch 43/240000\n",
      "2188/2188 [==============================] - 11s 5ms/step - loss: 2.5349 - accuracy: 0.4187 - val_loss: 3.0313 - val_accuracy: 0.3795\n",
      "Epoch 44/240000\n",
      "2188/2188 [==============================] - 13s 6ms/step - loss: 2.5264 - accuracy: 0.4190 - val_loss: 3.0345 - val_accuracy: 0.3803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f691f761d60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs = train_na_idxs\n",
    "val_idxs = np.arange(train_na_shape, train_na_shape + val_na_shape)\n",
    "test_idxs = np.arange(train_na_shape + val_na_shape, train_na_shape + val_na_shape + test_na_shape)\n",
    "\n",
    "gcn_generator = sg.mapper.GraphSAGENodeGenerator(colmentions_graph_city_lowres, 70000, [100], weighted=True)\n",
    "\n",
    "lr = ExponentialDecay(\n",
    "        0.001,\n",
    "        decay_steps=10,\n",
    "        decay_rate=0.5,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "clf = create_graphsage_model(\n",
    "    \"adam\",#Adam(learning_rate=lr),\n",
    "    len(encoder_city.classes_),\n",
    "    gcn_generator\n",
    ")\n",
    "\n",
    "X_train, y_train = gcn_generator.flow(train_idxs, train_cities_enc, shuffle=True)[0]\n",
    "X_val, y_val = gcn_generator.flow(val_idxs, val_cities_enc)[0]\n",
    "\n",
    "X_test = gcn_generator.flow(test_idxs)\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=30, min_delta=0.0001, restore_best_weights=True),\n",
    "    ],\n",
    "    epochs=240000,\n",
    "    shuffle=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prompt-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dominant-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3791        \n",
      "Acc@161: 0.6427        \n",
      "Balanced Acc: 0.2386812239101053        \n",
      "ROC AUC Ovo: NaN        \n",
      "Mean Dist Err: 432.05112370525273        \n",
      "Median Dist Err: 50.25373095404822\n"
     ]
    }
   ],
   "source": [
    "print(get_all_metrics(test_cities_enc, preds, encoder_city.classes_, cities_with_coords, users_coords_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-luxembourg",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "known-customs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<10000x17728 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 10309 stored elements in Compressed Sparse Row format>,\n",
       " <10000x3862 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 11371 stored elements in Compressed Sparse Row format>,\n",
       " <10000x2013 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 11381 stored elements in Compressed Sparse Row format>,\n",
       " <10000x1553 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 14746 stored elements in Compressed Sparse Row format>,\n",
       " <10000x1071 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 8662 stored elements in Compressed Sparse Row format>,\n",
       " <10000x1065 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 8644 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_of_clusters_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "split-quest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 3801899\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "word_index = tokenizer.word_index\n",
    "print('Tokens unicos %s' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "numerous-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nlp = tokenizer.texts_to_sequences(train_tweets)\n",
    "input_nlp = pad_sequences(input_nlp, maxlen=sequence_length, truncating='post', padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "disciplinary-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nlp_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "input_nlp_val = pad_sequences(input_nlp_val, maxlen=sequence_length, truncating='post', padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "medieval-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nlp_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "input_nlp_test = pad_sequences(input_nlp_test, maxlen=sequence_length, truncating='post', padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-crossing",
   "metadata": {},
   "source": [
    "# Twitter-US Complete model keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "removable-louisiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 256, 64)      640000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 256, 64)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          66000       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 14942)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 15042)        0           lstm[0][0]                       \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          1925504     concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,631,504\n",
      "Trainable params: 2,631,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#optimizer = Adam(learning_rate=0.005)#0.001)\n",
    "model = create_complete_model(\n",
    "    optimizer=\"adam\",\n",
    "    input_nlp_length=input_nlp.shape[1],\n",
    "    input_mentions_length=vector_of_clusters.shape[1]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "silver-video",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6714/6714 [==============================] - 1208s 180ms/step - loss: 2.1364 - accuracy: 0.4591 - val_loss: 2.7670 - val_accuracy: 0.3724\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(\n",
    "    [input_nlp, vector_of_clusters],\n",
    "    train_regions_enc,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    #validation_split=0.2,\n",
    "    validation_data=([input_nlp_val, vector_of_clusters_val], val_cities_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "danish-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x14942 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 9372 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_clusters_val = vectorizer_m.transform(test_na[\"clusters\"]).astype(np.float32)\n",
    "vector_of_clusters_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "protected-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([input_nlp_test, vector_of_clusters_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "threaded-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([encoder.classes_[x] for x in np.argmax(preds, axis=1)]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "billion-resistance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3673"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_cities.astype('int'), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bridal-juvenile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_161km(test_cities.astype('int'), a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-lawyer",
   "metadata": {},
   "source": [
    "# Model with keras and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "computational-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<429652x4000 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 78238479 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizer_w = CountVectorizer(\n",
    "#    strip_accents=\"ascii\",\n",
    "#    lowercase=True,\n",
    "    #min_df=10,\n",
    "    #max_df=0.05,\n",
    "#    max_features=4000\n",
    "    #vocabulary=total_users\n",
    "#)\n",
    "\n",
    "#vector_of_words = vectorizer_w.fit_transform(train_tweets).astype(np.uint8)\n",
    "#vector_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "chubby-ireland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 256, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12928     \n",
      "=================================================================\n",
      "Total params: 718,928\n",
      "Trainable params: 718,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nlp_model = create_nlp_model(\n",
    "    optimizer=\"adam\",\n",
    "    input_length=input_nlp.shape[1]\n",
    ")\n",
    "\n",
    "nlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "vietnamese-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6714/6714 [==============================] - 1190s 177ms/step - loss: 4.6239 - accuracy: 0.0272 - val_loss: 4.2926 - val_accuracy: 0.0518\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 64\n",
    "\n",
    "history = nlp_model.fit(\n",
    "    input_nlp,\n",
    "    train_cities_enc,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(input_nlp_val, val_cities_enc),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-blond",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "content_estimator = {\n",
    "    \"name\": \"Content\",\n",
    "    \"estimator\": KerasClassifier(\n",
    "        build_fn=create_nlp_model,\n",
    "        verbose=2,\n",
    "        callbacks=EarlyStopping(monitor='loss', patience=3, min_delta=0.0001),\n",
    "        optimizer=\"adam\",\n",
    "        epochs=30,\n",
    "        batch_size=64,\n",
    "        input_length=input_nlp.shape[1],\n",
    "    ),\n",
    "    \"params_grid\": {\n",
    "        \"optimizer\": [\"adam\"],\n",
    "        \"epochs\": [30],\n",
    "        \"batch_size\": [64],\n",
    "        \"input_length\": [input_nlp.shape[1]],\n",
    "    }\n",
    "}\n",
    "\n",
    "content_clf, content_preds = nested_cross_val_predict(\n",
    "    content_estimator[\"name\"],\n",
    "    content_estimator[\"estimator\"],\n",
    "    content_estimator[\"params_grid\"],\n",
    "    input_nlp,\n",
    "    train_cities_enc,\n",
    "    perform_scores=False,\n",
    "    Stratified=False,\n",
    "    inner_cv=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-pollution",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''mentions_estimator = {\n",
    "    \"name\": \"Mentions\",\n",
    "    \"estimator\": DecisionTreeClassifier(random_state=36),\n",
    "    \"params_grid\": {'max_depth': [8, 80, 200, 500, None], 'min_samples_leaf': [1], 'class_weight': ['balanced']}\n",
    "}'''\n",
    "\n",
    "mentions_estimator = {\n",
    "    \"name\": \"Mentions\",\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params_grid\": {\n",
    "        \"alpha\": [0.1, 0.5, 1.0, 2.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "mentions_clfs = []\n",
    "mentions_all_preds = []\n",
    "\n",
    "for clusters in vectors_of_clusters:\n",
    "    mentions_clf, mentions_preds = nested_cross_val_predict(\n",
    "        mentions_estimator[\"name\"],\n",
    "        mentions_estimator[\"estimator\"],\n",
    "        mentions_estimator[\"params_grid\"],\n",
    "        clusters,\n",
    "        train_cities,\n",
    "        scoringCV=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        scoringVAL={\n",
    "            'accuracy': 'accuracy',\n",
    "            'balanced_accuracy': 'balanced_accuracy',\n",
    "            'roc_auc_ovo_weighted': 'roc_auc_ovo_weighted',\n",
    "            'accuracy@161': make_scorer(accuracy_161km, greater_is_better=True)            \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    mentions_clfs.append(mentions_clf)\n",
    "    mentions_all_preds.append(mentions_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "entire-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds = content_preds\n",
    "\n",
    "for mentions_preds in mentions_all_preds:\n",
    "    total_preds = np.concatenate((total_preds, mentions_preds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "italian-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../tmp_paper/total_preds.pickle', 'wb') as handle:\n",
    " #   pickle.dump(total_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "advisory-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../tmp_paper/total_preds.pickle', 'rb') as handle:\n",
    "    total_preds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "appointed-drilling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    }
   ],
   "source": [
    "meta_estimator = {\n",
    "    \"name\": \"Meta classifier\",\n",
    "    #\"estimator\": SGDClassifier(early_stopping=True, class_weight=\"balanced\", random_state=35, n_jobs=3),\n",
    "    \"estimator\": LogisticRegression(class_weight=\"balanced\",random_state=35,n_jobs=-1),\n",
    "    \"params_grid\": {'C': [1.0], 'class_weight': ['balanced']}\n",
    "    #\"params_grid\": {'loss': ['hinge'], 'class_weight': ['balanced']}\n",
    "}\n",
    "\n",
    "meta_clf, meta_preds = nested_cross_val_predict(\n",
    "    meta_estimator[\"name\"],\n",
    "    meta_estimator[\"estimator\"],\n",
    "    meta_estimator[\"params_grid\"],\n",
    "    total_preds,\n",
    "    train_cities,\n",
    "    scoringCV=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    scoringVAL={\n",
    "        'accuracy': 'accuracy',\n",
    "        'balanced_accuracy': 'balanced_accuracy',\n",
    "        'roc_auc_ovo_weighted': 'roc_auc_ovo_weighted',\n",
    "        'accuracy@161': make_scorer(accuracy_161km, greater_is_better=True)            \n",
    "    },\n",
    "    probs=False,\n",
    "    perform_scores=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "rising-season",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 5s\n"
     ]
    }
   ],
   "source": [
    "total_test_probs = content_clf.predict_proba(input_nlp_test)\n",
    "\n",
    "for mentions_clf, clusters in zip(mentions_clfs, vectors_of_clusters_test):\n",
    "    mention_test_preds = mentions_clf.predict_proba(clusters)\n",
    "        \n",
    "    total_test_probs = np.concatenate((total_test_probs, mention_test_preds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "stainless-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../tmp_paper/total_test_preds.pickle', 'wb') as handle:\n",
    "#    pickle.dump(total_test_probs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "separated-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../tmp_paper/total_test_preds.pickle', 'rb') as handle:\n",
    "    total_test_probs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "gross-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_preds = meta_clf.predict(total_test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "patient-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3682"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_cities, test_final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "level-witch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5765"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_161km(test_cities, test_final_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-italian",
   "metadata": {},
   "source": [
    "Save for training transformer with cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "demographic-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 2991176\n",
      "Embedding dim recomendado:  41.58727764989378\n",
      "Tokens unicos 2977502\n",
      "Embedding dim recomendado:  41.53966745414833\n",
      "Tokens unicos 3005692\n",
      "Embedding dim recomendado:  41.6376412369621\n",
      "Tokens unicos 2986990\n",
      "Embedding dim recomendado:  41.57272018342885\n",
      "Tokens unicos 2978470\n",
      "Embedding dim recomendado:  41.5430432282707\n"
     ]
    }
   ],
   "source": [
    "encoder_t = LabelBinarizer()\n",
    "i = 0\n",
    "\n",
    "for fold in folds_cities:\n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "                \n",
    "    encoder_t.fit(y_train)\n",
    "                \n",
    "    y_train = encoder_t.transform(y_train)\n",
    "    y_test = encoder_t.transform(y_test)                    \n",
    "                \n",
    "    fold = Fold(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = fold.unpack(val_split=0.1)\n",
    "    \n",
    "    train_tweets = X_train[\"all_tweets\"].to_numpy()\n",
    "    val_tweets = X_val[\"all_tweets\"].to_numpy()\n",
    "    test_tweets = X_test[\"all_tweets\"].to_numpy()\n",
    "    \n",
    "    max_features = 50000\n",
    "    sequence_length = 512\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(train_tweets)\n",
    "    \n",
    "    print('Tokens unicos %s' % len(tokenizer.word_index))\n",
    "    print('Embedding dim recomendado: ', len(tokenizer.word_index)**(1/4))\n",
    "    \n",
    "    X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "    X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "    X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "    X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "    X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "    X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "    to_save = [X_train, encoder_t.inverse_transform(y_train), X_val, encoder_t.inverse_transform(y_val), X_test]\n",
    "    \n",
    "    with open(tmp_save + 'fold_' + str(i) + '_city_twitter_us.pickle', 'wb') as handle:\n",
    "        pickle.dump(to_save, handle, protocol=4)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "with open(tmp_save + 'encoder_t_city_twitter_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(encoder_t, handle, protocol=4)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "middle-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'test_cities_idxs_twitter_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_cities_idxs, handle, protocol=4)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-diploma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "boolean-attachment",
   "metadata": {},
   "source": [
    "Cargamos cada fold para entrenar externamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mysterious-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "relative-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "1193514 words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove_100d = load_glove_model(tmp_save + 'glove_100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "academic-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1505.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_na[\"all_tweets\"].apply(len).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_split(row):\n",
    "    return row[\"all_tweets\"].split('|||')[:100]\n",
    "\n",
    "twitter_na_txt = twitter_na.loc[:, [\"username\", \"latitude\", \"longitude\", \"all_tweets\", \"class\", \"closest_city\"]]\n",
    "twitter_na_txt[\"all_tweets\"] = twitter_na_txt.apply(tweets_split, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "governmental-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 62\n",
    "glove_dim = 100\n",
    "\n",
    "train_na_tweets = train_na.loc[:, [\"username\", \"class\", \"all_tweets\"]]\n",
    "val_na_tweets = val_na.loc[:, [\"username\", \"class\", \"all_tweets\"]]\n",
    "test_na_tweets = test_na.loc[:, [\"username\", \"class\", \"all_tweets\"]]\n",
    "\n",
    "train_na_tweets[\"all_tweets\"] = train_na_tweets.apply(tweets_split, axis=1)\n",
    "train_na_tweets = train_na_tweets.explode(\"all_tweets\")\n",
    "\n",
    "val_na_tweets[\"all_tweets\"] = val_na_tweets.apply(tweets_split, axis=1)\n",
    "val_na_tweets = val_na_tweets.explode(\"all_tweets\")\n",
    "\n",
    "test_na_tweets[\"all_tweets\"] = test_na_tweets.apply(tweets_split, axis=1)\n",
    "test_na_tweets = test_na_tweets.explode(\"all_tweets\")\n",
    "\n",
    "train_tweets = train_na_tweets[\"all_tweets\"].to_numpy()\n",
    "val_tweets = val_na_tweets[\"all_tweets\"].to_numpy()\n",
    "test_tweets = test_na_tweets[\"all_tweets\"].to_numpy()\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    #strip_accents='unicode',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    max_df=0.7,\n",
    "    min_df=10,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "vectorizer.fit(train_tweets)\n",
    "    \n",
    "av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "embeddings = np.zeros((len(tokenizer.word_index) + 1, glove_dim))\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embeddings[idx] =  glove_100d[word]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dried-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'X_train_us_kd_text_fit2.pickle', 'wb') as handle:\n",
    "#    pickle.dump([X_train, train_na_tweets[[\"username\", \"class\"]]], handle, protocol=4)  \n",
    "    \n",
    "#with open(tmp_save + 'X_val_us_kd_text_fit2.pickle', 'wb') as handle:\n",
    "#    pickle.dump([X_val, val_na_tweets[[\"username\", \"class\"]]], handle, protocol=4) \n",
    "    \n",
    "#with open(tmp_save + 'X_test_us_kd_text_fit2.pickle', 'wb') as handle:\n",
    "#    pickle.dump([X_test, test_na_tweets[[\"username\", \"class\"]]], handle, protocol=4)  \n",
    "    \n",
    "#with open(tmp_save + 'embeddings_glove_kd_text_fit2.pickle', 'wb') as handle:\n",
    "#    pickle.dump(embeddings, handle, protocol=4)  \n",
    "    \n",
    "with open(tmp_save + 'encoder_kd_fit2.pickle', 'wb') as handle:\n",
    "    pickle.dump(encoder, handle, protocol=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "answering-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'X_train_us_kd_text_fit2.pickle', 'rb') as handle:\n",
    "    X_train, train_na_tweets = pickle.load(handle)  \n",
    "    \n",
    "with open(tmp_save + 'X_val_us_kd_text_fit2.pickle', 'rb') as handle:\n",
    "    X_val, val_na_tweets = pickle.load(handle)  \n",
    "    \n",
    "with open(tmp_save + 'X_test_us_kd_text_fit2.pickle', 'rb') as handle:\n",
    "    X_test, test_na_tweets = pickle.load(handle)  \n",
    "    \n",
    "with open(tmp_save + 'embeddings_glove_kd_text_fit2.pickle', 'rb') as handle:\n",
    "    embeddings = pickle.load(handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "severe-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    tmp_save + 'text_data_us',\n",
    "    X_train=X_train,\n",
    "    y_train=train_na_tweets.to_numpy()[:, 1].astype(int),\n",
    "    X_val=X_val,\n",
    "    y_val=val_na_tweets.to_numpy()[:, 1].astype(int),\n",
    "    X_test=X_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statistical-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(tmp_save + 'text_data_us.npz', allow_pickle=True)\n",
    "\n",
    "X_train = loaded[\"X_train\"]\n",
    "y_train = loaded[\"y_train\"]\n",
    "\n",
    "X_val = loaded[\"X_val\"]\n",
    "y_val = loaded[\"y_val\"]\n",
    "    \n",
    "X_test = loaded[\"X_test\"]\n",
    "y_test = loaded[\"y_test\"]\n",
    "    \n",
    "with open(tmp_save + 'embeddings_glove_kd_text_fit2.pickle', 'rb') as handle:\n",
    "    embeddings = pickle.load(handle)\n",
    "    \n",
    "with open(tmp_save + 'encoder_kd_fit2.pickle', 'rb') as handle:\n",
    "    encoder = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adapted-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "amber-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, weights):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, weights=[weights], trainable=True)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "domestic-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer_model(optimizer, num_classes, input_length, vocab_size, emb_dim, num_heads, ff_dim, weights):\n",
    "    inputs = layers.Input(shape=(input_length,))\n",
    "    \n",
    "    embedding_layer = TokenAndPositionEmbedding(input_length, vocab_size, emb_dim, weights)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(emb_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    #x = transformer_block(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    #x = layers.Dense(20, activation=\"relu\")(x)\n",
    "    #x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        #loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fiscal-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/utils/losses_utils.py:180 squeeze_or_expand_dimensions\n        y_true, y_pred = remove_squeezable_dimensions(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/utils/losses_utils.py:110 remove_squeezable_dimensions\n        labels = ops.convert_to_tensor_v2_with_dispatch(labels)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1430 convert_to_tensor_v2_with_dispatch\n        return convert_to_tensor_v2(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1436 convert_to_tensor_v2\n        return convert_to_tensor(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:551 make_tensor_proto\n        raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse:1\", shape=(None,), dtype=int64), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ea2168e98e8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m clf.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_na_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/utils/losses_utils.py:180 squeeze_or_expand_dimensions\n        y_true, y_pred = remove_squeezable_dimensions(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/keras/utils/losses_utils.py:110 remove_squeezable_dimensions\n        labels = ops.convert_to_tensor_v2_with_dispatch(labels)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1430 convert_to_tensor_v2_with_dispatch\n        return convert_to_tensor_v2(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1436 convert_to_tensor_v2\n        return convert_to_tensor(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:551 make_tensor_proto\n        raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse:1\", shape=(None,), dtype=int64), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 62\n",
    "    \n",
    "clf = create_transformer_model(\n",
    "    optimizer=\"adam\",#Adam(learning_rate=3e-4),\n",
    "    num_classes=total_regions,\n",
    "    input_length=sequence_length,\n",
    "    vocab_size=embeddings.shape[0],\n",
    "    emb_dim=100,\n",
    "    num_heads=10,\n",
    "    ff_dim=100,\n",
    "    weights=embeddings\n",
    ")\n",
    "    \n",
    "clf.fit(\n",
    "    X_train,\n",
    "    encoder.transform(train_na_tweets[\"class\"].to_numpy().astype(int)),\n",
    "    validation_data=(X_val, encoder.transform(val_na_tweets[\"class\"].to_numpy().astype(int))),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001, restore_best_weights=True)],\n",
    "    epochs=500,\n",
    "    batch_size=64        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-kenya",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "pursuant-portrait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 185493\n",
      "Embedding dim recomendado:  20.753047557164745\n",
      "Tokens unicos 183978\n",
      "Embedding dim recomendado:  20.710542415440084\n",
      "Tokens unicos 185255\n",
      "Embedding dim recomendado:  20.74638746270256\n",
      "Tokens unicos 184971\n",
      "Embedding dim recomendado:  20.738431720254386\n",
      "Tokens unicos 184812\n",
      "Embedding dim recomendado:  20.7339736239988\n"
     ]
    }
   ],
   "source": [
    "encoder_t = LabelBinarizer()\n",
    "i = 0\n",
    "\n",
    "for fold in folds_kd:\n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "                \n",
    "    encoder_t.fit(y_train)\n",
    "                \n",
    "    y_train = encoder_t.transform(y_train)\n",
    "    y_test = encoder_t.transform(y_test)                    \n",
    "                \n",
    "    fold = Fold(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = fold.unpack(val_split=0.1)\n",
    "    \n",
    "    train_tweets = X_train[\"all_tweets\"].to_numpy()\n",
    "    val_tweets = X_val[\"all_tweets\"].to_numpy()\n",
    "    test_tweets = X_test[\"all_tweets\"].to_numpy()\n",
    "    \n",
    "    sequence_length = 512\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        #strip_accents='unicode',\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        max_df=0.7,\n",
    "        min_df=10,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "\n",
    "    vectorizer.fit(train_tweets)\n",
    "\n",
    "    av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "    train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(train_tweets)\n",
    "    \n",
    "    print('Tokens unicos %s' % len(tokenizer.word_index))\n",
    "    print('Embedding dim recomendado: ', len(tokenizer.word_index)**(1/4))\n",
    "    \n",
    "    X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "    X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "    X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "    X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "    X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "    X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "    embeddings = np.zeros((len(tokenizer.word_index) + 1, glove_dim))\n",
    "\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embeddings[idx] =  glove_100d[word]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    to_save = [X_train, encoder_t.inverse_transform(y_train), X_val, encoder_t.inverse_transform(y_val), X_test, embeddings]\n",
    "    \n",
    "    with open(tmp_save + 'fold_' + str(i) + '_kd_twitter_us.pickle', 'wb') as handle:\n",
    "        pickle.dump(to_save, handle, protocol=4)\n",
    "    \n",
    "    with open(tmp_save + 'encoder_t_kd_' + str(i) '_twitter_us.pickle', 'wb') as handle:\n",
    "        pickle.dump(encoder_t, handle, protocol=4)          \n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "chemical-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 512\n",
    "glove_dim = 100\n",
    "    \n",
    "train_tweets = train_na_cities[\"all_tweets\"].to_numpy()\n",
    "val_tweets = val_na[\"all_tweets\"].to_numpy()\n",
    "test_tweets = test_na[\"all_tweets\"].to_numpy()\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    #strip_accents='unicode',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    max_df=0.7,\n",
    "    min_df=10,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "vectorizer.fit(train_tweets)\n",
    "    \n",
    "av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_tweets)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "embeddings = np.zeros((len(tokenizer.word_index) + 1, glove_dim))\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embeddings[idx] =  glove_100d[word]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "unavailable-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'X_train_us_city_text_fit.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_train, handle, protocol=4)  \n",
    "    \n",
    "with open(tmp_save + 'X_val_us_city_text_fit.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_val, handle, protocol=4) \n",
    "    \n",
    "with open(tmp_save + 'X_test_us_city_text_fit.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_test, handle, protocol=4)  \n",
    "    \n",
    "with open(tmp_save + 'embeddings_glove_city_text_fit.pickle', 'wb') as handle:\n",
    "    pickle.dump(embeddings, handle, protocol=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fluid-merchant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 184783\n",
      "Embedding dim recomendado:  20.73316020195354\n",
      "Tokens unicos 184416\n",
      "Embedding dim recomendado:  20.722857923676703\n",
      "Tokens unicos 185191\n",
      "Embedding dim recomendado:  20.744595418160884\n",
      "Tokens unicos 184879\n",
      "Embedding dim recomendado:  20.735852543408345\n",
      "Tokens unicos 184154\n",
      "Embedding dim recomendado:  20.71549375279081\n"
     ]
    }
   ],
   "source": [
    "encoder_t = LabelBinarizer()\n",
    "i = 0\n",
    "\n",
    "for fold in folds_cities:\n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "                \n",
    "    encoder_t.fit(y_train)\n",
    "                \n",
    "    y_train = encoder_t.transform(y_train)\n",
    "    y_test = encoder_t.transform(y_test)                    \n",
    "                \n",
    "    fold = Fold(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = fold.unpack(val_split=0.1)\n",
    "    \n",
    "    train_tweets = X_train[\"all_tweets\"].to_numpy()\n",
    "    val_tweets = X_val[\"all_tweets\"].to_numpy()\n",
    "    test_tweets = X_test[\"all_tweets\"].to_numpy()\n",
    "    \n",
    "    sequence_length = 512\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        #strip_accents='unicode',\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        max_df=0.7,\n",
    "        min_df=10,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "\n",
    "    vectorizer.fit(train_tweets)\n",
    "\n",
    "    av_words = set(vectorizer.get_feature_names())\n",
    "\n",
    "    train_tweets = np.array(list(map(lambda tweets: ' '.join([word for word in re.split(\"\\W+\", tweets) if word in av_words]), train_tweets)), dtype=object)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(train_tweets)\n",
    "    \n",
    "    print('Tokens unicos %s' % len(tokenizer.word_index))\n",
    "    print('Embedding dim recomendado: ', len(tokenizer.word_index)**(1/4))\n",
    "    \n",
    "    X_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "    X_train = pad_sequences(X_train, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "    \n",
    "    X_val = tokenizer.texts_to_sequences(val_tweets)\n",
    "    X_val = pad_sequences(X_val, maxlen=sequence_length, truncating='post', padding='pre')   \n",
    "    \n",
    "    X_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "    X_test = pad_sequences(X_test, maxlen=sequence_length, truncating='post', padding='pre')\n",
    "\n",
    "    embeddings = np.zeros((len(tokenizer.word_index) + 1, glove_dim))\n",
    "\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embeddings[idx] =  glove_100d[word]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    to_save = [X_train, encoder_t.inverse_transform(y_train), X_val, encoder_t.inverse_transform(y_val), X_test, embeddings]\n",
    "    \n",
    "    with open(tmp_save + 'fold_' + str(i) + '_city_twitter_us.pickle', 'wb') as handle:\n",
    "        pickle.dump(to_save, handle, protocol=4)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "with open(tmp_save + 'encoder_t_city_twitter_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(encoder_t, handle, protocol=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-christopher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "demonstrated-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(\n",
    "    train_tweets_list,\n",
    "    vector_size=128,\n",
    "    window=5,\n",
    "    min_count=0,\n",
    "    sg=1,\n",
    "    workers=6,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "starting-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(tokenizer.word_index) + 1, 128))\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embeddings[idx] =  word2vec.wv[word]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "collaborative-supplier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233762"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "nonprofit-virtue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233762, 128)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "hollow-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233762"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "brown-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'X_train_us_kd_text.pickle', 'wb') as handle:\n",
    "#    pickle.dump(X_train, handle, protocol=4)  \n",
    "    \n",
    "#with open(tmp_save + 'X_val_us_kd_text.pickle', 'wb') as handle:\n",
    "#    pickle.dump(X_val, handle, protocol=4) \n",
    "    \n",
    "#with open(tmp_save + 'X_test_us_kd_text.pickle', 'wb') as handle:\n",
    "#    pickle.dump(X_test, handle, protocol=4)  \n",
    "    \n",
    "with open(tmp_save + 'embeddings_w2v_kd_text.pickle', 'wb') as handle:\n",
    "    pickle.dump(embeddings, handle, protocol=4)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffunes-3.8",
   "language": "python",
   "name": "ffunes-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
