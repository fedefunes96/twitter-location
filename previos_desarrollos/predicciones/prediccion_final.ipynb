{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organizational-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold, cross_val_predict, cross_validate\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, mutual_info_score\n",
    "from collections import OrderedDict\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import scipy.sparse\n",
    "import seaborn as sns\n",
    "import lightgbm as lgbm\n",
    "import category_encoders as ce\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, Normalizer\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model, clone_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Concatenate, Input, Dropout, Bidirectional, concatenate\n",
    "from tensorflow.keras.layers import Reshape, Flatten, MultiHeadAttention, Attention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from shapely.geometry import Polygon, box\n",
    "from scipy.sparse import hstack \n",
    "import os.path\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from spektral.data.loaders import SingleLoader, MixedLoader\n",
    "from spektral.datasets.citation import Citation\n",
    "from spektral.layers import GCNConv, GlobalSumPool, ChebConv\n",
    "from spektral.models.gcn import GCN\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from spektral.data import Dataset, DisjointLoader, Graph\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.base import clone\n",
    "#from scikeras.wrappers import KerasClassifier\n",
    "import stellargraph as sg\n",
    "from io import BytesIO\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from pecanpy import node2vec\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2, SelectKBest, SelectFromModel, SelectFpr, SelectFdr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "import multiprocessing\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.patches as mpatches\n",
    "import colorcet as cc\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import ticker\n",
    "\n",
    "import os\n",
    "os.environ[\"METIS_DLL\"] = '/usr/local/lib/libmetis.so'\n",
    "\n",
    "import metis\n",
    "#metis.part_graph(vector_of_mentions_local.tolil(), 10)\n",
    "\n",
    "tf.random.set_seed(seed=0)\n",
    "\n",
    "unTPath = \"../../../../../unT/ffunes/\"\n",
    "gcnPath = \"../../../gcn_input/\"\n",
    "tmp_save = unTPath + \"tmp_saves/\"\n",
    "figuresPath = unTPath + \"figures/\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-category",
   "metadata": {},
   "source": [
    "# Definición de métricas y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acquired-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\n",
    "    \"city_name\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"country\"\n",
    "]\n",
    "\n",
    "geonames = pd.read_csv(unTPath + \"geonames/geonames_parsed.csv\", usecols=colnames)\n",
    "\n",
    "from math import radians, sin, cos, atan2, sqrt\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = radians(lat2-lat1)\n",
    "    dlon = radians(lon2-lon1)\n",
    "    a = sin(dlat/2) * sin(dlat/2) + cos(radians(lat1)) \\\n",
    "        * cos(radians(lat2)) * sin(dlon/2) * sin(dlon/2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def determine_distance(row):\n",
    "    predicted_lat = row['predicted_lat']\n",
    "    predicted_lon = row['predicted_lon']\n",
    "    real_lat = row['real_lat']\n",
    "    real_long = row['real_lon']\n",
    "    \n",
    "    return haversine_distance(predicted_lat, predicted_lon, real_lat, real_long)\n",
    "\n",
    "def get_difference_distance(predicted_place, real_place, places_with_coords):\n",
    "    df_prediction = pd.DataFrame({\n",
    "        'predicted_place': predicted_place,\n",
    "        'real_place': real_place\n",
    "    }, dtype=str)\n",
    "        \n",
    "    df_prediction = pd.merge(\n",
    "        left=df_prediction,\n",
    "        right=places_with_coords,\n",
    "        how='inner',\n",
    "        left_on='predicted_place',\n",
    "        right_on='class',\n",
    "        #validate='m:1'\n",
    "    ).rename(columns={'latitude': 'predicted_lat', 'longitude': 'predicted_lon'})\n",
    "        \n",
    "    df_prediction = pd.merge(\n",
    "        left=df_prediction,\n",
    "        right=places_with_coords,\n",
    "        how='inner',\n",
    "        left_on='real_place',\n",
    "        right_on='class',\n",
    "        #validate='m:1'\n",
    "    ).rename(columns={'latitude': 'real_lat', 'longitude': 'real_lon'})    \n",
    "        \n",
    "    return df_prediction.apply(determine_distance, axis=1)\n",
    "\n",
    "def accuracy_161km(real_place, pred_place, places_with_coords):\n",
    "    dif_distance = get_difference_distance(pred_place, real_place, places_with_coords)\n",
    "    \n",
    "    total_positives = 0\n",
    "    \n",
    "    for val in dif_distance:\n",
    "        if val <= 161:\n",
    "            total_positives += 1\n",
    "    \n",
    "\n",
    "    return total_positives / len(dif_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exposed-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fold:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def unpack(self, val_split=None, random_state=40):\n",
    "        if val_split:\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=random_state)\n",
    "                                \n",
    "            for train_ix, val_ix in sss.split(self.X_train, self.y_train):\n",
    "                X_train_ = self.X_train.iloc[train_ix]\n",
    "                X_val = self.X_train.iloc[val_ix]\n",
    "                    \n",
    "                y_train_, y_val = self.y_train[train_ix], self.y_train[val_ix]\n",
    "                    \n",
    "                return X_train_, y_train_, X_val, y_val, self.X_test, self.y_test\n",
    "        \n",
    "        return self.X_train, self.y_train, self.X_test, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exposed-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldGen:\n",
    "    def create_folds(self, X, y, outer_cv=5, random_state=40):\n",
    "        outer_cv_fold = StratifiedKFold(n_splits=outer_cv, shuffle=True, random_state=random_state)\n",
    "\n",
    "        folds = []    \n",
    "        test_idx = np.array([])\n",
    "\n",
    "        for train_ix, test_ix in outer_cv_fold.split(X, y):\n",
    "            X_train = X.iloc[train_ix]\n",
    "            X_test = X.iloc[test_ix]\n",
    "\n",
    "            y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "            folds.append(Fold(X_train, y_train, X_test, y_test))\n",
    "\n",
    "            test_idx = np.concatenate([test_idx, test_ix])\n",
    "\n",
    "        return folds, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "everyday-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "    def __init__(self, name, encoder=None):\n",
    "        self.name = name\n",
    "        self.encoder = encoder\n",
    "            \n",
    "    #def classifier(self):\n",
    "        #return clone(self.clf)\n",
    "    \n",
    "    def classes_order(self):\n",
    "        if self.encoder:\n",
    "            return self.encoder.classes_\n",
    "        \n",
    "        return self.classes_\n",
    "            \n",
    "    def predict_proba(self, clf, X):\n",
    "        return clf.predict_proba(X)\n",
    "    \n",
    "    '''def cross_score(self, X, y, scoring, outer_cv=5, n_jobs=-1):\n",
    "        return cross_validate(\n",
    "            self.classifier(),\n",
    "            X=X[0] if len(X) == 1 else X,\n",
    "            y=y if self.encoder is None else encoder.transform(y),\n",
    "            cv=outer_cv,\n",
    "            n_jobs=n_jobs,\n",
    "            scoring=scoring,\n",
    "            verbose=2\n",
    "        )'''\n",
    "            \n",
    "    def cross_predict(\n",
    "            self, folds, test_idx, outer_cv=5, predict_proba=True, random_state=40, preprocess=None, *args, **kwargs\n",
    "        ):\n",
    "        results = None\n",
    "        \n",
    "        for fold in folds:\n",
    "            if self.encoder:\n",
    "                X_train, y_train, X_test, y_test = fold.unpack()\n",
    "                \n",
    "                if self.encoder:\n",
    "                    self.encoder.fit(y_train)\n",
    "                \n",
    "                    y_train = self.encoder.transform(y_train)\n",
    "                    y_test = self.encoder.transform(y_test)                    \n",
    "                \n",
    "                fold = Fold(X_train, y_train, X_test, y_test)\n",
    "                \n",
    "            #if preprocess is not None:\n",
    "            #    fold = preprocess(fold)\n",
    "            \n",
    "            if preprocess is not None:\n",
    "                clf, X_test = preprocess(fold)\n",
    "            \n",
    "            #clf = self.classifier()\n",
    "                \n",
    "            #if len(fold) == 6:\n",
    "            #    X_train, y_train, X_val, y_val, X_test, y_test = fold\n",
    "                \n",
    "            #    clf.fit(X_train, y_train, validation_data=(X_val, y_val), **kwargs)\n",
    "            #else:\n",
    "            #    X_train, y_train, X_test, y_test = fold                \n",
    "                    \n",
    "            #    clf.fit(X_train, y_train, **kwargs)     \n",
    "            \n",
    "            try:\n",
    "                self.classes_ = clf.classes_\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Print best params when searching for best params\n",
    "            try:\n",
    "                print(\"Best params: \", clf.best_params_)\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "            y_pred = self.predict_proba(clf, X_test)\n",
    "    \n",
    "            if not predict_proba:\n",
    "                y_pred = np.array([self.classes_order()[x] for x in np.argmax(y_pred, axis=1)])\n",
    "            \n",
    "            if results is None:\n",
    "                results = y_pred\n",
    "            else:\n",
    "                results = np.concatenate((results, y_pred))\n",
    "            \n",
    "        preds = results[test_idx.argsort()]\n",
    "\n",
    "        return preds\n",
    "    \n",
    "class KerasCrossValidator(CrossValidator):\n",
    "    #def classifier(self):\n",
    "        #return self.clf()\n",
    "    \n",
    "    def predict_proba(self, clf, X):\n",
    "        return clf.predict(X).squeeze()\n",
    "    \n",
    "class GCNCrossValidator(CrossValidator):\n",
    "    #def classifier(self):\n",
    "        #return self.clf()\n",
    "    \n",
    "    def predict_proba(self, clf, X):\n",
    "        return clf.predict(X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "common-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(y_true, y_pred, classes_order, places_with_coords):\n",
    "    y_true_ = np.array([classes_order[x] for x in np.argmax(y_true, axis=1)])\n",
    "    y_pred_ = np.array([classes_order[x] for x in np.argmax(y_pred, axis=1)])\n",
    "    \n",
    "    acc = accuracy_score(y_true_, y_pred_)\n",
    "    acc_161 = accuracy_161km(y_true_, y_pred_, places_with_coords)\n",
    "    bal_acc = balanced_accuracy_score(y_true_, y_pred_)\n",
    "    roc_auc_ovo = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovo')\n",
    "        \n",
    "    diffs_distance = get_difference_distance(y_true_, y_pred_, places_with_coords)\n",
    "    \n",
    "    #diffs_distance_ge_zero = [dist for dist in diffs_distance if dist > 0]\n",
    "        \n",
    "    return \"Accuracy: {}\\\n",
    "        \\nAcc@161: {}\\\n",
    "        \\nBalanced Acc: {}\\\n",
    "        \\nROC AUC Ovo: {}\\\n",
    "        \\nMean Dist Err: {}\\\n",
    "        \\nMedian Dist Err: {}\".format(\n",
    "        acc, acc_161, bal_acc, roc_auc_ovo, np.mean(diffs_distance), np.median(diffs_distance)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-victorian",
   "metadata": {},
   "source": [
    "# Oslom parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unusual-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infomap(filename):\n",
    "    \"\"\"Funcion que extrae las comunidades detectadas por INFOMAP a las que pertence un vertice de la red.\"\"\"\n",
    "    colnames = [\n",
    "        \"node_id\", \"module\", \"flow\"\n",
    "    ]\n",
    "    \n",
    "    dtypes = {\n",
    "        \"node_id\": np.int64,\n",
    "        \"module\": np.int64,\n",
    "        \"flow\": np.float64\n",
    "    }\n",
    "    \n",
    "    df = pd.read_csv(filename, comment=\"#\", names=colnames, dtype=dtypes, sep=\" \")\n",
    "    \n",
    "    #df = df.sort_values(\"flow\", ascending=False).drop_duplicates(\"node_id\", keep='first')\n",
    "    \n",
    "    del df[\"flow\"]\n",
    "    \n",
    "    df = df.groupby(\n",
    "        [\"node_id\"]\n",
    "    )['module'].apply(list).reset_index(name='modules')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_oslom(filename):\n",
    "    \"\"\"Funcion que extrae las comunidades detectadas por OSLOM a las que pertence un vertice de la red.\"\"\"\n",
    "    clusters = {}\n",
    "    hashtag_clusters = {}\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        cluster = \"\"\n",
    "        for line in f:\n",
    "            m = re.search(\"^#module\\s([0-9]+).*\", line)\n",
    "            #print line\n",
    "            if (m is not None):\n",
    "                cluster = int(m.group(1))\n",
    "            else:\n",
    "                l = line.replace('\\n', ' ').strip().split(\" \")\n",
    "                l = list(map(int, l))\n",
    "                clusters[cluster] = l\n",
    "                for i in l:\n",
    "                    if not i in hashtag_clusters:\n",
    "                        hashtag_clusters[i] = set()\n",
    "                    hashtag_clusters[i].add(cluster)\n",
    "                    data.append([i, cluster])\n",
    "    return pd.DataFrame(data=data, columns=[\"id\", \"cluster\"]), hashtag_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-upper",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tutorial-catholic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141209, 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train = pd.read_pickle(unTPath + \"bounding_box/total_users_parsed.pkl\")\n",
    "users_with_content = pd.read_pickle(unTPath + \"bounding_box/users_with_content.pkl\")\n",
    "users_with_mentions = pd.read_pickle(unTPath + \"bounding_box/users_with_mentions.pkl\")\n",
    "users_with_follows = pd.read_pickle(unTPath + \"bounding_box/users_with_follows.pkl\")\n",
    "\n",
    "users_train = pd.merge(\n",
    "    left=users_train,\n",
    "    right=users_with_content,\n",
    "    how='inner',\n",
    "    validate='1:1'\n",
    ")\n",
    "\n",
    "users_train = pd.merge(\n",
    "    left=users_train,\n",
    "    right=users_with_mentions.loc[:, [\"id\", \"users_mentioned\"]],\n",
    "    how='inner',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "\n",
    "users_train = pd.merge(\n",
    "    left=users_train,\n",
    "    right=users_with_follows.loc[:, [\"id\", \"followees\", \"followers\"]],\n",
    "    how='inner',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "\n",
    "users_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lightweight-sterling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train[\"unified_place\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "creative-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train[\"place_country\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wound-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_cities = users_train.loc[:, [\"unified_place\", \"id\"]].groupby(\"unified_place\").count().reset_index().sort_values(\"id\", ascending=False)\n",
    "#top_cities = top_cities.head(95).loc[:, [\"unified_place\"]]\n",
    "\n",
    "#users_train = pd.merge(\n",
    "#    left=users_train,\n",
    "#    right=top_cities,\n",
    "#    how='inner'\n",
    "#)\n",
    "\n",
    "#users_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "colored-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train.loc[users_train['users_mentioned'].isnull(), ['users_mentioned']] = users_train.loc[users_train['users_mentioned'].isnull(),'users_mentioned'].apply(lambda x: [])\n",
    "users_train.loc[users_train['followees'].isnull(), ['followees']] = users_train.loc[users_train['followees'].isnull(),'followees'].apply(lambda x: [])\n",
    "users_train.loc[users_train['all_tweets'].isnull(), ['all_tweets']] = users_train.loc[users_train['all_tweets'].isnull(),'all_tweets'].apply(lambda x: '')\n",
    "users_train.loc[users_train['followers'].isnull(), ['followers']] = users_train.loc[users_train['followers'].isnull(),'followers'].apply(lambda x: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beginning-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train[\"users_mentioned\"] = users_train[\"users_mentioned\"].apply(lambda x: list(map(int, x)))\n",
    "users_train[\"followees\"] = users_train[\"followees\"].apply(lambda x: list(map(int, x)))\n",
    "users_train[\"followers\"] = users_train[\"followers\"].apply(lambda x: list(map(int, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sunrise-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003838"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = users_train[\"id\"].to_numpy()\n",
    "\n",
    "set_users = set(users_ids)\n",
    "\n",
    "for x in users_train[\"users_mentioned\"].to_numpy():\n",
    "    set_users |= set(x)\n",
    "\n",
    "mentioned_users = list(set_users.difference(set(users_ids)))\n",
    "\n",
    "total_users_mentions = list(users_ids) + mentioned_users\n",
    "len(total_users_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "finite-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Verify order\n",
    "\n",
    "value = True\n",
    "\n",
    "for i in range(0, len(users_train[\"id\"])):\n",
    "    if total_users_mentions[i] != users_train[\"id\"][i]:\n",
    "        value = False\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "personalized-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_mentions_dir = nx.DiGraph()\n",
    "\n",
    "graph_mentions_dir.add_nodes_from(users_ids)\n",
    "\n",
    "for user_id, users_mentioned in zip(users_ids, users_train[\"users_mentioned\"].to_numpy()):\n",
    "    ocurrences = list(Counter(users_mentioned).items())\n",
    "            \n",
    "    graph_mentions_dir.add_weighted_edges_from(list(map(lambda x: (user_id, x[0], x[1]), ocurrences)))\n",
    "                    \n",
    "graph_mentions_dir.remove_edges_from(nx.selfloop_edges(graph_mentions_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "arctic-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1003838x1003838 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 1751056 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_dir = nx.adjacency_matrix(graph_mentions_dir, nodelist=total_users_mentions).astype(np.uint8)\n",
    "vector_of_mentions_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "attractive-heavy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x141209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 136796 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_dir_local = vector_of_mentions_dir[0:len(users_ids), 0:len(users_ids)]\n",
    "vector_of_mentions_dir_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expected-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x141209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 259854 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_undir_local = vector_of_mentions_dir_local + vector_of_mentions_dir_local.T\n",
    "vector_of_mentions_undir_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "absent-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x862629 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 1614260 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_mentions_dir_bip = vector_of_mentions_dir[:len(users_ids), len(users_ids):]\n",
    "# Convertimos a bool para que los pesos de las aristas pasen a ser todos 1\n",
    "vector_of_mentions_dir_bip = vector_of_mentions_dir_bip.astype(bool).astype(np.uint8)\n",
    "vector_of_mentions_dir_bip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hollywood-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<141209x141209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 3923984 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_comentions_ext = vector_of_mentions_dir_bip.dot(vector_of_mentions_dir_bip.T)\n",
    "# Eliminamos la diagonal\n",
    "vector_of_comentions_ext.setdiag(0, k=0)\n",
    "vector_of_comentions_ext.eliminate_zeros()\n",
    "vector_of_comentions_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alien-lebanon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x141209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 4120706 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_col_mentions = vector_of_mentions_undir_local + vector_of_comentions_ext\n",
    "vector_of_col_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "local-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794449"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = users_train[\"id\"].to_numpy()\n",
    "\n",
    "set_users = set(users_ids)\n",
    "\n",
    "for x in users_train[\"followees\"].to_numpy():\n",
    "    set_users |= set(x)\n",
    "    \n",
    "for x in users_train[\"followers\"].to_numpy():\n",
    "    set_users |= set(x)\n",
    "    \n",
    "follows_users = list(set_users.difference(set(users_ids)))\n",
    "\n",
    "total_users_follows = list(users_ids) + follows_users\n",
    "len(total_users_follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "finished-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Verify order\n",
    "\n",
    "value = True\n",
    "\n",
    "for i in range(0, len(users_train[\"id\"])):\n",
    "    if total_users_follows[i] != users_train[\"id\"][i]:\n",
    "        value = False\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "completed-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_follows_dir = nx.DiGraph()\n",
    "\n",
    "graph_follows_dir.add_nodes_from(users_ids)\n",
    "\n",
    "for user_id, users_followed in zip(users_ids, users_train[\"followees\"].to_numpy()):\n",
    "    graph_follows_dir.add_edges_from(list(map(lambda x: (user_id, x), users_followed)))\n",
    "    \n",
    "for user_id, users_follower in zip(users_ids, users_train[\"followers\"].to_numpy()):\n",
    "    graph_follows_dir.add_edges_from(list(map(lambda x: (x, user_id), users_follower)))\n",
    "                    \n",
    "graph_follows_dir.remove_edges_from(nx.selfloop_edges(graph_follows_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "distinguished-phoenix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<794449x794449 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 13263642 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_fol_dir = nx.adjacency_matrix(graph_follows_dir, nodelist=total_users_follows).astype(np.uint8)\n",
    "vector_of_fol_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "heated-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x141209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 3418882 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_fol_dir_local = vector_of_fol_dir[0:len(users_ids), 0:len(users_ids)]\n",
    "vector_of_fol_undir_local = vector_of_fol_dir_local + vector_of_fol_dir_local.T\n",
    "vector_of_fol_undir_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "alive-omaha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x653240 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 1929133 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_fol_dir_bip = vector_of_fol_dir[:len(users_ids), len(users_ids):]\n",
    "# Convertimos a bool para que los pesos de las aristas pasen a ser todos 1\n",
    "vector_of_fol_dir_bip = vector_of_fol_dir_bip.astype(bool).astype(np.uint8)\n",
    "vector_of_fol_dir_bip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "popular-documentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x141209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 7775810 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_cofol_ext = vector_of_fol_dir_bip.dot(vector_of_fol_dir_bip.T)\n",
    "# Eliminamos la diagonal\n",
    "vector_of_cofol_ext.setdiag(0, k=0)\n",
    "vector_of_cofol_ext.eliminate_zeros()\n",
    "vector_of_cofol_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "opposed-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<141209x141209 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 10474256 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_col_follows = vector_of_fol_undir_local + vector_of_cofol_ext\n",
    "vector_of_col_follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "automatic-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train_final = users_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "chubby-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_city = LabelBinarizer()\n",
    "\n",
    "cities_true = users_train_final[\"unified_place\"].to_numpy()\n",
    "cities_true_enc = encoder_city.fit_transform(cities_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adequate-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_with_coords = users_train_final.loc[:, [\"unified_place\", \"latitude\", \"longitude\"]].groupby(\"unified_place\").mean().reset_index().rename(columns={\"unified_place\": \"class\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "blond-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_cities, test_cities_idxs = FoldGen().create_folds(users_train_final, cities_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "improved-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cities = len(np.unique(cities_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "registered-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'users_train_final_bbox.pickle', 'wb') as handle:\n",
    "#    pickle.dump(users_train_final, handle, protocol=4)  \n",
    "\n",
    "#with open(tmp_save + 'folds_cities_bbox.pickle', 'wb') as handle:\n",
    "#    pickle.dump(folds_cities, handle, protocol=4)\n",
    "    \n",
    "#with open(tmp_save + 'test_cities_idxs_bbox.pickle', 'wb') as handle:\n",
    "#    pickle.dump(test_cities_idxs, handle, protocol=4)\n",
    "\n",
    "#with open(tmp_save + 'total_cities_bbox.pickle', 'wb') as handle:\n",
    "#    pickle.dump(total_cities, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-might",
   "metadata": {},
   "source": [
    "# Resultados métodos principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "younger-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChiSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocab, k=50):\n",
    "        self.vocab = vocab\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        features_sel = np.array([])\n",
    "        \n",
    "        for target in np.unique(y):\n",
    "            #print(\"CAlculating chi2\")\n",
    "            chi, p = chi2(X, y==target)\n",
    "            \n",
    "            idxs = np.argsort(chi)[-self.k:]\n",
    "            \n",
    "            features_sel = np.concatenate([features_sel, idxs])\n",
    "            \n",
    "            #Top words of this target is at self.vocab[idxs]\n",
    "            #print(\"Top vocab for city\", target,\": \", self.vocab[idxs])\n",
    "                \n",
    "        features_sel = np.unique(features_sel)\n",
    "        \n",
    "        self.features_selected = features_sel\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        #print(len(self.features_selected))\n",
    "        return X[:, self.features_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "searching-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        #strip_accents='unicode',\n",
    "        strip_accents='ascii',\n",
    "        lowercase=True,\n",
    "        max_df=0.2,\n",
    "        min_df=10,\n",
    "        ngram_range=(1, 3)\n",
    "    )\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train[\"all_tweets\"].to_numpy()).astype(np.uint8)\n",
    "        \n",
    "    X_test = vectorizer.transform(X_test[\"all_tweets\"].to_numpy()).astype(np.uint8)\n",
    "    \n",
    "    estimator = Pipeline(\n",
    "        [\n",
    "            (\"chi2\", ChiSelector(np.array(vectorizer.get_feature_names()), k=50)),\n",
    "            (\"naive_bayes\", MultinomialNB(alpha=0.5))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    clf = estimator\n",
    "    \n",
    "    '''clf=GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid={\n",
    "            \"naive_bayes__alpha\": [0.01, 0.05, 0.1, 0.5],\n",
    "            \"chi2__k\": [50, 100, 150, 300, 400, 500]\n",
    "        },\n",
    "        cv=3,\n",
    "        #n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )'''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Contenido Mutual information + Naive Bayes\",\n",
    ")\n",
    "\n",
    "content_preds = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(cities_true_enc, content_preds, cn_cross_val.classes_order(), cities_with_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "negative-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4426862443607117        \n",
      "Acc@161: 0.5665309294898873        \n",
      "Balanced Acc: 0.3617682048250076        \n",
      "ROC AUC Ovo: 0.7984549718626661        \n",
      "Mean Dist Err: 885.9984022351324        \n",
      "Median Dist Err: 22.6347245535071\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fluid-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39576797512906403        \n",
      "Acc@161: 0.5179981445941831        \n",
      "Balanced Acc: 0.2865558716504422        \n",
      "ROC AUC Ovo: 0.7916975669560959        \n",
      "Mean Dist Err: 1082.7356295585605        \n",
      "Median Dist Err: 66.7884287670517\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "indian-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'content_preds_bbox.pickle', 'wb') as handle:\n",
    "#    pickle.dump(content_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-shelf",
   "metadata": {},
   "source": [
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "official-remedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.397028518012308        \n",
      "Acc@161: 0.5328626362342344        \n",
      "Balanced Acc: 0.20902178473246372        \n",
      "ROC AUC Ovo: 0.8443312552526588        \n",
      "Mean Dist Err: 914.730661954212        \n",
      "Median Dist Err: 51.63366173590518\n"
     ]
    }
   ],
   "source": [
    "with open(tmp_save + 'transformer_bbox_preds.pickle', 'rb') as handle:\n",
    "    transformer_preds = pickle.load(handle)\n",
    "    \n",
    "count_score_city = get_all_metrics(cities_true_enc, transformer_preds, encoder_city.classes_, cities_with_coords)\n",
    "\n",
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-jones",
   "metadata": {},
   "source": [
    "BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "embedded-folks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35767550226968536        \n",
      "Acc@161: 0.4957474381944494        \n",
      "Balanced Acc: 0.12604494778138745        \n",
      "ROC AUC Ovo: 0.8314804839782075        \n",
      "Mean Dist Err: 989.9372504759406        \n",
      "Median Dist Err: 191.59928718581807\n"
     ]
    }
   ],
   "source": [
    "with open(tmp_save + 'bilstm_bbox_preds.pickle', 'rb') as handle:\n",
    "    bilstm_preds = pickle.load(handle)\n",
    "    \n",
    "count_score_city = get_all_metrics(cities_true_enc, bilstm_preds, encoder_city.classes_, cities_with_coords)\n",
    "\n",
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "returning-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node2vec_pecanpy(\n",
    "    adj_mat, out_dim=128, p=1.0, q=1.0, num_walks=10, length_walks=100\n",
    "):    \n",
    "    tmp_fold = tmp_save\n",
    "    \n",
    "    cx = adj_mat.tocoo()\n",
    "\n",
    "    edges = []\n",
    "\n",
    "    already_passed = {}\n",
    "\n",
    "    for i in range(adj_mat.shape[0]):\n",
    "        already_passed[i] = []\n",
    "\n",
    "    for i,j,v in zip(cx.row, cx.col, cx.data):    \n",
    "        if i in already_passed[j]:\n",
    "            continue\n",
    "\n",
    "        #edges.append(str(users_ids[i]) + \"\\t\" + str(users_ids[j]) + \"\\t\" + str(v))\n",
    "        edges.append(str(i) + \"\\t\" + str(j) + \"\\t\" + str(v))\n",
    "\n",
    "        already_passed[i].append(j)    \n",
    "        \n",
    "    edges = pd.DataFrame({\"edges\": edges})\n",
    "    \n",
    "    save_in = tmp_fold + \"edges_node2vec_bbox.edg\"\n",
    "    emb_save_in = tmp_fold + \"edges_node2vec_bbox.emb\"\n",
    "    \n",
    "    edges.to_csv(save_in, header=False, index=False)\n",
    "    \n",
    "    !pecanpy --input $save_in --output $emb_save_in --mode SparseOTF\\\n",
    "    --dimensions $out_dim --walk-length $length_walks --num-walks $num_walks --p $p --q $q --weighted\n",
    "    \n",
    "    df = pd.read_csv(emb_save_in, header=None,  skiprows=[0], sep=\" \")\n",
    "    \n",
    "    all_users_ids = set(np.arange(len(users_ids)))\n",
    "    users_embedded = set(df[0].to_numpy())\n",
    "    missing_users = np.array(list(all_users_ids.difference(users_embedded)))\n",
    "    missing_embs = [np.append(np.array([int(x)]), np.zeros(shape=(1, out_dim))) for x in missing_users]\n",
    "    \n",
    "    return df.append(missing_embs).sort_values(0).to_numpy()[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "closed-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 00:00:04.16 to load graph\n",
      "Took 00:00:00.00 to pre-compute transition probabilities\n",
      "Took 00:09:01.87 to generate walks\n",
      "Took 00:13:46.52 to train embeddings\n"
     ]
    }
   ],
   "source": [
    "node2vec_pec_embs = node2vec_pecanpy(vector_of_col_mentions, num_walks=20, length_walks=100, p=1.0, q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "chemical-beijing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 00:00:23.85 to load graph\n",
      "Took 00:00:00.00 to pre-compute transition probabilities\n",
      "Took 00:09:21.64 to generate walks\n",
      "Took 00:12:22.19 to train embeddings\n"
     ]
    }
   ],
   "source": [
    "node2vec_fol_pec_embs = node2vec_pecanpy(vector_of_col_follows, num_walks=20, length_walks=100, p=1.0, q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "appropriate-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'node2vec_pec_embs_bbox.pickle', 'wb') as handle:\n",
    "    pickle.dump(node2vec_pec_embs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "closed-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'node2vec_fol_pec_embs_bbox.pickle', 'wb') as handle:\n",
    "    pickle.dump(node2vec_fol_pec_embs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "studied-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    X_train = node2vec_pec_embs[X_train.index.to_numpy()]\n",
    "    X_test = node2vec_pec_embs[X_test.index.to_numpy()]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=35,n_jobs=-1,C=0.5)\n",
    "    \n",
    "    '''clf=GridSearchCV(\n",
    "        estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "        param_grid={'C': [0.05, 0.1, 0.5, 1.0]},\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )'''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Contenido Mutual information + Naive Bayes\",\n",
    ")\n",
    "\n",
    "node2vec_mentions_preds = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_ment = get_all_metrics(cities_true_enc, node2vec_mentions_preds, cn_cross_val.classes_order(), cities_with_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "allied-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3570239857232896        \n",
      "Acc@161: 0.5181185335212345        \n",
      "Balanced Acc: 0.1455183729493383        \n",
      "ROC AUC Ovo: 0.7846710432953892        \n",
      "Mean Dist Err: 1032.5649052556669        \n",
      "Median Dist Err: 66.7884287670517\n"
     ]
    }
   ],
   "source": [
    "print(count_score_ment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "lesser-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'node2vec_mentions_preds_bbox.pickle', 'wb') as handle:\n",
    "    pickle.dump(node2vec_mentions_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "diverse-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    X_train = node2vec_fol_pec_embs[X_train.index.to_numpy()]\n",
    "    X_test = node2vec_fol_pec_embs[X_test.index.to_numpy()]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=35,n_jobs=-1,C=0.5)\n",
    "    \n",
    "    '''clf=GridSearchCV(\n",
    "        estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "        param_grid={'C': [0.05, 0.1, 0.5, 1.0]},\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )'''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Node2vec follows\"\n",
    ")\n",
    "\n",
    "node2vec_follows_preds = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_fol = get_all_metrics(cities_true_enc, node2vec_follows_preds, cn_cross_val.classes_order(), cities_with_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "academic-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36885750908228226        \n",
      "Acc@161: 0.5319066065194145        \n",
      "Balanced Acc: 0.15673964070117608        \n",
      "ROC AUC Ovo: 0.7945247656901298        \n",
      "Mean Dist Err: 1023.1593742867433        \n",
      "Median Dist Err: 51.63366173590518\n"
     ]
    }
   ],
   "source": [
    "print(count_score_fol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abstract-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'node2vec_follows_preds_bbox.pickle', 'wb') as handle:\n",
    "    pickle.dump(node2vec_follows_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "supposed-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best params:  {'C': 4.0}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best params:  {'C': 4.0}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best params:  {'C': 4.0}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best params:  {'C': 4.0}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best params:  {'C': 4.0}\n"
     ]
    }
   ],
   "source": [
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_test, y_test = fold.unpack()\n",
    "    \n",
    "    train_idxs = X_train.index.to_numpy()\n",
    "    test_idxs = X_test.index.to_numpy()\n",
    "    \n",
    "    total_preds_train = transformer_preds[train_idxs]\n",
    "    \n",
    "    total_preds_train = np.concatenate(\n",
    "        (total_preds_train, node2vec_mentions_preds[train_idxs], node2vec_follows_preds[train_idxs]), axis=1)\n",
    "    \n",
    "    total_preds_test = transformer_preds[test_idxs]\n",
    "    \n",
    "    total_preds_test = np.concatenate(\n",
    "        (total_preds_test, node2vec_mentions_preds[test_idxs], node2vec_follows_preds[test_idxs]), axis=1)\n",
    "        \n",
    "    clf=GridSearchCV(\n",
    "        estimator=LogisticRegression(random_state=35,n_jobs=-1),\n",
    "        param_grid={'C': [0.1, 0.5, 1.0, 2.0, 4.0]},\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        scoring=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "        refit='roc_auc_ovo_weighted',\n",
    "        verbose=3\n",
    "    )\n",
    "    \n",
    "    clf.fit(total_preds_train, y_train)\n",
    "    \n",
    "    return clf, total_preds_test\n",
    "    \n",
    "cn_cross_val = CrossValidator(\n",
    "    name=\"Meta classifier solo Menciones y contenido\",\n",
    ")\n",
    "\n",
    "nb_prob = cn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_total = get_all_metrics(cities_true_enc, nb_prob, cn_cross_val.classes_order(), cities_with_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "toxic-member",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5740077387087508        \n",
      "Acc@161: 0.7056333744487437        \n",
      "Balanced Acc: 0.4380625762615354        \n",
      "ROC AUC Ovo: 0.901882276590723        \n",
      "Mean Dist Err: 527.8776428291005        \n",
      "Median Dist Err: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(count_score_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "valuable-geology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5151867090624536        \n",
      "Acc@161: 0.652968295221976        \n",
      "Balanced Acc: 0.34020364367103595        \n",
      "ROC AUC Ovo: 0.9055081030719918        \n",
      "Mean Dist Err: 719.2375264539235        \n",
      "Median Dist Err: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(count_score_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-treat",
   "metadata": {},
   "source": [
    "# RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "joint-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  weight\n",
       "0       3     377       1\n",
       "1       3     500       2\n",
       "2       3     638       1\n",
       "3       3     791       1\n",
       "4       3    1998       1\n",
       "5       3    2088       1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx = vector_of_fol_undir_local.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_fol_undir_local.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "    \n",
    "    #edges_tails.append(users_ids[i])\n",
    "    #edges_head.append(users_ids[j])\n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)\n",
    "    \n",
    "follows_edges = pd.DataFrame({\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight})\n",
    "follows_edges.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "alternative-stylus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cx = vector_of_cofol_ext.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_cofol_ext.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "    \n",
    "    #edges_tails.append(users_ids[i])\n",
    "    #edges_head.append(users_ids[j])\n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)\n",
    "    \n",
    "colfollows_edges = pd.DataFrame(\n",
    "    {\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight},\n",
    "    index=np.arange(len(follows_edges), len(edges_tails) + len(follows_edges))\n",
    ")\n",
    "\n",
    "last_index = len(edges_tails) + len(follows_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "meaning-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_mentions_undir_local.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_mentions_undir_local.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "    \n",
    "    #edges_tails.append(users_ids[i])\n",
    "    #edges_head.append(users_ids[j])\n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)\n",
    "    \n",
    "mentions_edges = pd.DataFrame(\n",
    "    {\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight},\n",
    "    index=np.arange(last_index, len(edges_tails) + last_index)\n",
    ")\n",
    "\n",
    "last_index = len(edges_tails) + last_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "alpha-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_comentions_ext.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_comentions_ext.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "    \n",
    "    #edges_tails.append(users_ids[i])\n",
    "    #edges_head.append(users_ids[j])\n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)\n",
    "    \n",
    "colmentions_edges = pd.DataFrame(\n",
    "    {\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight},\n",
    "    index=np.arange(last_index, len(edges_tails) + last_index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "metropolitan-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_col_mentions.tocoo()\n",
    "\n",
    "edges_tails = []\n",
    "edges_head = []\n",
    "edges_weight = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_col_mentions.shape[0]):\n",
    "    already_passed[i] = set()\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    already_passed[i].add(j)\n",
    "\n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "    \n",
    "    #edges_tails.append(users_ids[i])\n",
    "    #edges_head.append(users_ids[j])\n",
    "    edges_tails.append(i)\n",
    "    edges_head.append(j)\n",
    "    edges_weight.append(v)\n",
    "    \n",
    "colmentions_edges_normal = pd.DataFrame(\n",
    "    {\"source\": edges_tails, \"target\": edges_head, \"weight\": edges_weight},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "mature-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_content_preds = sg.IndexedArray(transformer_preds, index=np.arange(len(users_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "auburn-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 141209, Edges: 7689265\n",
      "\n",
      " Node types:\n",
      "  default: [141209]\n",
      "    Features: float32 vector, length 229\n",
      "    Edge types: default-col_follows->default, default-col_mentions->default, default-follows->default, default-mentions->default\n",
      "\n",
      " Edge types:\n",
      "    default-col_follows->default: [3887905]\n",
      "        Weights: range=[1, 234], mean=1.55471, std=2.30892\n",
      "        Features: none\n",
      "    default-col_mentions->default: [1961992]\n",
      "        Weights: range=[1, 255], mean=1.38977, std=2.3674\n",
      "        Features: none\n",
      "    default-follows->default: [1709441]\n",
      "        Weights: range=[1, 2], mean=1.17545, std=0.380355\n",
      "        Features: none\n",
      "    default-mentions->default: [129927]\n",
      "        Weights: range=[1, 255], mean=2.5254, std=6.6606\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "multilayer_graph = sg.StellarGraph(\n",
    "    nodes_content_preds, {\n",
    "        \"follows\": follows_edges,\n",
    "        \"col_follows\": colfollows_edges,\n",
    "        \"mentions\": mentions_edges,\n",
    "        \"col_mentions\": colmentions_edges\n",
    "    }\n",
    ")\n",
    "print(multilayer_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "civic-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 141209, Edges: 2060353\n",
      "\n",
      " Node types:\n",
      "  default: [141209]\n",
      "    Features: float32 vector, length 229\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [2060353]\n",
      "        Weights: range=[1, 255], mean=1.48193, std=2.97286\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "colmentions_graph = sg.StellarGraph(\n",
    "    nodes_content_preds,\n",
    "    colmentions_edges_normal\n",
    ")\n",
    "\n",
    "print(colmentions_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "heard-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(tmp_save + 'multilayer_graph_bbox.pickle', 'wb') as handle:\n",
    "#    pickle.dump(multilayer_graph, handle, protocol=4)     \n",
    "\n",
    "#with open(tmp_save + 'colmentions_graph_bbox.pickle', 'wb') as handle:\n",
    "#    pickle.dump(colmentions_graph, handle, protocol=4)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stuffed-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'colmentions_graph_bbox.pickle', 'rb') as handle:\n",
    "    colmentions_graph = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "touched-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rgcn_model(optimizer, num_classes, generator):\n",
    "    clear_session()\n",
    "    \n",
    "    rgcn = sg.layer.RGCN(\n",
    "        layer_sizes=[128, 64, num_classes],\n",
    "        activations=[\"relu\", \"relu\", \"softmax\"],\n",
    "        generator=generator,\n",
    "        num_bases=0,\n",
    "        dropout=0.2,\n",
    "        bias=True\n",
    "    )\n",
    "    \n",
    "    x_inp, x_out = rgcn.in_out_tensors()\n",
    "\n",
    "    #predictions = tf.keras.layers.Dense(units=num_classes, activation=\"softmax\")(x_out)\n",
    "\n",
    "    model = tf.keras.Model(inputs=x_inp, outputs=x_out)\n",
    "\n",
    "    model.compile(optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fiscal-array",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/12000\n",
      "1/1 [==============================] - 16s 16s/step - loss: 5.4341 - accuracy: 0.0029 - val_loss: 8.9523 - val_accuracy: 0.2066\n",
      "Epoch 2/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 8.9120 - accuracy: 0.2063 - val_loss: 5.1985 - val_accuracy: 0.0535\n",
      "Epoch 3/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 5.1980 - accuracy: 0.0433 - val_loss: 5.3670 - val_accuracy: 0.0221\n",
      "Epoch 4/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 5.4161 - accuracy: 0.0187 - val_loss: 5.1246 - val_accuracy: 0.0197\n",
      "Epoch 5/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 5.1271 - accuracy: 0.0236 - val_loss: 4.9722 - val_accuracy: 0.0377\n",
      "Epoch 6/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.9725 - accuracy: 0.0343 - val_loss: 4.7839 - val_accuracy: 0.0489\n",
      "Epoch 7/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.7818 - accuracy: 0.0506 - val_loss: 4.6279 - val_accuracy: 0.1162\n",
      "Epoch 8/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.6205 - accuracy: 0.1176 - val_loss: 4.5445 - val_accuracy: 0.1275\n",
      "Epoch 9/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4.5279 - accuracy: 0.1434 - val_loss: 4.5828 - val_accuracy: 0.1799\n",
      "Epoch 10/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.5663 - accuracy: 0.1769 - val_loss: 4.3997 - val_accuracy: 0.1686\n",
      "Epoch 11/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.3956 - accuracy: 0.1682 - val_loss: 4.4217 - val_accuracy: 0.1496\n",
      "Epoch 12/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.4210 - accuracy: 0.1434 - val_loss: 4.3901 - val_accuracy: 0.1268\n",
      "Epoch 13/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.3897 - accuracy: 0.1279 - val_loss: 4.3214 - val_accuracy: 0.1469\n",
      "Epoch 14/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.3300 - accuracy: 0.1442 - val_loss: 4.2442 - val_accuracy: 0.1589\n",
      "Epoch 15/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.2461 - accuracy: 0.1592 - val_loss: 4.2242 - val_accuracy: 0.1653\n",
      "Epoch 16/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.2381 - accuracy: 0.1683 - val_loss: 4.1099 - val_accuracy: 0.1631\n",
      "Epoch 17/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4.1223 - accuracy: 0.1649 - val_loss: 4.0493 - val_accuracy: 0.1668\n",
      "Epoch 18/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.0596 - accuracy: 0.1641 - val_loss: 4.0116 - val_accuracy: 0.1758\n",
      "Epoch 19/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.0244 - accuracy: 0.1718 - val_loss: 4.0392 - val_accuracy: 0.1754\n",
      "Epoch 20/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4.0616 - accuracy: 0.1784 - val_loss: 3.9377 - val_accuracy: 0.1944\n",
      "Epoch 21/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.9517 - accuracy: 0.1945 - val_loss: 3.9451 - val_accuracy: 0.2059\n",
      "Epoch 22/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.9556 - accuracy: 0.2075 - val_loss: 3.9032 - val_accuracy: 0.2063\n",
      "Epoch 23/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.9096 - accuracy: 0.2087 - val_loss: 3.8944 - val_accuracy: 0.2062\n",
      "Epoch 24/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.9050 - accuracy: 0.2079 - val_loss: 3.8806 - val_accuracy: 0.2130\n",
      "Epoch 25/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.8854 - accuracy: 0.2138 - val_loss: 3.8805 - val_accuracy: 0.2140\n",
      "Epoch 26/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.8844 - accuracy: 0.2175 - val_loss: 3.8479 - val_accuracy: 0.2144\n",
      "Epoch 27/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.8553 - accuracy: 0.2203 - val_loss: 3.8263 - val_accuracy: 0.2147\n",
      "Epoch 28/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.8316 - accuracy: 0.2258 - val_loss: 3.8216 - val_accuracy: 0.2441\n",
      "Epoch 29/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.8322 - accuracy: 0.2333 - val_loss: 3.7994 - val_accuracy: 0.2441\n",
      "Epoch 30/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.8163 - accuracy: 0.2466 - val_loss: 3.7781 - val_accuracy: 0.2471\n",
      "Epoch 31/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.7902 - accuracy: 0.2462 - val_loss: 3.8032 - val_accuracy: 0.2463\n",
      "Epoch 32/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.8331 - accuracy: 0.2467 - val_loss: 3.7878 - val_accuracy: 0.2456\n",
      "Epoch 33/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7795 - accuracy: 0.2485 - val_loss: 3.7840 - val_accuracy: 0.2483\n",
      "Epoch 34/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7898 - accuracy: 0.2490 - val_loss: 3.7574 - val_accuracy: 0.2523\n",
      "Epoch 35/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7707 - accuracy: 0.2520 - val_loss: 3.7477 - val_accuracy: 0.2526\n",
      "Epoch 36/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7617 - accuracy: 0.2508 - val_loss: 3.7465 - val_accuracy: 0.2510\n",
      "Epoch 37/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7561 - accuracy: 0.2503 - val_loss: 3.7360 - val_accuracy: 0.2508\n",
      "Epoch 38/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7449 - accuracy: 0.2513 - val_loss: 3.7264 - val_accuracy: 0.2494\n",
      "Epoch 39/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7325 - accuracy: 0.2513 - val_loss: 3.7158 - val_accuracy: 0.2534\n",
      "Epoch 40/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7191 - accuracy: 0.2529 - val_loss: 3.7078 - val_accuracy: 0.2556\n",
      "Epoch 41/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.7203 - accuracy: 0.2528 - val_loss: 3.6969 - val_accuracy: 0.2564\n",
      "Epoch 42/12000\n",
      "1/1 [==============================] - 11s 11s/step - loss: 3.7015 - accuracy: 0.2548 - val_loss: 3.6805 - val_accuracy: 0.2574\n",
      "Epoch 43/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6880 - accuracy: 0.2573 - val_loss: 3.6701 - val_accuracy: 0.2629\n",
      "Epoch 44/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6883 - accuracy: 0.2633 - val_loss: 3.6614 - val_accuracy: 0.2578\n",
      "Epoch 45/12000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 3.6691 - accuracy: 0.2588 - val_loss: 3.6559 - val_accuracy: 0.2588\n",
      "Epoch 46/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.6532 - accuracy: 0.2596 - val_loss: 3.6478 - val_accuracy: 0.2590\n",
      "Epoch 47/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.6490 - accuracy: 0.2587 - val_loss: 3.6423 - val_accuracy: 0.2615\n",
      "Epoch 48/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6382 - accuracy: 0.2609 - val_loss: 3.6176 - val_accuracy: 0.2677\n",
      "Epoch 49/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6223 - accuracy: 0.2661 - val_loss: 3.6046 - val_accuracy: 0.2737\n",
      "Epoch 50/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6129 - accuracy: 0.2691 - val_loss: 3.6204 - val_accuracy: 0.2710\n",
      "Epoch 51/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6316 - accuracy: 0.2688 - val_loss: 3.6658 - val_accuracy: 0.2607\n",
      "Epoch 52/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.6694 - accuracy: 0.2622 - val_loss: 3.6175 - val_accuracy: 0.2663\n",
      "Epoch 53/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.6271 - accuracy: 0.2649 - val_loss: 3.7105 - val_accuracy: 0.2509\n",
      "Epoch 54/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.6823 - accuracy: 0.2544 - val_loss: 3.6368 - val_accuracy: 0.2668\n",
      "Epoch 55/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.6293 - accuracy: 0.2688 - val_loss: 3.6214 - val_accuracy: 0.2657\n",
      "Epoch 56/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.6407 - accuracy: 0.2637 - val_loss: 3.5886 - val_accuracy: 0.2679\n",
      "Epoch 57/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.6043 - accuracy: 0.2683 - val_loss: 3.5858 - val_accuracy: 0.2695\n",
      "Epoch 58/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5888 - accuracy: 0.2683 - val_loss: 3.5914 - val_accuracy: 0.2648\n",
      "Epoch 59/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5838 - accuracy: 0.2663 - val_loss: 3.5687 - val_accuracy: 0.2681\n",
      "Epoch 60/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.5669 - accuracy: 0.2689 - val_loss: 3.5532 - val_accuracy: 0.2725\n",
      "Epoch 61/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5652 - accuracy: 0.2699 - val_loss: 3.5315 - val_accuracy: 0.2771\n",
      "Epoch 62/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5446 - accuracy: 0.2731 - val_loss: 3.5392 - val_accuracy: 0.2789\n",
      "Epoch 63/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5409 - accuracy: 0.2765 - val_loss: 3.5424 - val_accuracy: 0.2801\n",
      "Epoch 64/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.5305 - accuracy: 0.2770 - val_loss: 3.5064 - val_accuracy: 0.2769\n",
      "Epoch 65/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5123 - accuracy: 0.2754 - val_loss: 3.5210 - val_accuracy: 0.2718\n",
      "Epoch 66/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.5871 - accuracy: 0.2680 - val_loss: 3.5946 - val_accuracy: 0.2670\n",
      "Epoch 67/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5496 - accuracy: 0.2715 - val_loss: 3.6058 - val_accuracy: 0.2654\n",
      "Epoch 68/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5776 - accuracy: 0.2700 - val_loss: 3.5482 - val_accuracy: 0.2773\n",
      "Epoch 69/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5435 - accuracy: 0.2743 - val_loss: 3.5328 - val_accuracy: 0.2801\n",
      "Epoch 70/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5425 - accuracy: 0.2752 - val_loss: 3.5322 - val_accuracy: 0.2772\n",
      "Epoch 71/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5526 - accuracy: 0.2728 - val_loss: 3.5121 - val_accuracy: 0.2787\n",
      "Epoch 72/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5171 - accuracy: 0.2778 - val_loss: 3.5332 - val_accuracy: 0.2764\n",
      "Epoch 73/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.5323 - accuracy: 0.2754 - val_loss: 3.5352 - val_accuracy: 0.2750\n",
      "Epoch 74/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.5198 - accuracy: 0.2760 - val_loss: 3.5293 - val_accuracy: 0.2762\n",
      "Epoch 75/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.5234 - accuracy: 0.2790 - val_loss: 3.5037 - val_accuracy: 0.2796\n",
      "Epoch 76/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4996 - accuracy: 0.2772 - val_loss: 3.4916 - val_accuracy: 0.2821\n",
      "Epoch 77/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4907 - accuracy: 0.2788 - val_loss: 3.4821 - val_accuracy: 0.2851\n",
      "Epoch 78/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4929 - accuracy: 0.2797 - val_loss: 3.4740 - val_accuracy: 0.2865\n",
      "Epoch 79/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4904 - accuracy: 0.2784 - val_loss: 3.4767 - val_accuracy: 0.2855\n",
      "Epoch 80/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4721 - accuracy: 0.2844 - val_loss: 3.4782 - val_accuracy: 0.2843\n",
      "Epoch 81/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.4682 - accuracy: 0.2851 - val_loss: 3.4565 - val_accuracy: 0.2833\n",
      "Epoch 82/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.4545 - accuracy: 0.2832 - val_loss: 3.4451 - val_accuracy: 0.2841\n",
      "Epoch 83/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4661 - accuracy: 0.2797 - val_loss: 3.4396 - val_accuracy: 0.2880\n",
      "Epoch 84/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4471 - accuracy: 0.2838 - val_loss: 3.4469 - val_accuracy: 0.2871\n",
      "Epoch 85/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4508 - accuracy: 0.2853 - val_loss: 3.4351 - val_accuracy: 0.2880\n",
      "Epoch 86/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.4499 - accuracy: 0.2838 - val_loss: 3.4221 - val_accuracy: 0.2899\n",
      "Epoch 87/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4374 - accuracy: 0.2862 - val_loss: 3.4172 - val_accuracy: 0.2880\n",
      "Epoch 88/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4225 - accuracy: 0.2857 - val_loss: 3.4214 - val_accuracy: 0.2861\n",
      "Epoch 89/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.4187 - accuracy: 0.2847 - val_loss: 3.4146 - val_accuracy: 0.2884\n",
      "Epoch 90/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.4064 - accuracy: 0.2866 - val_loss: 3.3982 - val_accuracy: 0.2902\n",
      "Epoch 91/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3963 - accuracy: 0.2886 - val_loss: 3.3778 - val_accuracy: 0.2907\n",
      "Epoch 92/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3860 - accuracy: 0.2887 - val_loss: 3.3637 - val_accuracy: 0.2936\n",
      "Epoch 93/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3852 - accuracy: 0.2878 - val_loss: 3.3613 - val_accuracy: 0.2964\n",
      "Epoch 94/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.3777 - accuracy: 0.2939 - val_loss: 3.3714 - val_accuracy: 0.2910\n",
      "Epoch 95/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3680 - accuracy: 0.2929 - val_loss: 3.3502 - val_accuracy: 0.2893\n",
      "Epoch 96/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3562 - accuracy: 0.2903 - val_loss: 3.3457 - val_accuracy: 0.2897\n",
      "Epoch 97/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3602 - accuracy: 0.2898 - val_loss: 3.3405 - val_accuracy: 0.2939\n",
      "Epoch 98/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3532 - accuracy: 0.2896 - val_loss: 3.3130 - val_accuracy: 0.2983\n",
      "Epoch 99/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3219 - accuracy: 0.2973 - val_loss: 3.3111 - val_accuracy: 0.3050\n",
      "Epoch 100/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.3383 - accuracy: 0.3000 - val_loss: 3.2986 - val_accuracy: 0.3046\n",
      "Epoch 101/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.3228 - accuracy: 0.2995 - val_loss: 3.3009 - val_accuracy: 0.3022\n",
      "Epoch 102/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3219 - accuracy: 0.2997 - val_loss: 3.3121 - val_accuracy: 0.3096\n",
      "Epoch 103/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.3094 - accuracy: 0.3050 - val_loss: 3.2727 - val_accuracy: 0.3134\n",
      "Epoch 104/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2850 - accuracy: 0.3095 - val_loss: 3.2585 - val_accuracy: 0.3113\n",
      "Epoch 105/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2774 - accuracy: 0.3092 - val_loss: 3.2400 - val_accuracy: 0.3138\n",
      "Epoch 106/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2579 - accuracy: 0.3099 - val_loss: 3.2493 - val_accuracy: 0.3172\n",
      "Epoch 107/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2486 - accuracy: 0.3159 - val_loss: 3.2184 - val_accuracy: 0.3242\n",
      "Epoch 108/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2268 - accuracy: 0.3169 - val_loss: 3.1983 - val_accuracy: 0.3239\n",
      "Epoch 109/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2200 - accuracy: 0.3185 - val_loss: 3.2034 - val_accuracy: 0.3299\n",
      "Epoch 110/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2116 - accuracy: 0.3229 - val_loss: 3.1910 - val_accuracy: 0.3199\n",
      "Epoch 111/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2072 - accuracy: 0.3178 - val_loss: 3.1804 - val_accuracy: 0.3297\n",
      "Epoch 112/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 3.1873 - accuracy: 0.3221 - val_loss: 3.1552 - val_accuracy: 0.3335\n",
      "Epoch 113/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1753 - accuracy: 0.3261 - val_loss: 3.1483 - val_accuracy: 0.3305\n",
      "Epoch 114/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1746 - accuracy: 0.3225 - val_loss: 3.1355 - val_accuracy: 0.3336\n",
      "Epoch 115/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1536 - accuracy: 0.3264 - val_loss: 3.1397 - val_accuracy: 0.3313\n",
      "Epoch 116/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1605 - accuracy: 0.3219 - val_loss: 3.1340 - val_accuracy: 0.3317\n",
      "Epoch 117/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1420 - accuracy: 0.3266 - val_loss: 3.1079 - val_accuracy: 0.3353\n",
      "Epoch 118/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1315 - accuracy: 0.3275 - val_loss: 3.1116 - val_accuracy: 0.3381\n",
      "Epoch 119/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1416 - accuracy: 0.3291 - val_loss: 3.1321 - val_accuracy: 0.3273\n",
      "Epoch 120/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1367 - accuracy: 0.3261 - val_loss: 3.1236 - val_accuracy: 0.3297\n",
      "Epoch 121/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.1400 - accuracy: 0.3264 - val_loss: 3.0781 - val_accuracy: 0.3414\n",
      "Epoch 122/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1046 - accuracy: 0.3323 - val_loss: 3.0667 - val_accuracy: 0.3481\n",
      "Epoch 123/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1040 - accuracy: 0.3359 - val_loss: 3.0589 - val_accuracy: 0.3348\n",
      "Epoch 124/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.0891 - accuracy: 0.3293 - val_loss: 3.1445 - val_accuracy: 0.3308\n",
      "Epoch 125/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.1466 - accuracy: 0.3298 - val_loss: 3.2293 - val_accuracy: 0.3164\n",
      "Epoch 126/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2543 - accuracy: 0.3145 - val_loss: 3.2697 - val_accuracy: 0.3191\n",
      "Epoch 127/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2796 - accuracy: 0.3172 - val_loss: 3.1659 - val_accuracy: 0.3304\n",
      "Epoch 128/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.2027 - accuracy: 0.3252 - val_loss: 3.0984 - val_accuracy: 0.3354\n",
      "Epoch 129/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1267 - accuracy: 0.3322 - val_loss: 3.1268 - val_accuracy: 0.3290\n",
      "Epoch 130/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1376 - accuracy: 0.3262 - val_loss: 3.0821 - val_accuracy: 0.3323\n",
      "Epoch 131/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1189 - accuracy: 0.3233 - val_loss: 3.0604 - val_accuracy: 0.3409\n",
      "Epoch 132/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.1050 - accuracy: 0.3295 - val_loss: 3.0559 - val_accuracy: 0.3415\n",
      "Epoch 133/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.0835 - accuracy: 0.3360 - val_loss: 3.0593 - val_accuracy: 0.3476\n",
      "Epoch 134/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.0811 - accuracy: 0.3385 - val_loss: 3.0331 - val_accuracy: 0.3530\n",
      "Epoch 135/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.0628 - accuracy: 0.3415 - val_loss: 3.0070 - val_accuracy: 0.3543\n",
      "Epoch 136/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.0488 - accuracy: 0.3445 - val_loss: 2.9921 - val_accuracy: 0.3556\n",
      "Epoch 137/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.0307 - accuracy: 0.3465 - val_loss: 2.9863 - val_accuracy: 0.3585\n",
      "Epoch 138/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.0162 - accuracy: 0.3478 - val_loss: 2.9839 - val_accuracy: 0.3545\n",
      "Epoch 139/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.0104 - accuracy: 0.3531 - val_loss: 2.9627 - val_accuracy: 0.3559\n",
      "Epoch 140/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9987 - accuracy: 0.3519 - val_loss: 2.9388 - val_accuracy: 0.3639\n",
      "Epoch 141/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9906 - accuracy: 0.3545 - val_loss: 2.9334 - val_accuracy: 0.3673\n",
      "Epoch 142/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.9674 - accuracy: 0.3594 - val_loss: 2.9287 - val_accuracy: 0.3679\n",
      "Epoch 143/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.9670 - accuracy: 0.3578 - val_loss: 2.9207 - val_accuracy: 0.3720\n",
      "Epoch 144/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9528 - accuracy: 0.3628 - val_loss: 2.9138 - val_accuracy: 0.3743\n",
      "Epoch 145/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9495 - accuracy: 0.3619 - val_loss: 2.8985 - val_accuracy: 0.3763\n",
      "Epoch 146/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9384 - accuracy: 0.3623 - val_loss: 2.8923 - val_accuracy: 0.3756\n",
      "Epoch 147/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9192 - accuracy: 0.3672 - val_loss: 2.8865 - val_accuracy: 0.3771\n",
      "Epoch 148/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.9215 - accuracy: 0.3673 - val_loss: 2.8820 - val_accuracy: 0.3768\n",
      "Epoch 149/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9313 - accuracy: 0.3671 - val_loss: 2.8748 - val_accuracy: 0.3790\n",
      "Epoch 150/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9088 - accuracy: 0.3719 - val_loss: 2.8622 - val_accuracy: 0.3819\n",
      "Epoch 151/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.8977 - accuracy: 0.3703 - val_loss: 2.8628 - val_accuracy: 0.3791\n",
      "Epoch 152/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9176 - accuracy: 0.3679 - val_loss: 2.8619 - val_accuracy: 0.3788\n",
      "Epoch 153/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9000 - accuracy: 0.3693 - val_loss: 2.8531 - val_accuracy: 0.3856\n",
      "Epoch 154/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8934 - accuracy: 0.3750 - val_loss: 2.8465 - val_accuracy: 0.3862\n",
      "Epoch 155/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9111 - accuracy: 0.3736 - val_loss: 2.8496 - val_accuracy: 0.3830\n",
      "Epoch 156/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.8958 - accuracy: 0.3698 - val_loss: 2.8707 - val_accuracy: 0.3767\n",
      "Epoch 157/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.9004 - accuracy: 0.3688 - val_loss: 2.8298 - val_accuracy: 0.3891\n",
      "Epoch 158/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8614 - accuracy: 0.3795 - val_loss: 2.8260 - val_accuracy: 0.3975\n",
      "Epoch 159/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8764 - accuracy: 0.3819 - val_loss: 2.8015 - val_accuracy: 0.3955\n",
      "Epoch 160/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.8471 - accuracy: 0.3805 - val_loss: 2.8210 - val_accuracy: 0.3918\n",
      "Epoch 161/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8547 - accuracy: 0.3799 - val_loss: 2.8053 - val_accuracy: 0.3914\n",
      "Epoch 162/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8391 - accuracy: 0.3800 - val_loss: 2.7931 - val_accuracy: 0.3963\n",
      "Epoch 163/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8400 - accuracy: 0.3849 - val_loss: 2.7805 - val_accuracy: 0.4034\n",
      "Epoch 164/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8232 - accuracy: 0.3883 - val_loss: 2.7876 - val_accuracy: 0.3960\n",
      "Epoch 165/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.8226 - accuracy: 0.3836 - val_loss: 2.7768 - val_accuracy: 0.3992\n",
      "Epoch 166/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8213 - accuracy: 0.3843 - val_loss: 2.7634 - val_accuracy: 0.4040\n",
      "Epoch 167/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8114 - accuracy: 0.3902 - val_loss: 2.7730 - val_accuracy: 0.4003\n",
      "Epoch 168/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.8134 - accuracy: 0.3883 - val_loss: 2.7635 - val_accuracy: 0.4022\n",
      "Epoch 169/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 2.7992 - accuracy: 0.3908 - val_loss: 2.7536 - val_accuracy: 0.4059\n",
      "Epoch 170/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7949 - accuracy: 0.3898 - val_loss: 2.7492 - val_accuracy: 0.4081\n",
      "Epoch 171/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7853 - accuracy: 0.3921 - val_loss: 2.7524 - val_accuracy: 0.4063\n",
      "Epoch 172/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7894 - accuracy: 0.3935 - val_loss: 2.7466 - val_accuracy: 0.4039\n",
      "Epoch 173/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7866 - accuracy: 0.3893 - val_loss: 2.7497 - val_accuracy: 0.4076\n",
      "Epoch 174/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7844 - accuracy: 0.3935 - val_loss: 2.7515 - val_accuracy: 0.4069\n",
      "Epoch 175/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7834 - accuracy: 0.3919 - val_loss: 2.7524 - val_accuracy: 0.4057\n",
      "Epoch 176/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7848 - accuracy: 0.3940 - val_loss: 2.7545 - val_accuracy: 0.4141\n",
      "Epoch 177/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7938 - accuracy: 0.3968 - val_loss: 2.7560 - val_accuracy: 0.4056\n",
      "Epoch 178/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7887 - accuracy: 0.3933 - val_loss: 2.7477 - val_accuracy: 0.4060\n",
      "Epoch 179/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7820 - accuracy: 0.3903 - val_loss: 2.7360 - val_accuracy: 0.4100\n",
      "Epoch 180/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7685 - accuracy: 0.3974 - val_loss: 2.7251 - val_accuracy: 0.4143\n",
      "Epoch 181/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7680 - accuracy: 0.3991 - val_loss: 2.7115 - val_accuracy: 0.4181\n",
      "Epoch 182/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7529 - accuracy: 0.4000 - val_loss: 2.7268 - val_accuracy: 0.4106\n",
      "Epoch 183/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7625 - accuracy: 0.3965 - val_loss: 2.7139 - val_accuracy: 0.4088\n",
      "Epoch 184/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7506 - accuracy: 0.3968 - val_loss: 2.7088 - val_accuracy: 0.4189\n",
      "Epoch 185/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7507 - accuracy: 0.4037 - val_loss: 2.7116 - val_accuracy: 0.4242\n",
      "Epoch 186/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7475 - accuracy: 0.4050 - val_loss: 2.7196 - val_accuracy: 0.4086\n",
      "Epoch 187/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7720 - accuracy: 0.3923 - val_loss: 2.7266 - val_accuracy: 0.4139\n",
      "Epoch 188/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.7545 - accuracy: 0.4006 - val_loss: 2.7217 - val_accuracy: 0.4146\n",
      "Epoch 189/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7417 - accuracy: 0.4049 - val_loss: 2.6934 - val_accuracy: 0.4254\n",
      "Epoch 190/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7363 - accuracy: 0.4045 - val_loss: 2.6852 - val_accuracy: 0.4257\n",
      "Epoch 191/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7307 - accuracy: 0.4047 - val_loss: 2.6911 - val_accuracy: 0.4198\n",
      "Epoch 192/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.7262 - accuracy: 0.4055 - val_loss: 2.6898 - val_accuracy: 0.4244\n",
      "Epoch 193/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7217 - accuracy: 0.4088 - val_loss: 2.6855 - val_accuracy: 0.4223\n",
      "Epoch 194/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7168 - accuracy: 0.4058 - val_loss: 2.6790 - val_accuracy: 0.4268\n",
      "Epoch 195/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7155 - accuracy: 0.4082 - val_loss: 2.6684 - val_accuracy: 0.4316\n",
      "Epoch 196/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7085 - accuracy: 0.4122 - val_loss: 2.6634 - val_accuracy: 0.4292\n",
      "Epoch 197/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7095 - accuracy: 0.4116 - val_loss: 2.6650 - val_accuracy: 0.4267\n",
      "Epoch 198/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.7041 - accuracy: 0.4110 - val_loss: 2.6644 - val_accuracy: 0.4319\n",
      "Epoch 199/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6931 - accuracy: 0.4140 - val_loss: 2.6564 - val_accuracy: 0.4348\n",
      "Epoch 200/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6913 - accuracy: 0.4138 - val_loss: 2.6466 - val_accuracy: 0.4375\n",
      "Epoch 201/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6823 - accuracy: 0.4141 - val_loss: 2.6577 - val_accuracy: 0.4326\n",
      "Epoch 202/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.6874 - accuracy: 0.4151 - val_loss: 2.6558 - val_accuracy: 0.4340\n",
      "Epoch 203/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6846 - accuracy: 0.4156 - val_loss: 2.6587 - val_accuracy: 0.4297\n",
      "Epoch 204/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6829 - accuracy: 0.4151 - val_loss: 2.6494 - val_accuracy: 0.4322\n",
      "Epoch 205/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6710 - accuracy: 0.4192 - val_loss: 2.6359 - val_accuracy: 0.4386\n",
      "Epoch 206/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6772 - accuracy: 0.4184 - val_loss: 2.6467 - val_accuracy: 0.4352\n",
      "Epoch 207/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.6851 - accuracy: 0.4158 - val_loss: 2.6483 - val_accuracy: 0.4337\n",
      "Epoch 208/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6827 - accuracy: 0.4163 - val_loss: 2.6585 - val_accuracy: 0.4391\n",
      "Epoch 209/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6768 - accuracy: 0.4224 - val_loss: 2.6491 - val_accuracy: 0.4355\n",
      "Epoch 210/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6818 - accuracy: 0.4168 - val_loss: 2.6293 - val_accuracy: 0.4382\n",
      "Epoch 211/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.6744 - accuracy: 0.4171 - val_loss: 2.6408 - val_accuracy: 0.4383\n",
      "Epoch 212/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6713 - accuracy: 0.4185 - val_loss: 2.6324 - val_accuracy: 0.4388\n",
      "Epoch 213/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6670 - accuracy: 0.4156 - val_loss: 2.6320 - val_accuracy: 0.4402\n",
      "Epoch 214/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6626 - accuracy: 0.4227 - val_loss: 2.6277 - val_accuracy: 0.4408\n",
      "Epoch 215/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6507 - accuracy: 0.4227 - val_loss: 2.6316 - val_accuracy: 0.4345\n",
      "Epoch 216/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6589 - accuracy: 0.4175 - val_loss: 2.6205 - val_accuracy: 0.4408\n",
      "Epoch 217/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6485 - accuracy: 0.4239 - val_loss: 2.6212 - val_accuracy: 0.4437\n",
      "Epoch 218/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6547 - accuracy: 0.4231 - val_loss: 2.6284 - val_accuracy: 0.4371\n",
      "Epoch 219/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6603 - accuracy: 0.4165 - val_loss: 2.6223 - val_accuracy: 0.4433\n",
      "Epoch 220/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6531 - accuracy: 0.4222 - val_loss: 2.6377 - val_accuracy: 0.4380\n",
      "Epoch 221/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6611 - accuracy: 0.4191 - val_loss: 2.6242 - val_accuracy: 0.4433\n",
      "Epoch 222/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6386 - accuracy: 0.4240 - val_loss: 2.6139 - val_accuracy: 0.4489\n",
      "Epoch 223/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6352 - accuracy: 0.4270 - val_loss: 2.6041 - val_accuracy: 0.4472\n",
      "Epoch 224/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6334 - accuracy: 0.4260 - val_loss: 2.6079 - val_accuracy: 0.4466\n",
      "Epoch 225/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.6244 - accuracy: 0.4283 - val_loss: 2.6093 - val_accuracy: 0.4439\n",
      "Epoch 226/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 2.6294 - accuracy: 0.4253 - val_loss: 2.6086 - val_accuracy: 0.4437\n",
      "Epoch 227/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6340 - accuracy: 0.4240 - val_loss: 2.6158 - val_accuracy: 0.4454\n",
      "Epoch 228/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6307 - accuracy: 0.4279 - val_loss: 2.5975 - val_accuracy: 0.4440\n",
      "Epoch 229/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6211 - accuracy: 0.4252 - val_loss: 2.6088 - val_accuracy: 0.4483\n",
      "Epoch 230/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6417 - accuracy: 0.4243 - val_loss: 2.5969 - val_accuracy: 0.4427\n",
      "Epoch 231/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6137 - accuracy: 0.4262 - val_loss: 2.6008 - val_accuracy: 0.4457\n",
      "Epoch 232/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6229 - accuracy: 0.4263 - val_loss: 2.5983 - val_accuracy: 0.4481\n",
      "Epoch 233/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6194 - accuracy: 0.4302 - val_loss: 2.5858 - val_accuracy: 0.4485\n",
      "Epoch 234/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6107 - accuracy: 0.4279 - val_loss: 2.6003 - val_accuracy: 0.4527\n",
      "Epoch 235/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6126 - accuracy: 0.4325 - val_loss: 2.6008 - val_accuracy: 0.4467\n",
      "Epoch 236/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.6080 - accuracy: 0.4290 - val_loss: 2.5844 - val_accuracy: 0.4522\n",
      "Epoch 237/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6007 - accuracy: 0.4317 - val_loss: 2.5846 - val_accuracy: 0.4548\n",
      "Epoch 238/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6002 - accuracy: 0.4338 - val_loss: 2.5858 - val_accuracy: 0.4499\n",
      "Epoch 239/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6111 - accuracy: 0.4298 - val_loss: 2.6009 - val_accuracy: 0.4543\n",
      "Epoch 240/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6103 - accuracy: 0.4338 - val_loss: 2.5902 - val_accuracy: 0.4518\n",
      "Epoch 241/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6046 - accuracy: 0.4301 - val_loss: 2.5816 - val_accuracy: 0.4475\n",
      "Epoch 242/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5968 - accuracy: 0.4287 - val_loss: 2.5895 - val_accuracy: 0.4541\n",
      "Epoch 243/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5992 - accuracy: 0.4345 - val_loss: 2.5949 - val_accuracy: 0.4516\n",
      "Epoch 244/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.6042 - accuracy: 0.4324 - val_loss: 2.5800 - val_accuracy: 0.4491\n",
      "Epoch 245/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5977 - accuracy: 0.4299 - val_loss: 2.5837 - val_accuracy: 0.4552\n",
      "Epoch 246/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5960 - accuracy: 0.4350 - val_loss: 2.5816 - val_accuracy: 0.4496\n",
      "Epoch 247/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5947 - accuracy: 0.4299 - val_loss: 2.5906 - val_accuracy: 0.4580\n",
      "Epoch 248/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.6008 - accuracy: 0.4345 - val_loss: 2.5790 - val_accuracy: 0.4599\n",
      "Epoch 249/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5863 - accuracy: 0.4358 - val_loss: 2.5742 - val_accuracy: 0.4510\n",
      "Epoch 250/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5909 - accuracy: 0.4309 - val_loss: 2.5898 - val_accuracy: 0.4542\n",
      "Epoch 251/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5903 - accuracy: 0.4374 - val_loss: 2.5703 - val_accuracy: 0.4550\n",
      "Epoch 252/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5864 - accuracy: 0.4344 - val_loss: 2.5652 - val_accuracy: 0.4575\n",
      "Epoch 253/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5784 - accuracy: 0.4360 - val_loss: 2.5804 - val_accuracy: 0.4626\n",
      "Epoch 254/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5891 - accuracy: 0.4386 - val_loss: 2.5706 - val_accuracy: 0.4554\n",
      "Epoch 255/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5862 - accuracy: 0.4331 - val_loss: 2.5594 - val_accuracy: 0.4545\n",
      "Epoch 256/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5815 - accuracy: 0.4330 - val_loss: 2.5750 - val_accuracy: 0.4566\n",
      "Epoch 257/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5820 - accuracy: 0.4375 - val_loss: 2.5737 - val_accuracy: 0.4530\n",
      "Epoch 258/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5779 - accuracy: 0.4346 - val_loss: 2.5612 - val_accuracy: 0.4545\n",
      "Epoch 259/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5690 - accuracy: 0.4367 - val_loss: 2.5595 - val_accuracy: 0.4619\n",
      "Epoch 260/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5734 - accuracy: 0.4401 - val_loss: 2.5611 - val_accuracy: 0.4578\n",
      "Epoch 261/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5698 - accuracy: 0.4364 - val_loss: 2.5760 - val_accuracy: 0.4588\n",
      "Epoch 262/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5658 - accuracy: 0.4409 - val_loss: 2.5654 - val_accuracy: 0.4560\n",
      "Epoch 263/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5721 - accuracy: 0.4360 - val_loss: 2.5538 - val_accuracy: 0.4587\n",
      "Epoch 264/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5669 - accuracy: 0.4384 - val_loss: 2.5607 - val_accuracy: 0.4581\n",
      "Epoch 265/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5651 - accuracy: 0.4395 - val_loss: 2.5669 - val_accuracy: 0.4561\n",
      "Epoch 266/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5700 - accuracy: 0.4403 - val_loss: 2.5581 - val_accuracy: 0.4550\n",
      "Epoch 267/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5685 - accuracy: 0.4362 - val_loss: 2.5464 - val_accuracy: 0.4574\n",
      "Epoch 268/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5697 - accuracy: 0.4370 - val_loss: 2.5573 - val_accuracy: 0.4555\n",
      "Epoch 269/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5670 - accuracy: 0.4379 - val_loss: 2.5568 - val_accuracy: 0.4584\n",
      "Epoch 270/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5608 - accuracy: 0.4378 - val_loss: 2.5559 - val_accuracy: 0.4591\n",
      "Epoch 271/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5575 - accuracy: 0.4422 - val_loss: 2.5484 - val_accuracy: 0.4577\n",
      "Epoch 272/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5542 - accuracy: 0.4428 - val_loss: 2.5456 - val_accuracy: 0.4596\n",
      "Epoch 273/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5545 - accuracy: 0.4403 - val_loss: 2.5582 - val_accuracy: 0.4618\n",
      "Epoch 274/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5468 - accuracy: 0.4441 - val_loss: 2.5479 - val_accuracy: 0.4588\n",
      "Epoch 275/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5511 - accuracy: 0.4391 - val_loss: 2.5456 - val_accuracy: 0.4624\n",
      "Epoch 276/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5477 - accuracy: 0.4426 - val_loss: 2.5395 - val_accuracy: 0.4638\n",
      "Epoch 277/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5446 - accuracy: 0.4437 - val_loss: 2.5523 - val_accuracy: 0.4631\n",
      "Epoch 278/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5514 - accuracy: 0.4437 - val_loss: 2.5456 - val_accuracy: 0.4631\n",
      "Epoch 279/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5389 - accuracy: 0.4461 - val_loss: 2.5401 - val_accuracy: 0.4607\n",
      "Epoch 280/12000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.5463 - accuracy: 0.4434 - val_loss: 2.5558 - val_accuracy: 0.4609\n",
      "Epoch 281/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5504 - accuracy: 0.4445 - val_loss: 2.5506 - val_accuracy: 0.4564\n",
      "Epoch 282/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5534 - accuracy: 0.4411 - val_loss: 2.5465 - val_accuracy: 0.4610\n",
      "Epoch 283/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 2.5424 - accuracy: 0.4444 - val_loss: 2.5326 - val_accuracy: 0.4630\n",
      "Epoch 284/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5383 - accuracy: 0.4425 - val_loss: 2.5471 - val_accuracy: 0.4627\n",
      "Epoch 285/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5481 - accuracy: 0.4461 - val_loss: 2.5492 - val_accuracy: 0.4556\n",
      "Epoch 286/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5466 - accuracy: 0.4408 - val_loss: 2.5677 - val_accuracy: 0.4648\n",
      "Epoch 287/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5490 - accuracy: 0.4491 - val_loss: 2.5475 - val_accuracy: 0.4577\n",
      "Epoch 288/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5512 - accuracy: 0.4388 - val_loss: 2.5568 - val_accuracy: 0.4634\n",
      "Epoch 289/12000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.5474 - accuracy: 0.4456 - val_loss: 2.5375 - val_accuracy: 0.4654\n",
      "Epoch 290/12000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.5338 - accuracy: 0.4464 - val_loss: 2.5455 - val_accuracy: 0.4576\n",
      "Epoch 291/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5554 - accuracy: 0.4383 - val_loss: 2.5849 - val_accuracy: 0.4668\n",
      "Epoch 292/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5602 - accuracy: 0.4507 - val_loss: 2.5427 - val_accuracy: 0.4598\n",
      "Epoch 293/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5412 - accuracy: 0.4433 - val_loss: 2.5428 - val_accuracy: 0.4579\n",
      "Epoch 294/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5582 - accuracy: 0.4371 - val_loss: 2.5618 - val_accuracy: 0.4677\n",
      "Epoch 295/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5536 - accuracy: 0.4485 - val_loss: 2.5518 - val_accuracy: 0.4579\n",
      "Epoch 296/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5528 - accuracy: 0.4419 - val_loss: 2.5372 - val_accuracy: 0.4599\n",
      "Epoch 297/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5371 - accuracy: 0.4408 - val_loss: 2.5482 - val_accuracy: 0.4706\n",
      "Epoch 298/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5505 - accuracy: 0.4475 - val_loss: 2.5324 - val_accuracy: 0.4610\n",
      "Epoch 299/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5343 - accuracy: 0.4460 - val_loss: 2.5407 - val_accuracy: 0.4585\n",
      "Epoch 300/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5383 - accuracy: 0.4440 - val_loss: 2.5437 - val_accuracy: 0.4676\n",
      "Epoch 301/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5269 - accuracy: 0.4509 - val_loss: 2.5429 - val_accuracy: 0.4680\n",
      "Epoch 302/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5251 - accuracy: 0.4498 - val_loss: 2.5383 - val_accuracy: 0.4616\n",
      "Epoch 303/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5296 - accuracy: 0.4432 - val_loss: 2.5357 - val_accuracy: 0.4678\n",
      "Epoch 304/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5304 - accuracy: 0.4473 - val_loss: 2.5255 - val_accuracy: 0.4694\n",
      "Epoch 305/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5165 - accuracy: 0.4504 - val_loss: 2.5279 - val_accuracy: 0.4695\n",
      "Epoch 306/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5226 - accuracy: 0.4506 - val_loss: 2.5243 - val_accuracy: 0.4670\n",
      "Epoch 307/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5204 - accuracy: 0.4490 - val_loss: 2.5357 - val_accuracy: 0.4684\n",
      "Epoch 308/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5218 - accuracy: 0.4499 - val_loss: 2.5236 - val_accuracy: 0.4701\n",
      "Epoch 309/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5182 - accuracy: 0.4481 - val_loss: 2.5256 - val_accuracy: 0.4690\n",
      "Epoch 310/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5129 - accuracy: 0.4491 - val_loss: 2.5248 - val_accuracy: 0.4684\n",
      "Epoch 311/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5173 - accuracy: 0.4498 - val_loss: 2.5245 - val_accuracy: 0.4683\n",
      "Epoch 312/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5131 - accuracy: 0.4496 - val_loss: 2.5292 - val_accuracy: 0.4659\n",
      "Epoch 313/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5102 - accuracy: 0.4493 - val_loss: 2.5294 - val_accuracy: 0.4712\n",
      "Epoch 314/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5107 - accuracy: 0.4535 - val_loss: 2.5207 - val_accuracy: 0.4707\n",
      "Epoch 315/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5180 - accuracy: 0.4502 - val_loss: 2.5107 - val_accuracy: 0.4699\n",
      "Epoch 316/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5065 - accuracy: 0.4495 - val_loss: 2.5214 - val_accuracy: 0.4749\n",
      "Epoch 317/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5045 - accuracy: 0.4531 - val_loss: 2.5125 - val_accuracy: 0.4653\n",
      "Epoch 318/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5075 - accuracy: 0.4479 - val_loss: 2.5302 - val_accuracy: 0.4667\n",
      "Epoch 319/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5227 - accuracy: 0.4503 - val_loss: 2.5284 - val_accuracy: 0.4676\n",
      "Epoch 320/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5228 - accuracy: 0.4488 - val_loss: 2.5109 - val_accuracy: 0.4695\n",
      "Epoch 321/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4986 - accuracy: 0.4529 - val_loss: 2.5128 - val_accuracy: 0.4723\n",
      "Epoch 322/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5097 - accuracy: 0.4530 - val_loss: 2.5156 - val_accuracy: 0.4690\n",
      "Epoch 323/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5153 - accuracy: 0.4483 - val_loss: 2.5212 - val_accuracy: 0.4689\n",
      "Epoch 324/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5092 - accuracy: 0.4507 - val_loss: 2.5254 - val_accuracy: 0.4668\n",
      "Epoch 325/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5063 - accuracy: 0.4513 - val_loss: 2.5163 - val_accuracy: 0.4721\n",
      "Epoch 326/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4934 - accuracy: 0.4567 - val_loss: 2.5062 - val_accuracy: 0.4707\n",
      "Epoch 327/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5018 - accuracy: 0.4518 - val_loss: 2.5242 - val_accuracy: 0.4733\n",
      "Epoch 328/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5081 - accuracy: 0.4544 - val_loss: 2.5158 - val_accuracy: 0.4706\n",
      "Epoch 329/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5017 - accuracy: 0.4528 - val_loss: 2.5079 - val_accuracy: 0.4682\n",
      "Epoch 330/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4963 - accuracy: 0.4510 - val_loss: 2.5123 - val_accuracy: 0.4704\n",
      "Epoch 331/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4997 - accuracy: 0.4541 - val_loss: 2.5079 - val_accuracy: 0.4706\n",
      "Epoch 332/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4931 - accuracy: 0.4535 - val_loss: 2.5103 - val_accuracy: 0.4714\n",
      "Epoch 333/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5013 - accuracy: 0.4516 - val_loss: 2.5116 - val_accuracy: 0.4714\n",
      "Epoch 334/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4968 - accuracy: 0.4541 - val_loss: 2.5145 - val_accuracy: 0.4684\n",
      "Epoch 335/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4947 - accuracy: 0.4542 - val_loss: 2.5082 - val_accuracy: 0.4700\n",
      "Epoch 336/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4916 - accuracy: 0.4538 - val_loss: 2.5138 - val_accuracy: 0.4749\n",
      "Epoch 337/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4926 - accuracy: 0.4561 - val_loss: 2.5162 - val_accuracy: 0.4708\n",
      "Epoch 338/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5009 - accuracy: 0.4527 - val_loss: 2.5186 - val_accuracy: 0.4670\n",
      "Epoch 339/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4890 - accuracy: 0.4531 - val_loss: 2.5197 - val_accuracy: 0.4711\n",
      "Epoch 340/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4947 - accuracy: 0.4552 - val_loss: 2.5030 - val_accuracy: 0.4729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4908 - accuracy: 0.4538 - val_loss: 2.4996 - val_accuracy: 0.4735\n",
      "Epoch 342/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4847 - accuracy: 0.4562 - val_loss: 2.5132 - val_accuracy: 0.4733\n",
      "Epoch 343/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4847 - accuracy: 0.4590 - val_loss: 2.5031 - val_accuracy: 0.4684\n",
      "Epoch 344/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4928 - accuracy: 0.4496 - val_loss: 2.5194 - val_accuracy: 0.4719\n",
      "Epoch 345/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4902 - accuracy: 0.4556 - val_loss: 2.5155 - val_accuracy: 0.4684\n",
      "Epoch 346/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4965 - accuracy: 0.4537 - val_loss: 2.5201 - val_accuracy: 0.4706\n",
      "Epoch 347/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5058 - accuracy: 0.4532 - val_loss: 2.5208 - val_accuracy: 0.4703\n",
      "Epoch 348/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4962 - accuracy: 0.4543 - val_loss: 2.5112 - val_accuracy: 0.4703\n",
      "Epoch 349/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4929 - accuracy: 0.4528 - val_loss: 2.5215 - val_accuracy: 0.4744\n",
      "Epoch 350/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4975 - accuracy: 0.4577 - val_loss: 2.5055 - val_accuracy: 0.4730\n",
      "Epoch 351/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4916 - accuracy: 0.4534 - val_loss: 2.5072 - val_accuracy: 0.4750\n",
      "Epoch 352/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4860 - accuracy: 0.4569 - val_loss: 2.5070 - val_accuracy: 0.4743\n",
      "Epoch 353/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4859 - accuracy: 0.4584 - val_loss: 2.5050 - val_accuracy: 0.4694\n",
      "Epoch 354/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4782 - accuracy: 0.4570 - val_loss: 2.5055 - val_accuracy: 0.4699\n",
      "Epoch 355/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4769 - accuracy: 0.4563 - val_loss: 2.5105 - val_accuracy: 0.4752\n",
      "Epoch 356/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4813 - accuracy: 0.4585 - val_loss: 2.4988 - val_accuracy: 0.4754\n",
      "Epoch 357/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4832 - accuracy: 0.4556 - val_loss: 2.4981 - val_accuracy: 0.4712\n",
      "Epoch 358/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4802 - accuracy: 0.4533 - val_loss: 2.5150 - val_accuracy: 0.4739\n",
      "Epoch 359/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4745 - accuracy: 0.4612 - val_loss: 2.5083 - val_accuracy: 0.4734\n",
      "Epoch 360/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4863 - accuracy: 0.4552 - val_loss: 2.5099 - val_accuracy: 0.4775\n",
      "Epoch 361/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4812 - accuracy: 0.4593 - val_loss: 2.4983 - val_accuracy: 0.4725\n",
      "Epoch 362/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4797 - accuracy: 0.4563 - val_loss: 2.4928 - val_accuracy: 0.4733\n",
      "Epoch 363/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4724 - accuracy: 0.4564 - val_loss: 2.4975 - val_accuracy: 0.4770\n",
      "Epoch 364/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4734 - accuracy: 0.4595 - val_loss: 2.4980 - val_accuracy: 0.4736\n",
      "Epoch 365/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4765 - accuracy: 0.4578 - val_loss: 2.5141 - val_accuracy: 0.4747\n",
      "Epoch 366/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4775 - accuracy: 0.4596 - val_loss: 2.5039 - val_accuracy: 0.4725\n",
      "Epoch 367/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4784 - accuracy: 0.4570 - val_loss: 2.5071 - val_accuracy: 0.4736\n",
      "Epoch 368/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4686 - accuracy: 0.4611 - val_loss: 2.5011 - val_accuracy: 0.4789\n",
      "Epoch 369/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4656 - accuracy: 0.4623 - val_loss: 2.4945 - val_accuracy: 0.4742\n",
      "Epoch 370/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4665 - accuracy: 0.4575 - val_loss: 2.4940 - val_accuracy: 0.4773\n",
      "Epoch 371/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4749 - accuracy: 0.4587 - val_loss: 2.4953 - val_accuracy: 0.4773\n",
      "Epoch 372/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4667 - accuracy: 0.4624 - val_loss: 2.4993 - val_accuracy: 0.4732\n",
      "Epoch 373/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4752 - accuracy: 0.4551 - val_loss: 2.5188 - val_accuracy: 0.4774\n",
      "Epoch 374/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4782 - accuracy: 0.4612 - val_loss: 2.5090 - val_accuracy: 0.4704\n",
      "Epoch 375/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4809 - accuracy: 0.4531 - val_loss: 2.4948 - val_accuracy: 0.4753\n",
      "Epoch 376/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4768 - accuracy: 0.4588 - val_loss: 2.5058 - val_accuracy: 0.4752\n",
      "Epoch 377/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4729 - accuracy: 0.4621 - val_loss: 2.5036 - val_accuracy: 0.4721\n",
      "Epoch 378/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4826 - accuracy: 0.4578 - val_loss: 2.5141 - val_accuracy: 0.4740\n",
      "Epoch 379/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4807 - accuracy: 0.4608 - val_loss: 2.4966 - val_accuracy: 0.4701\n",
      "Epoch 380/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4692 - accuracy: 0.4573 - val_loss: 2.5120 - val_accuracy: 0.4769\n",
      "Epoch 381/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4713 - accuracy: 0.4613 - val_loss: 2.5012 - val_accuracy: 0.4758\n",
      "Epoch 382/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4668 - accuracy: 0.4595 - val_loss: 2.4941 - val_accuracy: 0.4704\n",
      "Epoch 383/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4685 - accuracy: 0.4554 - val_loss: 2.5148 - val_accuracy: 0.4785\n",
      "Epoch 384/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4739 - accuracy: 0.4636 - val_loss: 2.5038 - val_accuracy: 0.4709\n",
      "Epoch 385/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4793 - accuracy: 0.4541 - val_loss: 2.4995 - val_accuracy: 0.4746\n",
      "Epoch 386/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4632 - accuracy: 0.4595 - val_loss: 2.5078 - val_accuracy: 0.4765\n",
      "Epoch 387/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4661 - accuracy: 0.4635 - val_loss: 2.4931 - val_accuracy: 0.4724\n",
      "Epoch 388/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4650 - accuracy: 0.4594 - val_loss: 2.4941 - val_accuracy: 0.4726\n",
      "Epoch 389/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4795 - accuracy: 0.4557 - val_loss: 2.5197 - val_accuracy: 0.4807\n",
      "Epoch 390/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4734 - accuracy: 0.4632 - val_loss: 2.4996 - val_accuracy: 0.4706\n",
      "Epoch 391/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4706 - accuracy: 0.4552 - val_loss: 2.5073 - val_accuracy: 0.4715\n",
      "Epoch 392/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4667 - accuracy: 0.4578 - val_loss: 2.5052 - val_accuracy: 0.4767\n",
      "Epoch 393/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4653 - accuracy: 0.4633 - val_loss: 2.4894 - val_accuracy: 0.4780\n",
      "Epoch 394/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4607 - accuracy: 0.4608 - val_loss: 2.4985 - val_accuracy: 0.4756\n",
      "Epoch 395/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4579 - accuracy: 0.4616 - val_loss: 2.5088 - val_accuracy: 0.4792\n",
      "Epoch 396/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4659 - accuracy: 0.4644 - val_loss: 2.4960 - val_accuracy: 0.4748\n",
      "Epoch 397/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4639 - accuracy: 0.4604 - val_loss: 2.4965 - val_accuracy: 0.4753\n",
      "Epoch 398/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4756 - accuracy: 0.4561 - val_loss: 2.5306 - val_accuracy: 0.4785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4943 - accuracy: 0.4612 - val_loss: 2.5150 - val_accuracy: 0.4696\n",
      "Epoch 400/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4781 - accuracy: 0.4556 - val_loss: 2.5013 - val_accuracy: 0.4735\n",
      "Epoch 401/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4673 - accuracy: 0.4580 - val_loss: 2.4976 - val_accuracy: 0.4765\n",
      "Epoch 402/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4754 - accuracy: 0.4581 - val_loss: 2.4932 - val_accuracy: 0.4803\n",
      "Epoch 403/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4594 - accuracy: 0.4619 - val_loss: 2.4909 - val_accuracy: 0.4718\n",
      "Epoch 404/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4616 - accuracy: 0.4563 - val_loss: 2.4935 - val_accuracy: 0.4750\n",
      "Epoch 405/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4593 - accuracy: 0.4604 - val_loss: 2.5059 - val_accuracy: 0.4782\n",
      "Epoch 406/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4623 - accuracy: 0.4638 - val_loss: 2.5034 - val_accuracy: 0.4734\n",
      "Epoch 407/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4575 - accuracy: 0.4579 - val_loss: 2.4960 - val_accuracy: 0.4781\n",
      "Epoch 408/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4464 - accuracy: 0.4632 - val_loss: 2.4987 - val_accuracy: 0.4770\n",
      "Epoch 409/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4576 - accuracy: 0.4643 - val_loss: 2.4972 - val_accuracy: 0.4753\n",
      "Epoch 410/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4564 - accuracy: 0.4575 - val_loss: 2.5065 - val_accuracy: 0.4792\n",
      "Epoch 411/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4567 - accuracy: 0.4632 - val_loss: 2.4908 - val_accuracy: 0.4763\n",
      "Epoch 412/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4453 - accuracy: 0.4634 - val_loss: 2.4875 - val_accuracy: 0.4760\n",
      "Epoch 413/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4526 - accuracy: 0.4600 - val_loss: 2.5015 - val_accuracy: 0.4789\n",
      "Epoch 414/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4525 - accuracy: 0.4651 - val_loss: 2.5045 - val_accuracy: 0.4733\n",
      "Epoch 415/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4623 - accuracy: 0.4558 - val_loss: 2.4987 - val_accuracy: 0.4744\n",
      "Epoch 416/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4563 - accuracy: 0.4612 - val_loss: 2.4960 - val_accuracy: 0.4794\n",
      "Epoch 417/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4535 - accuracy: 0.4639 - val_loss: 2.5017 - val_accuracy: 0.4741\n",
      "Epoch 418/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4590 - accuracy: 0.4610 - val_loss: 2.4990 - val_accuracy: 0.4741\n",
      "Epoch 419/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4478 - accuracy: 0.4615 - val_loss: 2.4955 - val_accuracy: 0.4784\n",
      "Epoch 420/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4529 - accuracy: 0.4646 - val_loss: 2.4933 - val_accuracy: 0.4800\n",
      "Epoch 421/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4522 - accuracy: 0.4641 - val_loss: 2.4915 - val_accuracy: 0.4767\n",
      "Epoch 422/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4465 - accuracy: 0.4631 - val_loss: 2.4929 - val_accuracy: 0.4750\n",
      "Epoch 423/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4512 - accuracy: 0.4612 - val_loss: 2.4995 - val_accuracy: 0.4781\n",
      "Epoch 424/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4535 - accuracy: 0.4599 - val_loss: 2.5007 - val_accuracy: 0.4823\n",
      "Epoch 425/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4466 - accuracy: 0.4672 - val_loss: 2.4872 - val_accuracy: 0.4770\n",
      "Epoch 426/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4518 - accuracy: 0.4601 - val_loss: 2.5065 - val_accuracy: 0.4802\n",
      "Epoch 427/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4588 - accuracy: 0.4640 - val_loss: 2.4898 - val_accuracy: 0.4793\n",
      "Epoch 428/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4420 - accuracy: 0.4636 - val_loss: 2.4843 - val_accuracy: 0.4756\n",
      "Epoch 429/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4443 - accuracy: 0.4593 - val_loss: 2.5027 - val_accuracy: 0.4806\n",
      "Epoch 430/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4546 - accuracy: 0.4667 - val_loss: 2.4872 - val_accuracy: 0.4768\n",
      "Epoch 431/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4467 - accuracy: 0.4623 - val_loss: 2.4981 - val_accuracy: 0.4769\n",
      "Epoch 432/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4412 - accuracy: 0.4634 - val_loss: 2.5008 - val_accuracy: 0.4807\n",
      "Epoch 433/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4404 - accuracy: 0.4670 - val_loss: 2.4873 - val_accuracy: 0.4777\n",
      "Epoch 434/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4415 - accuracy: 0.4630 - val_loss: 2.4950 - val_accuracy: 0.4737\n",
      "Epoch 435/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4398 - accuracy: 0.4626 - val_loss: 2.5083 - val_accuracy: 0.4792\n",
      "Epoch 436/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4426 - accuracy: 0.4673 - val_loss: 2.4823 - val_accuracy: 0.4773\n",
      "Epoch 437/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4366 - accuracy: 0.4611 - val_loss: 2.4770 - val_accuracy: 0.4824\n",
      "Epoch 438/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4312 - accuracy: 0.4683 - val_loss: 2.4910 - val_accuracy: 0.4835\n",
      "Epoch 439/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4400 - accuracy: 0.4676 - val_loss: 2.4826 - val_accuracy: 0.4813\n",
      "Epoch 440/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4356 - accuracy: 0.4636 - val_loss: 2.4851 - val_accuracy: 0.4800\n",
      "Epoch 441/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4355 - accuracy: 0.4667 - val_loss: 2.4917 - val_accuracy: 0.4794\n",
      "Epoch 442/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4400 - accuracy: 0.4656 - val_loss: 2.4979 - val_accuracy: 0.4772\n",
      "Epoch 443/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4485 - accuracy: 0.4624 - val_loss: 2.4893 - val_accuracy: 0.4811\n",
      "Epoch 444/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4368 - accuracy: 0.4665 - val_loss: 2.4938 - val_accuracy: 0.4761\n",
      "Epoch 445/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4465 - accuracy: 0.4619 - val_loss: 2.4827 - val_accuracy: 0.4769\n",
      "Epoch 446/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4331 - accuracy: 0.4636 - val_loss: 2.4999 - val_accuracy: 0.4816\n",
      "Epoch 447/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4412 - accuracy: 0.4669 - val_loss: 2.4907 - val_accuracy: 0.4746\n",
      "Epoch 448/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4342 - accuracy: 0.4619 - val_loss: 2.4863 - val_accuracy: 0.4789\n",
      "Epoch 449/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4380 - accuracy: 0.4664 - val_loss: 2.4865 - val_accuracy: 0.4811\n",
      "Epoch 450/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4306 - accuracy: 0.4672 - val_loss: 2.4806 - val_accuracy: 0.4779\n",
      "Epoch 451/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4335 - accuracy: 0.4629 - val_loss: 2.4872 - val_accuracy: 0.4838\n",
      "Epoch 452/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4365 - accuracy: 0.4666 - val_loss: 2.4905 - val_accuracy: 0.4805\n",
      "Epoch 453/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4316 - accuracy: 0.4667 - val_loss: 2.4893 - val_accuracy: 0.4753\n",
      "Epoch 454/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4338 - accuracy: 0.4618 - val_loss: 2.4995 - val_accuracy: 0.4819\n",
      "Epoch 455/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4367 - accuracy: 0.4684 - val_loss: 2.4788 - val_accuracy: 0.4816\n",
      "Epoch 456/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4272 - accuracy: 0.4659 - val_loss: 2.4805 - val_accuracy: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4347 - accuracy: 0.4618 - val_loss: 2.5002 - val_accuracy: 0.4820\n",
      "Epoch 458/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4359 - accuracy: 0.4687 - val_loss: 2.4890 - val_accuracy: 0.4782\n",
      "Epoch 459/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4356 - accuracy: 0.4649 - val_loss: 2.4805 - val_accuracy: 0.4781\n",
      "Epoch 460/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4360 - accuracy: 0.4632 - val_loss: 2.4813 - val_accuracy: 0.4816\n",
      "Epoch 461/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4239 - accuracy: 0.4678 - val_loss: 2.4841 - val_accuracy: 0.4860\n",
      "Epoch 462/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4259 - accuracy: 0.4709 - val_loss: 2.4788 - val_accuracy: 0.4788\n",
      "Epoch 463/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4287 - accuracy: 0.4655 - val_loss: 2.4941 - val_accuracy: 0.4797\n",
      "Epoch 464/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4301 - accuracy: 0.4672 - val_loss: 2.4807 - val_accuracy: 0.4792\n",
      "Epoch 465/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4279 - accuracy: 0.4654 - val_loss: 2.4815 - val_accuracy: 0.4802\n",
      "Epoch 466/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4369 - accuracy: 0.4643 - val_loss: 2.4855 - val_accuracy: 0.4823\n",
      "Epoch 467/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4318 - accuracy: 0.4673 - val_loss: 2.4853 - val_accuracy: 0.4802\n",
      "Epoch 468/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4266 - accuracy: 0.4680 - val_loss: 2.4987 - val_accuracy: 0.4803\n",
      "Epoch 469/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4409 - accuracy: 0.4651 - val_loss: 2.5003 - val_accuracy: 0.4744\n",
      "Epoch 470/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4337 - accuracy: 0.4645 - val_loss: 2.4924 - val_accuracy: 0.4764\n",
      "Epoch 471/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4336 - accuracy: 0.4652 - val_loss: 2.4794 - val_accuracy: 0.4828\n",
      "Epoch 472/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4310 - accuracy: 0.4677 - val_loss: 2.4905 - val_accuracy: 0.4800\n",
      "Epoch 473/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4431 - accuracy: 0.4655 - val_loss: 2.4823 - val_accuracy: 0.4755\n",
      "Epoch 474/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4275 - accuracy: 0.4630 - val_loss: 2.4957 - val_accuracy: 0.4804\n",
      "Epoch 475/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4374 - accuracy: 0.4691 - val_loss: 2.4780 - val_accuracy: 0.4784\n",
      "Epoch 476/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4198 - accuracy: 0.4672 - val_loss: 2.4812 - val_accuracy: 0.4801\n",
      "Epoch 477/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4335 - accuracy: 0.4634 - val_loss: 2.4807 - val_accuracy: 0.4828\n",
      "Epoch 478/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4203 - accuracy: 0.4692 - val_loss: 2.4837 - val_accuracy: 0.4806\n",
      "Epoch 479/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4199 - accuracy: 0.4694 - val_loss: 2.4797 - val_accuracy: 0.4793\n",
      "Epoch 480/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4247 - accuracy: 0.4649 - val_loss: 2.4970 - val_accuracy: 0.4815\n",
      "Epoch 481/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4276 - accuracy: 0.4684 - val_loss: 2.4763 - val_accuracy: 0.4773\n",
      "Epoch 482/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4293 - accuracy: 0.4622 - val_loss: 2.4832 - val_accuracy: 0.4852\n",
      "Epoch 483/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4194 - accuracy: 0.4686 - val_loss: 2.4839 - val_accuracy: 0.4868\n",
      "Epoch 484/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4184 - accuracy: 0.4691 - val_loss: 2.4769 - val_accuracy: 0.4833\n",
      "Epoch 485/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4143 - accuracy: 0.4677 - val_loss: 2.4826 - val_accuracy: 0.4800\n",
      "Epoch 486/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4145 - accuracy: 0.4698 - val_loss: 2.4815 - val_accuracy: 0.4784\n",
      "Epoch 487/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4263 - accuracy: 0.4679 - val_loss: 2.4811 - val_accuracy: 0.4816\n",
      "Epoch 488/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4197 - accuracy: 0.4692 - val_loss: 2.4704 - val_accuracy: 0.4834\n",
      "Epoch 489/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4096 - accuracy: 0.4684 - val_loss: 2.4769 - val_accuracy: 0.4831\n",
      "Epoch 490/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4189 - accuracy: 0.4681 - val_loss: 2.4739 - val_accuracy: 0.4820\n",
      "Epoch 491/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4160 - accuracy: 0.4674 - val_loss: 2.4860 - val_accuracy: 0.4860\n",
      "Epoch 492/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4178 - accuracy: 0.4712 - val_loss: 2.4779 - val_accuracy: 0.4804\n",
      "Epoch 493/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4129 - accuracy: 0.4683 - val_loss: 2.4835 - val_accuracy: 0.4807\n",
      "Epoch 494/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4170 - accuracy: 0.4672 - val_loss: 2.4835 - val_accuracy: 0.4834\n",
      "Epoch 495/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4203 - accuracy: 0.4684 - val_loss: 2.4721 - val_accuracy: 0.4830\n",
      "Epoch 496/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4165 - accuracy: 0.4671 - val_loss: 2.4807 - val_accuracy: 0.4830\n",
      "Epoch 497/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4109 - accuracy: 0.4692 - val_loss: 2.4853 - val_accuracy: 0.4847\n",
      "Epoch 498/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4205 - accuracy: 0.4700 - val_loss: 2.4756 - val_accuracy: 0.4786\n",
      "Epoch 499/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4178 - accuracy: 0.4673 - val_loss: 2.4884 - val_accuracy: 0.4807\n",
      "Epoch 500/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4159 - accuracy: 0.4695 - val_loss: 2.4892 - val_accuracy: 0.4800\n",
      "Epoch 501/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4178 - accuracy: 0.4688 - val_loss: 2.4809 - val_accuracy: 0.4808\n",
      "Epoch 502/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4104 - accuracy: 0.4691 - val_loss: 2.4758 - val_accuracy: 0.4850\n",
      "Epoch 503/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4036 - accuracy: 0.4724 - val_loss: 2.4810 - val_accuracy: 0.4793\n",
      "Epoch 504/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4141 - accuracy: 0.4689 - val_loss: 2.4796 - val_accuracy: 0.4801\n",
      "Epoch 505/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4090 - accuracy: 0.4685 - val_loss: 2.4822 - val_accuracy: 0.4801\n",
      "Epoch 506/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4012 - accuracy: 0.4724 - val_loss: 2.4820 - val_accuracy: 0.4817\n",
      "Epoch 507/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4069 - accuracy: 0.4695 - val_loss: 2.4762 - val_accuracy: 0.4829\n",
      "Epoch 508/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4097 - accuracy: 0.4719 - val_loss: 2.4732 - val_accuracy: 0.4820\n",
      "Epoch 509/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4112 - accuracy: 0.4699 - val_loss: 2.4807 - val_accuracy: 0.4814\n",
      "Epoch 510/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4171 - accuracy: 0.4687 - val_loss: 2.4898 - val_accuracy: 0.4792\n",
      "Epoch 511/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4161 - accuracy: 0.4686 - val_loss: 2.4704 - val_accuracy: 0.4830\n",
      "Epoch 512/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4045 - accuracy: 0.4690 - val_loss: 2.4723 - val_accuracy: 0.4882\n",
      "Epoch 513/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4072 - accuracy: 0.4712 - val_loss: 2.4715 - val_accuracy: 0.4822\n",
      "Epoch 514/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4081 - accuracy: 0.4693 - val_loss: 2.4744 - val_accuracy: 0.4784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4092 - accuracy: 0.4691 - val_loss: 2.4775 - val_accuracy: 0.4792\n",
      "Epoch 516/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4175 - accuracy: 0.4664 - val_loss: 2.4848 - val_accuracy: 0.4842\n",
      "Epoch 517/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4228 - accuracy: 0.4673 - val_loss: 2.4742 - val_accuracy: 0.4826\n",
      "Epoch 518/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4081 - accuracy: 0.4689 - val_loss: 2.4696 - val_accuracy: 0.4814\n",
      "Epoch 519/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4079 - accuracy: 0.4689 - val_loss: 2.4796 - val_accuracy: 0.4847\n",
      "Epoch 520/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4146 - accuracy: 0.4707 - val_loss: 2.4878 - val_accuracy: 0.4770\n",
      "Epoch 521/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4255 - accuracy: 0.4622 - val_loss: 2.5030 - val_accuracy: 0.4825\n",
      "Epoch 522/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4224 - accuracy: 0.4699 - val_loss: 2.4730 - val_accuracy: 0.4799\n",
      "Epoch 523/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4177 - accuracy: 0.4661 - val_loss: 2.4883 - val_accuracy: 0.4804\n",
      "Epoch 524/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4248 - accuracy: 0.4692 - val_loss: 2.4818 - val_accuracy: 0.4827\n",
      "Epoch 525/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4138 - accuracy: 0.4715 - val_loss: 2.4774 - val_accuracy: 0.4800\n",
      "Epoch 526/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4182 - accuracy: 0.4649 - val_loss: 2.4925 - val_accuracy: 0.4834\n",
      "Epoch 527/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4134 - accuracy: 0.4728 - val_loss: 2.4734 - val_accuracy: 0.4840\n",
      "Epoch 528/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4118 - accuracy: 0.4703 - val_loss: 2.4731 - val_accuracy: 0.4838\n",
      "Epoch 529/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4043 - accuracy: 0.4722 - val_loss: 2.4790 - val_accuracy: 0.4809\n",
      "Epoch 530/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4080 - accuracy: 0.4697 - val_loss: 2.4688 - val_accuracy: 0.4837\n",
      "Epoch 531/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4101 - accuracy: 0.4697 - val_loss: 2.4841 - val_accuracy: 0.4828\n",
      "Epoch 532/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4048 - accuracy: 0.4709 - val_loss: 2.4791 - val_accuracy: 0.4829\n",
      "Epoch 533/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4021 - accuracy: 0.4712 - val_loss: 2.4700 - val_accuracy: 0.4815\n",
      "Epoch 534/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4043 - accuracy: 0.4707 - val_loss: 2.4816 - val_accuracy: 0.4823\n",
      "Epoch 535/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4082 - accuracy: 0.4701 - val_loss: 2.4882 - val_accuracy: 0.4813\n",
      "Epoch 536/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4071 - accuracy: 0.4717 - val_loss: 2.4711 - val_accuracy: 0.4796\n",
      "Epoch 537/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4075 - accuracy: 0.4647 - val_loss: 2.5035 - val_accuracy: 0.4850\n",
      "Epoch 538/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4149 - accuracy: 0.4731 - val_loss: 2.4695 - val_accuracy: 0.4823\n",
      "Epoch 539/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4037 - accuracy: 0.4683 - val_loss: 2.4693 - val_accuracy: 0.4842\n",
      "Epoch 540/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4045 - accuracy: 0.4691 - val_loss: 2.4972 - val_accuracy: 0.4838\n",
      "Epoch 541/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4153 - accuracy: 0.4740 - val_loss: 2.4702 - val_accuracy: 0.4800\n",
      "Epoch 542/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4015 - accuracy: 0.4715 - val_loss: 2.4686 - val_accuracy: 0.4807\n",
      "Epoch 543/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3999 - accuracy: 0.4704 - val_loss: 2.4816 - val_accuracy: 0.4817\n",
      "Epoch 544/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4068 - accuracy: 0.4713 - val_loss: 2.4752 - val_accuracy: 0.4821\n",
      "Epoch 545/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4025 - accuracy: 0.4723 - val_loss: 2.4671 - val_accuracy: 0.4839\n",
      "Epoch 546/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3979 - accuracy: 0.4710 - val_loss: 2.4733 - val_accuracy: 0.4878\n",
      "Epoch 547/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3939 - accuracy: 0.4757 - val_loss: 2.4686 - val_accuracy: 0.4823\n",
      "Epoch 548/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3972 - accuracy: 0.4715 - val_loss: 2.4763 - val_accuracy: 0.4830\n",
      "Epoch 549/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4010 - accuracy: 0.4733 - val_loss: 2.4799 - val_accuracy: 0.4805\n",
      "Epoch 550/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4027 - accuracy: 0.4698 - val_loss: 2.4703 - val_accuracy: 0.4807\n",
      "Epoch 551/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3959 - accuracy: 0.4718 - val_loss: 2.4732 - val_accuracy: 0.4863\n",
      "Epoch 552/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4019 - accuracy: 0.4726 - val_loss: 2.4701 - val_accuracy: 0.4880\n",
      "Epoch 553/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3945 - accuracy: 0.4718 - val_loss: 2.4810 - val_accuracy: 0.4854\n",
      "Epoch 554/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4006 - accuracy: 0.4718 - val_loss: 2.4838 - val_accuracy: 0.4807\n",
      "Epoch 555/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3944 - accuracy: 0.4714 - val_loss: 2.4720 - val_accuracy: 0.4853\n",
      "Epoch 556/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3997 - accuracy: 0.4721 - val_loss: 2.4710 - val_accuracy: 0.4842\n",
      "Epoch 557/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3977 - accuracy: 0.4717 - val_loss: 2.4823 - val_accuracy: 0.4808\n",
      "Epoch 558/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4038 - accuracy: 0.4703 - val_loss: 2.4797 - val_accuracy: 0.4827\n",
      "Epoch 559/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3914 - accuracy: 0.4742 - val_loss: 2.4730 - val_accuracy: 0.4831\n",
      "Epoch 560/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3937 - accuracy: 0.4728 - val_loss: 2.4774 - val_accuracy: 0.4818\n",
      "Epoch 561/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3987 - accuracy: 0.4713 - val_loss: 2.4723 - val_accuracy: 0.4776\n",
      "Epoch 562/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4048 - accuracy: 0.4668 - val_loss: 2.4927 - val_accuracy: 0.4877\n",
      "Epoch 563/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4190 - accuracy: 0.4749 - val_loss: 2.4879 - val_accuracy: 0.4787\n",
      "Epoch 564/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4073 - accuracy: 0.4668 - val_loss: 2.4775 - val_accuracy: 0.4814\n",
      "Epoch 565/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4028 - accuracy: 0.4689 - val_loss: 2.4850 - val_accuracy: 0.4854\n",
      "Epoch 566/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4015 - accuracy: 0.4734 - val_loss: 2.4795 - val_accuracy: 0.4776\n",
      "Epoch 567/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4116 - accuracy: 0.4666 - val_loss: 2.4962 - val_accuracy: 0.4834\n",
      "Epoch 568/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4081 - accuracy: 0.4740 - val_loss: 2.4753 - val_accuracy: 0.4827\n",
      "Epoch 569/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3964 - accuracy: 0.4710 - val_loss: 2.4725 - val_accuracy: 0.4774\n",
      "Epoch 570/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4064 - accuracy: 0.4654 - val_loss: 2.5042 - val_accuracy: 0.4844\n",
      "Epoch 571/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4091 - accuracy: 0.4754 - val_loss: 2.4892 - val_accuracy: 0.4764\n",
      "Epoch 572/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4110 - accuracy: 0.4682 - val_loss: 2.4768 - val_accuracy: 0.4773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4030 - accuracy: 0.4680 - val_loss: 2.4923 - val_accuracy: 0.4865\n",
      "Epoch 574/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4104 - accuracy: 0.4748 - val_loss: 2.4792 - val_accuracy: 0.4802\n",
      "Epoch 575/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4103 - accuracy: 0.4672 - val_loss: 2.4899 - val_accuracy: 0.4772\n",
      "Epoch 576/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4053 - accuracy: 0.4685 - val_loss: 2.4893 - val_accuracy: 0.4863\n",
      "Epoch 577/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4104 - accuracy: 0.4715 - val_loss: 2.4714 - val_accuracy: 0.4833\n",
      "Epoch 578/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4068 - accuracy: 0.4684 - val_loss: 2.4713 - val_accuracy: 0.4817\n",
      "Epoch 579/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3985 - accuracy: 0.4692 - val_loss: 2.4985 - val_accuracy: 0.4833\n",
      "Epoch 580/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4136 - accuracy: 0.4730 - val_loss: 2.4916 - val_accuracy: 0.4794\n",
      "Epoch 581/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3971 - accuracy: 0.4724 - val_loss: 2.4723 - val_accuracy: 0.4776\n",
      "Epoch 582/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3972 - accuracy: 0.4680 - val_loss: 2.4881 - val_accuracy: 0.4845\n",
      "Epoch 583/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4032 - accuracy: 0.4743 - val_loss: 2.4732 - val_accuracy: 0.4807\n",
      "Epoch 584/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3995 - accuracy: 0.4679 - val_loss: 2.4847 - val_accuracy: 0.4816\n",
      "Epoch 585/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4014 - accuracy: 0.4711 - val_loss: 2.4805 - val_accuracy: 0.4849\n",
      "Epoch 586/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4004 - accuracy: 0.4733 - val_loss: 2.4720 - val_accuracy: 0.4792\n",
      "Epoch 587/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4005 - accuracy: 0.4687 - val_loss: 2.4755 - val_accuracy: 0.4855\n",
      "Epoch 588/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4022 - accuracy: 0.4716 - val_loss: 2.4940 - val_accuracy: 0.4850\n",
      "Epoch 589/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4070 - accuracy: 0.4695 - val_loss: 2.4696 - val_accuracy: 0.4831\n",
      "Epoch 590/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4059 - accuracy: 0.4683 - val_loss: 2.4906 - val_accuracy: 0.4874\n",
      "Epoch 591/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4123 - accuracy: 0.4736 - val_loss: 2.4962 - val_accuracy: 0.4749\n",
      "Epoch 592/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4179 - accuracy: 0.4660 - val_loss: 2.4730 - val_accuracy: 0.4821\n",
      "Epoch 593/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4079 - accuracy: 0.4684 - val_loss: 2.4938 - val_accuracy: 0.4853\n",
      "Epoch 594/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4114 - accuracy: 0.4734 - val_loss: 2.4739 - val_accuracy: 0.4808\n",
      "Epoch 595/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3942 - accuracy: 0.4707 - val_loss: 2.4735 - val_accuracy: 0.4793\n",
      "Epoch 596/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4072 - accuracy: 0.4675 - val_loss: 2.4938 - val_accuracy: 0.4818\n",
      "Epoch 597/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4195 - accuracy: 0.4706 - val_loss: 2.5065 - val_accuracy: 0.4755\n",
      "Epoch 598/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4265 - accuracy: 0.4656 - val_loss: 2.4764 - val_accuracy: 0.4785\n",
      "Epoch 599/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4109 - accuracy: 0.4663 - val_loss: 2.4916 - val_accuracy: 0.4868\n",
      "Epoch 600/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4085 - accuracy: 0.4758 - val_loss: 2.4832 - val_accuracy: 0.4815\n",
      "Epoch 601/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3983 - accuracy: 0.4718 - val_loss: 2.4795 - val_accuracy: 0.4763\n",
      "Epoch 602/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4095 - accuracy: 0.4651 - val_loss: 2.4853 - val_accuracy: 0.4823\n",
      "Epoch 603/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3965 - accuracy: 0.4747 - val_loss: 2.4828 - val_accuracy: 0.4805\n",
      "Epoch 604/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4029 - accuracy: 0.4706 - val_loss: 2.4756 - val_accuracy: 0.4807\n",
      "Epoch 605/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3983 - accuracy: 0.4708 - val_loss: 2.4768 - val_accuracy: 0.4846\n",
      "Epoch 606/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3911 - accuracy: 0.4719 - val_loss: 2.4871 - val_accuracy: 0.4818\n",
      "Epoch 607/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4002 - accuracy: 0.4718 - val_loss: 2.4856 - val_accuracy: 0.4806\n",
      "Epoch 608/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3944 - accuracy: 0.4737 - val_loss: 2.4823 - val_accuracy: 0.4776\n",
      "Epoch 609/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3917 - accuracy: 0.4717 - val_loss: 2.4766 - val_accuracy: 0.4836\n",
      "Epoch 610/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3952 - accuracy: 0.4702 - val_loss: 2.4935 - val_accuracy: 0.4836\n",
      "Epoch 611/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3941 - accuracy: 0.4748 - val_loss: 2.4624 - val_accuracy: 0.4816\n",
      "Epoch 612/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3877 - accuracy: 0.4697 - val_loss: 2.4642 - val_accuracy: 0.4843\n",
      "Epoch 613/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3899 - accuracy: 0.4715 - val_loss: 2.4867 - val_accuracy: 0.4885\n",
      "Epoch 614/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4024 - accuracy: 0.4747 - val_loss: 2.4666 - val_accuracy: 0.4823\n",
      "Epoch 615/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3929 - accuracy: 0.4703 - val_loss: 2.4750 - val_accuracy: 0.4823\n",
      "Epoch 616/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3881 - accuracy: 0.4755 - val_loss: 2.4681 - val_accuracy: 0.4846\n",
      "Epoch 617/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3828 - accuracy: 0.4759 - val_loss: 2.4654 - val_accuracy: 0.4790\n",
      "Epoch 618/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3900 - accuracy: 0.4704 - val_loss: 2.4847 - val_accuracy: 0.4869\n",
      "Epoch 619/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3836 - accuracy: 0.4769 - val_loss: 2.4826 - val_accuracy: 0.4869\n",
      "Epoch 620/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3858 - accuracy: 0.4738 - val_loss: 2.4643 - val_accuracy: 0.4852\n",
      "Epoch 621/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3905 - accuracy: 0.4710 - val_loss: 2.4806 - val_accuracy: 0.4856\n",
      "Epoch 622/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3841 - accuracy: 0.4762 - val_loss: 2.4810 - val_accuracy: 0.4795\n",
      "Epoch 623/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3884 - accuracy: 0.4737 - val_loss: 2.4681 - val_accuracy: 0.4815\n",
      "Epoch 624/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3901 - accuracy: 0.4706 - val_loss: 2.4828 - val_accuracy: 0.4841\n",
      "Epoch 625/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3916 - accuracy: 0.4744 - val_loss: 2.4669 - val_accuracy: 0.4862\n",
      "Epoch 626/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3857 - accuracy: 0.4756 - val_loss: 2.4681 - val_accuracy: 0.4795\n",
      "Epoch 627/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3903 - accuracy: 0.4706 - val_loss: 2.4860 - val_accuracy: 0.4870\n",
      "Epoch 628/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3930 - accuracy: 0.4772 - val_loss: 2.4755 - val_accuracy: 0.4799\n",
      "Epoch 629/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3865 - accuracy: 0.4729 - val_loss: 2.4726 - val_accuracy: 0.4795\n",
      "Epoch 630/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3907 - accuracy: 0.4693 - val_loss: 2.4802 - val_accuracy: 0.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3873 - accuracy: 0.4763 - val_loss: 2.4775 - val_accuracy: 0.4876\n",
      "Epoch 632/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3972 - accuracy: 0.4747 - val_loss: 2.4692 - val_accuracy: 0.4799\n",
      "Epoch 633/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3963 - accuracy: 0.4683 - val_loss: 2.4868 - val_accuracy: 0.4878\n",
      "Epoch 634/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3988 - accuracy: 0.4766 - val_loss: 2.4640 - val_accuracy: 0.4860\n",
      "Epoch 635/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3903 - accuracy: 0.4737 - val_loss: 2.4669 - val_accuracy: 0.4769\n",
      "Epoch 636/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3952 - accuracy: 0.4687 - val_loss: 2.4877 - val_accuracy: 0.4827\n",
      "Epoch 637/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3917 - accuracy: 0.4773 - val_loss: 2.4723 - val_accuracy: 0.4861\n",
      "Epoch 638/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3910 - accuracy: 0.4740 - val_loss: 2.4621 - val_accuracy: 0.4807\n",
      "Epoch 639/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3938 - accuracy: 0.4685 - val_loss: 2.4829 - val_accuracy: 0.4849\n",
      "Epoch 640/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3911 - accuracy: 0.4741 - val_loss: 2.4811 - val_accuracy: 0.4872\n",
      "Epoch 641/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3913 - accuracy: 0.4738 - val_loss: 2.4776 - val_accuracy: 0.4891\n",
      "Epoch 642/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3876 - accuracy: 0.4770 - val_loss: 2.4827 - val_accuracy: 0.4806\n",
      "Epoch 643/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3931 - accuracy: 0.4705 - val_loss: 2.4722 - val_accuracy: 0.4850\n",
      "Epoch 644/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3829 - accuracy: 0.4750 - val_loss: 2.4738 - val_accuracy: 0.4818\n",
      "Epoch 645/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3851 - accuracy: 0.4724 - val_loss: 2.4752 - val_accuracy: 0.4822\n",
      "Epoch 646/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3744 - accuracy: 0.4755 - val_loss: 2.4732 - val_accuracy: 0.4833\n",
      "Epoch 647/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3816 - accuracy: 0.4759 - val_loss: 2.4656 - val_accuracy: 0.4838\n",
      "Epoch 648/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3765 - accuracy: 0.4728 - val_loss: 2.4682 - val_accuracy: 0.4877\n",
      "Epoch 649/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3819 - accuracy: 0.4755 - val_loss: 2.4746 - val_accuracy: 0.4822\n",
      "Epoch 650/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3839 - accuracy: 0.4738 - val_loss: 2.4685 - val_accuracy: 0.4858\n",
      "Epoch 651/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3751 - accuracy: 0.4764 - val_loss: 2.4754 - val_accuracy: 0.4807\n",
      "Epoch 652/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3819 - accuracy: 0.4710 - val_loss: 2.4679 - val_accuracy: 0.4862\n",
      "Epoch 653/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3817 - accuracy: 0.4750 - val_loss: 2.4686 - val_accuracy: 0.4866\n",
      "Epoch 654/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3867 - accuracy: 0.4751 - val_loss: 2.4740 - val_accuracy: 0.4805\n",
      "Epoch 655/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3774 - accuracy: 0.4746 - val_loss: 2.4734 - val_accuracy: 0.4839\n",
      "Epoch 656/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3839 - accuracy: 0.4753 - val_loss: 2.4668 - val_accuracy: 0.4862\n",
      "Epoch 657/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3762 - accuracy: 0.4762 - val_loss: 2.4607 - val_accuracy: 0.4851\n",
      "Epoch 658/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3752 - accuracy: 0.4737 - val_loss: 2.4791 - val_accuracy: 0.4878\n",
      "Epoch 659/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3835 - accuracy: 0.4748 - val_loss: 2.4658 - val_accuracy: 0.4855\n",
      "Epoch 660/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4753 - val_loss: 2.4616 - val_accuracy: 0.4832\n",
      "Epoch 661/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3830 - accuracy: 0.4725 - val_loss: 2.4756 - val_accuracy: 0.4851\n",
      "Epoch 662/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3801 - accuracy: 0.4761 - val_loss: 2.4662 - val_accuracy: 0.4869\n",
      "Epoch 663/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3838 - accuracy: 0.4759 - val_loss: 2.4638 - val_accuracy: 0.4858\n",
      "Epoch 664/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3762 - accuracy: 0.4747 - val_loss: 2.4727 - val_accuracy: 0.4845\n",
      "Epoch 665/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3749 - accuracy: 0.4766 - val_loss: 2.4609 - val_accuracy: 0.4829\n",
      "Epoch 666/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3803 - accuracy: 0.4727 - val_loss: 2.4684 - val_accuracy: 0.4846\n",
      "Epoch 667/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3776 - accuracy: 0.4753 - val_loss: 2.4774 - val_accuracy: 0.4869\n",
      "Epoch 668/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3752 - accuracy: 0.4781 - val_loss: 2.4592 - val_accuracy: 0.4825\n",
      "Epoch 669/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3774 - accuracy: 0.4718 - val_loss: 2.4751 - val_accuracy: 0.4863\n",
      "Epoch 670/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3856 - accuracy: 0.4756 - val_loss: 2.4720 - val_accuracy: 0.4831\n",
      "Epoch 671/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3832 - accuracy: 0.4734 - val_loss: 2.4575 - val_accuracy: 0.4867\n",
      "Epoch 672/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3774 - accuracy: 0.4736 - val_loss: 2.4766 - val_accuracy: 0.4876\n",
      "Epoch 673/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3810 - accuracy: 0.4762 - val_loss: 2.4663 - val_accuracy: 0.4812\n",
      "Epoch 674/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3859 - accuracy: 0.4696 - val_loss: 2.4849 - val_accuracy: 0.4823\n",
      "Epoch 675/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3986 - accuracy: 0.4713 - val_loss: 2.4744 - val_accuracy: 0.4850\n",
      "Epoch 676/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3845 - accuracy: 0.4740 - val_loss: 2.4689 - val_accuracy: 0.4829\n",
      "Epoch 677/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3846 - accuracy: 0.4719 - val_loss: 2.4747 - val_accuracy: 0.4894\n",
      "Epoch 678/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3842 - accuracy: 0.4778 - val_loss: 2.4763 - val_accuracy: 0.4863\n",
      "Epoch 679/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3828 - accuracy: 0.4761 - val_loss: 2.4681 - val_accuracy: 0.4821\n",
      "Epoch 680/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3771 - accuracy: 0.4726 - val_loss: 2.4733 - val_accuracy: 0.4849\n",
      "Epoch 681/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3834 - accuracy: 0.4731 - val_loss: 2.4661 - val_accuracy: 0.4873\n",
      "Epoch 682/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3770 - accuracy: 0.4746 - val_loss: 2.4665 - val_accuracy: 0.4861\n",
      "Epoch 683/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3798 - accuracy: 0.4754 - val_loss: 2.4747 - val_accuracy: 0.4817\n",
      "Epoch 684/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3860 - accuracy: 0.4716 - val_loss: 2.4827 - val_accuracy: 0.4853\n",
      "Epoch 685/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3805 - accuracy: 0.4750 - val_loss: 2.4754 - val_accuracy: 0.4843\n",
      "Epoch 686/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3938 - accuracy: 0.4751 - val_loss: 2.4735 - val_accuracy: 0.4779\n",
      "Epoch 687/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3890 - accuracy: 0.4672 - val_loss: 2.4808 - val_accuracy: 0.4860\n",
      "Epoch 688/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3872 - accuracy: 0.4762 - val_loss: 2.4635 - val_accuracy: 0.4859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3736 - accuracy: 0.4756 - val_loss: 2.4763 - val_accuracy: 0.4822\n",
      "Epoch 690/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3864 - accuracy: 0.4731 - val_loss: 2.4978 - val_accuracy: 0.4849\n",
      "Epoch 691/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4018 - accuracy: 0.4764 - val_loss: 2.4712 - val_accuracy: 0.4776\n",
      "Epoch 692/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3887 - accuracy: 0.4673 - val_loss: 2.4675 - val_accuracy: 0.4813\n",
      "Epoch 693/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3843 - accuracy: 0.4724 - val_loss: 2.4924 - val_accuracy: 0.4886\n",
      "Epoch 694/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4046 - accuracy: 0.4752 - val_loss: 2.4631 - val_accuracy: 0.4815\n",
      "Epoch 695/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3829 - accuracy: 0.4704 - val_loss: 2.4679 - val_accuracy: 0.4829\n",
      "Epoch 696/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3866 - accuracy: 0.4729 - val_loss: 2.4734 - val_accuracy: 0.4866\n",
      "Epoch 697/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3824 - accuracy: 0.4773 - val_loss: 2.4648 - val_accuracy: 0.4839\n",
      "Epoch 698/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3802 - accuracy: 0.4740 - val_loss: 2.4684 - val_accuracy: 0.4815\n",
      "Epoch 699/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3774 - accuracy: 0.4719 - val_loss: 2.4832 - val_accuracy: 0.4867\n",
      "Epoch 700/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3906 - accuracy: 0.4773 - val_loss: 2.4740 - val_accuracy: 0.4785\n",
      "Epoch 701/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3900 - accuracy: 0.4677 - val_loss: 2.4783 - val_accuracy: 0.4816\n",
      "Epoch 702/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3931 - accuracy: 0.4737 - val_loss: 2.4668 - val_accuracy: 0.4817\n",
      "Epoch 703/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3814 - accuracy: 0.4737 - val_loss: 2.4775 - val_accuracy: 0.4819\n",
      "Epoch 704/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3890 - accuracy: 0.4742 - val_loss: 2.4732 - val_accuracy: 0.4828\n",
      "Epoch 705/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3865 - accuracy: 0.4726 - val_loss: 2.4618 - val_accuracy: 0.4854\n",
      "Epoch 706/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3715 - accuracy: 0.4778 - val_loss: 2.4685 - val_accuracy: 0.4832\n",
      "Epoch 707/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3842 - accuracy: 0.4730 - val_loss: 2.4661 - val_accuracy: 0.4855\n",
      "Epoch 708/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3760 - accuracy: 0.4764 - val_loss: 2.4794 - val_accuracy: 0.4873\n",
      "Epoch 709/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3830 - accuracy: 0.4770 - val_loss: 2.4697 - val_accuracy: 0.4837\n",
      "Epoch 710/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3693 - accuracy: 0.4748 - val_loss: 2.4740 - val_accuracy: 0.4843\n",
      "Epoch 711/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3876 - accuracy: 0.4727 - val_loss: 2.4758 - val_accuracy: 0.4846\n",
      "Epoch 712/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3855 - accuracy: 0.4759 - val_loss: 2.4658 - val_accuracy: 0.4816\n",
      "Epoch 713/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3782 - accuracy: 0.4741 - val_loss: 2.4710 - val_accuracy: 0.4859\n",
      "Epoch 714/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3785 - accuracy: 0.4768 - val_loss: 2.4613 - val_accuracy: 0.4852\n",
      "Epoch 715/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3711 - accuracy: 0.4745 - val_loss: 2.4621 - val_accuracy: 0.4846\n",
      "Epoch 716/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3745 - accuracy: 0.4745 - val_loss: 2.4651 - val_accuracy: 0.4851\n",
      "Epoch 717/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3735 - accuracy: 0.4745 - val_loss: 2.4805 - val_accuracy: 0.4851\n",
      "Epoch 718/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3791 - accuracy: 0.4766 - val_loss: 2.4695 - val_accuracy: 0.4825\n",
      "Epoch 719/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3734 - accuracy: 0.4753 - val_loss: 2.4733 - val_accuracy: 0.4834\n",
      "Epoch 720/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3726 - accuracy: 0.4768 - val_loss: 2.4742 - val_accuracy: 0.4831\n",
      "Epoch 721/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3738 - accuracy: 0.4746 - val_loss: 2.4637 - val_accuracy: 0.4847\n",
      "Epoch 722/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3765 - accuracy: 0.4746 - val_loss: 2.4673 - val_accuracy: 0.4844\n",
      "Epoch 723/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3724 - accuracy: 0.4757 - val_loss: 2.4687 - val_accuracy: 0.4806\n",
      "Epoch 724/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3770 - accuracy: 0.4731 - val_loss: 2.4789 - val_accuracy: 0.4847\n",
      "Epoch 725/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3871 - accuracy: 0.4749 - val_loss: 2.4694 - val_accuracy: 0.4784\n",
      "Epoch 726/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3832 - accuracy: 0.4720 - val_loss: 2.4742 - val_accuracy: 0.4877\n",
      "Epoch 727/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3742 - accuracy: 0.4799 - val_loss: 2.4725 - val_accuracy: 0.4846\n",
      "Epoch 728/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3797 - accuracy: 0.4752 - val_loss: 2.4743 - val_accuracy: 0.4823\n",
      "Epoch 729/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3796 - accuracy: 0.4735 - val_loss: 2.4782 - val_accuracy: 0.4861\n",
      "Epoch 730/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3864 - accuracy: 0.4765 - val_loss: 2.4656 - val_accuracy: 0.4842\n",
      "Epoch 731/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3738 - accuracy: 0.4756 - val_loss: 2.4931 - val_accuracy: 0.4786\n",
      "Epoch 732/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4073 - accuracy: 0.4702 - val_loss: 2.4933 - val_accuracy: 0.4834\n",
      "Epoch 733/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4121 - accuracy: 0.4730 - val_loss: 2.4776 - val_accuracy: 0.4855\n",
      "Epoch 734/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3771 - accuracy: 0.4749 - val_loss: 2.4802 - val_accuracy: 0.4837\n",
      "Epoch 735/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3904 - accuracy: 0.4731 - val_loss: 2.4697 - val_accuracy: 0.4836\n",
      "Epoch 736/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3876 - accuracy: 0.4704 - val_loss: 2.4869 - val_accuracy: 0.4866\n",
      "Epoch 737/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3874 - accuracy: 0.4782 - val_loss: 2.4813 - val_accuracy: 0.4809\n",
      "Epoch 738/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3808 - accuracy: 0.4723 - val_loss: 2.4758 - val_accuracy: 0.4814\n",
      "Epoch 739/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3782 - accuracy: 0.4737 - val_loss: 2.4765 - val_accuracy: 0.4846\n",
      "Epoch 740/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3752 - accuracy: 0.4759 - val_loss: 2.4678 - val_accuracy: 0.4815\n",
      "Epoch 741/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3669 - accuracy: 0.4756 - val_loss: 2.4647 - val_accuracy: 0.4852\n",
      "Epoch 742/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3766 - accuracy: 0.4748 - val_loss: 2.4793 - val_accuracy: 0.4871\n",
      "Epoch 743/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3702 - accuracy: 0.4796 - val_loss: 2.4653 - val_accuracy: 0.4818\n",
      "Epoch 744/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3748 - accuracy: 0.4734 - val_loss: 2.4683 - val_accuracy: 0.4825\n",
      "Epoch 745/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3670 - accuracy: 0.4757 - val_loss: 2.4886 - val_accuracy: 0.4848\n",
      "Epoch 746/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3684 - accuracy: 0.4793 - val_loss: 2.4674 - val_accuracy: 0.4838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 747/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3743 - accuracy: 0.4740 - val_loss: 2.4763 - val_accuracy: 0.4805\n",
      "Epoch 748/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3719 - accuracy: 0.4728 - val_loss: 2.4819 - val_accuracy: 0.4842\n",
      "Epoch 749/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3770 - accuracy: 0.4768 - val_loss: 2.4546 - val_accuracy: 0.4881\n",
      "Epoch 750/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3692 - accuracy: 0.4755 - val_loss: 2.4637 - val_accuracy: 0.4893\n",
      "Epoch 751/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3662 - accuracy: 0.4772 - val_loss: 2.4795 - val_accuracy: 0.4846\n",
      "Epoch 752/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3754 - accuracy: 0.4771 - val_loss: 2.4592 - val_accuracy: 0.4823\n",
      "Epoch 753/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3728 - accuracy: 0.4728 - val_loss: 2.4638 - val_accuracy: 0.4894\n",
      "Epoch 754/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3690 - accuracy: 0.4793 - val_loss: 2.4620 - val_accuracy: 0.4859\n",
      "Epoch 755/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3684 - accuracy: 0.4735 - val_loss: 2.4646 - val_accuracy: 0.4840\n",
      "Epoch 756/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3666 - accuracy: 0.4768 - val_loss: 2.4756 - val_accuracy: 0.4824\n",
      "Epoch 757/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3711 - accuracy: 0.4754 - val_loss: 2.4648 - val_accuracy: 0.4818\n",
      "Epoch 758/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3695 - accuracy: 0.4751 - val_loss: 2.4818 - val_accuracy: 0.4858\n",
      "Epoch 759/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3751 - accuracy: 0.4776 - val_loss: 2.4606 - val_accuracy: 0.4863\n",
      "Epoch 760/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3568 - accuracy: 0.4794 - val_loss: 2.4621 - val_accuracy: 0.4835\n",
      "Epoch 761/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3686 - accuracy: 0.4751 - val_loss: 2.4732 - val_accuracy: 0.4861\n",
      "Epoch 762/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3636 - accuracy: 0.4787 - val_loss: 2.4568 - val_accuracy: 0.4849\n",
      "Epoch 763/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3698 - accuracy: 0.4753 - val_loss: 2.4560 - val_accuracy: 0.4868\n",
      "Epoch 764/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3604 - accuracy: 0.4782 - val_loss: 2.4731 - val_accuracy: 0.4880\n",
      "Epoch 765/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3644 - accuracy: 0.4778 - val_loss: 2.4725 - val_accuracy: 0.4879\n",
      "Epoch 766/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3691 - accuracy: 0.4787 - val_loss: 2.4559 - val_accuracy: 0.4832\n",
      "Epoch 767/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3616 - accuracy: 0.4750 - val_loss: 2.4625 - val_accuracy: 0.4889\n",
      "Epoch 768/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3649 - accuracy: 0.4803 - val_loss: 2.4673 - val_accuracy: 0.4845\n",
      "Epoch 769/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3717 - accuracy: 0.4768 - val_loss: 2.4635 - val_accuracy: 0.4845\n",
      "Epoch 770/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3756 - accuracy: 0.4744 - val_loss: 2.4734 - val_accuracy: 0.4836\n",
      "Epoch 771/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3694 - accuracy: 0.4784 - val_loss: 2.4680 - val_accuracy: 0.4856\n",
      "Epoch 772/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3750 - accuracy: 0.4768 - val_loss: 2.4568 - val_accuracy: 0.4890\n",
      "Epoch 773/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3632 - accuracy: 0.4760 - val_loss: 2.4614 - val_accuracy: 0.4842\n",
      "Epoch 774/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3585 - accuracy: 0.4770 - val_loss: 2.4696 - val_accuracy: 0.4863\n",
      "Epoch 775/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3621 - accuracy: 0.4805 - val_loss: 2.4630 - val_accuracy: 0.4843\n",
      "Epoch 776/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3613 - accuracy: 0.4778 - val_loss: 2.4755 - val_accuracy: 0.4833\n",
      "Epoch 777/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3720 - accuracy: 0.4728 - val_loss: 2.4676 - val_accuracy: 0.4880\n",
      "Epoch 778/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3624 - accuracy: 0.4790 - val_loss: 2.4626 - val_accuracy: 0.4868\n",
      "Epoch 779/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3601 - accuracy: 0.4786 - val_loss: 2.4603 - val_accuracy: 0.4854\n",
      "Epoch 780/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3656 - accuracy: 0.4763 - val_loss: 2.4615 - val_accuracy: 0.4838\n",
      "Epoch 781/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3668 - accuracy: 0.4758 - val_loss: 2.4690 - val_accuracy: 0.4846\n",
      "Epoch 782/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3578 - accuracy: 0.4783 - val_loss: 2.4640 - val_accuracy: 0.4879\n",
      "Epoch 783/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3588 - accuracy: 0.4778 - val_loss: 2.4589 - val_accuracy: 0.4867\n",
      "Epoch 784/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3577 - accuracy: 0.4786 - val_loss: 2.4728 - val_accuracy: 0.4893\n",
      "Epoch 785/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3620 - accuracy: 0.4807 - val_loss: 2.4688 - val_accuracy: 0.4852\n",
      "Epoch 786/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3561 - accuracy: 0.4786 - val_loss: 2.4607 - val_accuracy: 0.4851\n",
      "Epoch 787/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3635 - accuracy: 0.4771 - val_loss: 2.4722 - val_accuracy: 0.4884\n",
      "Epoch 788/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3637 - accuracy: 0.4797 - val_loss: 2.4628 - val_accuracy: 0.4843\n",
      "Epoch 789/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3604 - accuracy: 0.4771 - val_loss: 2.4638 - val_accuracy: 0.4815\n",
      "Epoch 790/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3610 - accuracy: 0.4755 - val_loss: 2.4942 - val_accuracy: 0.4908\n",
      "Epoch 791/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3806 - accuracy: 0.4819 - val_loss: 2.4680 - val_accuracy: 0.4783\n",
      "Epoch 792/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3733 - accuracy: 0.4723 - val_loss: 2.4739 - val_accuracy: 0.4829\n",
      "Epoch 793/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3682 - accuracy: 0.4748 - val_loss: 2.4851 - val_accuracy: 0.4872\n",
      "Epoch 794/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3734 - accuracy: 0.4794 - val_loss: 2.4564 - val_accuracy: 0.4848\n",
      "Epoch 795/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3665 - accuracy: 0.4735 - val_loss: 2.4598 - val_accuracy: 0.4861\n",
      "Epoch 796/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3619 - accuracy: 0.4758 - val_loss: 2.4783 - val_accuracy: 0.4875\n",
      "Epoch 797/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3680 - accuracy: 0.4784 - val_loss: 2.4612 - val_accuracy: 0.4842\n",
      "Epoch 798/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3615 - accuracy: 0.4761 - val_loss: 2.4619 - val_accuracy: 0.4872\n",
      "Epoch 799/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3643 - accuracy: 0.4761 - val_loss: 2.4786 - val_accuracy: 0.4870\n",
      "Epoch 800/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3662 - accuracy: 0.4777 - val_loss: 2.4684 - val_accuracy: 0.4841\n",
      "Epoch 801/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3633 - accuracy: 0.4765 - val_loss: 2.4617 - val_accuracy: 0.4849\n",
      "Epoch 802/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3652 - accuracy: 0.4755 - val_loss: 2.4722 - val_accuracy: 0.4876\n",
      "Epoch 803/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3657 - accuracy: 0.4799 - val_loss: 2.4770 - val_accuracy: 0.4823\n",
      "Epoch 804/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3712 - accuracy: 0.4755 - val_loss: 2.4695 - val_accuracy: 0.4905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 805/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3808 - accuracy: 0.4768 - val_loss: 2.4718 - val_accuracy: 0.4842\n",
      "Epoch 806/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3697 - accuracy: 0.4768 - val_loss: 2.4733 - val_accuracy: 0.4806\n",
      "Epoch 807/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3626 - accuracy: 0.4747 - val_loss: 2.4625 - val_accuracy: 0.4877\n",
      "Epoch 808/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3570 - accuracy: 0.4803 - val_loss: 2.4710 - val_accuracy: 0.4859\n",
      "Epoch 809/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3758 - accuracy: 0.4762 - val_loss: 2.4792 - val_accuracy: 0.4853\n",
      "Epoch 810/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3791 - accuracy: 0.4771 - val_loss: 2.4846 - val_accuracy: 0.4818\n",
      "Epoch 811/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3762 - accuracy: 0.4755 - val_loss: 2.4697 - val_accuracy: 0.4841\n",
      "Epoch 812/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3724 - accuracy: 0.4749 - val_loss: 2.4617 - val_accuracy: 0.4857\n",
      "Epoch 813/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3697 - accuracy: 0.4765 - val_loss: 2.4862 - val_accuracy: 0.4868\n",
      "Epoch 814/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3810 - accuracy: 0.4777 - val_loss: 2.4679 - val_accuracy: 0.4800\n",
      "Epoch 815/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3705 - accuracy: 0.4740 - val_loss: 2.4762 - val_accuracy: 0.4807\n",
      "Epoch 816/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3696 - accuracy: 0.4770 - val_loss: 2.4681 - val_accuracy: 0.4854\n",
      "Epoch 817/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3614 - accuracy: 0.4779 - val_loss: 2.4626 - val_accuracy: 0.4885\n",
      "Epoch 818/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3655 - accuracy: 0.4798 - val_loss: 2.4692 - val_accuracy: 0.4845\n",
      "Epoch 819/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3663 - accuracy: 0.4765 - val_loss: 2.4901 - val_accuracy: 0.4878\n",
      "Epoch 820/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3873 - accuracy: 0.4777 - val_loss: 2.4744 - val_accuracy: 0.4779\n",
      "Epoch 821/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3900 - accuracy: 0.4684 - val_loss: 2.4767 - val_accuracy: 0.4846\n",
      "Epoch 822/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3801 - accuracy: 0.4748 - val_loss: 2.4728 - val_accuracy: 0.4832\n",
      "Epoch 823/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3743 - accuracy: 0.4751 - val_loss: 2.4745 - val_accuracy: 0.4829\n",
      "Epoch 824/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3769 - accuracy: 0.4716 - val_loss: 2.4751 - val_accuracy: 0.4861\n",
      "Epoch 825/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3619 - accuracy: 0.4796 - val_loss: 2.4779 - val_accuracy: 0.4826\n",
      "Epoch 826/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3709 - accuracy: 0.4745 - val_loss: 2.4787 - val_accuracy: 0.4859\n",
      "Epoch 827/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3640 - accuracy: 0.4768 - val_loss: 2.4903 - val_accuracy: 0.4838\n",
      "Epoch 828/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4770 - val_loss: 2.4600 - val_accuracy: 0.4823\n",
      "Epoch 829/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3642 - accuracy: 0.4748 - val_loss: 2.4686 - val_accuracy: 0.4803\n",
      "Epoch 830/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3665 - accuracy: 0.4762 - val_loss: 2.4700 - val_accuracy: 0.4877\n",
      "Epoch 831/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3618 - accuracy: 0.4796 - val_loss: 2.4645 - val_accuracy: 0.4839\n",
      "Epoch 832/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3635 - accuracy: 0.4744 - val_loss: 2.4686 - val_accuracy: 0.4889\n",
      "Epoch 833/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3636 - accuracy: 0.4783 - val_loss: 2.4739 - val_accuracy: 0.4866\n",
      "Epoch 834/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3686 - accuracy: 0.4761 - val_loss: 2.4605 - val_accuracy: 0.4835\n",
      "Epoch 835/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3667 - accuracy: 0.4746 - val_loss: 2.4626 - val_accuracy: 0.4871\n",
      "Epoch 836/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3606 - accuracy: 0.4773 - val_loss: 2.4748 - val_accuracy: 0.4852\n",
      "Epoch 837/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3660 - accuracy: 0.4772 - val_loss: 2.4868 - val_accuracy: 0.4840\n",
      "Epoch 838/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3807 - accuracy: 0.4776 - val_loss: 2.4820 - val_accuracy: 0.4811\n",
      "Epoch 839/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3738 - accuracy: 0.4739 - val_loss: 2.4762 - val_accuracy: 0.4874\n",
      "Epoch 840/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3653 - accuracy: 0.4787 - val_loss: 2.4662 - val_accuracy: 0.4862\n",
      "Epoch 841/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3767 - accuracy: 0.4753 - val_loss: 2.4619 - val_accuracy: 0.4852\n",
      "Epoch 842/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3720 - accuracy: 0.4758 - val_loss: 2.4727 - val_accuracy: 0.4907\n",
      "Epoch 843/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3702 - accuracy: 0.4776 - val_loss: 2.4850 - val_accuracy: 0.4811\n",
      "Epoch 844/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3834 - accuracy: 0.4712 - val_loss: 2.4881 - val_accuracy: 0.4854\n",
      "Epoch 845/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3840 - accuracy: 0.4772 - val_loss: 2.4699 - val_accuracy: 0.4776\n",
      "Epoch 846/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3870 - accuracy: 0.4692 - val_loss: 2.4846 - val_accuracy: 0.4854\n",
      "Epoch 847/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3770 - accuracy: 0.4786 - val_loss: 2.4810 - val_accuracy: 0.4836\n",
      "Epoch 848/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3710 - accuracy: 0.4764 - val_loss: 2.4649 - val_accuracy: 0.4841\n",
      "Epoch 849/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3864 - accuracy: 0.4719 - val_loss: 2.4751 - val_accuracy: 0.4844\n",
      "Epoch 850/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3706 - accuracy: 0.4764 - val_loss: 2.4836 - val_accuracy: 0.4833\n",
      "Epoch 851/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3792 - accuracy: 0.4754 - val_loss: 2.4744 - val_accuracy: 0.4819\n",
      "Epoch 852/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3673 - accuracy: 0.4747 - val_loss: 2.4755 - val_accuracy: 0.4868\n",
      "Epoch 853/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3672 - accuracy: 0.4797 - val_loss: 2.4606 - val_accuracy: 0.4851\n",
      "Epoch 854/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3659 - accuracy: 0.4754 - val_loss: 2.4724 - val_accuracy: 0.4877\n",
      "Epoch 855/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3612 - accuracy: 0.4784 - val_loss: 2.4785 - val_accuracy: 0.4842\n",
      "Epoch 856/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3662 - accuracy: 0.4780 - val_loss: 2.4624 - val_accuracy: 0.4843\n",
      "Epoch 857/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3614 - accuracy: 0.4767 - val_loss: 2.4634 - val_accuracy: 0.4822\n",
      "Epoch 858/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3729 - accuracy: 0.4749 - val_loss: 2.4670 - val_accuracy: 0.4851\n",
      "Epoch 859/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3708 - accuracy: 0.4779 - val_loss: 2.4805 - val_accuracy: 0.4825\n",
      "Epoch 860/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3754 - accuracy: 0.4743 - val_loss: 2.4900 - val_accuracy: 0.4844\n",
      "Epoch 861/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3931 - accuracy: 0.4730 - val_loss: 2.4697 - val_accuracy: 0.4829\n",
      "Epoch 862/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3737 - accuracy: 0.4741 - val_loss: 2.4730 - val_accuracy: 0.4815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3835 - accuracy: 0.4737 - val_loss: 2.4732 - val_accuracy: 0.4883\n",
      "Epoch 864/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3812 - accuracy: 0.4785 - val_loss: 2.4767 - val_accuracy: 0.4868\n",
      "Epoch 865/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4751 - val_loss: 2.4698 - val_accuracy: 0.4830\n",
      "Epoch 866/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3690 - accuracy: 0.4759 - val_loss: 2.4683 - val_accuracy: 0.4851\n",
      "Epoch 867/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3731 - accuracy: 0.4765 - val_loss: 2.4802 - val_accuracy: 0.4852\n",
      "Epoch 868/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3535 - accuracy: 0.4812 - val_loss: 2.4749 - val_accuracy: 0.4830\n",
      "Epoch 869/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3786 - accuracy: 0.4737 - val_loss: 2.4662 - val_accuracy: 0.4833\n",
      "Epoch 870/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3616 - accuracy: 0.4772 - val_loss: 2.4824 - val_accuracy: 0.4824\n",
      "Epoch 871/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3721 - accuracy: 0.4756 - val_loss: 2.4717 - val_accuracy: 0.4849\n",
      "Epoch 872/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3650 - accuracy: 0.4782 - val_loss: 2.4798 - val_accuracy: 0.4809\n",
      "Epoch 873/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3666 - accuracy: 0.4732 - val_loss: 2.4779 - val_accuracy: 0.4875\n",
      "Epoch 874/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3648 - accuracy: 0.4810 - val_loss: 2.4831 - val_accuracy: 0.4785\n",
      "Epoch 875/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3812 - accuracy: 0.4707 - val_loss: 2.5325 - val_accuracy: 0.4845\n",
      "Epoch 876/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4179 - accuracy: 0.4752 - val_loss: 2.5012 - val_accuracy: 0.4743\n",
      "Epoch 877/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4004 - accuracy: 0.4680 - val_loss: 2.4822 - val_accuracy: 0.4769\n",
      "Epoch 878/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3932 - accuracy: 0.4697 - val_loss: 2.4749 - val_accuracy: 0.4871\n",
      "Epoch 879/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3762 - accuracy: 0.4782 - val_loss: 2.4714 - val_accuracy: 0.4869\n",
      "Epoch 880/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3757 - accuracy: 0.4750 - val_loss: 2.4684 - val_accuracy: 0.4822\n",
      "Epoch 881/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3787 - accuracy: 0.4705 - val_loss: 2.4780 - val_accuracy: 0.4841\n",
      "Epoch 882/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3731 - accuracy: 0.4760 - val_loss: 2.4779 - val_accuracy: 0.4840\n",
      "Epoch 883/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3664 - accuracy: 0.4780 - val_loss: 2.4729 - val_accuracy: 0.4808\n",
      "Epoch 884/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3640 - accuracy: 0.4740 - val_loss: 2.4848 - val_accuracy: 0.4842\n",
      "Epoch 885/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3747 - accuracy: 0.4761 - val_loss: 2.5081 - val_accuracy: 0.4763\n",
      "Epoch 886/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3942 - accuracy: 0.4720 - val_loss: 2.6233 - val_accuracy: 0.4709\n",
      "Epoch 887/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5318 - accuracy: 0.4609 - val_loss: 2.5773 - val_accuracy: 0.4580\n",
      "Epoch 888/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5062 - accuracy: 0.4451 - val_loss: 2.5492 - val_accuracy: 0.4670\n",
      "Epoch 889/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4929 - accuracy: 0.4536 - val_loss: 2.5733 - val_accuracy: 0.4745\n",
      "Epoch 890/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5323 - accuracy: 0.4574 - val_loss: 2.5385 - val_accuracy: 0.4687\n",
      "Epoch 891/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4926 - accuracy: 0.4499 - val_loss: 2.5521 - val_accuracy: 0.4680\n",
      "Epoch 892/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4859 - accuracy: 0.4542 - val_loss: 2.5507 - val_accuracy: 0.4751\n",
      "Epoch 893/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4660 - accuracy: 0.4678 - val_loss: 2.5399 - val_accuracy: 0.4673\n",
      "Epoch 894/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4844 - accuracy: 0.4577 - val_loss: 2.6059 - val_accuracy: 0.4620\n",
      "Epoch 895/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5766 - accuracy: 0.4459 - val_loss: 2.8599 - val_accuracy: 0.4398\n",
      "Epoch 896/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8509 - accuracy: 0.4232 - val_loss: 3.1578 - val_accuracy: 0.3743\n",
      "Epoch 897/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2195 - accuracy: 0.3488 - val_loss: 3.2378 - val_accuracy: 0.3400\n",
      "Epoch 898/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2496 - accuracy: 0.3321 - val_loss: 11.0053 - val_accuracy: 0.0790\n",
      "Epoch 899/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0226 - accuracy: 0.0711 - val_loss: 12.6009 - val_accuracy: 0.0685\n",
      "Epoch 900/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.8352 - accuracy: 0.0601 - val_loss: 13.1285 - val_accuracy: 0.0620\n",
      "Epoch 901/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.2731 - accuracy: 0.0523 - val_loss: 12.2537 - val_accuracy: 0.1359\n",
      "Epoch 902/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.4594 - accuracy: 0.1187 - val_loss: 12.6287 - val_accuracy: 0.1197\n",
      "Epoch 903/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.7867 - accuracy: 0.1092 - val_loss: 11.7875 - val_accuracy: 0.1764\n",
      "Epoch 904/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.0414 - accuracy: 0.1601 - val_loss: 11.5398 - val_accuracy: 0.1916\n",
      "Epoch 905/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.6784 - accuracy: 0.1798 - val_loss: 11.2704 - val_accuracy: 0.2067\n",
      "Epoch 906/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.3429 - accuracy: 0.1979 - val_loss: 11.0923 - val_accuracy: 0.2177\n",
      "Epoch 907/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.1327 - accuracy: 0.2101 - val_loss: 11.1074 - val_accuracy: 0.2186\n",
      "Epoch 908/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.1290 - accuracy: 0.2115 - val_loss: 11.1191 - val_accuracy: 0.2155\n",
      "Epoch 909/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.1423 - accuracy: 0.2118 - val_loss: 11.1282 - val_accuracy: 0.2148\n",
      "Epoch 910/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.1598 - accuracy: 0.2105 - val_loss: 11.1444 - val_accuracy: 0.2161\n",
      "Epoch 911/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.1703 - accuracy: 0.2096 - val_loss: 11.1417 - val_accuracy: 0.2171\n",
      "Epoch 912/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.1941 - accuracy: 0.2072 - val_loss: 11.1446 - val_accuracy: 0.2173\n",
      "Epoch 913/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2066 - accuracy: 0.2065 - val_loss: 11.1455 - val_accuracy: 0.2155\n",
      "Epoch 914/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2188 - accuracy: 0.2069 - val_loss: 11.1565 - val_accuracy: 0.2147\n",
      "Epoch 915/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2246 - accuracy: 0.2070 - val_loss: 11.1647 - val_accuracy: 0.2138\n",
      "Epoch 916/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2322 - accuracy: 0.2061 - val_loss: 11.1601 - val_accuracy: 0.2147\n",
      "Epoch 917/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2604 - accuracy: 0.2039 - val_loss: 11.1577 - val_accuracy: 0.2150\n",
      "Epoch 918/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2597 - accuracy: 0.2033 - val_loss: 11.1638 - val_accuracy: 0.2155\n",
      "Epoch 919/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2683 - accuracy: 0.2027 - val_loss: 11.1697 - val_accuracy: 0.2170\n",
      "Epoch 920/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2856 - accuracy: 0.2019 - val_loss: 11.1760 - val_accuracy: 0.2174\n",
      "Epoch 921/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2939 - accuracy: 0.2012 - val_loss: 11.1745 - val_accuracy: 0.2179\n",
      "Epoch 922/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2958 - accuracy: 0.2022 - val_loss: 11.1728 - val_accuracy: 0.2176\n",
      "Epoch 923/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.3152 - accuracy: 0.2014 - val_loss: 11.1722 - val_accuracy: 0.2180\n",
      "Epoch 924/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.3224 - accuracy: 0.2012 - val_loss: 11.1743 - val_accuracy: 0.2168\n",
      "Epoch 925/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.3351 - accuracy: 0.2009 - val_loss: 11.1758 - val_accuracy: 0.2167\n",
      "Epoch 926/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.3646 - accuracy: 0.1988 - val_loss: 11.1795 - val_accuracy: 0.2172\n",
      "Epoch 927/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.3530 - accuracy: 0.1998 - val_loss: 11.1809 - val_accuracy: 0.2175\n",
      "Epoch 928/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.3705 - accuracy: 0.1986 - val_loss: 11.0308 - val_accuracy: 0.2254\n",
      "Epoch 929/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0512 - accuracy: 0.2179 - val_loss: 11.0253 - val_accuracy: 0.2242\n",
      "Epoch 930/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0432 - accuracy: 0.2189 - val_loss: 11.0410 - val_accuracy: 0.2231\n",
      "Epoch 931/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0573 - accuracy: 0.2180 - val_loss: 11.0383 - val_accuracy: 0.2240\n",
      "Epoch 932/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0635 - accuracy: 0.2176 - val_loss: 11.0411 - val_accuracy: 0.2261\n",
      "Epoch 933/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0600 - accuracy: 0.2182 - val_loss: 11.0462 - val_accuracy: 0.2267\n",
      "Epoch 934/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0623 - accuracy: 0.2178 - val_loss: 11.0439 - val_accuracy: 0.2271\n",
      "Epoch 935/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0659 - accuracy: 0.2178 - val_loss: 11.0427 - val_accuracy: 0.2269\n",
      "Epoch 936/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0596 - accuracy: 0.2183 - val_loss: 11.0426 - val_accuracy: 0.2258\n",
      "Epoch 937/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0602 - accuracy: 0.2181 - val_loss: 11.0408 - val_accuracy: 0.2256\n",
      "Epoch 938/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0617 - accuracy: 0.2177 - val_loss: 11.0405 - val_accuracy: 0.2257\n",
      "Epoch 939/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0567 - accuracy: 0.2183 - val_loss: 11.0396 - val_accuracy: 0.2258\n",
      "Epoch 940/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0588 - accuracy: 0.2180 - val_loss: 11.0414 - val_accuracy: 0.2261\n",
      "Epoch 941/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0589 - accuracy: 0.2185 - val_loss: 11.0422 - val_accuracy: 0.2263\n",
      "Epoch 942/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0580 - accuracy: 0.2182 - val_loss: 11.0435 - val_accuracy: 0.2259\n",
      "Epoch 943/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0523 - accuracy: 0.2189 - val_loss: 11.0428 - val_accuracy: 0.2258\n",
      "Epoch 944/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0512 - accuracy: 0.2190 - val_loss: 11.0411 - val_accuracy: 0.2261\n",
      "Epoch 945/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0518 - accuracy: 0.2191 - val_loss: 11.0379 - val_accuracy: 0.2269\n",
      "Epoch 946/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0516 - accuracy: 0.2190 - val_loss: 11.0347 - val_accuracy: 0.2278\n",
      "Epoch 947/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0502 - accuracy: 0.2191 - val_loss: 11.0330 - val_accuracy: 0.2282\n",
      "Epoch 948/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0493 - accuracy: 0.2190 - val_loss: 11.0322 - val_accuracy: 0.2282\n",
      "Epoch 949/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.0493 - accuracy: 0.2194 - val_loss: 11.0319 - val_accuracy: 0.2281\n",
      "Epoch 1/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 5.4315 - accuracy: 0.0050 - val_loss: 9.4912 - val_accuracy: 0.2065\n",
      "Epoch 2/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 9.5304 - accuracy: 0.2063 - val_loss: 5.0071 - val_accuracy: 0.0455\n",
      "Epoch 3/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.0075 - accuracy: 0.0454 - val_loss: 6.7094 - val_accuracy: 0.0333\n",
      "Epoch 4/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 6.7838 - accuracy: 0.0331 - val_loss: 5.0474 - val_accuracy: 0.0408\n",
      "Epoch 5/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.0493 - accuracy: 0.0378 - val_loss: 5.1113 - val_accuracy: 0.0269\n",
      "Epoch 6/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.1121 - accuracy: 0.0266 - val_loss: 4.9286 - val_accuracy: 0.0965\n",
      "Epoch 7/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.9309 - accuracy: 0.0928 - val_loss: 4.6737 - val_accuracy: 0.0965\n",
      "Epoch 8/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6791 - accuracy: 0.0945 - val_loss: 4.5629 - val_accuracy: 0.0974\n",
      "Epoch 9/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.5730 - accuracy: 0.0958 - val_loss: 4.5930 - val_accuracy: 0.1072\n",
      "Epoch 10/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6064 - accuracy: 0.1109 - val_loss: 4.4906 - val_accuracy: 0.1585\n",
      "Epoch 11/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4991 - accuracy: 0.1394 - val_loss: 4.4542 - val_accuracy: 0.1584\n",
      "Epoch 12/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4637 - accuracy: 0.1558 - val_loss: 4.4685 - val_accuracy: 0.1562\n",
      "Epoch 13/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4731 - accuracy: 0.1528 - val_loss: 4.4348 - val_accuracy: 0.1577\n",
      "Epoch 14/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4370 - accuracy: 0.1543 - val_loss: 4.3680 - val_accuracy: 0.1594\n",
      "Epoch 15/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3717 - accuracy: 0.1613 - val_loss: 4.3733 - val_accuracy: 0.1669\n",
      "Epoch 16/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3774 - accuracy: 0.1685 - val_loss: 4.3530 - val_accuracy: 0.1672\n",
      "Epoch 17/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3591 - accuracy: 0.1681 - val_loss: 4.3630 - val_accuracy: 0.1584\n",
      "Epoch 18/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3807 - accuracy: 0.1593 - val_loss: 4.2689 - val_accuracy: 0.1634\n",
      "Epoch 19/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2745 - accuracy: 0.1636 - val_loss: 4.2663 - val_accuracy: 0.1721\n",
      "Epoch 20/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2658 - accuracy: 0.1687 - val_loss: 4.2599 - val_accuracy: 0.1774\n",
      "Epoch 21/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2603 - accuracy: 0.1749 - val_loss: 4.2506 - val_accuracy: 0.1796\n",
      "Epoch 22/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2528 - accuracy: 0.1797 - val_loss: 4.2265 - val_accuracy: 0.1806\n",
      "Epoch 23/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2305 - accuracy: 0.1839 - val_loss: 4.1975 - val_accuracy: 0.2078\n",
      "Epoch 24/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2061 - accuracy: 0.1959 - val_loss: 4.1725 - val_accuracy: 0.2121\n",
      "Epoch 25/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1800 - accuracy: 0.2024 - val_loss: 4.1457 - val_accuracy: 0.2102\n",
      "Epoch 26/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1539 - accuracy: 0.2038 - val_loss: 4.1001 - val_accuracy: 0.2119\n",
      "Epoch 27/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1118 - accuracy: 0.2087 - val_loss: 4.1081 - val_accuracy: 0.2130\n",
      "Epoch 28/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 4.1376 - accuracy: 0.2100 - val_loss: 4.0289 - val_accuracy: 0.2162\n",
      "Epoch 29/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0529 - accuracy: 0.2135 - val_loss: 4.0319 - val_accuracy: 0.2196\n",
      "Epoch 30/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0677 - accuracy: 0.2159 - val_loss: 4.0351 - val_accuracy: 0.2189\n",
      "Epoch 31/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0506 - accuracy: 0.2156 - val_loss: 4.0063 - val_accuracy: 0.2202\n",
      "Epoch 32/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0244 - accuracy: 0.2158 - val_loss: 3.9970 - val_accuracy: 0.2210\n",
      "Epoch 33/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0201 - accuracy: 0.2155 - val_loss: 3.9687 - val_accuracy: 0.2228\n",
      "Epoch 34/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9967 - accuracy: 0.2171 - val_loss: 4.1947 - val_accuracy: 0.2225\n",
      "Epoch 35/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2141 - accuracy: 0.2180 - val_loss: 3.9369 - val_accuracy: 0.2230\n",
      "Epoch 36/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9596 - accuracy: 0.2176 - val_loss: 3.9240 - val_accuracy: 0.2260\n",
      "Epoch 37/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9510 - accuracy: 0.2187 - val_loss: 3.9109 - val_accuracy: 0.2278\n",
      "Epoch 38/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9411 - accuracy: 0.2207 - val_loss: 3.8919 - val_accuracy: 0.2284\n",
      "Epoch 39/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9261 - accuracy: 0.2210 - val_loss: 3.8793 - val_accuracy: 0.2284\n",
      "Epoch 40/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9156 - accuracy: 0.2223 - val_loss: 3.8608 - val_accuracy: 0.2282\n",
      "Epoch 41/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8884 - accuracy: 0.2222 - val_loss: 3.8305 - val_accuracy: 0.2258\n",
      "Epoch 42/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8808 - accuracy: 0.2221 - val_loss: 3.8275 - val_accuracy: 0.2267\n",
      "Epoch 43/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8577 - accuracy: 0.2235 - val_loss: 3.8165 - val_accuracy: 0.2308\n",
      "Epoch 44/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8445 - accuracy: 0.2277 - val_loss: 3.7902 - val_accuracy: 0.2320\n",
      "Epoch 45/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8258 - accuracy: 0.2304 - val_loss: 3.7952 - val_accuracy: 0.2327\n",
      "Epoch 46/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8192 - accuracy: 0.2293 - val_loss: 3.7753 - val_accuracy: 0.2367\n",
      "Epoch 47/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8132 - accuracy: 0.2310 - val_loss: 3.7650 - val_accuracy: 0.2370\n",
      "Epoch 48/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7988 - accuracy: 0.2310 - val_loss: 3.7505 - val_accuracy: 0.2376\n",
      "Epoch 49/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7851 - accuracy: 0.2325 - val_loss: 3.7304 - val_accuracy: 0.2409\n",
      "Epoch 50/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7698 - accuracy: 0.2349 - val_loss: 3.7152 - val_accuracy: 0.2414\n",
      "Epoch 51/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7489 - accuracy: 0.2374 - val_loss: 3.6807 - val_accuracy: 0.2469\n",
      "Epoch 52/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7212 - accuracy: 0.2416 - val_loss: 3.6852 - val_accuracy: 0.2497\n",
      "Epoch 53/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7387 - accuracy: 0.2444 - val_loss: 3.6520 - val_accuracy: 0.2476\n",
      "Epoch 54/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7000 - accuracy: 0.2455 - val_loss: 3.6491 - val_accuracy: 0.2504\n",
      "Epoch 55/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7005 - accuracy: 0.2438 - val_loss: 3.6595 - val_accuracy: 0.2425\n",
      "Epoch 56/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6992 - accuracy: 0.2396 - val_loss: 3.6402 - val_accuracy: 0.2447\n",
      "Epoch 57/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6775 - accuracy: 0.2428 - val_loss: 3.6191 - val_accuracy: 0.2516\n",
      "Epoch 58/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6703 - accuracy: 0.2473 - val_loss: 3.6032 - val_accuracy: 0.2533\n",
      "Epoch 59/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6538 - accuracy: 0.2468 - val_loss: 3.5916 - val_accuracy: 0.2619\n",
      "Epoch 60/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6494 - accuracy: 0.2555 - val_loss: 3.5670 - val_accuracy: 0.2607\n",
      "Epoch 61/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6075 - accuracy: 0.2578 - val_loss: 3.5596 - val_accuracy: 0.2664\n",
      "Epoch 62/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6103 - accuracy: 0.2601 - val_loss: 3.5424 - val_accuracy: 0.2649\n",
      "Epoch 63/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5912 - accuracy: 0.2622 - val_loss: 3.5168 - val_accuracy: 0.2697\n",
      "Epoch 64/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5652 - accuracy: 0.2643 - val_loss: 3.5029 - val_accuracy: 0.2726\n",
      "Epoch 65/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5654 - accuracy: 0.2652 - val_loss: 3.5085 - val_accuracy: 0.2665\n",
      "Epoch 66/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5906 - accuracy: 0.2618 - val_loss: 3.4892 - val_accuracy: 0.2769\n",
      "Epoch 67/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5427 - accuracy: 0.2700 - val_loss: 3.4632 - val_accuracy: 0.2801\n",
      "Epoch 68/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5302 - accuracy: 0.2726 - val_loss: 3.4483 - val_accuracy: 0.2808\n",
      "Epoch 69/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5052 - accuracy: 0.2739 - val_loss: 3.4476 - val_accuracy: 0.2833\n",
      "Epoch 70/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5033 - accuracy: 0.2746 - val_loss: 3.4323 - val_accuracy: 0.2875\n",
      "Epoch 71/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4926 - accuracy: 0.2791 - val_loss: 3.4123 - val_accuracy: 0.2872\n",
      "Epoch 72/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4643 - accuracy: 0.2822 - val_loss: 3.3996 - val_accuracy: 0.2837\n",
      "Epoch 73/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4491 - accuracy: 0.2781 - val_loss: 3.3837 - val_accuracy: 0.2864\n",
      "Epoch 74/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4469 - accuracy: 0.2798 - val_loss: 3.3542 - val_accuracy: 0.2941\n",
      "Epoch 75/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4203 - accuracy: 0.2891 - val_loss: 3.3434 - val_accuracy: 0.3001\n",
      "Epoch 76/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4073 - accuracy: 0.2896 - val_loss: 3.3390 - val_accuracy: 0.2991\n",
      "Epoch 77/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3852 - accuracy: 0.2929 - val_loss: 3.3201 - val_accuracy: 0.3035\n",
      "Epoch 78/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3744 - accuracy: 0.2953 - val_loss: 3.3132 - val_accuracy: 0.3044\n",
      "Epoch 79/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3648 - accuracy: 0.2971 - val_loss: 3.2917 - val_accuracy: 0.3110\n",
      "Epoch 80/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3605 - accuracy: 0.3001 - val_loss: 3.2975 - val_accuracy: 0.3103\n",
      "Epoch 81/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3416 - accuracy: 0.3024 - val_loss: 3.2769 - val_accuracy: 0.3140\n",
      "Epoch 82/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3290 - accuracy: 0.3051 - val_loss: 3.2654 - val_accuracy: 0.3091\n",
      "Epoch 83/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3359 - accuracy: 0.3008 - val_loss: 3.2661 - val_accuracy: 0.3204\n",
      "Epoch 84/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3164 - accuracy: 0.3114 - val_loss: 3.2506 - val_accuracy: 0.3206\n",
      "Epoch 85/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3148 - accuracy: 0.3109 - val_loss: 3.2609 - val_accuracy: 0.3192\n",
      "Epoch 86/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2999 - accuracy: 0.3111 - val_loss: 3.2217 - val_accuracy: 0.3214\n",
      "Epoch 87/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2813 - accuracy: 0.3117 - val_loss: 3.2381 - val_accuracy: 0.3258\n",
      "Epoch 88/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2862 - accuracy: 0.3143 - val_loss: 3.2042 - val_accuracy: 0.3273\n",
      "Epoch 89/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2560 - accuracy: 0.3186 - val_loss: 3.1975 - val_accuracy: 0.3287\n",
      "Epoch 90/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2435 - accuracy: 0.3215 - val_loss: 3.1681 - val_accuracy: 0.3319\n",
      "Epoch 91/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2287 - accuracy: 0.3255 - val_loss: 3.1390 - val_accuracy: 0.3381\n",
      "Epoch 92/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2075 - accuracy: 0.3308 - val_loss: 3.2119 - val_accuracy: 0.3283\n",
      "Epoch 93/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2406 - accuracy: 0.3276 - val_loss: 3.1030 - val_accuracy: 0.3471\n",
      "Epoch 94/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1851 - accuracy: 0.3348 - val_loss: 3.0989 - val_accuracy: 0.3494\n",
      "Epoch 95/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1990 - accuracy: 0.3338 - val_loss: 3.1371 - val_accuracy: 0.3456\n",
      "Epoch 96/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1760 - accuracy: 0.3380 - val_loss: 3.1034 - val_accuracy: 0.3504\n",
      "Epoch 97/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1510 - accuracy: 0.3439 - val_loss: 3.0683 - val_accuracy: 0.3549\n",
      "Epoch 98/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1462 - accuracy: 0.3416 - val_loss: 3.0429 - val_accuracy: 0.3618\n",
      "Epoch 99/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1230 - accuracy: 0.3471 - val_loss: 3.0651 - val_accuracy: 0.3595\n",
      "Epoch 100/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1084 - accuracy: 0.3499 - val_loss: 3.0344 - val_accuracy: 0.3635\n",
      "Epoch 101/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0842 - accuracy: 0.3532 - val_loss: 3.0323 - val_accuracy: 0.3719\n",
      "Epoch 102/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0939 - accuracy: 0.3577 - val_loss: 3.0709 - val_accuracy: 0.3453\n",
      "Epoch 103/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1569 - accuracy: 0.3339 - val_loss: 3.0339 - val_accuracy: 0.3728\n",
      "Epoch 104/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0925 - accuracy: 0.3585 - val_loss: 3.0219 - val_accuracy: 0.3723\n",
      "Epoch 105/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0786 - accuracy: 0.3537 - val_loss: 3.0002 - val_accuracy: 0.3588\n",
      "Epoch 106/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0711 - accuracy: 0.3466 - val_loss: 2.9835 - val_accuracy: 0.3694\n",
      "Epoch 107/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0520 - accuracy: 0.3541 - val_loss: 2.9848 - val_accuracy: 0.3759\n",
      "Epoch 108/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0452 - accuracy: 0.3602 - val_loss: 2.9864 - val_accuracy: 0.3712\n",
      "Epoch 109/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0401 - accuracy: 0.3590 - val_loss: 2.9767 - val_accuracy: 0.3814\n",
      "Epoch 110/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0249 - accuracy: 0.3650 - val_loss: 2.9374 - val_accuracy: 0.3868\n",
      "Epoch 111/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0369 - accuracy: 0.3671 - val_loss: 2.9755 - val_accuracy: 0.3874\n",
      "Epoch 112/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0114 - accuracy: 0.3689 - val_loss: 2.9383 - val_accuracy: 0.3851\n",
      "Epoch 113/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9974 - accuracy: 0.3676 - val_loss: 2.9151 - val_accuracy: 0.3874\n",
      "Epoch 114/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9839 - accuracy: 0.3719 - val_loss: 2.9018 - val_accuracy: 0.3846\n",
      "Epoch 115/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9614 - accuracy: 0.3717 - val_loss: 2.9003 - val_accuracy: 0.3818\n",
      "Epoch 116/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9540 - accuracy: 0.3688 - val_loss: 2.8951 - val_accuracy: 0.3878\n",
      "Epoch 117/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9412 - accuracy: 0.3747 - val_loss: 2.8541 - val_accuracy: 0.3910\n",
      "Epoch 118/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9217 - accuracy: 0.3788 - val_loss: 2.8413 - val_accuracy: 0.3956\n",
      "Epoch 119/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9111 - accuracy: 0.3803 - val_loss: 2.8474 - val_accuracy: 0.4022\n",
      "Epoch 120/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9027 - accuracy: 0.3850 - val_loss: 2.8218 - val_accuracy: 0.4024\n",
      "Epoch 121/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8916 - accuracy: 0.3832 - val_loss: 2.8123 - val_accuracy: 0.4017\n",
      "Epoch 122/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8847 - accuracy: 0.3846 - val_loss: 2.8085 - val_accuracy: 0.4029\n",
      "Epoch 123/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8695 - accuracy: 0.3866 - val_loss: 2.7974 - val_accuracy: 0.4076\n",
      "Epoch 124/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8651 - accuracy: 0.3874 - val_loss: 2.7889 - val_accuracy: 0.4082\n",
      "Epoch 125/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8662 - accuracy: 0.3857 - val_loss: 2.7800 - val_accuracy: 0.4102\n",
      "Epoch 126/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8496 - accuracy: 0.3916 - val_loss: 2.7793 - val_accuracy: 0.4089\n",
      "Epoch 127/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8475 - accuracy: 0.3901 - val_loss: 2.7774 - val_accuracy: 0.4091\n",
      "Epoch 128/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8362 - accuracy: 0.3918 - val_loss: 2.7595 - val_accuracy: 0.4143\n",
      "Epoch 129/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8389 - accuracy: 0.3931 - val_loss: 2.7808 - val_accuracy: 0.4114\n",
      "Epoch 130/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8285 - accuracy: 0.3953 - val_loss: 2.7577 - val_accuracy: 0.4093\n",
      "Epoch 131/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8255 - accuracy: 0.3915 - val_loss: 2.7547 - val_accuracy: 0.4129\n",
      "Epoch 132/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8074 - accuracy: 0.3957 - val_loss: 2.7426 - val_accuracy: 0.4144\n",
      "Epoch 133/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8094 - accuracy: 0.3952 - val_loss: 2.7447 - val_accuracy: 0.4142\n",
      "Epoch 134/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8051 - accuracy: 0.3970 - val_loss: 2.7340 - val_accuracy: 0.4140\n",
      "Epoch 135/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7969 - accuracy: 0.3964 - val_loss: 2.7330 - val_accuracy: 0.4190\n",
      "Epoch 136/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7862 - accuracy: 0.4027 - val_loss: 2.7090 - val_accuracy: 0.4206\n",
      "Epoch 137/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7840 - accuracy: 0.4019 - val_loss: 2.7545 - val_accuracy: 0.4187\n",
      "Epoch 138/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7926 - accuracy: 0.4014 - val_loss: 2.7182 - val_accuracy: 0.4156\n",
      "Epoch 139/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7817 - accuracy: 0.3982 - val_loss: 2.6992 - val_accuracy: 0.4183\n",
      "Epoch 140/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7701 - accuracy: 0.4014 - val_loss: 2.7431 - val_accuracy: 0.4207\n",
      "Epoch 141/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7906 - accuracy: 0.4012 - val_loss: 2.6952 - val_accuracy: 0.4210\n",
      "Epoch 142/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7631 - accuracy: 0.4039 - val_loss: 2.7067 - val_accuracy: 0.4194\n",
      "Epoch 143/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7643 - accuracy: 0.4021 - val_loss: 2.7046 - val_accuracy: 0.4238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7639 - accuracy: 0.4051 - val_loss: 2.7048 - val_accuracy: 0.4198\n",
      "Epoch 145/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7691 - accuracy: 0.4016 - val_loss: 2.7014 - val_accuracy: 0.4232\n",
      "Epoch 146/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7606 - accuracy: 0.4049 - val_loss: 2.6825 - val_accuracy: 0.4277\n",
      "Epoch 147/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7444 - accuracy: 0.4089 - val_loss: 2.6843 - val_accuracy: 0.4260\n",
      "Epoch 148/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7498 - accuracy: 0.4086 - val_loss: 2.7130 - val_accuracy: 0.4234\n",
      "Epoch 149/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7544 - accuracy: 0.4038 - val_loss: 2.6787 - val_accuracy: 0.4283\n",
      "Epoch 150/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7492 - accuracy: 0.4078 - val_loss: 2.6841 - val_accuracy: 0.4307\n",
      "Epoch 151/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7358 - accuracy: 0.4076 - val_loss: 2.6858 - val_accuracy: 0.4297\n",
      "Epoch 152/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7371 - accuracy: 0.4088 - val_loss: 2.6584 - val_accuracy: 0.4268\n",
      "Epoch 153/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7354 - accuracy: 0.4083 - val_loss: 2.7174 - val_accuracy: 0.4255\n",
      "Epoch 154/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7630 - accuracy: 0.4088 - val_loss: 2.6801 - val_accuracy: 0.4307\n",
      "Epoch 155/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7338 - accuracy: 0.4091 - val_loss: 2.6711 - val_accuracy: 0.4210\n",
      "Epoch 156/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7470 - accuracy: 0.4042 - val_loss: 2.7073 - val_accuracy: 0.4287\n",
      "Epoch 157/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7392 - accuracy: 0.4115 - val_loss: 2.6943 - val_accuracy: 0.4347\n",
      "Epoch 158/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7363 - accuracy: 0.4123 - val_loss: 2.6602 - val_accuracy: 0.4275\n",
      "Epoch 159/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7293 - accuracy: 0.4091 - val_loss: 2.6709 - val_accuracy: 0.4269\n",
      "Epoch 160/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7150 - accuracy: 0.4090 - val_loss: 2.6713 - val_accuracy: 0.4308\n",
      "Epoch 161/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7133 - accuracy: 0.4137 - val_loss: 2.6510 - val_accuracy: 0.4331\n",
      "Epoch 162/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7124 - accuracy: 0.4162 - val_loss: 2.6554 - val_accuracy: 0.4314\n",
      "Epoch 163/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6978 - accuracy: 0.4158 - val_loss: 2.6508 - val_accuracy: 0.4312\n",
      "Epoch 164/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7011 - accuracy: 0.4139 - val_loss: 2.6454 - val_accuracy: 0.4368\n",
      "Epoch 165/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6997 - accuracy: 0.4181 - val_loss: 2.6517 - val_accuracy: 0.4330\n",
      "Epoch 166/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6888 - accuracy: 0.4163 - val_loss: 2.6368 - val_accuracy: 0.4331\n",
      "Epoch 167/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6894 - accuracy: 0.4165 - val_loss: 2.6328 - val_accuracy: 0.4400\n",
      "Epoch 168/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6793 - accuracy: 0.4207 - val_loss: 2.6275 - val_accuracy: 0.4433\n",
      "Epoch 169/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6700 - accuracy: 0.4225 - val_loss: 2.6156 - val_accuracy: 0.4418\n",
      "Epoch 170/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6633 - accuracy: 0.4221 - val_loss: 2.6189 - val_accuracy: 0.4425\n",
      "Epoch 171/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6663 - accuracy: 0.4204 - val_loss: 2.6302 - val_accuracy: 0.4405\n",
      "Epoch 172/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6656 - accuracy: 0.4217 - val_loss: 2.6199 - val_accuracy: 0.4406\n",
      "Epoch 173/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6589 - accuracy: 0.4258 - val_loss: 2.6129 - val_accuracy: 0.4385\n",
      "Epoch 174/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6610 - accuracy: 0.4218 - val_loss: 2.6335 - val_accuracy: 0.4417\n",
      "Epoch 175/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6620 - accuracy: 0.4248 - val_loss: 2.6041 - val_accuracy: 0.4474\n",
      "Epoch 176/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6507 - accuracy: 0.4267 - val_loss: 2.5957 - val_accuracy: 0.4425\n",
      "Epoch 177/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6526 - accuracy: 0.4225 - val_loss: 2.6210 - val_accuracy: 0.4441\n",
      "Epoch 178/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6534 - accuracy: 0.4255 - val_loss: 2.5939 - val_accuracy: 0.4485\n",
      "Epoch 179/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6358 - accuracy: 0.4281 - val_loss: 2.5923 - val_accuracy: 0.4445\n",
      "Epoch 180/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6452 - accuracy: 0.4234 - val_loss: 2.6057 - val_accuracy: 0.4455\n",
      "Epoch 181/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6409 - accuracy: 0.4265 - val_loss: 2.5944 - val_accuracy: 0.4478\n",
      "Epoch 182/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6345 - accuracy: 0.4285 - val_loss: 2.6086 - val_accuracy: 0.4437\n",
      "Epoch 183/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6470 - accuracy: 0.4265 - val_loss: 2.6175 - val_accuracy: 0.4408\n",
      "Epoch 184/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6614 - accuracy: 0.4212 - val_loss: 2.6097 - val_accuracy: 0.4508\n",
      "Epoch 185/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6394 - accuracy: 0.4311 - val_loss: 2.6070 - val_accuracy: 0.4452\n",
      "Epoch 186/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6455 - accuracy: 0.4267 - val_loss: 2.5997 - val_accuracy: 0.4469\n",
      "Epoch 187/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6321 - accuracy: 0.4273 - val_loss: 2.6173 - val_accuracy: 0.4514\n",
      "Epoch 188/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6420 - accuracy: 0.4301 - val_loss: 2.5864 - val_accuracy: 0.4525\n",
      "Epoch 189/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6236 - accuracy: 0.4335 - val_loss: 2.5941 - val_accuracy: 0.4476\n",
      "Epoch 190/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6253 - accuracy: 0.4306 - val_loss: 2.5873 - val_accuracy: 0.4464\n",
      "Epoch 191/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6145 - accuracy: 0.4299 - val_loss: 2.5687 - val_accuracy: 0.4550\n",
      "Epoch 192/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6198 - accuracy: 0.4323 - val_loss: 2.5934 - val_accuracy: 0.4568\n",
      "Epoch 193/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6215 - accuracy: 0.4357 - val_loss: 2.5789 - val_accuracy: 0.4516\n",
      "Epoch 194/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6174 - accuracy: 0.4296 - val_loss: 2.5789 - val_accuracy: 0.4453\n",
      "Epoch 195/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6154 - accuracy: 0.4274 - val_loss: 2.5822 - val_accuracy: 0.4570\n",
      "Epoch 196/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6071 - accuracy: 0.4360 - val_loss: 2.5808 - val_accuracy: 0.4557\n",
      "Epoch 197/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6147 - accuracy: 0.4343 - val_loss: 2.5726 - val_accuracy: 0.4538\n",
      "Epoch 198/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6128 - accuracy: 0.4319 - val_loss: 2.5716 - val_accuracy: 0.4530\n",
      "Epoch 199/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6058 - accuracy: 0.4334 - val_loss: 2.5793 - val_accuracy: 0.4545\n",
      "Epoch 200/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6110 - accuracy: 0.4338 - val_loss: 2.5753 - val_accuracy: 0.4563\n",
      "Epoch 201/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6000 - accuracy: 0.4363 - val_loss: 2.5609 - val_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6015 - accuracy: 0.4340 - val_loss: 2.5759 - val_accuracy: 0.4551\n",
      "Epoch 203/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5994 - accuracy: 0.4360 - val_loss: 2.5840 - val_accuracy: 0.4511\n",
      "Epoch 204/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6017 - accuracy: 0.4343 - val_loss: 2.5589 - val_accuracy: 0.4511\n",
      "Epoch 205/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6000 - accuracy: 0.4314 - val_loss: 2.5912 - val_accuracy: 0.4597\n",
      "Epoch 206/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6117 - accuracy: 0.4374 - val_loss: 2.5714 - val_accuracy: 0.4607\n",
      "Epoch 207/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6075 - accuracy: 0.4393 - val_loss: 2.5982 - val_accuracy: 0.4376\n",
      "Epoch 208/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6264 - accuracy: 0.4226 - val_loss: 2.5693 - val_accuracy: 0.4460\n",
      "Epoch 209/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6076 - accuracy: 0.4303 - val_loss: 2.6173 - val_accuracy: 0.4551\n",
      "Epoch 210/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6314 - accuracy: 0.4348 - val_loss: 2.5929 - val_accuracy: 0.4512\n",
      "Epoch 211/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6234 - accuracy: 0.4336 - val_loss: 2.5867 - val_accuracy: 0.4489\n",
      "Epoch 212/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6135 - accuracy: 0.4282 - val_loss: 2.5940 - val_accuracy: 0.4568\n",
      "Epoch 213/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6281 - accuracy: 0.4347 - val_loss: 2.5678 - val_accuracy: 0.4565\n",
      "Epoch 214/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5988 - accuracy: 0.4357 - val_loss: 2.5733 - val_accuracy: 0.4500\n",
      "Epoch 215/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6042 - accuracy: 0.4299 - val_loss: 2.5578 - val_accuracy: 0.4574\n",
      "Epoch 216/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6019 - accuracy: 0.4342 - val_loss: 2.5589 - val_accuracy: 0.4638\n",
      "Epoch 217/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5986 - accuracy: 0.4404 - val_loss: 2.5614 - val_accuracy: 0.4627\n",
      "Epoch 218/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5889 - accuracy: 0.4390 - val_loss: 2.5535 - val_accuracy: 0.4554\n",
      "Epoch 219/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5901 - accuracy: 0.4367 - val_loss: 2.5545 - val_accuracy: 0.4549\n",
      "Epoch 220/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5860 - accuracy: 0.4347 - val_loss: 2.5593 - val_accuracy: 0.4612\n",
      "Epoch 221/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5801 - accuracy: 0.4401 - val_loss: 2.5442 - val_accuracy: 0.4659\n",
      "Epoch 222/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5874 - accuracy: 0.4397 - val_loss: 2.5459 - val_accuracy: 0.4589\n",
      "Epoch 223/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5716 - accuracy: 0.4385 - val_loss: 2.5507 - val_accuracy: 0.4630\n",
      "Epoch 224/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5754 - accuracy: 0.4413 - val_loss: 2.5421 - val_accuracy: 0.4656\n",
      "Epoch 225/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5643 - accuracy: 0.4432 - val_loss: 2.5448 - val_accuracy: 0.4648\n",
      "Epoch 226/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5623 - accuracy: 0.4428 - val_loss: 2.5356 - val_accuracy: 0.4654\n",
      "Epoch 227/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5665 - accuracy: 0.4425 - val_loss: 2.5296 - val_accuracy: 0.4654\n",
      "Epoch 228/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5565 - accuracy: 0.4431 - val_loss: 2.5323 - val_accuracy: 0.4656\n",
      "Epoch 229/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5539 - accuracy: 0.4447 - val_loss: 2.5253 - val_accuracy: 0.4677\n",
      "Epoch 230/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5506 - accuracy: 0.4443 - val_loss: 2.5340 - val_accuracy: 0.4676\n",
      "Epoch 231/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5542 - accuracy: 0.4457 - val_loss: 2.5191 - val_accuracy: 0.4649\n",
      "Epoch 232/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5660 - accuracy: 0.4413 - val_loss: 2.5761 - val_accuracy: 0.4579\n",
      "Epoch 233/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5808 - accuracy: 0.4407 - val_loss: 2.5328 - val_accuracy: 0.4630\n",
      "Epoch 234/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5518 - accuracy: 0.4441 - val_loss: 2.5300 - val_accuracy: 0.4659\n",
      "Epoch 235/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5610 - accuracy: 0.4442 - val_loss: 2.5493 - val_accuracy: 0.4603\n",
      "Epoch 236/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5600 - accuracy: 0.4419 - val_loss: 2.5253 - val_accuracy: 0.4653\n",
      "Epoch 237/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5512 - accuracy: 0.4451 - val_loss: 2.5240 - val_accuracy: 0.4711\n",
      "Epoch 238/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5476 - accuracy: 0.4501 - val_loss: 2.5207 - val_accuracy: 0.4683\n",
      "Epoch 239/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5424 - accuracy: 0.4467 - val_loss: 2.5147 - val_accuracy: 0.4639\n",
      "Epoch 240/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5476 - accuracy: 0.4409 - val_loss: 2.5262 - val_accuracy: 0.4662\n",
      "Epoch 241/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5377 - accuracy: 0.4485 - val_loss: 2.5181 - val_accuracy: 0.4678\n",
      "Epoch 242/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5443 - accuracy: 0.4501 - val_loss: 2.5189 - val_accuracy: 0.4703\n",
      "Epoch 243/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5317 - accuracy: 0.4485 - val_loss: 2.5282 - val_accuracy: 0.4623\n",
      "Epoch 244/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5314 - accuracy: 0.4453 - val_loss: 2.5096 - val_accuracy: 0.4705\n",
      "Epoch 245/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5321 - accuracy: 0.4496 - val_loss: 2.5289 - val_accuracy: 0.4753\n",
      "Epoch 246/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5333 - accuracy: 0.4536 - val_loss: 2.5143 - val_accuracy: 0.4630\n",
      "Epoch 247/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5340 - accuracy: 0.4442 - val_loss: 2.5167 - val_accuracy: 0.4661\n",
      "Epoch 248/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5218 - accuracy: 0.4486 - val_loss: 2.5236 - val_accuracy: 0.4721\n",
      "Epoch 249/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5314 - accuracy: 0.4509 - val_loss: 2.5169 - val_accuracy: 0.4669\n",
      "Epoch 250/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5345 - accuracy: 0.4459 - val_loss: 2.5304 - val_accuracy: 0.4639\n",
      "Epoch 251/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5394 - accuracy: 0.4444 - val_loss: 2.5214 - val_accuracy: 0.4725\n",
      "Epoch 252/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5375 - accuracy: 0.4494 - val_loss: 2.5112 - val_accuracy: 0.4676\n",
      "Epoch 253/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5273 - accuracy: 0.4467 - val_loss: 2.5299 - val_accuracy: 0.4706\n",
      "Epoch 254/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5370 - accuracy: 0.4482 - val_loss: 2.4987 - val_accuracy: 0.4712\n",
      "Epoch 255/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5240 - accuracy: 0.4518 - val_loss: 2.5052 - val_accuracy: 0.4750\n",
      "Epoch 256/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5139 - accuracy: 0.4522 - val_loss: 2.5186 - val_accuracy: 0.4712\n",
      "Epoch 257/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5212 - accuracy: 0.4497 - val_loss: 2.4991 - val_accuracy: 0.4681\n",
      "Epoch 258/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5197 - accuracy: 0.4469 - val_loss: 2.5038 - val_accuracy: 0.4758\n",
      "Epoch 259/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5086 - accuracy: 0.4553 - val_loss: 2.4999 - val_accuracy: 0.4761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5089 - accuracy: 0.4543 - val_loss: 2.4908 - val_accuracy: 0.4702\n",
      "Epoch 261/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5130 - accuracy: 0.4484 - val_loss: 2.5168 - val_accuracy: 0.4742\n",
      "Epoch 262/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5165 - accuracy: 0.4550 - val_loss: 2.4951 - val_accuracy: 0.4728\n",
      "Epoch 263/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5097 - accuracy: 0.4518 - val_loss: 2.5028 - val_accuracy: 0.4695\n",
      "Epoch 264/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5031 - accuracy: 0.4529 - val_loss: 2.4983 - val_accuracy: 0.4739\n",
      "Epoch 265/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4992 - accuracy: 0.4546 - val_loss: 2.4922 - val_accuracy: 0.4758\n",
      "Epoch 266/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5074 - accuracy: 0.4548 - val_loss: 2.4964 - val_accuracy: 0.4728\n",
      "Epoch 267/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4963 - accuracy: 0.4532 - val_loss: 2.5001 - val_accuracy: 0.4754\n",
      "Epoch 268/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4966 - accuracy: 0.4553 - val_loss: 2.4920 - val_accuracy: 0.4776\n",
      "Epoch 269/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4913 - accuracy: 0.4560 - val_loss: 2.4951 - val_accuracy: 0.4766\n",
      "Epoch 270/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4960 - accuracy: 0.4543 - val_loss: 2.4930 - val_accuracy: 0.4723\n",
      "Epoch 271/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5008 - accuracy: 0.4528 - val_loss: 2.4906 - val_accuracy: 0.4769\n",
      "Epoch 272/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4957 - accuracy: 0.4565 - val_loss: 2.5034 - val_accuracy: 0.4753\n",
      "Epoch 273/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4906 - accuracy: 0.4581 - val_loss: 2.4849 - val_accuracy: 0.4742\n",
      "Epoch 274/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4916 - accuracy: 0.4530 - val_loss: 2.4883 - val_accuracy: 0.4752\n",
      "Epoch 275/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4938 - accuracy: 0.4541 - val_loss: 2.4950 - val_accuracy: 0.4752\n",
      "Epoch 276/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4893 - accuracy: 0.4559 - val_loss: 2.4874 - val_accuracy: 0.4780\n",
      "Epoch 277/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4971 - accuracy: 0.4549 - val_loss: 2.4918 - val_accuracy: 0.4776\n",
      "Epoch 278/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4951 - accuracy: 0.4551 - val_loss: 2.4829 - val_accuracy: 0.4787\n",
      "Epoch 279/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4891 - accuracy: 0.4592 - val_loss: 2.4906 - val_accuracy: 0.4755\n",
      "Epoch 280/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4779 - accuracy: 0.4575 - val_loss: 2.5040 - val_accuracy: 0.4703\n",
      "Epoch 281/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4927 - accuracy: 0.4544 - val_loss: 2.4862 - val_accuracy: 0.4789\n",
      "Epoch 282/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4979 - accuracy: 0.4555 - val_loss: 2.5045 - val_accuracy: 0.4766\n",
      "Epoch 283/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5018 - accuracy: 0.4576 - val_loss: 2.5123 - val_accuracy: 0.4653\n",
      "Epoch 284/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5160 - accuracy: 0.4452 - val_loss: 2.5052 - val_accuracy: 0.4688\n",
      "Epoch 285/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5060 - accuracy: 0.4512 - val_loss: 2.5094 - val_accuracy: 0.4748\n",
      "Epoch 286/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5055 - accuracy: 0.4574 - val_loss: 2.4863 - val_accuracy: 0.4754\n",
      "Epoch 287/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4893 - accuracy: 0.4568 - val_loss: 2.4909 - val_accuracy: 0.4755\n",
      "Epoch 288/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4893 - accuracy: 0.4530 - val_loss: 2.4964 - val_accuracy: 0.4789\n",
      "Epoch 289/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4806 - accuracy: 0.4595 - val_loss: 2.4842 - val_accuracy: 0.4787\n",
      "Epoch 290/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4911 - accuracy: 0.4564 - val_loss: 2.4854 - val_accuracy: 0.4795\n",
      "Epoch 291/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4779 - accuracy: 0.4593 - val_loss: 2.4849 - val_accuracy: 0.4787\n",
      "Epoch 292/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4833 - accuracy: 0.4580 - val_loss: 2.4844 - val_accuracy: 0.4795\n",
      "Epoch 293/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4717 - accuracy: 0.4601 - val_loss: 2.4826 - val_accuracy: 0.4719\n",
      "Epoch 294/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4840 - accuracy: 0.4541 - val_loss: 2.4780 - val_accuracy: 0.4797\n",
      "Epoch 295/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4705 - accuracy: 0.4601 - val_loss: 2.4854 - val_accuracy: 0.4810\n",
      "Epoch 296/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4719 - accuracy: 0.4601 - val_loss: 2.4725 - val_accuracy: 0.4776\n",
      "Epoch 297/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4715 - accuracy: 0.4583 - val_loss: 2.4794 - val_accuracy: 0.4810\n",
      "Epoch 298/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4696 - accuracy: 0.4606 - val_loss: 2.4767 - val_accuracy: 0.4805\n",
      "Epoch 299/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4624 - accuracy: 0.4625 - val_loss: 2.4735 - val_accuracy: 0.4776\n",
      "Epoch 300/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4672 - accuracy: 0.4573 - val_loss: 2.4897 - val_accuracy: 0.4793\n",
      "Epoch 301/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4680 - accuracy: 0.4615 - val_loss: 2.4710 - val_accuracy: 0.4826\n",
      "Epoch 302/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4638 - accuracy: 0.4615 - val_loss: 2.4799 - val_accuracy: 0.4801\n",
      "Epoch 303/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4628 - accuracy: 0.4612 - val_loss: 2.4757 - val_accuracy: 0.4774\n",
      "Epoch 304/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4661 - accuracy: 0.4592 - val_loss: 2.4785 - val_accuracy: 0.4809\n",
      "Epoch 305/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4564 - accuracy: 0.4635 - val_loss: 2.4683 - val_accuracy: 0.4815\n",
      "Epoch 306/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4565 - accuracy: 0.4624 - val_loss: 2.4695 - val_accuracy: 0.4803\n",
      "Epoch 307/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4557 - accuracy: 0.4637 - val_loss: 2.4709 - val_accuracy: 0.4798\n",
      "Epoch 308/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4592 - accuracy: 0.4604 - val_loss: 2.4753 - val_accuracy: 0.4794\n",
      "Epoch 309/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4604 - accuracy: 0.4605 - val_loss: 2.4669 - val_accuracy: 0.4835\n",
      "Epoch 310/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4515 - accuracy: 0.4655 - val_loss: 2.4633 - val_accuracy: 0.4780\n",
      "Epoch 311/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4651 - accuracy: 0.4587 - val_loss: 2.4886 - val_accuracy: 0.4802\n",
      "Epoch 312/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4701 - accuracy: 0.4604 - val_loss: 2.4752 - val_accuracy: 0.4791\n",
      "Epoch 313/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4599 - accuracy: 0.4597 - val_loss: 2.4747 - val_accuracy: 0.4787\n",
      "Epoch 314/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4681 - accuracy: 0.4611 - val_loss: 2.4948 - val_accuracy: 0.4796\n",
      "Epoch 315/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4755 - accuracy: 0.4610 - val_loss: 2.4652 - val_accuracy: 0.4810\n",
      "Epoch 316/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4575 - accuracy: 0.4611 - val_loss: 2.4825 - val_accuracy: 0.4798\n",
      "Epoch 317/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4623 - accuracy: 0.4616 - val_loss: 2.4710 - val_accuracy: 0.4753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4577 - accuracy: 0.4595 - val_loss: 2.4783 - val_accuracy: 0.4799\n",
      "Epoch 319/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4534 - accuracy: 0.4619 - val_loss: 2.4772 - val_accuracy: 0.4839\n",
      "Epoch 320/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4635 - accuracy: 0.4649 - val_loss: 2.4666 - val_accuracy: 0.4784\n",
      "Epoch 321/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4560 - accuracy: 0.4589 - val_loss: 2.4690 - val_accuracy: 0.4820\n",
      "Epoch 322/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4541 - accuracy: 0.4640 - val_loss: 2.4825 - val_accuracy: 0.4804\n",
      "Epoch 323/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4581 - accuracy: 0.4648 - val_loss: 2.4683 - val_accuracy: 0.4728\n",
      "Epoch 324/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4629 - accuracy: 0.4556 - val_loss: 2.4802 - val_accuracy: 0.4795\n",
      "Epoch 325/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4561 - accuracy: 0.4623 - val_loss: 2.4697 - val_accuracy: 0.4837\n",
      "Epoch 326/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4534 - accuracy: 0.4654 - val_loss: 2.4804 - val_accuracy: 0.4791\n",
      "Epoch 327/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4627 - accuracy: 0.4616 - val_loss: 2.4777 - val_accuracy: 0.4757\n",
      "Epoch 328/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4599 - accuracy: 0.4578 - val_loss: 2.4847 - val_accuracy: 0.4823\n",
      "Epoch 329/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4560 - accuracy: 0.4646 - val_loss: 2.4642 - val_accuracy: 0.4837\n",
      "Epoch 330/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4554 - accuracy: 0.4619 - val_loss: 2.4715 - val_accuracy: 0.4836\n",
      "Epoch 331/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4542 - accuracy: 0.4631 - val_loss: 2.4646 - val_accuracy: 0.4807\n",
      "Epoch 332/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4462 - accuracy: 0.4625 - val_loss: 2.4735 - val_accuracy: 0.4802\n",
      "Epoch 333/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4524 - accuracy: 0.4634 - val_loss: 2.4623 - val_accuracy: 0.4807\n",
      "Epoch 334/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4499 - accuracy: 0.4609 - val_loss: 2.4818 - val_accuracy: 0.4824\n",
      "Epoch 335/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4502 - accuracy: 0.4654 - val_loss: 2.4615 - val_accuracy: 0.4830\n",
      "Epoch 336/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4485 - accuracy: 0.4640 - val_loss: 2.4567 - val_accuracy: 0.4807\n",
      "Epoch 337/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4413 - accuracy: 0.4625 - val_loss: 2.4687 - val_accuracy: 0.4854\n",
      "Epoch 338/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4420 - accuracy: 0.4683 - val_loss: 2.4632 - val_accuracy: 0.4860\n",
      "Epoch 339/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4330 - accuracy: 0.4684 - val_loss: 2.4706 - val_accuracy: 0.4785\n",
      "Epoch 340/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4427 - accuracy: 0.4614 - val_loss: 2.4560 - val_accuracy: 0.4818\n",
      "Epoch 341/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4335 - accuracy: 0.4634 - val_loss: 2.4671 - val_accuracy: 0.4875\n",
      "Epoch 342/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4380 - accuracy: 0.4692 - val_loss: 2.4587 - val_accuracy: 0.4868\n",
      "Epoch 343/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4334 - accuracy: 0.4657 - val_loss: 2.4527 - val_accuracy: 0.4801\n",
      "Epoch 344/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4411 - accuracy: 0.4606 - val_loss: 2.4658 - val_accuracy: 0.4835\n",
      "Epoch 345/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4317 - accuracy: 0.4662 - val_loss: 2.4637 - val_accuracy: 0.4832\n",
      "Epoch 346/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4273 - accuracy: 0.4678 - val_loss: 2.4608 - val_accuracy: 0.4814\n",
      "Epoch 347/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4372 - accuracy: 0.4660 - val_loss: 2.4695 - val_accuracy: 0.4844\n",
      "Epoch 348/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4319 - accuracy: 0.4666 - val_loss: 2.4558 - val_accuracy: 0.4812\n",
      "Epoch 349/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4397 - accuracy: 0.4644 - val_loss: 2.4603 - val_accuracy: 0.4843\n",
      "Epoch 350/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4252 - accuracy: 0.4677 - val_loss: 2.4675 - val_accuracy: 0.4847\n",
      "Epoch 351/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4334 - accuracy: 0.4682 - val_loss: 2.4505 - val_accuracy: 0.4842\n",
      "Epoch 352/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4288 - accuracy: 0.4653 - val_loss: 2.4730 - val_accuracy: 0.4872\n",
      "Epoch 353/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4344 - accuracy: 0.4691 - val_loss: 2.4531 - val_accuracy: 0.4868\n",
      "Epoch 354/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4286 - accuracy: 0.4656 - val_loss: 2.4505 - val_accuracy: 0.4840\n",
      "Epoch 355/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4247 - accuracy: 0.4649 - val_loss: 2.4690 - val_accuracy: 0.4858\n",
      "Epoch 356/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4374 - accuracy: 0.4658 - val_loss: 2.4586 - val_accuracy: 0.4817\n",
      "Epoch 357/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4280 - accuracy: 0.4667 - val_loss: 2.4591 - val_accuracy: 0.4858\n",
      "Epoch 358/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4261 - accuracy: 0.4690 - val_loss: 2.4593 - val_accuracy: 0.4856\n",
      "Epoch 359/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4255 - accuracy: 0.4697 - val_loss: 2.4537 - val_accuracy: 0.4807\n",
      "Epoch 360/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4321 - accuracy: 0.4621 - val_loss: 2.4585 - val_accuracy: 0.4864\n",
      "Epoch 361/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4191 - accuracy: 0.4678 - val_loss: 2.4580 - val_accuracy: 0.4838\n",
      "Epoch 362/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4227 - accuracy: 0.4681 - val_loss: 2.4523 - val_accuracy: 0.4815\n",
      "Epoch 363/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4236 - accuracy: 0.4651 - val_loss: 2.4520 - val_accuracy: 0.4872\n",
      "Epoch 364/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4191 - accuracy: 0.4682 - val_loss: 2.4669 - val_accuracy: 0.4850\n",
      "Epoch 365/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4310 - accuracy: 0.4694 - val_loss: 2.4612 - val_accuracy: 0.4802\n",
      "Epoch 366/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4291 - accuracy: 0.4646 - val_loss: 2.4532 - val_accuracy: 0.4820\n",
      "Epoch 367/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4319 - accuracy: 0.4661 - val_loss: 2.4878 - val_accuracy: 0.4857\n",
      "Epoch 368/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4425 - accuracy: 0.4693 - val_loss: 2.4582 - val_accuracy: 0.4765\n",
      "Epoch 369/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4340 - accuracy: 0.4612 - val_loss: 2.4532 - val_accuracy: 0.4830\n",
      "Epoch 370/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4307 - accuracy: 0.4647 - val_loss: 2.4690 - val_accuracy: 0.4833\n",
      "Epoch 371/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4370 - accuracy: 0.4683 - val_loss: 2.4494 - val_accuracy: 0.4832\n",
      "Epoch 372/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4194 - accuracy: 0.4670 - val_loss: 2.4599 - val_accuracy: 0.4854\n",
      "Epoch 373/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4376 - accuracy: 0.4654 - val_loss: 2.4588 - val_accuracy: 0.4857\n",
      "Epoch 374/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4243 - accuracy: 0.4681 - val_loss: 2.4684 - val_accuracy: 0.4846\n",
      "Epoch 375/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4423 - accuracy: 0.4658 - val_loss: 2.4511 - val_accuracy: 0.4831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4264 - accuracy: 0.4678 - val_loss: 2.4683 - val_accuracy: 0.4833\n",
      "Epoch 377/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4354 - accuracy: 0.4668 - val_loss: 2.4563 - val_accuracy: 0.4814\n",
      "Epoch 378/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4282 - accuracy: 0.4658 - val_loss: 2.4665 - val_accuracy: 0.4851\n",
      "Epoch 379/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4257 - accuracy: 0.4697 - val_loss: 2.4534 - val_accuracy: 0.4815\n",
      "Epoch 380/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4230 - accuracy: 0.4652 - val_loss: 2.4564 - val_accuracy: 0.4845\n",
      "Epoch 381/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4232 - accuracy: 0.4685 - val_loss: 2.4636 - val_accuracy: 0.4863\n",
      "Epoch 382/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4200 - accuracy: 0.4712 - val_loss: 2.4490 - val_accuracy: 0.4808\n",
      "Epoch 383/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4283 - accuracy: 0.4622 - val_loss: 2.4561 - val_accuracy: 0.4884\n",
      "Epoch 384/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4157 - accuracy: 0.4709 - val_loss: 2.4490 - val_accuracy: 0.4882\n",
      "Epoch 385/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4156 - accuracy: 0.4699 - val_loss: 2.4483 - val_accuracy: 0.4813\n",
      "Epoch 386/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4111 - accuracy: 0.4659 - val_loss: 2.4570 - val_accuracy: 0.4862\n",
      "Epoch 387/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4127 - accuracy: 0.4700 - val_loss: 2.4437 - val_accuracy: 0.4899\n",
      "Epoch 388/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4159 - accuracy: 0.4719 - val_loss: 2.4417 - val_accuracy: 0.4854\n",
      "Epoch 389/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4105 - accuracy: 0.4664 - val_loss: 2.4537 - val_accuracy: 0.4893\n",
      "Epoch 390/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4126 - accuracy: 0.4703 - val_loss: 2.4549 - val_accuracy: 0.4890\n",
      "Epoch 391/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4129 - accuracy: 0.4719 - val_loss: 2.4511 - val_accuracy: 0.4845\n",
      "Epoch 392/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4140 - accuracy: 0.4681 - val_loss: 2.4454 - val_accuracy: 0.4849\n",
      "Epoch 393/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4147 - accuracy: 0.4687 - val_loss: 2.4633 - val_accuracy: 0.4881\n",
      "Epoch 394/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4225 - accuracy: 0.4706 - val_loss: 2.4518 - val_accuracy: 0.4860\n",
      "Epoch 395/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4104 - accuracy: 0.4675 - val_loss: 2.4615 - val_accuracy: 0.4843\n",
      "Epoch 396/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4132 - accuracy: 0.4693 - val_loss: 2.4515 - val_accuracy: 0.4868\n",
      "Epoch 397/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4070 - accuracy: 0.4704 - val_loss: 2.4432 - val_accuracy: 0.4854\n",
      "Epoch 398/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4143 - accuracy: 0.4681 - val_loss: 2.4497 - val_accuracy: 0.4890\n",
      "Epoch 399/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4079 - accuracy: 0.4727 - val_loss: 2.4519 - val_accuracy: 0.4881\n",
      "Epoch 400/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4116 - accuracy: 0.4699 - val_loss: 2.4563 - val_accuracy: 0.4861\n",
      "Epoch 401/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4269 - accuracy: 0.4676 - val_loss: 2.4534 - val_accuracy: 0.4880\n",
      "Epoch 402/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4269 - accuracy: 0.4688 - val_loss: 2.4551 - val_accuracy: 0.4861\n",
      "Epoch 403/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4193 - accuracy: 0.4682 - val_loss: 2.4556 - val_accuracy: 0.4854\n",
      "Epoch 404/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4218 - accuracy: 0.4678 - val_loss: 2.4582 - val_accuracy: 0.4875\n",
      "Epoch 405/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4148 - accuracy: 0.4704 - val_loss: 2.4480 - val_accuracy: 0.4861\n",
      "Epoch 406/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4174 - accuracy: 0.4666 - val_loss: 2.4539 - val_accuracy: 0.4887\n",
      "Epoch 407/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4073 - accuracy: 0.4726 - val_loss: 2.4528 - val_accuracy: 0.4872\n",
      "Epoch 408/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4026 - accuracy: 0.4711 - val_loss: 2.4475 - val_accuracy: 0.4838\n",
      "Epoch 409/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4155 - accuracy: 0.4661 - val_loss: 2.4534 - val_accuracy: 0.4896\n",
      "Epoch 410/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4064 - accuracy: 0.4721 - val_loss: 2.4473 - val_accuracy: 0.4891\n",
      "Epoch 411/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4111 - accuracy: 0.4706 - val_loss: 2.4321 - val_accuracy: 0.4864\n",
      "Epoch 412/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4046 - accuracy: 0.4674 - val_loss: 2.4550 - val_accuracy: 0.4931\n",
      "Epoch 413/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4041 - accuracy: 0.4756 - val_loss: 2.4408 - val_accuracy: 0.4888\n",
      "Epoch 414/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4025 - accuracy: 0.4715 - val_loss: 2.4538 - val_accuracy: 0.4871\n",
      "Epoch 415/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4076 - accuracy: 0.4688 - val_loss: 2.4391 - val_accuracy: 0.4906\n",
      "Epoch 416/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4010 - accuracy: 0.4709 - val_loss: 2.4455 - val_accuracy: 0.4893\n",
      "Epoch 417/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4099 - accuracy: 0.4682 - val_loss: 2.4484 - val_accuracy: 0.4918\n",
      "Epoch 418/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4027 - accuracy: 0.4717 - val_loss: 2.4446 - val_accuracy: 0.4877\n",
      "Epoch 419/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4110 - accuracy: 0.4662 - val_loss: 2.4559 - val_accuracy: 0.4891\n",
      "Epoch 420/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4025 - accuracy: 0.4737 - val_loss: 2.4489 - val_accuracy: 0.4894\n",
      "Epoch 421/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4029 - accuracy: 0.4741 - val_loss: 2.4484 - val_accuracy: 0.4867\n",
      "Epoch 422/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4102 - accuracy: 0.4686 - val_loss: 2.4408 - val_accuracy: 0.4843\n",
      "Epoch 423/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4047 - accuracy: 0.4676 - val_loss: 2.4633 - val_accuracy: 0.4874\n",
      "Epoch 424/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4129 - accuracy: 0.4725 - val_loss: 2.4482 - val_accuracy: 0.4887\n",
      "Epoch 425/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4027 - accuracy: 0.4721 - val_loss: 2.4400 - val_accuracy: 0.4850\n",
      "Epoch 426/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4081 - accuracy: 0.4671 - val_loss: 2.4442 - val_accuracy: 0.4927\n",
      "Epoch 427/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4007 - accuracy: 0.4734 - val_loss: 2.4443 - val_accuracy: 0.4889\n",
      "Epoch 428/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3950 - accuracy: 0.4728 - val_loss: 2.4484 - val_accuracy: 0.4907\n",
      "Epoch 429/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4033 - accuracy: 0.4724 - val_loss: 2.4460 - val_accuracy: 0.4879\n",
      "Epoch 430/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3928 - accuracy: 0.4731 - val_loss: 2.4382 - val_accuracy: 0.4889\n",
      "Epoch 431/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4005 - accuracy: 0.4691 - val_loss: 2.4634 - val_accuracy: 0.4917\n",
      "Epoch 432/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4042 - accuracy: 0.4732 - val_loss: 2.4441 - val_accuracy: 0.4875\n",
      "Epoch 433/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4032 - accuracy: 0.4690 - val_loss: 2.4384 - val_accuracy: 0.4877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4005 - accuracy: 0.4686 - val_loss: 2.4487 - val_accuracy: 0.4892\n",
      "Epoch 435/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4045 - accuracy: 0.4701 - val_loss: 2.4372 - val_accuracy: 0.4874\n",
      "Epoch 436/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4038 - accuracy: 0.4688 - val_loss: 2.4524 - val_accuracy: 0.4888\n",
      "Epoch 437/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4127 - accuracy: 0.4723 - val_loss: 2.4401 - val_accuracy: 0.4906\n",
      "Epoch 438/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3918 - accuracy: 0.4737 - val_loss: 2.4424 - val_accuracy: 0.4854\n",
      "Epoch 439/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4058 - accuracy: 0.4677 - val_loss: 2.4731 - val_accuracy: 0.4905\n",
      "Epoch 440/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4080 - accuracy: 0.4753 - val_loss: 2.4414 - val_accuracy: 0.4848\n",
      "Epoch 441/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3932 - accuracy: 0.4683 - val_loss: 2.4353 - val_accuracy: 0.4874\n",
      "Epoch 442/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3980 - accuracy: 0.4695 - val_loss: 2.4592 - val_accuracy: 0.4943\n",
      "Epoch 443/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4009 - accuracy: 0.4770 - val_loss: 2.4305 - val_accuracy: 0.4897\n",
      "Epoch 444/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3965 - accuracy: 0.4711 - val_loss: 2.4442 - val_accuracy: 0.4880\n",
      "Epoch 445/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3969 - accuracy: 0.4698 - val_loss: 2.4549 - val_accuracy: 0.4907\n",
      "Epoch 446/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3945 - accuracy: 0.4759 - val_loss: 2.4392 - val_accuracy: 0.4864\n",
      "Epoch 447/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3961 - accuracy: 0.4698 - val_loss: 2.4362 - val_accuracy: 0.4890\n",
      "Epoch 448/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3877 - accuracy: 0.4740 - val_loss: 2.4387 - val_accuracy: 0.4908\n",
      "Epoch 449/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3875 - accuracy: 0.4746 - val_loss: 2.4401 - val_accuracy: 0.4871\n",
      "Epoch 450/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3982 - accuracy: 0.4707 - val_loss: 2.4322 - val_accuracy: 0.4926\n",
      "Epoch 451/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3863 - accuracy: 0.4757 - val_loss: 2.4386 - val_accuracy: 0.4926\n",
      "Epoch 452/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3917 - accuracy: 0.4732 - val_loss: 2.4333 - val_accuracy: 0.4865\n",
      "Epoch 453/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3801 - accuracy: 0.4723 - val_loss: 2.4339 - val_accuracy: 0.4869\n",
      "Epoch 454/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3837 - accuracy: 0.4723 - val_loss: 2.4617 - val_accuracy: 0.4931\n",
      "Epoch 455/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3978 - accuracy: 0.4756 - val_loss: 2.4393 - val_accuracy: 0.4879\n",
      "Epoch 456/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3909 - accuracy: 0.4716 - val_loss: 2.4390 - val_accuracy: 0.4894\n",
      "Epoch 457/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3896 - accuracy: 0.4737 - val_loss: 2.4424 - val_accuracy: 0.4934\n",
      "Epoch 458/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3854 - accuracy: 0.4775 - val_loss: 2.4283 - val_accuracy: 0.4910\n",
      "Epoch 459/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3891 - accuracy: 0.4725 - val_loss: 2.4497 - val_accuracy: 0.4915\n",
      "Epoch 460/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3946 - accuracy: 0.4749 - val_loss: 2.4402 - val_accuracy: 0.4886\n",
      "Epoch 461/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3861 - accuracy: 0.4742 - val_loss: 2.4237 - val_accuracy: 0.4886\n",
      "Epoch 462/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3889 - accuracy: 0.4708 - val_loss: 2.4370 - val_accuracy: 0.4919\n",
      "Epoch 463/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3804 - accuracy: 0.4784 - val_loss: 2.4369 - val_accuracy: 0.4918\n",
      "Epoch 464/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3890 - accuracy: 0.4758 - val_loss: 2.4289 - val_accuracy: 0.4915\n",
      "Epoch 465/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3831 - accuracy: 0.4750 - val_loss: 2.4336 - val_accuracy: 0.4894\n",
      "Epoch 466/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3891 - accuracy: 0.4733 - val_loss: 2.4366 - val_accuracy: 0.4908\n",
      "Epoch 467/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3937 - accuracy: 0.4709 - val_loss: 2.4360 - val_accuracy: 0.4893\n",
      "Epoch 468/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3783 - accuracy: 0.4758 - val_loss: 2.4342 - val_accuracy: 0.4875\n",
      "Epoch 469/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3858 - accuracy: 0.4726 - val_loss: 2.4425 - val_accuracy: 0.4918\n",
      "Epoch 470/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3833 - accuracy: 0.4772 - val_loss: 2.4315 - val_accuracy: 0.4892\n",
      "Epoch 471/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3901 - accuracy: 0.4717 - val_loss: 2.4687 - val_accuracy: 0.4912\n",
      "Epoch 472/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4105 - accuracy: 0.4753 - val_loss: 2.4448 - val_accuracy: 0.4874\n",
      "Epoch 473/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3952 - accuracy: 0.4697 - val_loss: 2.4451 - val_accuracy: 0.4859\n",
      "Epoch 474/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3956 - accuracy: 0.4706 - val_loss: 2.4519 - val_accuracy: 0.4907\n",
      "Epoch 475/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4039 - accuracy: 0.4735 - val_loss: 2.4377 - val_accuracy: 0.4874\n",
      "Epoch 476/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3970 - accuracy: 0.4715 - val_loss: 2.4382 - val_accuracy: 0.4903\n",
      "Epoch 477/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3969 - accuracy: 0.4734 - val_loss: 2.4366 - val_accuracy: 0.4914\n",
      "Epoch 478/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3851 - accuracy: 0.4741 - val_loss: 2.4338 - val_accuracy: 0.4895\n",
      "Epoch 479/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3807 - accuracy: 0.4732 - val_loss: 2.4322 - val_accuracy: 0.4881\n",
      "Epoch 480/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3852 - accuracy: 0.4751 - val_loss: 2.4474 - val_accuracy: 0.4890\n",
      "Epoch 481/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3917 - accuracy: 0.4753 - val_loss: 2.4338 - val_accuracy: 0.4857\n",
      "Epoch 482/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3951 - accuracy: 0.4678 - val_loss: 2.4388 - val_accuracy: 0.4915\n",
      "Epoch 483/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3833 - accuracy: 0.4751 - val_loss: 2.4424 - val_accuracy: 0.4935\n",
      "Epoch 484/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3832 - accuracy: 0.4766 - val_loss: 2.4298 - val_accuracy: 0.4876\n",
      "Epoch 485/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3880 - accuracy: 0.4710 - val_loss: 2.4538 - val_accuracy: 0.4894\n",
      "Epoch 486/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3937 - accuracy: 0.4750 - val_loss: 2.4430 - val_accuracy: 0.4897\n",
      "Epoch 487/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3947 - accuracy: 0.4732 - val_loss: 2.4333 - val_accuracy: 0.4902\n",
      "Epoch 488/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3808 - accuracy: 0.4739 - val_loss: 2.4367 - val_accuracy: 0.4949\n",
      "Epoch 489/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3796 - accuracy: 0.4776 - val_loss: 2.4279 - val_accuracy: 0.4938\n",
      "Epoch 490/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3840 - accuracy: 0.4759 - val_loss: 2.4216 - val_accuracy: 0.4916\n",
      "Epoch 491/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3736 - accuracy: 0.4749 - val_loss: 2.4417 - val_accuracy: 0.4928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3898 - accuracy: 0.4745 - val_loss: 2.4312 - val_accuracy: 0.4915\n",
      "Epoch 493/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3759 - accuracy: 0.4760 - val_loss: 2.4348 - val_accuracy: 0.4909\n",
      "Epoch 494/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3755 - accuracy: 0.4764 - val_loss: 2.4374 - val_accuracy: 0.4916\n",
      "Epoch 495/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3791 - accuracy: 0.4762 - val_loss: 2.4291 - val_accuracy: 0.4901\n",
      "Epoch 496/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3736 - accuracy: 0.4751 - val_loss: 2.4290 - val_accuracy: 0.4908\n",
      "Epoch 497/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3748 - accuracy: 0.4765 - val_loss: 2.4372 - val_accuracy: 0.4906\n",
      "Epoch 498/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3750 - accuracy: 0.4764 - val_loss: 2.4287 - val_accuracy: 0.4950\n",
      "Epoch 499/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3678 - accuracy: 0.4783 - val_loss: 2.4318 - val_accuracy: 0.4954\n",
      "Epoch 500/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3633 - accuracy: 0.4797 - val_loss: 2.4292 - val_accuracy: 0.4915\n",
      "Epoch 501/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3704 - accuracy: 0.4763 - val_loss: 2.4336 - val_accuracy: 0.4931\n",
      "Epoch 502/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3684 - accuracy: 0.4777 - val_loss: 2.4331 - val_accuracy: 0.4921\n",
      "Epoch 503/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3815 - accuracy: 0.4734 - val_loss: 2.4487 - val_accuracy: 0.4913\n",
      "Epoch 504/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3773 - accuracy: 0.4771 - val_loss: 2.4364 - val_accuracy: 0.4838\n",
      "Epoch 505/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3964 - accuracy: 0.4670 - val_loss: 2.4663 - val_accuracy: 0.4949\n",
      "Epoch 506/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3984 - accuracy: 0.4760 - val_loss: 2.4340 - val_accuracy: 0.4899\n",
      "Epoch 507/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3905 - accuracy: 0.4700 - val_loss: 2.4379 - val_accuracy: 0.4911\n",
      "Epoch 508/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3954 - accuracy: 0.4712 - val_loss: 2.4763 - val_accuracy: 0.4891\n",
      "Epoch 509/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4058 - accuracy: 0.4754 - val_loss: 2.4563 - val_accuracy: 0.4856\n",
      "Epoch 510/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3948 - accuracy: 0.4726 - val_loss: 2.4498 - val_accuracy: 0.4801\n",
      "Epoch 511/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4099 - accuracy: 0.4660 - val_loss: 2.4658 - val_accuracy: 0.4886\n",
      "Epoch 512/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4110 - accuracy: 0.4726 - val_loss: 2.4598 - val_accuracy: 0.4852\n",
      "Epoch 513/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4125 - accuracy: 0.4698 - val_loss: 2.4551 - val_accuracy: 0.4856\n",
      "Epoch 514/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3983 - accuracy: 0.4727 - val_loss: 2.4498 - val_accuracy: 0.4919\n",
      "Epoch 515/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3949 - accuracy: 0.4750 - val_loss: 2.4371 - val_accuracy: 0.4913\n",
      "Epoch 516/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3942 - accuracy: 0.4710 - val_loss: 2.4498 - val_accuracy: 0.4927\n",
      "Epoch 517/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3982 - accuracy: 0.4753 - val_loss: 2.4442 - val_accuracy: 0.4907\n",
      "Epoch 518/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3875 - accuracy: 0.4733 - val_loss: 2.4410 - val_accuracy: 0.4883\n",
      "Epoch 519/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3946 - accuracy: 0.4696 - val_loss: 2.4470 - val_accuracy: 0.4938\n",
      "Epoch 520/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3813 - accuracy: 0.4775 - val_loss: 2.4372 - val_accuracy: 0.4921\n",
      "Epoch 521/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3837 - accuracy: 0.4745 - val_loss: 2.4266 - val_accuracy: 0.4879\n",
      "Epoch 522/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3844 - accuracy: 0.4705 - val_loss: 2.4436 - val_accuracy: 0.4935\n",
      "Epoch 523/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3819 - accuracy: 0.4770 - val_loss: 2.4402 - val_accuracy: 0.4927\n",
      "Epoch 524/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3793 - accuracy: 0.4772 - val_loss: 2.4286 - val_accuracy: 0.4896\n",
      "Epoch 525/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3680 - accuracy: 0.4752 - val_loss: 2.4344 - val_accuracy: 0.4912\n",
      "Epoch 526/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3861 - accuracy: 0.4754 - val_loss: 2.4706 - val_accuracy: 0.4892\n",
      "Epoch 527/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4049 - accuracy: 0.4748 - val_loss: 2.4383 - val_accuracy: 0.4876\n",
      "Epoch 528/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3808 - accuracy: 0.4721 - val_loss: 2.4416 - val_accuracy: 0.4841\n",
      "Epoch 529/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3875 - accuracy: 0.4726 - val_loss: 2.4440 - val_accuracy: 0.4910\n",
      "Epoch 530/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3806 - accuracy: 0.4765 - val_loss: 2.4376 - val_accuracy: 0.4938\n",
      "Epoch 531/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3765 - accuracy: 0.4761 - val_loss: 2.4346 - val_accuracy: 0.4952\n",
      "Epoch 532/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3766 - accuracy: 0.4751 - val_loss: 2.4403 - val_accuracy: 0.4915\n",
      "Epoch 533/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3732 - accuracy: 0.4773 - val_loss: 2.4372 - val_accuracy: 0.4904\n",
      "Epoch 534/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3781 - accuracy: 0.4767 - val_loss: 2.4301 - val_accuracy: 0.4935\n",
      "Epoch 535/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3705 - accuracy: 0.4766 - val_loss: 2.4351 - val_accuracy: 0.4952\n",
      "Epoch 536/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3786 - accuracy: 0.4777 - val_loss: 2.4200 - val_accuracy: 0.4885\n",
      "Epoch 537/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3768 - accuracy: 0.4715 - val_loss: 2.4464 - val_accuracy: 0.4944\n",
      "Epoch 538/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3761 - accuracy: 0.4799 - val_loss: 2.4377 - val_accuracy: 0.4928\n",
      "Epoch 539/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3757 - accuracy: 0.4772 - val_loss: 2.4494 - val_accuracy: 0.4903\n",
      "Epoch 540/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3870 - accuracy: 0.4755 - val_loss: 2.4413 - val_accuracy: 0.4903\n",
      "Epoch 541/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3858 - accuracy: 0.4731 - val_loss: 2.4756 - val_accuracy: 0.4892\n",
      "Epoch 542/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4102 - accuracy: 0.4747 - val_loss: 2.4549 - val_accuracy: 0.4853\n",
      "Epoch 543/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3948 - accuracy: 0.4701 - val_loss: 2.4568 - val_accuracy: 0.4891\n",
      "Epoch 544/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3948 - accuracy: 0.4748 - val_loss: 2.4524 - val_accuracy: 0.4898\n",
      "Epoch 545/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3941 - accuracy: 0.4733 - val_loss: 2.4490 - val_accuracy: 0.4851\n",
      "Epoch 546/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3926 - accuracy: 0.4719 - val_loss: 2.4375 - val_accuracy: 0.4912\n",
      "Epoch 547/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3816 - accuracy: 0.4785 - val_loss: 2.4324 - val_accuracy: 0.4886\n",
      "Epoch 548/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3856 - accuracy: 0.4727 - val_loss: 2.4472 - val_accuracy: 0.4948\n",
      "Epoch 549/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3798 - accuracy: 0.4793 - val_loss: 2.4521 - val_accuracy: 0.4884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3971 - accuracy: 0.4701 - val_loss: 2.4625 - val_accuracy: 0.4867\n",
      "Epoch 551/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3979 - accuracy: 0.4731 - val_loss: 2.4447 - val_accuracy: 0.4852\n",
      "Epoch 552/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3899 - accuracy: 0.4732 - val_loss: 2.4494 - val_accuracy: 0.4896\n",
      "Epoch 553/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3986 - accuracy: 0.4744 - val_loss: 2.4387 - val_accuracy: 0.4915\n",
      "Epoch 554/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3817 - accuracy: 0.4754 - val_loss: 2.4430 - val_accuracy: 0.4903\n",
      "Epoch 555/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3742 - accuracy: 0.4775 - val_loss: 2.4485 - val_accuracy: 0.4897\n",
      "Epoch 556/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3733 - accuracy: 0.4778 - val_loss: 2.4414 - val_accuracy: 0.4897\n",
      "Epoch 557/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3831 - accuracy: 0.4745 - val_loss: 2.4426 - val_accuracy: 0.4948\n",
      "Epoch 558/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3822 - accuracy: 0.4776 - val_loss: 2.4271 - val_accuracy: 0.4940\n",
      "Epoch 559/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3668 - accuracy: 0.4796 - val_loss: 2.4329 - val_accuracy: 0.4901\n",
      "Epoch 560/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3813 - accuracy: 0.4752 - val_loss: 2.4438 - val_accuracy: 0.4896\n",
      "Epoch 561/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3842 - accuracy: 0.4740 - val_loss: 2.4391 - val_accuracy: 0.4929\n",
      "Epoch 562/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3700 - accuracy: 0.4769 - val_loss: 2.4393 - val_accuracy: 0.4931\n",
      "Epoch 563/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3802 - accuracy: 0.4768 - val_loss: 2.4414 - val_accuracy: 0.4875\n",
      "Epoch 564/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3759 - accuracy: 0.4731 - val_loss: 2.4517 - val_accuracy: 0.4938\n",
      "Epoch 565/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3749 - accuracy: 0.4797 - val_loss: 2.4385 - val_accuracy: 0.4919\n",
      "Epoch 566/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3782 - accuracy: 0.4751 - val_loss: 2.4278 - val_accuracy: 0.4915\n",
      "Epoch 567/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3696 - accuracy: 0.4743 - val_loss: 2.4363 - val_accuracy: 0.4941\n",
      "Epoch 568/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3760 - accuracy: 0.4762 - val_loss: 2.4548 - val_accuracy: 0.4963\n",
      "Epoch 569/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3833 - accuracy: 0.4811 - val_loss: 2.4602 - val_accuracy: 0.4776\n",
      "Epoch 570/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4128 - accuracy: 0.4619 - val_loss: 2.5307 - val_accuracy: 0.4839\n",
      "Epoch 571/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4528 - accuracy: 0.4704 - val_loss: 2.4801 - val_accuracy: 0.4854\n",
      "Epoch 572/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4242 - accuracy: 0.4686 - val_loss: 2.4396 - val_accuracy: 0.4831\n",
      "Epoch 573/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4035 - accuracy: 0.4666 - val_loss: 2.4550 - val_accuracy: 0.4891\n",
      "Epoch 574/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4183 - accuracy: 0.4711 - val_loss: 2.4622 - val_accuracy: 0.4895\n",
      "Epoch 575/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4033 - accuracy: 0.4734 - val_loss: 2.4607 - val_accuracy: 0.4894\n",
      "Epoch 576/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3996 - accuracy: 0.4731 - val_loss: 2.4423 - val_accuracy: 0.4910\n",
      "Epoch 577/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3876 - accuracy: 0.4746 - val_loss: 2.4387 - val_accuracy: 0.4921\n",
      "Epoch 578/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3885 - accuracy: 0.4756 - val_loss: 2.4393 - val_accuracy: 0.4851\n",
      "Epoch 579/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3856 - accuracy: 0.4727 - val_loss: 2.4532 - val_accuracy: 0.4905\n",
      "Epoch 580/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3897 - accuracy: 0.4787 - val_loss: 2.4433 - val_accuracy: 0.4893\n",
      "Epoch 581/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3754 - accuracy: 0.4784 - val_loss: 2.4526 - val_accuracy: 0.4907\n",
      "Epoch 582/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4010 - accuracy: 0.4736 - val_loss: 2.4691 - val_accuracy: 0.4840\n",
      "Epoch 583/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4261 - accuracy: 0.4678 - val_loss: 2.5179 - val_accuracy: 0.4823\n",
      "Epoch 584/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4526 - accuracy: 0.4673 - val_loss: 2.4670 - val_accuracy: 0.4882\n",
      "Epoch 585/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4077 - accuracy: 0.4710 - val_loss: 2.4675 - val_accuracy: 0.4860\n",
      "Epoch 586/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4162 - accuracy: 0.4730 - val_loss: 2.4455 - val_accuracy: 0.4844\n",
      "Epoch 587/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4004 - accuracy: 0.4682 - val_loss: 2.4583 - val_accuracy: 0.4883\n",
      "Epoch 588/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3941 - accuracy: 0.4751 - val_loss: 2.4573 - val_accuracy: 0.4882\n",
      "Epoch 589/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3983 - accuracy: 0.4745 - val_loss: 2.4476 - val_accuracy: 0.4860\n",
      "Epoch 590/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3915 - accuracy: 0.4701 - val_loss: 2.4504 - val_accuracy: 0.4892\n",
      "Epoch 591/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3830 - accuracy: 0.4766 - val_loss: 2.4602 - val_accuracy: 0.4939\n",
      "Epoch 592/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3874 - accuracy: 0.4784 - val_loss: 2.4406 - val_accuracy: 0.4859\n",
      "Epoch 593/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3913 - accuracy: 0.4711 - val_loss: 2.4883 - val_accuracy: 0.4880\n",
      "Epoch 594/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4303 - accuracy: 0.4723 - val_loss: 2.4764 - val_accuracy: 0.4843\n",
      "Epoch 595/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4253 - accuracy: 0.4695 - val_loss: 2.4797 - val_accuracy: 0.4797\n",
      "Epoch 596/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4166 - accuracy: 0.4667 - val_loss: 2.4556 - val_accuracy: 0.4902\n",
      "Epoch 597/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3868 - accuracy: 0.4774 - val_loss: 2.4431 - val_accuracy: 0.4916\n",
      "Epoch 598/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3984 - accuracy: 0.4753 - val_loss: 2.4295 - val_accuracy: 0.4880\n",
      "Epoch 599/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3737 - accuracy: 0.4740 - val_loss: 2.4584 - val_accuracy: 0.4924\n",
      "Epoch 600/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3845 - accuracy: 0.4781 - val_loss: 2.4405 - val_accuracy: 0.4927\n",
      "Epoch 601/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3719 - accuracy: 0.4777 - val_loss: 2.4292 - val_accuracy: 0.4886\n",
      "Epoch 602/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3741 - accuracy: 0.4746 - val_loss: 2.4335 - val_accuracy: 0.4924\n",
      "Epoch 603/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3700 - accuracy: 0.4768 - val_loss: 2.4344 - val_accuracy: 0.4935\n",
      "Epoch 604/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3703 - accuracy: 0.4766 - val_loss: 2.4373 - val_accuracy: 0.4939\n",
      "Epoch 605/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3742 - accuracy: 0.4806 - val_loss: 2.4298 - val_accuracy: 0.4918\n",
      "Epoch 606/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3629 - accuracy: 0.4777 - val_loss: 2.4303 - val_accuracy: 0.4882\n",
      "Epoch 607/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3657 - accuracy: 0.4764 - val_loss: 2.4374 - val_accuracy: 0.4926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3648 - accuracy: 0.4785 - val_loss: 2.4356 - val_accuracy: 0.4903\n",
      "Epoch 609/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3578 - accuracy: 0.4807 - val_loss: 2.4346 - val_accuracy: 0.4909\n",
      "Epoch 610/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3629 - accuracy: 0.4796 - val_loss: 2.4323 - val_accuracy: 0.4895\n",
      "Epoch 611/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3693 - accuracy: 0.4756 - val_loss: 2.5141 - val_accuracy: 0.4895\n",
      "Epoch 612/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4518 - accuracy: 0.4732 - val_loss: 2.5467 - val_accuracy: 0.4661\n",
      "Epoch 613/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4894 - accuracy: 0.4537 - val_loss: 2.5100 - val_accuracy: 0.4761\n",
      "Epoch 614/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4606 - accuracy: 0.4628 - val_loss: 2.5093 - val_accuracy: 0.4846\n",
      "Epoch 615/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4686 - accuracy: 0.4682 - val_loss: 2.4764 - val_accuracy: 0.4824\n",
      "Epoch 616/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4513 - accuracy: 0.4662 - val_loss: 2.4973 - val_accuracy: 0.4816\n",
      "Epoch 617/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4598 - accuracy: 0.4658 - val_loss: 2.4824 - val_accuracy: 0.4823\n",
      "Epoch 618/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4278 - accuracy: 0.4669 - val_loss: 2.4871 - val_accuracy: 0.4862\n",
      "Epoch 619/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4369 - accuracy: 0.4699 - val_loss: 2.4675 - val_accuracy: 0.4827\n",
      "Epoch 620/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4188 - accuracy: 0.4682 - val_loss: 2.4741 - val_accuracy: 0.4873\n",
      "Epoch 621/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4209 - accuracy: 0.4724 - val_loss: 2.4891 - val_accuracy: 0.4841\n",
      "Epoch 622/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4378 - accuracy: 0.4702 - val_loss: 2.6633 - val_accuracy: 0.4626\n",
      "Epoch 623/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6457 - accuracy: 0.4403 - val_loss: 3.1205 - val_accuracy: 0.3810\n",
      "Epoch 624/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2149 - accuracy: 0.3579 - val_loss: 3.4869 - val_accuracy: 0.3051\n",
      "Epoch 625/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6122 - accuracy: 0.2811 - val_loss: 4.6737 - val_accuracy: 0.2717\n",
      "Epoch 626/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.8369 - accuracy: 0.2557 - val_loss: 9.8474 - val_accuracy: 0.0765\n",
      "Epoch 627/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 10.0229 - accuracy: 0.0671 - val_loss: 6.5920 - val_accuracy: 0.1365\n",
      "Epoch 628/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 7.0211 - accuracy: 0.1280 - val_loss: 12.0460 - val_accuracy: 0.0606\n",
      "Epoch 629/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.2438 - accuracy: 0.0556 - val_loss: 8.5421 - val_accuracy: 0.0918\n",
      "Epoch 630/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 9.1377 - accuracy: 0.0823 - val_loss: 8.2115 - val_accuracy: 0.0806\n",
      "Epoch 631/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 8.3669 - accuracy: 0.0759 - val_loss: 5.5447 - val_accuracy: 0.1966\n",
      "Epoch 632/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.7264 - accuracy: 0.1926 - val_loss: 5.4521 - val_accuracy: 0.2061\n",
      "Epoch 633/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.5549 - accuracy: 0.2021 - val_loss: 4.5790 - val_accuracy: 0.2079\n",
      "Epoch 634/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6542 - accuracy: 0.2084 - val_loss: 4.6303 - val_accuracy: 0.2074\n",
      "Epoch 635/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6831 - accuracy: 0.2086 - val_loss: 4.8504 - val_accuracy: 0.2057\n",
      "Epoch 636/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.9291 - accuracy: 0.2066 - val_loss: 4.5589 - val_accuracy: 0.2081\n",
      "Epoch 637/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6181 - accuracy: 0.2085 - val_loss: 4.4423 - val_accuracy: 0.2073\n",
      "Epoch 638/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4829 - accuracy: 0.2083 - val_loss: 4.3436 - val_accuracy: 0.2070\n",
      "Epoch 639/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3866 - accuracy: 0.2086 - val_loss: 4.3122 - val_accuracy: 0.2073\n",
      "Epoch 640/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3472 - accuracy: 0.2085 - val_loss: 4.3164 - val_accuracy: 0.2070\n",
      "Epoch 641/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3401 - accuracy: 0.2090 - val_loss: 4.2908 - val_accuracy: 0.2075\n",
      "Epoch 642/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3152 - accuracy: 0.2089 - val_loss: 4.2730 - val_accuracy: 0.2077\n",
      "Epoch 643/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2972 - accuracy: 0.2100 - val_loss: 4.2705 - val_accuracy: 0.2078\n",
      "Epoch 644/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2967 - accuracy: 0.2091 - val_loss: 4.2570 - val_accuracy: 0.2078\n",
      "Epoch 645/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2719 - accuracy: 0.2097 - val_loss: 4.2534 - val_accuracy: 0.2084\n",
      "Epoch 646/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2624 - accuracy: 0.2104 - val_loss: 4.2508 - val_accuracy: 0.2088\n",
      "Epoch 647/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2642 - accuracy: 0.2110 - val_loss: 4.2390 - val_accuracy: 0.2081\n",
      "Epoch 648/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2542 - accuracy: 0.2100 - val_loss: 4.2240 - val_accuracy: 0.2086\n",
      "Epoch 649/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2448 - accuracy: 0.2089 - val_loss: 4.2149 - val_accuracy: 0.2064\n",
      "Epoch 650/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2381 - accuracy: 0.2048 - val_loss: 4.2037 - val_accuracy: 0.2078\n",
      "Epoch 651/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2301 - accuracy: 0.2051 - val_loss: 4.1909 - val_accuracy: 0.2099\n",
      "Epoch 652/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2154 - accuracy: 0.2086 - val_loss: 4.1821 - val_accuracy: 0.2108\n",
      "Epoch 653/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2052 - accuracy: 0.2108 - val_loss: 4.1721 - val_accuracy: 0.2101\n",
      "Epoch 654/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1917 - accuracy: 0.2109 - val_loss: 4.1542 - val_accuracy: 0.2110\n",
      "Epoch 655/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1791 - accuracy: 0.2112 - val_loss: 4.1374 - val_accuracy: 0.2122\n",
      "Epoch 656/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1670 - accuracy: 0.2104 - val_loss: 4.1268 - val_accuracy: 0.2144\n",
      "Epoch 657/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1578 - accuracy: 0.2105 - val_loss: 4.1146 - val_accuracy: 0.2154\n",
      "Epoch 658/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1465 - accuracy: 0.2119 - val_loss: 4.1055 - val_accuracy: 0.2154\n",
      "Epoch 659/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1376 - accuracy: 0.2123 - val_loss: 4.1020 - val_accuracy: 0.2152\n",
      "Epoch 660/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1297 - accuracy: 0.2127 - val_loss: 4.0931 - val_accuracy: 0.2148\n",
      "Epoch 661/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1180 - accuracy: 0.2131 - val_loss: 4.0827 - val_accuracy: 0.2146\n",
      "Epoch 662/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1103 - accuracy: 0.2138 - val_loss: 4.0753 - val_accuracy: 0.2149\n",
      "Epoch 663/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1066 - accuracy: 0.2128 - val_loss: 4.0676 - val_accuracy: 0.2152\n",
      "Epoch 664/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0992 - accuracy: 0.2128 - val_loss: 4.0609 - val_accuracy: 0.2153\n",
      "Epoch 665/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0923 - accuracy: 0.2135 - val_loss: 4.0565 - val_accuracy: 0.2164\n",
      "Epoch 666/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0869 - accuracy: 0.2137 - val_loss: 4.0504 - val_accuracy: 0.2168\n",
      "Epoch 667/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0798 - accuracy: 0.2134 - val_loss: 4.0409 - val_accuracy: 0.2164\n",
      "Epoch 668/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0717 - accuracy: 0.2134 - val_loss: 4.0319 - val_accuracy: 0.2169\n",
      "Epoch 669/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0645 - accuracy: 0.2141 - val_loss: 4.0253 - val_accuracy: 0.2176\n",
      "Epoch 670/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0625 - accuracy: 0.2129 - val_loss: 4.0190 - val_accuracy: 0.2171\n",
      "Epoch 671/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0555 - accuracy: 0.2137 - val_loss: 4.0144 - val_accuracy: 0.2165\n",
      "Epoch 672/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0532 - accuracy: 0.2133 - val_loss: 4.0093 - val_accuracy: 0.2158\n",
      "Epoch 673/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0473 - accuracy: 0.2134 - val_loss: 4.0061 - val_accuracy: 0.2157\n",
      "Epoch 674/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0496 - accuracy: 0.2138 - val_loss: 4.0025 - val_accuracy: 0.2163\n",
      "Epoch 675/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0439 - accuracy: 0.2138 - val_loss: 3.9978 - val_accuracy: 0.2163\n",
      "Epoch 676/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0368 - accuracy: 0.2138 - val_loss: 3.9925 - val_accuracy: 0.2168\n",
      "Epoch 677/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0361 - accuracy: 0.2140 - val_loss: 3.9897 - val_accuracy: 0.2171\n",
      "Epoch 678/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0314 - accuracy: 0.2143 - val_loss: 3.9857 - val_accuracy: 0.2179\n",
      "Epoch 679/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0256 - accuracy: 0.2146 - val_loss: 3.9812 - val_accuracy: 0.2184\n",
      "Epoch 680/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0245 - accuracy: 0.2142 - val_loss: 3.9777 - val_accuracy: 0.2186\n",
      "Epoch 681/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0263 - accuracy: 0.2141 - val_loss: 3.9743 - val_accuracy: 0.2189\n",
      "Epoch 682/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0184 - accuracy: 0.2146 - val_loss: 3.9707 - val_accuracy: 0.2193\n",
      "Epoch 683/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0144 - accuracy: 0.2150 - val_loss: 3.9680 - val_accuracy: 0.2197\n",
      "Epoch 684/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0160 - accuracy: 0.2150 - val_loss: 3.9665 - val_accuracy: 0.2195\n",
      "Epoch 685/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0095 - accuracy: 0.2146 - val_loss: 3.9649 - val_accuracy: 0.2193\n",
      "Epoch 686/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0103 - accuracy: 0.2148 - val_loss: 3.9626 - val_accuracy: 0.2193\n",
      "Epoch 687/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0052 - accuracy: 0.2154 - val_loss: 3.9606 - val_accuracy: 0.2190\n",
      "Epoch 688/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0015 - accuracy: 0.2150 - val_loss: 3.9594 - val_accuracy: 0.2192\n",
      "Epoch 689/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0001 - accuracy: 0.2157 - val_loss: 3.9581 - val_accuracy: 0.2188\n",
      "Epoch 690/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9950 - accuracy: 0.2164 - val_loss: 3.9531 - val_accuracy: 0.2192\n",
      "Epoch 691/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9946 - accuracy: 0.2164 - val_loss: 3.9482 - val_accuracy: 0.2195\n",
      "Epoch 692/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9938 - accuracy: 0.2169 - val_loss: 3.9466 - val_accuracy: 0.2197\n",
      "Epoch 693/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9903 - accuracy: 0.2173 - val_loss: 3.9446 - val_accuracy: 0.2199\n",
      "Epoch 694/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9919 - accuracy: 0.2170 - val_loss: 3.9419 - val_accuracy: 0.2196\n",
      "Epoch 695/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9890 - accuracy: 0.2166 - val_loss: 3.9398 - val_accuracy: 0.2195\n",
      "Epoch 696/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9859 - accuracy: 0.2169 - val_loss: 3.9384 - val_accuracy: 0.2201\n",
      "Epoch 697/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9869 - accuracy: 0.2171 - val_loss: 3.9380 - val_accuracy: 0.2196\n",
      "Epoch 698/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9859 - accuracy: 0.2178 - val_loss: 3.9356 - val_accuracy: 0.2204\n",
      "Epoch 699/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9851 - accuracy: 0.2176 - val_loss: 3.9316 - val_accuracy: 0.2212\n",
      "Epoch 700/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9834 - accuracy: 0.2173 - val_loss: 4.0882 - val_accuracy: 0.2209\n",
      "Epoch 701/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2959 - accuracy: 0.2169 - val_loss: 3.9497 - val_accuracy: 0.2220\n",
      "Epoch 702/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9902 - accuracy: 0.2169 - val_loss: 3.9503 - val_accuracy: 0.2215\n",
      "Epoch 703/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9978 - accuracy: 0.2171 - val_loss: 3.9379 - val_accuracy: 0.2217\n",
      "Epoch 704/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9829 - accuracy: 0.2176 - val_loss: 3.9331 - val_accuracy: 0.2226\n",
      "Epoch 705/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9878 - accuracy: 0.2187 - val_loss: 3.9488 - val_accuracy: 0.2217\n",
      "Epoch 706/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0027 - accuracy: 0.2171 - val_loss: 3.9369 - val_accuracy: 0.2224\n",
      "Epoch 707/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9895 - accuracy: 0.2177 - val_loss: 3.9357 - val_accuracy: 0.2217\n",
      "Epoch 708/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9855 - accuracy: 0.2181 - val_loss: 3.9347 - val_accuracy: 0.2221\n",
      "Epoch 709/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9856 - accuracy: 0.2190 - val_loss: 3.9352 - val_accuracy: 0.2212\n",
      "Epoch 710/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9826 - accuracy: 0.2184 - val_loss: 3.9358 - val_accuracy: 0.2210\n",
      "Epoch 711/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9805 - accuracy: 0.2178 - val_loss: 3.9338 - val_accuracy: 0.2214\n",
      "Epoch 712/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9779 - accuracy: 0.2175 - val_loss: 3.9314 - val_accuracy: 0.2216\n",
      "Epoch 713/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9774 - accuracy: 0.2175 - val_loss: 3.9297 - val_accuracy: 0.2217\n",
      "Epoch 714/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9751 - accuracy: 0.2180 - val_loss: 3.9282 - val_accuracy: 0.2224\n",
      "Epoch 715/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9691 - accuracy: 0.2181 - val_loss: 3.9221 - val_accuracy: 0.2224\n",
      "Epoch 716/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9715 - accuracy: 0.2192 - val_loss: 3.9203 - val_accuracy: 0.2231\n",
      "Epoch 717/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9677 - accuracy: 0.2197 - val_loss: 3.9209 - val_accuracy: 0.2229\n",
      "Epoch 718/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9684 - accuracy: 0.2192 - val_loss: 3.9206 - val_accuracy: 0.2229\n",
      "Epoch 719/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9667 - accuracy: 0.2197 - val_loss: 3.9192 - val_accuracy: 0.2237\n",
      "Epoch 720/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9659 - accuracy: 0.2201 - val_loss: 3.9178 - val_accuracy: 0.2229\n",
      "Epoch 721/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9646 - accuracy: 0.2196 - val_loss: 3.9211 - val_accuracy: 0.2226\n",
      "Epoch 722/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9637 - accuracy: 0.2200 - val_loss: 3.9218 - val_accuracy: 0.2217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 723/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9626 - accuracy: 0.2196 - val_loss: 3.9191 - val_accuracy: 0.2220\n",
      "Epoch 724/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9609 - accuracy: 0.2192 - val_loss: 3.9175 - val_accuracy: 0.2229\n",
      "Epoch 725/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9617 - accuracy: 0.2194 - val_loss: 3.9179 - val_accuracy: 0.2228\n",
      "Epoch 726/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9608 - accuracy: 0.2194 - val_loss: 3.9160 - val_accuracy: 0.2232\n",
      "Epoch 727/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9631 - accuracy: 0.2188 - val_loss: 3.9142 - val_accuracy: 0.2235\n",
      "Epoch 728/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9620 - accuracy: 0.2206 - val_loss: 3.9134 - val_accuracy: 0.2232\n",
      "Epoch 729/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9579 - accuracy: 0.2208 - val_loss: 3.9135 - val_accuracy: 0.2240\n",
      "Epoch 730/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9596 - accuracy: 0.2205 - val_loss: 3.9095 - val_accuracy: 0.2240\n",
      "Epoch 731/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9576 - accuracy: 0.2206 - val_loss: 3.9088 - val_accuracy: 0.2247\n",
      "Epoch 732/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9594 - accuracy: 0.2200 - val_loss: 3.9106 - val_accuracy: 0.2248\n",
      "Epoch 733/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9568 - accuracy: 0.2200 - val_loss: 3.9128 - val_accuracy: 0.2239\n",
      "Epoch 734/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9565 - accuracy: 0.2203 - val_loss: 3.9125 - val_accuracy: 0.2239\n",
      "Epoch 735/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9618 - accuracy: 0.2204 - val_loss: 3.9125 - val_accuracy: 0.2240\n",
      "Epoch 736/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9546 - accuracy: 0.2211 - val_loss: 3.9098 - val_accuracy: 0.2249\n",
      "Epoch 1/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 5.4325 - accuracy: 0.0029 - val_loss: 9.4204 - val_accuracy: 0.1475\n",
      "Epoch 2/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 9.4283 - accuracy: 0.1388 - val_loss: 5.0300 - val_accuracy: 0.0346\n",
      "Epoch 3/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.0255 - accuracy: 0.0314 - val_loss: 5.6120 - val_accuracy: 0.0462\n",
      "Epoch 4/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.6586 - accuracy: 0.0433 - val_loss: 4.8518 - val_accuracy: 0.0354\n",
      "Epoch 5/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.8815 - accuracy: 0.0369 - val_loss: 5.0582 - val_accuracy: 0.1514\n",
      "Epoch 6/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.0509 - accuracy: 0.1462 - val_loss: 4.9481 - val_accuracy: 0.1723\n",
      "Epoch 7/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.9436 - accuracy: 0.1791 - val_loss: 4.6610 - val_accuracy: 0.1600\n",
      "Epoch 8/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6638 - accuracy: 0.1671 - val_loss: 5.1788 - val_accuracy: 0.1602\n",
      "Epoch 9/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.1895 - accuracy: 0.1679 - val_loss: 4.7581 - val_accuracy: 0.1353\n",
      "Epoch 10/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.7620 - accuracy: 0.1252 - val_loss: 4.7220 - val_accuracy: 0.0987\n",
      "Epoch 11/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.7296 - accuracy: 0.0993 - val_loss: 4.6792 - val_accuracy: 0.0987\n",
      "Epoch 12/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6897 - accuracy: 0.0995 - val_loss: 4.5593 - val_accuracy: 0.1107\n",
      "Epoch 13/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.5677 - accuracy: 0.1138 - val_loss: 4.4902 - val_accuracy: 0.1554\n",
      "Epoch 14/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4983 - accuracy: 0.1527 - val_loss: 4.4269 - val_accuracy: 0.1649\n",
      "Epoch 15/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4382 - accuracy: 0.1659 - val_loss: 4.4306 - val_accuracy: 0.1652\n",
      "Epoch 16/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4434 - accuracy: 0.1706 - val_loss: 4.3886 - val_accuracy: 0.1652\n",
      "Epoch 17/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3985 - accuracy: 0.1705 - val_loss: 4.3829 - val_accuracy: 0.1655\n",
      "Epoch 18/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3866 - accuracy: 0.1659 - val_loss: 4.3736 - val_accuracy: 0.1649\n",
      "Epoch 19/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3769 - accuracy: 0.1597 - val_loss: 4.3278 - val_accuracy: 0.1760\n",
      "Epoch 20/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3380 - accuracy: 0.1736 - val_loss: 4.3280 - val_accuracy: 0.1739\n",
      "Epoch 21/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3477 - accuracy: 0.1741 - val_loss: 4.3146 - val_accuracy: 0.1777\n",
      "Epoch 22/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3121 - accuracy: 0.1793 - val_loss: 4.4084 - val_accuracy: 0.1722\n",
      "Epoch 23/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4491 - accuracy: 0.1713 - val_loss: 4.4255 - val_accuracy: 0.1788\n",
      "Epoch 24/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4223 - accuracy: 0.1859 - val_loss: 4.2611 - val_accuracy: 0.2078\n",
      "Epoch 25/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2672 - accuracy: 0.2018 - val_loss: 4.3502 - val_accuracy: 0.1434\n",
      "Epoch 26/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3919 - accuracy: 0.1527 - val_loss: 4.3373 - val_accuracy: 0.1310\n",
      "Epoch 27/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3459 - accuracy: 0.1304 - val_loss: 4.3040 - val_accuracy: 0.1336\n",
      "Epoch 28/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3056 - accuracy: 0.1387 - val_loss: 4.2373 - val_accuracy: 0.1647\n",
      "Epoch 29/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2401 - accuracy: 0.1662 - val_loss: 4.1923 - val_accuracy: 0.2115\n",
      "Epoch 30/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2002 - accuracy: 0.2114 - val_loss: 4.1995 - val_accuracy: 0.2135\n",
      "Epoch 31/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2069 - accuracy: 0.2124 - val_loss: 4.2051 - val_accuracy: 0.2140\n",
      "Epoch 32/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2157 - accuracy: 0.2124 - val_loss: 4.1876 - val_accuracy: 0.2136\n",
      "Epoch 33/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1979 - accuracy: 0.2132 - val_loss: 4.1561 - val_accuracy: 0.2142\n",
      "Epoch 34/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1735 - accuracy: 0.2141 - val_loss: 4.1344 - val_accuracy: 0.2147\n",
      "Epoch 35/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1525 - accuracy: 0.2143 - val_loss: 4.1226 - val_accuracy: 0.2153\n",
      "Epoch 36/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1383 - accuracy: 0.2146 - val_loss: 4.1161 - val_accuracy: 0.2160\n",
      "Epoch 37/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1316 - accuracy: 0.2161 - val_loss: 4.1116 - val_accuracy: 0.2186\n",
      "Epoch 38/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1340 - accuracy: 0.2178 - val_loss: 4.1011 - val_accuracy: 0.2193\n",
      "Epoch 39/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1221 - accuracy: 0.2182 - val_loss: 4.0891 - val_accuracy: 0.2201\n",
      "Epoch 40/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1093 - accuracy: 0.2191 - val_loss: 4.0723 - val_accuracy: 0.2207\n",
      "Epoch 41/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0944 - accuracy: 0.2199 - val_loss: 4.0588 - val_accuracy: 0.2209\n",
      "Epoch 42/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0837 - accuracy: 0.2205 - val_loss: 4.0501 - val_accuracy: 0.2198\n",
      "Epoch 43/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0733 - accuracy: 0.2185 - val_loss: 4.0446 - val_accuracy: 0.2194\n",
      "Epoch 44/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0647 - accuracy: 0.2192 - val_loss: 4.0407 - val_accuracy: 0.2201\n",
      "Epoch 45/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 4.0567 - accuracy: 0.2197 - val_loss: 4.0366 - val_accuracy: 0.2202\n",
      "Epoch 46/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0496 - accuracy: 0.2204 - val_loss: 4.0290 - val_accuracy: 0.2211\n",
      "Epoch 47/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0436 - accuracy: 0.2213 - val_loss: 4.0232 - val_accuracy: 0.2200\n",
      "Epoch 48/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0357 - accuracy: 0.2209 - val_loss: 4.0194 - val_accuracy: 0.2207\n",
      "Epoch 49/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0330 - accuracy: 0.2209 - val_loss: 4.0167 - val_accuracy: 0.2194\n",
      "Epoch 50/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0238 - accuracy: 0.2199 - val_loss: 4.0094 - val_accuracy: 0.2207\n",
      "Epoch 51/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0136 - accuracy: 0.2228 - val_loss: 3.9859 - val_accuracy: 0.2271\n",
      "Epoch 52/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9941 - accuracy: 0.2286 - val_loss: 3.9643 - val_accuracy: 0.2365\n",
      "Epoch 53/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9924 - accuracy: 0.2352 - val_loss: 3.9553 - val_accuracy: 0.2368\n",
      "Epoch 54/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9789 - accuracy: 0.2368 - val_loss: 3.9469 - val_accuracy: 0.2327\n",
      "Epoch 55/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9598 - accuracy: 0.2339 - val_loss: 3.9392 - val_accuracy: 0.2292\n",
      "Epoch 56/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9500 - accuracy: 0.2301 - val_loss: 3.9307 - val_accuracy: 0.2290\n",
      "Epoch 57/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9427 - accuracy: 0.2304 - val_loss: 3.9175 - val_accuracy: 0.2324\n",
      "Epoch 58/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9318 - accuracy: 0.2335 - val_loss: 3.8975 - val_accuracy: 0.2397\n",
      "Epoch 59/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9225 - accuracy: 0.2384 - val_loss: 3.8832 - val_accuracy: 0.2427\n",
      "Epoch 60/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9120 - accuracy: 0.2410 - val_loss: 3.8764 - val_accuracy: 0.2387\n",
      "Epoch 61/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8955 - accuracy: 0.2387 - val_loss: 3.8763 - val_accuracy: 0.2364\n",
      "Epoch 62/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8911 - accuracy: 0.2370 - val_loss: 3.8498 - val_accuracy: 0.2389\n",
      "Epoch 63/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8716 - accuracy: 0.2401 - val_loss: 3.8221 - val_accuracy: 0.2456\n",
      "Epoch 64/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8613 - accuracy: 0.2439 - val_loss: 3.8134 - val_accuracy: 0.2459\n",
      "Epoch 65/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8413 - accuracy: 0.2445 - val_loss: 3.9066 - val_accuracy: 0.2443\n",
      "Epoch 66/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.9738 - accuracy: 0.2445 - val_loss: 3.8032 - val_accuracy: 0.2408\n",
      "Epoch 67/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8274 - accuracy: 0.2421 - val_loss: 3.7830 - val_accuracy: 0.2436\n",
      "Epoch 68/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8158 - accuracy: 0.2435 - val_loss: 3.7789 - val_accuracy: 0.2460\n",
      "Epoch 69/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8076 - accuracy: 0.2455 - val_loss: 3.7750 - val_accuracy: 0.2441\n",
      "Epoch 70/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7953 - accuracy: 0.2453 - val_loss: 3.7638 - val_accuracy: 0.2425\n",
      "Epoch 71/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7997 - accuracy: 0.2448 - val_loss: 3.7434 - val_accuracy: 0.2466\n",
      "Epoch 72/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7888 - accuracy: 0.2472 - val_loss: 3.7446 - val_accuracy: 0.2463\n",
      "Epoch 73/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7743 - accuracy: 0.2477 - val_loss: 3.7408 - val_accuracy: 0.2459\n",
      "Epoch 74/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7765 - accuracy: 0.2468 - val_loss: 3.7296 - val_accuracy: 0.2479\n",
      "Epoch 75/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7676 - accuracy: 0.2478 - val_loss: 3.7402 - val_accuracy: 0.2462\n",
      "Epoch 76/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7632 - accuracy: 0.2470 - val_loss: 3.7314 - val_accuracy: 0.2493\n",
      "Epoch 77/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7674 - accuracy: 0.2496 - val_loss: 4.0791 - val_accuracy: 0.2490\n",
      "Epoch 78/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2564 - accuracy: 0.2459 - val_loss: 3.7697 - val_accuracy: 0.2476\n",
      "Epoch 79/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8051 - accuracy: 0.2466 - val_loss: 3.7497 - val_accuracy: 0.2430\n",
      "Epoch 80/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7710 - accuracy: 0.2465 - val_loss: 3.7414 - val_accuracy: 0.2477\n",
      "Epoch 81/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7831 - accuracy: 0.2487 - val_loss: 3.7170 - val_accuracy: 0.2508\n",
      "Epoch 82/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7922 - accuracy: 0.2494 - val_loss: 3.7385 - val_accuracy: 0.2521\n",
      "Epoch 83/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8406 - accuracy: 0.2483 - val_loss: 3.8032 - val_accuracy: 0.2339\n",
      "Epoch 84/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8995 - accuracy: 0.2329 - val_loss: 3.7628 - val_accuracy: 0.2425\n",
      "Epoch 85/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8157 - accuracy: 0.2424 - val_loss: 3.7933 - val_accuracy: 0.2428\n",
      "Epoch 86/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8434 - accuracy: 0.2419 - val_loss: 3.7884 - val_accuracy: 0.2399\n",
      "Epoch 87/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8266 - accuracy: 0.2409 - val_loss: 3.7750 - val_accuracy: 0.2368\n",
      "Epoch 88/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8216 - accuracy: 0.2395 - val_loss: 3.7611 - val_accuracy: 0.2431\n",
      "Epoch 89/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8037 - accuracy: 0.2440 - val_loss: 3.7498 - val_accuracy: 0.2466\n",
      "Epoch 90/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7977 - accuracy: 0.2484 - val_loss: 3.7615 - val_accuracy: 0.2465\n",
      "Epoch 91/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.8164 - accuracy: 0.2482 - val_loss: 3.7452 - val_accuracy: 0.2443\n",
      "Epoch 92/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7953 - accuracy: 0.2460 - val_loss: 3.7247 - val_accuracy: 0.2503\n",
      "Epoch 93/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7797 - accuracy: 0.2506 - val_loss: 3.7065 - val_accuracy: 0.2535\n",
      "Epoch 94/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7596 - accuracy: 0.2526 - val_loss: 3.7110 - val_accuracy: 0.2525\n",
      "Epoch 95/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7564 - accuracy: 0.2525 - val_loss: 3.7082 - val_accuracy: 0.2504\n",
      "Epoch 96/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7445 - accuracy: 0.2520 - val_loss: 3.7051 - val_accuracy: 0.2467\n",
      "Epoch 97/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7377 - accuracy: 0.2498 - val_loss: 3.6989 - val_accuracy: 0.2481\n",
      "Epoch 98/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7303 - accuracy: 0.2510 - val_loss: 3.6812 - val_accuracy: 0.2545\n",
      "Epoch 99/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7150 - accuracy: 0.2552 - val_loss: 3.6703 - val_accuracy: 0.2603\n",
      "Epoch 100/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7111 - accuracy: 0.2593 - val_loss: 3.6578 - val_accuracy: 0.2610\n",
      "Epoch 101/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.7060 - accuracy: 0.2590 - val_loss: 3.6456 - val_accuracy: 0.2610\n",
      "Epoch 102/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6923 - accuracy: 0.2596 - val_loss: 3.6541 - val_accuracy: 0.2592\n",
      "Epoch 103/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6980 - accuracy: 0.2585 - val_loss: 3.6509 - val_accuracy: 0.2612\n",
      "Epoch 104/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6839 - accuracy: 0.2613 - val_loss: 3.6396 - val_accuracy: 0.2657\n",
      "Epoch 105/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6771 - accuracy: 0.2623 - val_loss: 3.6231 - val_accuracy: 0.2703\n",
      "Epoch 106/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6669 - accuracy: 0.2684 - val_loss: 3.6135 - val_accuracy: 0.2710\n",
      "Epoch 107/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6566 - accuracy: 0.2681 - val_loss: 3.6092 - val_accuracy: 0.2714\n",
      "Epoch 108/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6499 - accuracy: 0.2689 - val_loss: 3.6004 - val_accuracy: 0.2721\n",
      "Epoch 109/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6369 - accuracy: 0.2695 - val_loss: 3.5851 - val_accuracy: 0.2729\n",
      "Epoch 110/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6302 - accuracy: 0.2712 - val_loss: 3.5750 - val_accuracy: 0.2758\n",
      "Epoch 111/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6214 - accuracy: 0.2740 - val_loss: 3.5720 - val_accuracy: 0.2724\n",
      "Epoch 112/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6184 - accuracy: 0.2734 - val_loss: 3.5676 - val_accuracy: 0.2746\n",
      "Epoch 113/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6036 - accuracy: 0.2746 - val_loss: 3.5614 - val_accuracy: 0.2804\n",
      "Epoch 114/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5980 - accuracy: 0.2773 - val_loss: 3.5509 - val_accuracy: 0.2813\n",
      "Epoch 115/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5891 - accuracy: 0.2793 - val_loss: 3.5336 - val_accuracy: 0.2833\n",
      "Epoch 116/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5781 - accuracy: 0.2785 - val_loss: 3.5182 - val_accuracy: 0.2895\n",
      "Epoch 117/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5745 - accuracy: 0.2811 - val_loss: 3.5133 - val_accuracy: 0.2941\n",
      "Epoch 118/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5691 - accuracy: 0.2862 - val_loss: 3.5106 - val_accuracy: 0.2916\n",
      "Epoch 119/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5547 - accuracy: 0.2878 - val_loss: 3.5471 - val_accuracy: 0.2934\n",
      "Epoch 120/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6036 - accuracy: 0.2887 - val_loss: 3.6025 - val_accuracy: 0.2911\n",
      "Epoch 121/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6604 - accuracy: 0.2873 - val_loss: 3.5695 - val_accuracy: 0.2890\n",
      "Epoch 122/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6068 - accuracy: 0.2853 - val_loss: 3.5600 - val_accuracy: 0.2926\n",
      "Epoch 123/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6010 - accuracy: 0.2886 - val_loss: 3.5972 - val_accuracy: 0.2985\n",
      "Epoch 124/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6495 - accuracy: 0.2939 - val_loss: 3.5364 - val_accuracy: 0.2990\n",
      "Epoch 125/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6044 - accuracy: 0.2883 - val_loss: 3.5166 - val_accuracy: 0.3014\n",
      "Epoch 126/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5878 - accuracy: 0.2929 - val_loss: 3.5233 - val_accuracy: 0.3018\n",
      "Epoch 127/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5876 - accuracy: 0.2895 - val_loss: 3.4999 - val_accuracy: 0.2926\n",
      "Epoch 128/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5557 - accuracy: 0.2852 - val_loss: 3.4851 - val_accuracy: 0.2981\n",
      "Epoch 129/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5342 - accuracy: 0.2885 - val_loss: 3.4538 - val_accuracy: 0.3081\n",
      "Epoch 130/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5127 - accuracy: 0.2991 - val_loss: 3.4695 - val_accuracy: 0.3011\n",
      "Epoch 131/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5419 - accuracy: 0.2947 - val_loss: 3.4732 - val_accuracy: 0.2935\n",
      "Epoch 132/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5243 - accuracy: 0.2886 - val_loss: 3.4644 - val_accuracy: 0.3028\n",
      "Epoch 133/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5161 - accuracy: 0.2960 - val_loss: 3.4726 - val_accuracy: 0.3090\n",
      "Epoch 134/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5330 - accuracy: 0.2999 - val_loss: 3.4701 - val_accuracy: 0.3057\n",
      "Epoch 135/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5227 - accuracy: 0.2958 - val_loss: 3.4685 - val_accuracy: 0.3020\n",
      "Epoch 136/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5235 - accuracy: 0.2934 - val_loss: 3.4368 - val_accuracy: 0.3102\n",
      "Epoch 137/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4991 - accuracy: 0.3001 - val_loss: 3.4316 - val_accuracy: 0.3134\n",
      "Epoch 138/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5084 - accuracy: 0.2999 - val_loss: 3.4553 - val_accuracy: 0.3020\n",
      "Epoch 139/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.5042 - accuracy: 0.2955 - val_loss: 3.4415 - val_accuracy: 0.3017\n",
      "Epoch 140/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4882 - accuracy: 0.2944 - val_loss: 3.4030 - val_accuracy: 0.3110\n",
      "Epoch 141/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4653 - accuracy: 0.3026 - val_loss: 3.3966 - val_accuracy: 0.3142\n",
      "Epoch 142/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4598 - accuracy: 0.3063 - val_loss: 3.3840 - val_accuracy: 0.3169\n",
      "Epoch 143/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4414 - accuracy: 0.3089 - val_loss: 3.3927 - val_accuracy: 0.3147\n",
      "Epoch 144/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4405 - accuracy: 0.3064 - val_loss: 3.3762 - val_accuracy: 0.3165\n",
      "Epoch 145/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4281 - accuracy: 0.3087 - val_loss: 3.3728 - val_accuracy: 0.3204\n",
      "Epoch 146/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4323 - accuracy: 0.3126 - val_loss: 3.3752 - val_accuracy: 0.3106\n",
      "Epoch 147/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4296 - accuracy: 0.3076 - val_loss: 3.3600 - val_accuracy: 0.3143\n",
      "Epoch 148/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4103 - accuracy: 0.3125 - val_loss: 3.3611 - val_accuracy: 0.3211\n",
      "Epoch 149/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4146 - accuracy: 0.3143 - val_loss: 3.3411 - val_accuracy: 0.3178\n",
      "Epoch 150/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4050 - accuracy: 0.3136 - val_loss: 3.3356 - val_accuracy: 0.3180\n",
      "Epoch 151/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4051 - accuracy: 0.3126 - val_loss: 3.3223 - val_accuracy: 0.3202\n",
      "Epoch 152/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3814 - accuracy: 0.3150 - val_loss: 3.3242 - val_accuracy: 0.3234\n",
      "Epoch 153/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3853 - accuracy: 0.3160 - val_loss: 3.3191 - val_accuracy: 0.3227\n",
      "Epoch 154/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3814 - accuracy: 0.3162 - val_loss: 3.3028 - val_accuracy: 0.3242\n",
      "Epoch 155/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3602 - accuracy: 0.3207 - val_loss: 3.3072 - val_accuracy: 0.3280\n",
      "Epoch 156/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3768 - accuracy: 0.3199 - val_loss: 3.2928 - val_accuracy: 0.3273\n",
      "Epoch 157/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3554 - accuracy: 0.3209 - val_loss: 3.2861 - val_accuracy: 0.3277\n",
      "Epoch 158/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3506 - accuracy: 0.3217 - val_loss: 3.2729 - val_accuracy: 0.3308\n",
      "Epoch 159/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3474 - accuracy: 0.3246 - val_loss: 3.2686 - val_accuracy: 0.3311\n",
      "Epoch 160/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3408 - accuracy: 0.3241 - val_loss: 3.2670 - val_accuracy: 0.3282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3365 - accuracy: 0.3219 - val_loss: 3.2625 - val_accuracy: 0.3295\n",
      "Epoch 162/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3256 - accuracy: 0.3235 - val_loss: 3.2589 - val_accuracy: 0.3349\n",
      "Epoch 163/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3270 - accuracy: 0.3268 - val_loss: 3.2494 - val_accuracy: 0.3363\n",
      "Epoch 164/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3161 - accuracy: 0.3306 - val_loss: 3.2487 - val_accuracy: 0.3350\n",
      "Epoch 165/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3065 - accuracy: 0.3299 - val_loss: 3.2519 - val_accuracy: 0.3333\n",
      "Epoch 166/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3039 - accuracy: 0.3279 - val_loss: 3.2434 - val_accuracy: 0.3368\n",
      "Epoch 167/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3056 - accuracy: 0.3285 - val_loss: 3.2279 - val_accuracy: 0.3370\n",
      "Epoch 168/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2942 - accuracy: 0.3263 - val_loss: 3.2233 - val_accuracy: 0.3359\n",
      "Epoch 169/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2851 - accuracy: 0.3297 - val_loss: 3.2177 - val_accuracy: 0.3413\n",
      "Epoch 170/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2723 - accuracy: 0.3346 - val_loss: 3.2104 - val_accuracy: 0.3424\n",
      "Epoch 171/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2786 - accuracy: 0.3317 - val_loss: 3.2076 - val_accuracy: 0.3387\n",
      "Epoch 172/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2643 - accuracy: 0.3320 - val_loss: 3.2027 - val_accuracy: 0.3406\n",
      "Epoch 173/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2599 - accuracy: 0.3349 - val_loss: 3.1951 - val_accuracy: 0.3431\n",
      "Epoch 174/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2534 - accuracy: 0.3354 - val_loss: 3.1896 - val_accuracy: 0.3435\n",
      "Epoch 175/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2502 - accuracy: 0.3343 - val_loss: 3.1751 - val_accuracy: 0.3487\n",
      "Epoch 176/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2431 - accuracy: 0.3374 - val_loss: 3.1676 - val_accuracy: 0.3496\n",
      "Epoch 177/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2384 - accuracy: 0.3399 - val_loss: 3.1725 - val_accuracy: 0.3466\n",
      "Epoch 178/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2361 - accuracy: 0.3390 - val_loss: 3.1662 - val_accuracy: 0.3473\n",
      "Epoch 179/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2298 - accuracy: 0.3377 - val_loss: 3.1431 - val_accuracy: 0.3512\n",
      "Epoch 180/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2172 - accuracy: 0.3413 - val_loss: 3.1342 - val_accuracy: 0.3536\n",
      "Epoch 181/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2093 - accuracy: 0.3415 - val_loss: 3.1348 - val_accuracy: 0.3538\n",
      "Epoch 182/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2041 - accuracy: 0.3432 - val_loss: 3.1396 - val_accuracy: 0.3498\n",
      "Epoch 183/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2020 - accuracy: 0.3433 - val_loss: 3.1337 - val_accuracy: 0.3476\n",
      "Epoch 184/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2065 - accuracy: 0.3398 - val_loss: 3.1172 - val_accuracy: 0.3603\n",
      "Epoch 185/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2027 - accuracy: 0.3462 - val_loss: 3.1369 - val_accuracy: 0.3539\n",
      "Epoch 186/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2088 - accuracy: 0.3445 - val_loss: 3.1389 - val_accuracy: 0.3498\n",
      "Epoch 187/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.2030 - accuracy: 0.3408 - val_loss: 3.1287 - val_accuracy: 0.3556\n",
      "Epoch 188/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1917 - accuracy: 0.3455 - val_loss: 3.1114 - val_accuracy: 0.3556\n",
      "Epoch 189/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1826 - accuracy: 0.3443 - val_loss: 3.0851 - val_accuracy: 0.3606\n",
      "Epoch 190/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1657 - accuracy: 0.3469 - val_loss: 3.0625 - val_accuracy: 0.3658\n",
      "Epoch 191/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1557 - accuracy: 0.3513 - val_loss: 3.0870 - val_accuracy: 0.3504\n",
      "Epoch 192/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1669 - accuracy: 0.3413 - val_loss: 3.0700 - val_accuracy: 0.3613\n",
      "Epoch 193/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1428 - accuracy: 0.3549 - val_loss: 3.0595 - val_accuracy: 0.3636\n",
      "Epoch 194/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1413 - accuracy: 0.3552 - val_loss: 3.0412 - val_accuracy: 0.3650\n",
      "Epoch 195/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1261 - accuracy: 0.3560 - val_loss: 3.0291 - val_accuracy: 0.3713\n",
      "Epoch 196/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1131 - accuracy: 0.3589 - val_loss: 3.0473 - val_accuracy: 0.3643\n",
      "Epoch 197/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1181 - accuracy: 0.3571 - val_loss: 3.0347 - val_accuracy: 0.3619\n",
      "Epoch 198/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1049 - accuracy: 0.3558 - val_loss: 3.0131 - val_accuracy: 0.3797\n",
      "Epoch 199/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0928 - accuracy: 0.3639 - val_loss: 3.0091 - val_accuracy: 0.3706\n",
      "Epoch 200/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0805 - accuracy: 0.3608 - val_loss: 3.0109 - val_accuracy: 0.3642\n",
      "Epoch 201/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0755 - accuracy: 0.3576 - val_loss: 2.9868 - val_accuracy: 0.3773\n",
      "Epoch 202/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0711 - accuracy: 0.3641 - val_loss: 2.9888 - val_accuracy: 0.3753\n",
      "Epoch 203/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0586 - accuracy: 0.3647 - val_loss: 2.9788 - val_accuracy: 0.3746\n",
      "Epoch 204/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0482 - accuracy: 0.3664 - val_loss: 2.9718 - val_accuracy: 0.3774\n",
      "Epoch 205/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0462 - accuracy: 0.3674 - val_loss: 2.9981 - val_accuracy: 0.3700\n",
      "Epoch 206/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0606 - accuracy: 0.3627 - val_loss: 2.9643 - val_accuracy: 0.3824\n",
      "Epoch 207/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0442 - accuracy: 0.3690 - val_loss: 2.9721 - val_accuracy: 0.3720\n",
      "Epoch 208/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0342 - accuracy: 0.3646 - val_loss: 2.9530 - val_accuracy: 0.3824\n",
      "Epoch 209/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0139 - accuracy: 0.3682 - val_loss: 2.9355 - val_accuracy: 0.3830\n",
      "Epoch 210/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0121 - accuracy: 0.3720 - val_loss: 2.9392 - val_accuracy: 0.3753\n",
      "Epoch 211/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0023 - accuracy: 0.3673 - val_loss: 2.9321 - val_accuracy: 0.3819\n",
      "Epoch 212/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0035 - accuracy: 0.3721 - val_loss: 2.9283 - val_accuracy: 0.3829\n",
      "Epoch 213/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0020 - accuracy: 0.3717 - val_loss: 2.9063 - val_accuracy: 0.3836\n",
      "Epoch 214/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9855 - accuracy: 0.3719 - val_loss: 2.9388 - val_accuracy: 0.3798\n",
      "Epoch 215/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0137 - accuracy: 0.3679 - val_loss: 2.9362 - val_accuracy: 0.3810\n",
      "Epoch 216/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0215 - accuracy: 0.3707 - val_loss: 2.9281 - val_accuracy: 0.3759\n",
      "Epoch 217/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9960 - accuracy: 0.3702 - val_loss: 2.9215 - val_accuracy: 0.3857\n",
      "Epoch 218/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0039 - accuracy: 0.3712 - val_loss: 2.8906 - val_accuracy: 0.3859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9816 - accuracy: 0.3721 - val_loss: 2.9679 - val_accuracy: 0.3708\n",
      "Epoch 220/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0201 - accuracy: 0.3645 - val_loss: 2.9360 - val_accuracy: 0.3814\n",
      "Epoch 221/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0144 - accuracy: 0.3720 - val_loss: 2.9187 - val_accuracy: 0.3803\n",
      "Epoch 222/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9919 - accuracy: 0.3716 - val_loss: 2.9435 - val_accuracy: 0.3746\n",
      "Epoch 223/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0036 - accuracy: 0.3643 - val_loss: 2.8992 - val_accuracy: 0.3879\n",
      "Epoch 224/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9715 - accuracy: 0.3720 - val_loss: 2.8923 - val_accuracy: 0.3890\n",
      "Epoch 225/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9791 - accuracy: 0.3765 - val_loss: 2.8884 - val_accuracy: 0.3808\n",
      "Epoch 226/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9588 - accuracy: 0.3728 - val_loss: 2.8865 - val_accuracy: 0.3838\n",
      "Epoch 227/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9551 - accuracy: 0.3746 - val_loss: 2.8631 - val_accuracy: 0.3885\n",
      "Epoch 228/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9449 - accuracy: 0.3772 - val_loss: 2.8573 - val_accuracy: 0.3896\n",
      "Epoch 229/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9367 - accuracy: 0.3791 - val_loss: 2.8550 - val_accuracy: 0.3915\n",
      "Epoch 230/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9274 - accuracy: 0.3799 - val_loss: 2.8582 - val_accuracy: 0.3905\n",
      "Epoch 231/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9215 - accuracy: 0.3805 - val_loss: 2.8496 - val_accuracy: 0.3922\n",
      "Epoch 232/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9164 - accuracy: 0.3823 - val_loss: 2.8343 - val_accuracy: 0.3990\n",
      "Epoch 233/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9037 - accuracy: 0.3899 - val_loss: 2.8413 - val_accuracy: 0.3931\n",
      "Epoch 234/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8950 - accuracy: 0.3827 - val_loss: 2.8308 - val_accuracy: 0.3941\n",
      "Epoch 235/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8909 - accuracy: 0.3834 - val_loss: 2.8346 - val_accuracy: 0.3982\n",
      "Epoch 236/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9101 - accuracy: 0.3880 - val_loss: 2.8210 - val_accuracy: 0.3945\n",
      "Epoch 237/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8822 - accuracy: 0.3847 - val_loss: 2.8149 - val_accuracy: 0.4046\n",
      "Epoch 238/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8826 - accuracy: 0.3916 - val_loss: 2.8008 - val_accuracy: 0.4045\n",
      "Epoch 239/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8688 - accuracy: 0.3922 - val_loss: 2.7955 - val_accuracy: 0.4059\n",
      "Epoch 240/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8722 - accuracy: 0.3942 - val_loss: 2.8388 - val_accuracy: 0.3969\n",
      "Epoch 241/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9034 - accuracy: 0.3860 - val_loss: 2.8483 - val_accuracy: 0.3949\n",
      "Epoch 242/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9057 - accuracy: 0.3867 - val_loss: 2.8767 - val_accuracy: 0.3826\n",
      "Epoch 243/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9420 - accuracy: 0.3755 - val_loss: 2.8686 - val_accuracy: 0.3862\n",
      "Epoch 244/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9252 - accuracy: 0.3852 - val_loss: 2.9040 - val_accuracy: 0.3869\n",
      "Epoch 245/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9732 - accuracy: 0.3803 - val_loss: 2.9016 - val_accuracy: 0.3719\n",
      "Epoch 246/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9413 - accuracy: 0.3732 - val_loss: 2.8622 - val_accuracy: 0.3986\n",
      "Epoch 247/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9410 - accuracy: 0.3833 - val_loss: 2.8299 - val_accuracy: 0.4032\n",
      "Epoch 248/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9245 - accuracy: 0.3881 - val_loss: 2.8533 - val_accuracy: 0.3917\n",
      "Epoch 249/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9172 - accuracy: 0.3824 - val_loss: 2.8840 - val_accuracy: 0.3954\n",
      "Epoch 250/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9437 - accuracy: 0.3830 - val_loss: 2.8588 - val_accuracy: 0.3930\n",
      "Epoch 251/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9116 - accuracy: 0.3847 - val_loss: 2.8472 - val_accuracy: 0.3874\n",
      "Epoch 252/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9058 - accuracy: 0.3831 - val_loss: 2.8267 - val_accuracy: 0.4021\n",
      "Epoch 253/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8986 - accuracy: 0.3908 - val_loss: 2.8169 - val_accuracy: 0.4034\n",
      "Epoch 254/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8873 - accuracy: 0.3900 - val_loss: 2.8179 - val_accuracy: 0.3967\n",
      "Epoch 255/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8773 - accuracy: 0.3856 - val_loss: 2.8200 - val_accuracy: 0.3961\n",
      "Epoch 256/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8703 - accuracy: 0.3901 - val_loss: 2.7985 - val_accuracy: 0.4057\n",
      "Epoch 257/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8572 - accuracy: 0.3946 - val_loss: 2.7906 - val_accuracy: 0.4091\n",
      "Epoch 258/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8586 - accuracy: 0.3924 - val_loss: 2.7886 - val_accuracy: 0.4027\n",
      "Epoch 259/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8460 - accuracy: 0.3951 - val_loss: 2.7902 - val_accuracy: 0.3992\n",
      "Epoch 260/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8394 - accuracy: 0.3951 - val_loss: 2.7792 - val_accuracy: 0.4074\n",
      "Epoch 261/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8349 - accuracy: 0.3965 - val_loss: 2.7661 - val_accuracy: 0.4106\n",
      "Epoch 262/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8368 - accuracy: 0.3975 - val_loss: 2.7653 - val_accuracy: 0.4117\n",
      "Epoch 263/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8209 - accuracy: 0.3998 - val_loss: 2.7751 - val_accuracy: 0.4092\n",
      "Epoch 264/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8287 - accuracy: 0.3959 - val_loss: 2.7564 - val_accuracy: 0.4129\n",
      "Epoch 265/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8157 - accuracy: 0.3988 - val_loss: 2.7529 - val_accuracy: 0.4152\n",
      "Epoch 266/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8206 - accuracy: 0.4015 - val_loss: 2.7704 - val_accuracy: 0.4053\n",
      "Epoch 267/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8099 - accuracy: 0.3982 - val_loss: 2.7585 - val_accuracy: 0.4082\n",
      "Epoch 268/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8129 - accuracy: 0.3966 - val_loss: 2.7408 - val_accuracy: 0.4145\n",
      "Epoch 269/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8075 - accuracy: 0.4017 - val_loss: 2.7394 - val_accuracy: 0.4116\n",
      "Epoch 270/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7973 - accuracy: 0.3988 - val_loss: 2.7430 - val_accuracy: 0.4098\n",
      "Epoch 271/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7983 - accuracy: 0.3993 - val_loss: 2.7336 - val_accuracy: 0.4185\n",
      "Epoch 272/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7839 - accuracy: 0.4083 - val_loss: 2.7269 - val_accuracy: 0.4192\n",
      "Epoch 273/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7850 - accuracy: 0.4044 - val_loss: 2.7249 - val_accuracy: 0.4146\n",
      "Epoch 274/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7814 - accuracy: 0.4025 - val_loss: 2.7188 - val_accuracy: 0.4167\n",
      "Epoch 275/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7770 - accuracy: 0.4035 - val_loss: 2.7167 - val_accuracy: 0.4226\n",
      "Epoch 276/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7779 - accuracy: 0.4072 - val_loss: 2.7123 - val_accuracy: 0.4207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7697 - accuracy: 0.4056 - val_loss: 2.7046 - val_accuracy: 0.4231\n",
      "Epoch 278/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7642 - accuracy: 0.4069 - val_loss: 2.7101 - val_accuracy: 0.4207\n",
      "Epoch 279/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7583 - accuracy: 0.4083 - val_loss: 2.7087 - val_accuracy: 0.4200\n",
      "Epoch 280/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7534 - accuracy: 0.4073 - val_loss: 2.6927 - val_accuracy: 0.4275\n",
      "Epoch 281/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7543 - accuracy: 0.4128 - val_loss: 2.6954 - val_accuracy: 0.4213\n",
      "Epoch 282/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7603 - accuracy: 0.4062 - val_loss: 2.6962 - val_accuracy: 0.4251\n",
      "Epoch 283/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7528 - accuracy: 0.4109 - val_loss: 2.7113 - val_accuracy: 0.4160\n",
      "Epoch 284/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7584 - accuracy: 0.4039 - val_loss: 2.7141 - val_accuracy: 0.4304\n",
      "Epoch 285/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7747 - accuracy: 0.4118 - val_loss: 2.7226 - val_accuracy: 0.4100\n",
      "Epoch 286/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7662 - accuracy: 0.4002 - val_loss: 2.7013 - val_accuracy: 0.4175\n",
      "Epoch 287/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7466 - accuracy: 0.4076 - val_loss: 2.7073 - val_accuracy: 0.4228\n",
      "Epoch 288/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7531 - accuracy: 0.4135 - val_loss: 2.7114 - val_accuracy: 0.4166\n",
      "Epoch 289/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7526 - accuracy: 0.4045 - val_loss: 2.6877 - val_accuracy: 0.4235\n",
      "Epoch 290/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7394 - accuracy: 0.4111 - val_loss: 2.6896 - val_accuracy: 0.4268\n",
      "Epoch 291/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7422 - accuracy: 0.4150 - val_loss: 2.7023 - val_accuracy: 0.4198\n",
      "Epoch 292/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7484 - accuracy: 0.4072 - val_loss: 2.6872 - val_accuracy: 0.4296\n",
      "Epoch 293/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7354 - accuracy: 0.4143 - val_loss: 2.6729 - val_accuracy: 0.4286\n",
      "Epoch 294/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7436 - accuracy: 0.4127 - val_loss: 2.6973 - val_accuracy: 0.4239\n",
      "Epoch 295/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7427 - accuracy: 0.4105 - val_loss: 2.6788 - val_accuracy: 0.4286\n",
      "Epoch 296/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7238 - accuracy: 0.4135 - val_loss: 2.6780 - val_accuracy: 0.4318\n",
      "Epoch 297/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7319 - accuracy: 0.4175 - val_loss: 2.6785 - val_accuracy: 0.4230\n",
      "Epoch 298/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7323 - accuracy: 0.4117 - val_loss: 2.6939 - val_accuracy: 0.4180\n",
      "Epoch 299/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7375 - accuracy: 0.4076 - val_loss: 2.6920 - val_accuracy: 0.4252\n",
      "Epoch 300/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7379 - accuracy: 0.4126 - val_loss: 2.6919 - val_accuracy: 0.4216\n",
      "Epoch 301/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7303 - accuracy: 0.4114 - val_loss: 2.6876 - val_accuracy: 0.4221\n",
      "Epoch 302/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7194 - accuracy: 0.4121 - val_loss: 2.6773 - val_accuracy: 0.4298\n",
      "Epoch 303/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7226 - accuracy: 0.4161 - val_loss: 2.6774 - val_accuracy: 0.4316\n",
      "Epoch 304/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7221 - accuracy: 0.4160 - val_loss: 2.6907 - val_accuracy: 0.4240\n",
      "Epoch 305/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7369 - accuracy: 0.4118 - val_loss: 2.6821 - val_accuracy: 0.4231\n",
      "Epoch 306/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7209 - accuracy: 0.4136 - val_loss: 2.6813 - val_accuracy: 0.4274\n",
      "Epoch 307/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7274 - accuracy: 0.4166 - val_loss: 2.6967 - val_accuracy: 0.4191\n",
      "Epoch 308/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7384 - accuracy: 0.4097 - val_loss: 2.6913 - val_accuracy: 0.4309\n",
      "Epoch 309/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7404 - accuracy: 0.4143 - val_loss: 2.6959 - val_accuracy: 0.4156\n",
      "Epoch 310/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7274 - accuracy: 0.4086 - val_loss: 2.6877 - val_accuracy: 0.4227\n",
      "Epoch 311/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7188 - accuracy: 0.4162 - val_loss: 2.6694 - val_accuracy: 0.4350\n",
      "Epoch 312/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7158 - accuracy: 0.4207 - val_loss: 2.6678 - val_accuracy: 0.4336\n",
      "Epoch 313/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7053 - accuracy: 0.4171 - val_loss: 2.6764 - val_accuracy: 0.4269\n",
      "Epoch 314/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7201 - accuracy: 0.4124 - val_loss: 2.6713 - val_accuracy: 0.4361\n",
      "Epoch 315/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7137 - accuracy: 0.4210 - val_loss: 2.6677 - val_accuracy: 0.4276\n",
      "Epoch 316/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7024 - accuracy: 0.4156 - val_loss: 2.6644 - val_accuracy: 0.4245\n",
      "Epoch 317/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6997 - accuracy: 0.4151 - val_loss: 2.6671 - val_accuracy: 0.4352\n",
      "Epoch 318/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7018 - accuracy: 0.4192 - val_loss: 2.6657 - val_accuracy: 0.4298\n",
      "Epoch 319/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6966 - accuracy: 0.4176 - val_loss: 2.6598 - val_accuracy: 0.4294\n",
      "Epoch 320/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7009 - accuracy: 0.4168 - val_loss: 2.6672 - val_accuracy: 0.4350\n",
      "Epoch 321/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7043 - accuracy: 0.4217 - val_loss: 2.6583 - val_accuracy: 0.4306\n",
      "Epoch 322/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6955 - accuracy: 0.4179 - val_loss: 2.6677 - val_accuracy: 0.4300\n",
      "Epoch 323/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6937 - accuracy: 0.4157 - val_loss: 2.6615 - val_accuracy: 0.4376\n",
      "Epoch 324/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7011 - accuracy: 0.4192 - val_loss: 2.6538 - val_accuracy: 0.4364\n",
      "Epoch 325/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6969 - accuracy: 0.4182 - val_loss: 2.6423 - val_accuracy: 0.4368\n",
      "Epoch 326/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6813 - accuracy: 0.4212 - val_loss: 2.6554 - val_accuracy: 0.4359\n",
      "Epoch 327/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6921 - accuracy: 0.4218 - val_loss: 2.6602 - val_accuracy: 0.4311\n",
      "Epoch 328/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6898 - accuracy: 0.4160 - val_loss: 2.6538 - val_accuracy: 0.4341\n",
      "Epoch 329/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6888 - accuracy: 0.4176 - val_loss: 2.6469 - val_accuracy: 0.4455\n",
      "Epoch 330/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6849 - accuracy: 0.4268 - val_loss: 2.6489 - val_accuracy: 0.4359\n",
      "Epoch 331/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6890 - accuracy: 0.4215 - val_loss: 2.6643 - val_accuracy: 0.4245\n",
      "Epoch 332/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7005 - accuracy: 0.4142 - val_loss: 2.6832 - val_accuracy: 0.4358\n",
      "Epoch 333/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7110 - accuracy: 0.4185 - val_loss: 2.6551 - val_accuracy: 0.4348\n",
      "Epoch 334/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6863 - accuracy: 0.4224 - val_loss: 2.6686 - val_accuracy: 0.4280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6967 - accuracy: 0.4178 - val_loss: 2.6897 - val_accuracy: 0.4260\n",
      "Epoch 336/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7155 - accuracy: 0.4155 - val_loss: 2.6561 - val_accuracy: 0.4328\n",
      "Epoch 337/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6828 - accuracy: 0.4213 - val_loss: 2.6613 - val_accuracy: 0.4356\n",
      "Epoch 338/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7058 - accuracy: 0.4204 - val_loss: 2.6619 - val_accuracy: 0.4357\n",
      "Epoch 339/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6959 - accuracy: 0.4192 - val_loss: 2.6669 - val_accuracy: 0.4305\n",
      "Epoch 340/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6809 - accuracy: 0.4183 - val_loss: 2.6517 - val_accuracy: 0.4360\n",
      "Epoch 341/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6713 - accuracy: 0.4243 - val_loss: 2.6441 - val_accuracy: 0.4410\n",
      "Epoch 342/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6741 - accuracy: 0.4280 - val_loss: 2.6393 - val_accuracy: 0.4365\n",
      "Epoch 343/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6683 - accuracy: 0.4256 - val_loss: 2.6435 - val_accuracy: 0.4358\n",
      "Epoch 344/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6685 - accuracy: 0.4234 - val_loss: 2.6361 - val_accuracy: 0.4426\n",
      "Epoch 345/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6696 - accuracy: 0.4277 - val_loss: 2.6317 - val_accuracy: 0.4381\n",
      "Epoch 346/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6531 - accuracy: 0.4265 - val_loss: 2.6335 - val_accuracy: 0.4392\n",
      "Epoch 347/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6651 - accuracy: 0.4244 - val_loss: 2.6223 - val_accuracy: 0.4423\n",
      "Epoch 348/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6478 - accuracy: 0.4311 - val_loss: 2.6429 - val_accuracy: 0.4364\n",
      "Epoch 349/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6717 - accuracy: 0.4223 - val_loss: 2.6510 - val_accuracy: 0.4427\n",
      "Epoch 350/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6765 - accuracy: 0.4275 - val_loss: 2.6213 - val_accuracy: 0.4391\n",
      "Epoch 351/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6471 - accuracy: 0.4261 - val_loss: 2.6313 - val_accuracy: 0.4428\n",
      "Epoch 352/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6632 - accuracy: 0.4292 - val_loss: 2.6362 - val_accuracy: 0.4434\n",
      "Epoch 353/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6603 - accuracy: 0.4296 - val_loss: 2.6326 - val_accuracy: 0.4370\n",
      "Epoch 354/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6504 - accuracy: 0.4266 - val_loss: 2.6303 - val_accuracy: 0.4315\n",
      "Epoch 355/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6564 - accuracy: 0.4240 - val_loss: 2.6278 - val_accuracy: 0.4414\n",
      "Epoch 356/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6514 - accuracy: 0.4276 - val_loss: 2.6150 - val_accuracy: 0.4442\n",
      "Epoch 357/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6404 - accuracy: 0.4292 - val_loss: 2.6182 - val_accuracy: 0.4369\n",
      "Epoch 358/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6507 - accuracy: 0.4231 - val_loss: 2.6153 - val_accuracy: 0.4427\n",
      "Epoch 359/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6392 - accuracy: 0.4288 - val_loss: 2.6151 - val_accuracy: 0.4439\n",
      "Epoch 360/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6396 - accuracy: 0.4300 - val_loss: 2.6103 - val_accuracy: 0.4390\n",
      "Epoch 361/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6330 - accuracy: 0.4259 - val_loss: 2.6037 - val_accuracy: 0.4468\n",
      "Epoch 362/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6389 - accuracy: 0.4304 - val_loss: 2.6015 - val_accuracy: 0.4483\n",
      "Epoch 363/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6254 - accuracy: 0.4323 - val_loss: 2.6102 - val_accuracy: 0.4453\n",
      "Epoch 364/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6347 - accuracy: 0.4310 - val_loss: 2.6094 - val_accuracy: 0.4460\n",
      "Epoch 365/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6330 - accuracy: 0.4317 - val_loss: 2.6036 - val_accuracy: 0.4467\n",
      "Epoch 366/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6202 - accuracy: 0.4337 - val_loss: 2.6003 - val_accuracy: 0.4403\n",
      "Epoch 367/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6244 - accuracy: 0.4282 - val_loss: 2.5886 - val_accuracy: 0.4507\n",
      "Epoch 368/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6160 - accuracy: 0.4357 - val_loss: 2.5925 - val_accuracy: 0.4500\n",
      "Epoch 369/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6227 - accuracy: 0.4350 - val_loss: 2.6005 - val_accuracy: 0.4444\n",
      "Epoch 370/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6168 - accuracy: 0.4315 - val_loss: 2.5914 - val_accuracy: 0.4482\n",
      "Epoch 371/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6211 - accuracy: 0.4342 - val_loss: 2.5906 - val_accuracy: 0.4525\n",
      "Epoch 372/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6120 - accuracy: 0.4378 - val_loss: 2.5990 - val_accuracy: 0.4476\n",
      "Epoch 373/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6213 - accuracy: 0.4326 - val_loss: 2.5938 - val_accuracy: 0.4468\n",
      "Epoch 374/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6191 - accuracy: 0.4346 - val_loss: 2.5911 - val_accuracy: 0.4552\n",
      "Epoch 375/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6226 - accuracy: 0.4344 - val_loss: 2.5965 - val_accuracy: 0.4446\n",
      "Epoch 376/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6140 - accuracy: 0.4330 - val_loss: 2.6046 - val_accuracy: 0.4496\n",
      "Epoch 377/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6336 - accuracy: 0.4329 - val_loss: 2.6241 - val_accuracy: 0.4343\n",
      "Epoch 378/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6480 - accuracy: 0.4240 - val_loss: 2.6163 - val_accuracy: 0.4461\n",
      "Epoch 379/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6445 - accuracy: 0.4317 - val_loss: 2.5969 - val_accuracy: 0.4468\n",
      "Epoch 380/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6202 - accuracy: 0.4338 - val_loss: 2.6127 - val_accuracy: 0.4416\n",
      "Epoch 381/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6271 - accuracy: 0.4275 - val_loss: 2.6126 - val_accuracy: 0.4484\n",
      "Epoch 382/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6304 - accuracy: 0.4357 - val_loss: 2.5974 - val_accuracy: 0.4494\n",
      "Epoch 383/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6131 - accuracy: 0.4353 - val_loss: 2.5990 - val_accuracy: 0.4458\n",
      "Epoch 384/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6102 - accuracy: 0.4344 - val_loss: 2.5974 - val_accuracy: 0.4485\n",
      "Epoch 385/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6102 - accuracy: 0.4336 - val_loss: 2.5908 - val_accuracy: 0.4473\n",
      "Epoch 386/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6127 - accuracy: 0.4339 - val_loss: 2.5819 - val_accuracy: 0.4477\n",
      "Epoch 387/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6014 - accuracy: 0.4380 - val_loss: 2.5776 - val_accuracy: 0.4522\n",
      "Epoch 388/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6015 - accuracy: 0.4405 - val_loss: 2.5756 - val_accuracy: 0.4538\n",
      "Epoch 389/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6011 - accuracy: 0.4408 - val_loss: 2.5721 - val_accuracy: 0.4515\n",
      "Epoch 390/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5943 - accuracy: 0.4374 - val_loss: 2.5705 - val_accuracy: 0.4520\n",
      "Epoch 391/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5970 - accuracy: 0.4365 - val_loss: 2.5755 - val_accuracy: 0.4588\n",
      "Epoch 392/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6004 - accuracy: 0.4412 - val_loss: 2.5886 - val_accuracy: 0.4448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6048 - accuracy: 0.4353 - val_loss: 2.5837 - val_accuracy: 0.4537\n",
      "Epoch 394/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6086 - accuracy: 0.4395 - val_loss: 2.5826 - val_accuracy: 0.4522\n",
      "Epoch 395/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6012 - accuracy: 0.4373 - val_loss: 2.5856 - val_accuracy: 0.4482\n",
      "Epoch 396/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5923 - accuracy: 0.4382 - val_loss: 2.5933 - val_accuracy: 0.4488\n",
      "Epoch 397/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6005 - accuracy: 0.4379 - val_loss: 2.5854 - val_accuracy: 0.4491\n",
      "Epoch 398/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6113 - accuracy: 0.4369 - val_loss: 2.6062 - val_accuracy: 0.4553\n",
      "Epoch 399/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6325 - accuracy: 0.4376 - val_loss: 2.5764 - val_accuracy: 0.4499\n",
      "Epoch 400/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5994 - accuracy: 0.4362 - val_loss: 2.5906 - val_accuracy: 0.4507\n",
      "Epoch 401/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6223 - accuracy: 0.4330 - val_loss: 2.6014 - val_accuracy: 0.4560\n",
      "Epoch 402/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6221 - accuracy: 0.4373 - val_loss: 2.5997 - val_accuracy: 0.4498\n",
      "Epoch 403/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6171 - accuracy: 0.4347 - val_loss: 2.5970 - val_accuracy: 0.4414\n",
      "Epoch 404/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6114 - accuracy: 0.4313 - val_loss: 2.5876 - val_accuracy: 0.4526\n",
      "Epoch 405/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6088 - accuracy: 0.4356 - val_loss: 2.5785 - val_accuracy: 0.4610\n",
      "Epoch 406/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6065 - accuracy: 0.4410 - val_loss: 2.5807 - val_accuracy: 0.4506\n",
      "Epoch 407/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6046 - accuracy: 0.4376 - val_loss: 2.5955 - val_accuracy: 0.4528\n",
      "Epoch 408/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5978 - accuracy: 0.4406 - val_loss: 2.5723 - val_accuracy: 0.4566\n",
      "Epoch 409/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5854 - accuracy: 0.4426 - val_loss: 2.5691 - val_accuracy: 0.4560\n",
      "Epoch 410/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5943 - accuracy: 0.4400 - val_loss: 2.5853 - val_accuracy: 0.4548\n",
      "Epoch 411/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6065 - accuracy: 0.4382 - val_loss: 2.5834 - val_accuracy: 0.4458\n",
      "Epoch 412/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5941 - accuracy: 0.4347 - val_loss: 2.5861 - val_accuracy: 0.4580\n",
      "Epoch 413/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5938 - accuracy: 0.4433 - val_loss: 2.5701 - val_accuracy: 0.4562\n",
      "Epoch 414/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5848 - accuracy: 0.4417 - val_loss: 2.5734 - val_accuracy: 0.4541\n",
      "Epoch 415/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5963 - accuracy: 0.4389 - val_loss: 2.5694 - val_accuracy: 0.4524\n",
      "Epoch 416/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5821 - accuracy: 0.4385 - val_loss: 2.5758 - val_accuracy: 0.4559\n",
      "Epoch 417/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5839 - accuracy: 0.4418 - val_loss: 2.5593 - val_accuracy: 0.4599\n",
      "Epoch 418/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5778 - accuracy: 0.4446 - val_loss: 2.5622 - val_accuracy: 0.4589\n",
      "Epoch 419/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5855 - accuracy: 0.4406 - val_loss: 2.5534 - val_accuracy: 0.4602\n",
      "Epoch 420/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5832 - accuracy: 0.4417 - val_loss: 2.5619 - val_accuracy: 0.4599\n",
      "Epoch 421/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5764 - accuracy: 0.4436 - val_loss: 2.5674 - val_accuracy: 0.4528\n",
      "Epoch 422/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5782 - accuracy: 0.4402 - val_loss: 2.5612 - val_accuracy: 0.4564\n",
      "Epoch 423/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5692 - accuracy: 0.4423 - val_loss: 2.5499 - val_accuracy: 0.4590\n",
      "Epoch 424/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5778 - accuracy: 0.4436 - val_loss: 2.5539 - val_accuracy: 0.4581\n",
      "Epoch 425/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5666 - accuracy: 0.4437 - val_loss: 2.5563 - val_accuracy: 0.4597\n",
      "Epoch 426/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5723 - accuracy: 0.4449 - val_loss: 2.5546 - val_accuracy: 0.4567\n",
      "Epoch 427/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5720 - accuracy: 0.4410 - val_loss: 2.5579 - val_accuracy: 0.4557\n",
      "Epoch 428/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5710 - accuracy: 0.4442 - val_loss: 2.5600 - val_accuracy: 0.4640\n",
      "Epoch 429/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5774 - accuracy: 0.4466 - val_loss: 2.5550 - val_accuracy: 0.4522\n",
      "Epoch 430/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5774 - accuracy: 0.4398 - val_loss: 2.5569 - val_accuracy: 0.4531\n",
      "Epoch 431/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5719 - accuracy: 0.4401 - val_loss: 2.5644 - val_accuracy: 0.4591\n",
      "Epoch 432/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5813 - accuracy: 0.4447 - val_loss: 2.5506 - val_accuracy: 0.4548\n",
      "Epoch 433/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5700 - accuracy: 0.4407 - val_loss: 2.5502 - val_accuracy: 0.4607\n",
      "Epoch 434/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5687 - accuracy: 0.4435 - val_loss: 2.5478 - val_accuracy: 0.4641\n",
      "Epoch 435/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5648 - accuracy: 0.4471 - val_loss: 2.5533 - val_accuracy: 0.4593\n",
      "Epoch 436/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5603 - accuracy: 0.4450 - val_loss: 2.5483 - val_accuracy: 0.4576\n",
      "Epoch 437/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5668 - accuracy: 0.4442 - val_loss: 2.5350 - val_accuracy: 0.4615\n",
      "Epoch 438/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5534 - accuracy: 0.4491 - val_loss: 2.5458 - val_accuracy: 0.4581\n",
      "Epoch 439/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5617 - accuracy: 0.4434 - val_loss: 2.5474 - val_accuracy: 0.4599\n",
      "Epoch 440/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5555 - accuracy: 0.4458 - val_loss: 2.5444 - val_accuracy: 0.4607\n",
      "Epoch 441/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5508 - accuracy: 0.4461 - val_loss: 2.5415 - val_accuracy: 0.4648\n",
      "Epoch 442/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5573 - accuracy: 0.4463 - val_loss: 2.5388 - val_accuracy: 0.4608\n",
      "Epoch 443/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5444 - accuracy: 0.4485 - val_loss: 2.5472 - val_accuracy: 0.4598\n",
      "Epoch 444/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5538 - accuracy: 0.4477 - val_loss: 2.5347 - val_accuracy: 0.4642\n",
      "Epoch 445/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5474 - accuracy: 0.4515 - val_loss: 2.5359 - val_accuracy: 0.4599\n",
      "Epoch 446/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5475 - accuracy: 0.4446 - val_loss: 2.5416 - val_accuracy: 0.4633\n",
      "Epoch 447/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5464 - accuracy: 0.4485 - val_loss: 2.5372 - val_accuracy: 0.4613\n",
      "Epoch 448/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5486 - accuracy: 0.4488 - val_loss: 2.5318 - val_accuracy: 0.4591\n",
      "Epoch 449/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5486 - accuracy: 0.4432 - val_loss: 2.5532 - val_accuracy: 0.4691\n",
      "Epoch 450/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5751 - accuracy: 0.4475 - val_loss: 2.5316 - val_accuracy: 0.4622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5432 - accuracy: 0.4472 - val_loss: 2.5398 - val_accuracy: 0.4568\n",
      "Epoch 452/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5564 - accuracy: 0.4429 - val_loss: 2.5526 - val_accuracy: 0.4660\n",
      "Epoch 453/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5686 - accuracy: 0.4474 - val_loss: 2.5324 - val_accuracy: 0.4621\n",
      "Epoch 454/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5527 - accuracy: 0.4454 - val_loss: 2.5465 - val_accuracy: 0.4576\n",
      "Epoch 455/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5519 - accuracy: 0.4452 - val_loss: 2.5534 - val_accuracy: 0.4636\n",
      "Epoch 456/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5504 - accuracy: 0.4522 - val_loss: 2.5361 - val_accuracy: 0.4635\n",
      "Epoch 457/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5560 - accuracy: 0.4462 - val_loss: 2.5400 - val_accuracy: 0.4536\n",
      "Epoch 458/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5533 - accuracy: 0.4410 - val_loss: 2.5386 - val_accuracy: 0.4619\n",
      "Epoch 459/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5487 - accuracy: 0.4492 - val_loss: 2.5373 - val_accuracy: 0.4613\n",
      "Epoch 460/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5423 - accuracy: 0.4502 - val_loss: 2.5305 - val_accuracy: 0.4586\n",
      "Epoch 461/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5483 - accuracy: 0.4433 - val_loss: 2.5299 - val_accuracy: 0.4599\n",
      "Epoch 462/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5385 - accuracy: 0.4473 - val_loss: 2.5320 - val_accuracy: 0.4646\n",
      "Epoch 463/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5436 - accuracy: 0.4501 - val_loss: 2.5295 - val_accuracy: 0.4654\n",
      "Epoch 464/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5395 - accuracy: 0.4467 - val_loss: 2.5284 - val_accuracy: 0.4653\n",
      "Epoch 465/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5464 - accuracy: 0.4471 - val_loss: 2.5290 - val_accuracy: 0.4645\n",
      "Epoch 466/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5361 - accuracy: 0.4488 - val_loss: 2.5299 - val_accuracy: 0.4661\n",
      "Epoch 467/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5376 - accuracy: 0.4494 - val_loss: 2.5308 - val_accuracy: 0.4623\n",
      "Epoch 468/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5311 - accuracy: 0.4497 - val_loss: 2.5291 - val_accuracy: 0.4599\n",
      "Epoch 469/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5350 - accuracy: 0.4463 - val_loss: 2.5376 - val_accuracy: 0.4625\n",
      "Epoch 470/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5411 - accuracy: 0.4508 - val_loss: 2.5301 - val_accuracy: 0.4614\n",
      "Epoch 471/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5245 - accuracy: 0.4503 - val_loss: 2.5271 - val_accuracy: 0.4656\n",
      "Epoch 472/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5246 - accuracy: 0.4514 - val_loss: 2.5288 - val_accuracy: 0.4685\n",
      "Epoch 473/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5413 - accuracy: 0.4517 - val_loss: 2.5268 - val_accuracy: 0.4603\n",
      "Epoch 474/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5338 - accuracy: 0.4466 - val_loss: 2.5198 - val_accuracy: 0.4624\n",
      "Epoch 475/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5255 - accuracy: 0.4483 - val_loss: 2.5197 - val_accuracy: 0.4707\n",
      "Epoch 476/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5272 - accuracy: 0.4548 - val_loss: 2.5109 - val_accuracy: 0.4668\n",
      "Epoch 477/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5240 - accuracy: 0.4520 - val_loss: 2.5192 - val_accuracy: 0.4601\n",
      "Epoch 478/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5212 - accuracy: 0.4510 - val_loss: 2.5146 - val_accuracy: 0.4620\n",
      "Epoch 479/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5218 - accuracy: 0.4508 - val_loss: 2.5087 - val_accuracy: 0.4653\n",
      "Epoch 480/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5220 - accuracy: 0.4528 - val_loss: 2.5159 - val_accuracy: 0.4705\n",
      "Epoch 481/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5136 - accuracy: 0.4554 - val_loss: 2.5209 - val_accuracy: 0.4646\n",
      "Epoch 482/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5166 - accuracy: 0.4513 - val_loss: 2.5218 - val_accuracy: 0.4673\n",
      "Epoch 483/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5213 - accuracy: 0.4531 - val_loss: 2.5198 - val_accuracy: 0.4632\n",
      "Epoch 484/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5205 - accuracy: 0.4515 - val_loss: 2.5215 - val_accuracy: 0.4659\n",
      "Epoch 485/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5196 - accuracy: 0.4536 - val_loss: 2.5159 - val_accuracy: 0.4668\n",
      "Epoch 486/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5169 - accuracy: 0.4540 - val_loss: 2.5205 - val_accuracy: 0.4641\n",
      "Epoch 487/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5246 - accuracy: 0.4507 - val_loss: 2.5341 - val_accuracy: 0.4661\n",
      "Epoch 488/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5280 - accuracy: 0.4523 - val_loss: 2.5277 - val_accuracy: 0.4655\n",
      "Epoch 489/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5276 - accuracy: 0.4507 - val_loss: 2.5244 - val_accuracy: 0.4668\n",
      "Epoch 490/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5304 - accuracy: 0.4517 - val_loss: 2.5237 - val_accuracy: 0.4631\n",
      "Epoch 491/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5226 - accuracy: 0.4474 - val_loss: 2.5201 - val_accuracy: 0.4676\n",
      "Epoch 492/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5275 - accuracy: 0.4502 - val_loss: 2.5143 - val_accuracy: 0.4661\n",
      "Epoch 493/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5170 - accuracy: 0.4524 - val_loss: 2.5185 - val_accuracy: 0.4633\n",
      "Epoch 494/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5242 - accuracy: 0.4499 - val_loss: 2.5151 - val_accuracy: 0.4680\n",
      "Epoch 495/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5155 - accuracy: 0.4530 - val_loss: 2.5208 - val_accuracy: 0.4686\n",
      "Epoch 496/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5226 - accuracy: 0.4515 - val_loss: 2.5129 - val_accuracy: 0.4647\n",
      "Epoch 497/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5189 - accuracy: 0.4509 - val_loss: 2.5142 - val_accuracy: 0.4664\n",
      "Epoch 498/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5185 - accuracy: 0.4526 - val_loss: 2.5240 - val_accuracy: 0.4707\n",
      "Epoch 499/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5178 - accuracy: 0.4575 - val_loss: 2.5149 - val_accuracy: 0.4644\n",
      "Epoch 500/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5090 - accuracy: 0.4507 - val_loss: 2.5147 - val_accuracy: 0.4680\n",
      "Epoch 501/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5190 - accuracy: 0.4522 - val_loss: 2.5089 - val_accuracy: 0.4705\n",
      "Epoch 502/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5024 - accuracy: 0.4577 - val_loss: 2.5170 - val_accuracy: 0.4668\n",
      "Epoch 503/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5182 - accuracy: 0.4519 - val_loss: 2.5347 - val_accuracy: 0.4690\n",
      "Epoch 504/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5304 - accuracy: 0.4532 - val_loss: 2.5243 - val_accuracy: 0.4653\n",
      "Epoch 505/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5151 - accuracy: 0.4545 - val_loss: 2.5232 - val_accuracy: 0.4645\n",
      "Epoch 506/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5190 - accuracy: 0.4529 - val_loss: 2.5186 - val_accuracy: 0.4670\n",
      "Epoch 507/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5199 - accuracy: 0.4526 - val_loss: 2.5218 - val_accuracy: 0.4675\n",
      "Epoch 508/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5268 - accuracy: 0.4523 - val_loss: 2.5342 - val_accuracy: 0.4639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5230 - accuracy: 0.4505 - val_loss: 2.5239 - val_accuracy: 0.4640\n",
      "Epoch 510/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5178 - accuracy: 0.4495 - val_loss: 2.5096 - val_accuracy: 0.4693\n",
      "Epoch 511/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5231 - accuracy: 0.4513 - val_loss: 2.5237 - val_accuracy: 0.4653\n",
      "Epoch 512/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5252 - accuracy: 0.4530 - val_loss: 2.5333 - val_accuracy: 0.4643\n",
      "Epoch 513/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5276 - accuracy: 0.4517 - val_loss: 2.5299 - val_accuracy: 0.4651\n",
      "Epoch 514/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5232 - accuracy: 0.4502 - val_loss: 2.5184 - val_accuracy: 0.4693\n",
      "Epoch 515/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5260 - accuracy: 0.4521 - val_loss: 2.5159 - val_accuracy: 0.4656\n",
      "Epoch 516/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5248 - accuracy: 0.4499 - val_loss: 2.5244 - val_accuracy: 0.4627\n",
      "Epoch 517/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5324 - accuracy: 0.4465 - val_loss: 2.5306 - val_accuracy: 0.4715\n",
      "Epoch 518/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5298 - accuracy: 0.4537 - val_loss: 2.5435 - val_accuracy: 0.4584\n",
      "Epoch 519/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5382 - accuracy: 0.4472 - val_loss: 2.5231 - val_accuracy: 0.4622\n",
      "Epoch 520/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5200 - accuracy: 0.4505 - val_loss: 2.5259 - val_accuracy: 0.4695\n",
      "Epoch 521/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5263 - accuracy: 0.4525 - val_loss: 2.5354 - val_accuracy: 0.4644\n",
      "Epoch 522/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5357 - accuracy: 0.4517 - val_loss: 2.5197 - val_accuracy: 0.4653\n",
      "Epoch 523/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5131 - accuracy: 0.4539 - val_loss: 2.5301 - val_accuracy: 0.4666\n",
      "Epoch 524/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5296 - accuracy: 0.4509 - val_loss: 2.5209 - val_accuracy: 0.4661\n",
      "Epoch 525/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5115 - accuracy: 0.4557 - val_loss: 2.5251 - val_accuracy: 0.4606\n",
      "Epoch 526/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5258 - accuracy: 0.4507 - val_loss: 2.5139 - val_accuracy: 0.4654\n",
      "Epoch 527/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5156 - accuracy: 0.4522 - val_loss: 2.5270 - val_accuracy: 0.4708\n",
      "Epoch 528/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5345 - accuracy: 0.4504 - val_loss: 2.5125 - val_accuracy: 0.4698\n",
      "Epoch 529/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5155 - accuracy: 0.4547 - val_loss: 2.5150 - val_accuracy: 0.4672\n",
      "Epoch 530/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5078 - accuracy: 0.4555 - val_loss: 2.5101 - val_accuracy: 0.4675\n",
      "Epoch 531/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5068 - accuracy: 0.4549 - val_loss: 2.5095 - val_accuracy: 0.4733\n",
      "Epoch 532/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5118 - accuracy: 0.4564 - val_loss: 2.5057 - val_accuracy: 0.4687\n",
      "Epoch 533/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5060 - accuracy: 0.4534 - val_loss: 2.5021 - val_accuracy: 0.4699\n",
      "Epoch 534/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5036 - accuracy: 0.4556 - val_loss: 2.5039 - val_accuracy: 0.4715\n",
      "Epoch 535/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5017 - accuracy: 0.4563 - val_loss: 2.5010 - val_accuracy: 0.4732\n",
      "Epoch 536/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4966 - accuracy: 0.4580 - val_loss: 2.4998 - val_accuracy: 0.4715\n",
      "Epoch 537/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5047 - accuracy: 0.4540 - val_loss: 2.5034 - val_accuracy: 0.4715\n",
      "Epoch 538/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5024 - accuracy: 0.4562 - val_loss: 2.4974 - val_accuracy: 0.4716\n",
      "Epoch 539/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4917 - accuracy: 0.4576 - val_loss: 2.4960 - val_accuracy: 0.4721\n",
      "Epoch 540/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4881 - accuracy: 0.4582 - val_loss: 2.4976 - val_accuracy: 0.4717\n",
      "Epoch 541/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4942 - accuracy: 0.4594 - val_loss: 2.5014 - val_accuracy: 0.4687\n",
      "Epoch 542/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5066 - accuracy: 0.4552 - val_loss: 2.5150 - val_accuracy: 0.4712\n",
      "Epoch 543/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5069 - accuracy: 0.4578 - val_loss: 2.5005 - val_accuracy: 0.4715\n",
      "Epoch 544/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5001 - accuracy: 0.4549 - val_loss: 2.4981 - val_accuracy: 0.4727\n",
      "Epoch 545/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4958 - accuracy: 0.4568 - val_loss: 2.5006 - val_accuracy: 0.4762\n",
      "Epoch 546/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4987 - accuracy: 0.4573 - val_loss: 2.5024 - val_accuracy: 0.4711\n",
      "Epoch 547/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4985 - accuracy: 0.4550 - val_loss: 2.5054 - val_accuracy: 0.4686\n",
      "Epoch 548/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4974 - accuracy: 0.4556 - val_loss: 2.5038 - val_accuracy: 0.4738\n",
      "Epoch 549/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4949 - accuracy: 0.4607 - val_loss: 2.4932 - val_accuracy: 0.4724\n",
      "Epoch 550/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4972 - accuracy: 0.4568 - val_loss: 2.5084 - val_accuracy: 0.4684\n",
      "Epoch 551/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5013 - accuracy: 0.4543 - val_loss: 2.5279 - val_accuracy: 0.4748\n",
      "Epoch 552/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5200 - accuracy: 0.4597 - val_loss: 2.5069 - val_accuracy: 0.4699\n",
      "Epoch 553/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5071 - accuracy: 0.4560 - val_loss: 2.5380 - val_accuracy: 0.4621\n",
      "Epoch 554/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5417 - accuracy: 0.4457 - val_loss: 2.5595 - val_accuracy: 0.4730\n",
      "Epoch 555/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5414 - accuracy: 0.4579 - val_loss: 2.5493 - val_accuracy: 0.4734\n",
      "Epoch 556/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5342 - accuracy: 0.4577 - val_loss: 2.5176 - val_accuracy: 0.4639\n",
      "Epoch 557/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5172 - accuracy: 0.4517 - val_loss: 2.5220 - val_accuracy: 0.4593\n",
      "Epoch 558/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5223 - accuracy: 0.4452 - val_loss: 2.5196 - val_accuracy: 0.4722\n",
      "Epoch 559/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5216 - accuracy: 0.4542 - val_loss: 2.5163 - val_accuracy: 0.4731\n",
      "Epoch 560/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5139 - accuracy: 0.4574 - val_loss: 2.5142 - val_accuracy: 0.4684\n",
      "Epoch 561/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5087 - accuracy: 0.4546 - val_loss: 2.5064 - val_accuracy: 0.4685\n",
      "Epoch 562/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5033 - accuracy: 0.4529 - val_loss: 2.4999 - val_accuracy: 0.4749\n",
      "Epoch 563/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5020 - accuracy: 0.4585 - val_loss: 2.5003 - val_accuracy: 0.4722\n",
      "Epoch 564/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5028 - accuracy: 0.4597 - val_loss: 2.4992 - val_accuracy: 0.4705\n",
      "Epoch 565/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5040 - accuracy: 0.4558 - val_loss: 2.4995 - val_accuracy: 0.4707\n",
      "Epoch 566/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4888 - accuracy: 0.4582 - val_loss: 2.5051 - val_accuracy: 0.4735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4969 - accuracy: 0.4584 - val_loss: 2.4964 - val_accuracy: 0.4737\n",
      "Epoch 568/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4919 - accuracy: 0.4588 - val_loss: 2.4958 - val_accuracy: 0.4722\n",
      "Epoch 569/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4934 - accuracy: 0.4577 - val_loss: 2.4964 - val_accuracy: 0.4691\n",
      "Epoch 570/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4937 - accuracy: 0.4552 - val_loss: 2.4989 - val_accuracy: 0.4714\n",
      "Epoch 571/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4890 - accuracy: 0.4586 - val_loss: 2.4988 - val_accuracy: 0.4696\n",
      "Epoch 572/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4890 - accuracy: 0.4584 - val_loss: 2.4871 - val_accuracy: 0.4707\n",
      "Epoch 573/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4823 - accuracy: 0.4575 - val_loss: 2.4917 - val_accuracy: 0.4765\n",
      "Epoch 574/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4888 - accuracy: 0.4606 - val_loss: 2.4915 - val_accuracy: 0.4749\n",
      "Epoch 575/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4769 - accuracy: 0.4613 - val_loss: 2.4953 - val_accuracy: 0.4714\n",
      "Epoch 576/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4763 - accuracy: 0.4604 - val_loss: 2.4989 - val_accuracy: 0.4698\n",
      "Epoch 577/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4939 - accuracy: 0.4570 - val_loss: 2.4923 - val_accuracy: 0.4722\n",
      "Epoch 578/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4913 - accuracy: 0.4580 - val_loss: 2.4894 - val_accuracy: 0.4719\n",
      "Epoch 579/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4817 - accuracy: 0.4583 - val_loss: 2.4965 - val_accuracy: 0.4749\n",
      "Epoch 580/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4913 - accuracy: 0.4593 - val_loss: 2.5043 - val_accuracy: 0.4715\n",
      "Epoch 581/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4857 - accuracy: 0.4611 - val_loss: 2.4963 - val_accuracy: 0.4707\n",
      "Epoch 582/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4716 - accuracy: 0.4598 - val_loss: 2.4994 - val_accuracy: 0.4715\n",
      "Epoch 583/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4942 - accuracy: 0.4577 - val_loss: 2.4920 - val_accuracy: 0.4736\n",
      "Epoch 584/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4831 - accuracy: 0.4595 - val_loss: 2.5032 - val_accuracy: 0.4714\n",
      "Epoch 585/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4921 - accuracy: 0.4578 - val_loss: 2.4922 - val_accuracy: 0.4723\n",
      "Epoch 586/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4890 - accuracy: 0.4582 - val_loss: 2.4912 - val_accuracy: 0.4707\n",
      "Epoch 587/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4855 - accuracy: 0.4582 - val_loss: 2.4953 - val_accuracy: 0.4769\n",
      "Epoch 588/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4822 - accuracy: 0.4613 - val_loss: 2.4904 - val_accuracy: 0.4753\n",
      "Epoch 589/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4825 - accuracy: 0.4597 - val_loss: 2.4940 - val_accuracy: 0.4674\n",
      "Epoch 590/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4871 - accuracy: 0.4554 - val_loss: 2.4894 - val_accuracy: 0.4727\n",
      "Epoch 591/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4781 - accuracy: 0.4610 - val_loss: 2.4846 - val_accuracy: 0.4728\n",
      "Epoch 592/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4790 - accuracy: 0.4623 - val_loss: 2.4959 - val_accuracy: 0.4706\n",
      "Epoch 593/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4798 - accuracy: 0.4584 - val_loss: 2.4939 - val_accuracy: 0.4725\n",
      "Epoch 594/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4787 - accuracy: 0.4622 - val_loss: 2.4808 - val_accuracy: 0.4758\n",
      "Epoch 595/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4726 - accuracy: 0.4621 - val_loss: 2.4855 - val_accuracy: 0.4730\n",
      "Epoch 596/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4854 - accuracy: 0.4591 - val_loss: 2.4914 - val_accuracy: 0.4738\n",
      "Epoch 597/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4846 - accuracy: 0.4612 - val_loss: 2.4931 - val_accuracy: 0.4702\n",
      "Epoch 598/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4789 - accuracy: 0.4579 - val_loss: 2.5000 - val_accuracy: 0.4729\n",
      "Epoch 599/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4872 - accuracy: 0.4582 - val_loss: 2.4947 - val_accuracy: 0.4794\n",
      "Epoch 600/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4845 - accuracy: 0.4623 - val_loss: 2.4833 - val_accuracy: 0.4729\n",
      "Epoch 601/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4713 - accuracy: 0.4601 - val_loss: 2.4932 - val_accuracy: 0.4715\n",
      "Epoch 602/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4807 - accuracy: 0.4578 - val_loss: 2.4913 - val_accuracy: 0.4769\n",
      "Epoch 603/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4700 - accuracy: 0.4628 - val_loss: 2.4821 - val_accuracy: 0.4760\n",
      "Epoch 604/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4707 - accuracy: 0.4630 - val_loss: 2.4885 - val_accuracy: 0.4740\n",
      "Epoch 605/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4752 - accuracy: 0.4611 - val_loss: 2.4870 - val_accuracy: 0.4792\n",
      "Epoch 606/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4774 - accuracy: 0.4608 - val_loss: 2.4829 - val_accuracy: 0.4777\n",
      "Epoch 607/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4646 - accuracy: 0.4627 - val_loss: 2.4879 - val_accuracy: 0.4717\n",
      "Epoch 608/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4774 - accuracy: 0.4582 - val_loss: 2.4824 - val_accuracy: 0.4777\n",
      "Epoch 609/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4734 - accuracy: 0.4622 - val_loss: 2.4810 - val_accuracy: 0.4752\n",
      "Epoch 610/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4692 - accuracy: 0.4634 - val_loss: 2.4897 - val_accuracy: 0.4726\n",
      "Epoch 611/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4712 - accuracy: 0.4611 - val_loss: 2.4897 - val_accuracy: 0.4748\n",
      "Epoch 612/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4663 - accuracy: 0.4616 - val_loss: 2.4873 - val_accuracy: 0.4761\n",
      "Epoch 613/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4767 - accuracy: 0.4606 - val_loss: 2.4967 - val_accuracy: 0.4753\n",
      "Epoch 614/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4824 - accuracy: 0.4630 - val_loss: 2.4858 - val_accuracy: 0.4717\n",
      "Epoch 615/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4740 - accuracy: 0.4592 - val_loss: 2.4893 - val_accuracy: 0.4753\n",
      "Epoch 616/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4796 - accuracy: 0.4597 - val_loss: 2.4908 - val_accuracy: 0.4734\n",
      "Epoch 617/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4738 - accuracy: 0.4629 - val_loss: 2.4861 - val_accuracy: 0.4706\n",
      "Epoch 618/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4706 - accuracy: 0.4590 - val_loss: 2.4853 - val_accuracy: 0.4790\n",
      "Epoch 619/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4728 - accuracy: 0.4629 - val_loss: 2.4871 - val_accuracy: 0.4776\n",
      "Epoch 620/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4686 - accuracy: 0.4637 - val_loss: 2.4872 - val_accuracy: 0.4732\n",
      "Epoch 621/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4679 - accuracy: 0.4605 - val_loss: 2.4946 - val_accuracy: 0.4763\n",
      "Epoch 622/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4834 - accuracy: 0.4598 - val_loss: 2.4905 - val_accuracy: 0.4793\n",
      "Epoch 623/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4610 - accuracy: 0.4675 - val_loss: 2.4808 - val_accuracy: 0.4761\n",
      "Epoch 624/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4682 - accuracy: 0.4597 - val_loss: 2.4810 - val_accuracy: 0.4762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4700 - accuracy: 0.4607 - val_loss: 2.4792 - val_accuracy: 0.4784\n",
      "Epoch 626/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4642 - accuracy: 0.4646 - val_loss: 2.4879 - val_accuracy: 0.4764\n",
      "Epoch 627/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4727 - accuracy: 0.4628 - val_loss: 2.4786 - val_accuracy: 0.4739\n",
      "Epoch 628/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4691 - accuracy: 0.4603 - val_loss: 2.4748 - val_accuracy: 0.4792\n",
      "Epoch 629/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4567 - accuracy: 0.4647 - val_loss: 2.4797 - val_accuracy: 0.4786\n",
      "Epoch 630/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4617 - accuracy: 0.4652 - val_loss: 2.4808 - val_accuracy: 0.4761\n",
      "Epoch 631/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4711 - accuracy: 0.4603 - val_loss: 2.4791 - val_accuracy: 0.4746\n",
      "Epoch 632/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4656 - accuracy: 0.4602 - val_loss: 2.4739 - val_accuracy: 0.4743\n",
      "Epoch 633/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4578 - accuracy: 0.4633 - val_loss: 2.4700 - val_accuracy: 0.4797\n",
      "Epoch 634/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4554 - accuracy: 0.4679 - val_loss: 2.4725 - val_accuracy: 0.4777\n",
      "Epoch 635/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4548 - accuracy: 0.4645 - val_loss: 2.4705 - val_accuracy: 0.4749\n",
      "Epoch 636/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4514 - accuracy: 0.4649 - val_loss: 2.4747 - val_accuracy: 0.4816\n",
      "Epoch 637/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4555 - accuracy: 0.4658 - val_loss: 2.4740 - val_accuracy: 0.4772\n",
      "Epoch 638/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4514 - accuracy: 0.4642 - val_loss: 2.4776 - val_accuracy: 0.4752\n",
      "Epoch 639/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4667 - accuracy: 0.4612 - val_loss: 2.4786 - val_accuracy: 0.4797\n",
      "Epoch 640/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4651 - accuracy: 0.4659 - val_loss: 2.4775 - val_accuracy: 0.4746\n",
      "Epoch 641/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4661 - accuracy: 0.4612 - val_loss: 2.4752 - val_accuracy: 0.4756\n",
      "Epoch 642/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4508 - accuracy: 0.4644 - val_loss: 2.4790 - val_accuracy: 0.4757\n",
      "Epoch 643/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4631 - accuracy: 0.4647 - val_loss: 2.4680 - val_accuracy: 0.4781\n",
      "Epoch 644/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4485 - accuracy: 0.4641 - val_loss: 2.4778 - val_accuracy: 0.4775\n",
      "Epoch 645/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4611 - accuracy: 0.4633 - val_loss: 2.4790 - val_accuracy: 0.4779\n",
      "Epoch 646/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4563 - accuracy: 0.4663 - val_loss: 2.4789 - val_accuracy: 0.4743\n",
      "Epoch 647/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4590 - accuracy: 0.4607 - val_loss: 2.4765 - val_accuracy: 0.4770\n",
      "Epoch 648/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4595 - accuracy: 0.4616 - val_loss: 2.4860 - val_accuracy: 0.4815\n",
      "Epoch 649/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4716 - accuracy: 0.4652 - val_loss: 2.4770 - val_accuracy: 0.4752\n",
      "Epoch 650/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4607 - accuracy: 0.4618 - val_loss: 2.4813 - val_accuracy: 0.4781\n",
      "Epoch 651/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4570 - accuracy: 0.4637 - val_loss: 2.4841 - val_accuracy: 0.4763\n",
      "Epoch 652/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4616 - accuracy: 0.4627 - val_loss: 2.4703 - val_accuracy: 0.4784\n",
      "Epoch 653/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4555 - accuracy: 0.4633 - val_loss: 2.4702 - val_accuracy: 0.4793\n",
      "Epoch 654/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4533 - accuracy: 0.4642 - val_loss: 2.4837 - val_accuracy: 0.4773\n",
      "Epoch 655/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4664 - accuracy: 0.4641 - val_loss: 2.4751 - val_accuracy: 0.4753\n",
      "Epoch 656/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4635 - accuracy: 0.4604 - val_loss: 2.4756 - val_accuracy: 0.4800\n",
      "Epoch 657/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4545 - accuracy: 0.4655 - val_loss: 2.4766 - val_accuracy: 0.4785\n",
      "Epoch 658/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4623 - accuracy: 0.4644 - val_loss: 2.4695 - val_accuracy: 0.4751\n",
      "Epoch 659/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4559 - accuracy: 0.4641 - val_loss: 2.4715 - val_accuracy: 0.4738\n",
      "Epoch 660/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4527 - accuracy: 0.4629 - val_loss: 2.4775 - val_accuracy: 0.4773\n",
      "Epoch 661/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4584 - accuracy: 0.4659 - val_loss: 2.4785 - val_accuracy: 0.4784\n",
      "Epoch 662/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4640 - accuracy: 0.4650 - val_loss: 2.4739 - val_accuracy: 0.4769\n",
      "Epoch 663/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4636 - accuracy: 0.4611 - val_loss: 2.4802 - val_accuracy: 0.4761\n",
      "Epoch 664/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4582 - accuracy: 0.4633 - val_loss: 2.4763 - val_accuracy: 0.4776\n",
      "Epoch 665/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4521 - accuracy: 0.4660 - val_loss: 2.4751 - val_accuracy: 0.4780\n",
      "Epoch 666/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4542 - accuracy: 0.4625 - val_loss: 2.4694 - val_accuracy: 0.4809\n",
      "Epoch 667/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4479 - accuracy: 0.4669 - val_loss: 2.4715 - val_accuracy: 0.4787\n",
      "Epoch 668/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4479 - accuracy: 0.4659 - val_loss: 2.4682 - val_accuracy: 0.4783\n",
      "Epoch 669/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4389 - accuracy: 0.4659 - val_loss: 2.4711 - val_accuracy: 0.4796\n",
      "Epoch 670/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4484 - accuracy: 0.4651 - val_loss: 2.4807 - val_accuracy: 0.4782\n",
      "Epoch 671/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4552 - accuracy: 0.4657 - val_loss: 2.4807 - val_accuracy: 0.4815\n",
      "Epoch 672/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4612 - accuracy: 0.4672 - val_loss: 2.4734 - val_accuracy: 0.4784\n",
      "Epoch 673/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4500 - accuracy: 0.4651 - val_loss: 2.4798 - val_accuracy: 0.4749\n",
      "Epoch 674/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4582 - accuracy: 0.4614 - val_loss: 2.4756 - val_accuracy: 0.4788\n",
      "Epoch 675/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4609 - accuracy: 0.4640 - val_loss: 2.4770 - val_accuracy: 0.4781\n",
      "Epoch 676/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4555 - accuracy: 0.4646 - val_loss: 2.4793 - val_accuracy: 0.4740\n",
      "Epoch 677/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4626 - accuracy: 0.4625 - val_loss: 2.4860 - val_accuracy: 0.4796\n",
      "Epoch 678/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4639 - accuracy: 0.4660 - val_loss: 2.4796 - val_accuracy: 0.4761\n",
      "Epoch 679/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4549 - accuracy: 0.4648 - val_loss: 2.4892 - val_accuracy: 0.4733\n",
      "Epoch 680/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4666 - accuracy: 0.4641 - val_loss: 2.4963 - val_accuracy: 0.4788\n",
      "Epoch 681/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4764 - accuracy: 0.4641 - val_loss: 2.4856 - val_accuracy: 0.4727\n",
      "Epoch 682/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4694 - accuracy: 0.4597 - val_loss: 2.4905 - val_accuracy: 0.4718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4725 - accuracy: 0.4619 - val_loss: 2.4819 - val_accuracy: 0.4743\n",
      "Epoch 684/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4646 - accuracy: 0.4607 - val_loss: 2.4881 - val_accuracy: 0.4746\n",
      "Epoch 685/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4715 - accuracy: 0.4615 - val_loss: 2.4805 - val_accuracy: 0.4767\n",
      "Epoch 686/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4586 - accuracy: 0.4657 - val_loss: 2.4775 - val_accuracy: 0.4723\n",
      "Epoch 687/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4592 - accuracy: 0.4605 - val_loss: 2.4775 - val_accuracy: 0.4749\n",
      "Epoch 688/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4512 - accuracy: 0.4631 - val_loss: 2.4764 - val_accuracy: 0.4828\n",
      "Epoch 689/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4470 - accuracy: 0.4698 - val_loss: 2.4652 - val_accuracy: 0.4824\n",
      "Epoch 690/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4432 - accuracy: 0.4694 - val_loss: 2.4651 - val_accuracy: 0.4737\n",
      "Epoch 691/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4547 - accuracy: 0.4604 - val_loss: 2.4636 - val_accuracy: 0.4773\n",
      "Epoch 692/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4476 - accuracy: 0.4664 - val_loss: 2.4732 - val_accuracy: 0.4830\n",
      "Epoch 693/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4461 - accuracy: 0.4692 - val_loss: 2.4744 - val_accuracy: 0.4749\n",
      "Epoch 694/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4620 - accuracy: 0.4622 - val_loss: 2.4712 - val_accuracy: 0.4745\n",
      "Epoch 695/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4520 - accuracy: 0.4625 - val_loss: 2.4730 - val_accuracy: 0.4740\n",
      "Epoch 696/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4501 - accuracy: 0.4647 - val_loss: 2.4743 - val_accuracy: 0.4775\n",
      "Epoch 697/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4409 - accuracy: 0.4673 - val_loss: 2.4772 - val_accuracy: 0.4748\n",
      "Epoch 698/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4487 - accuracy: 0.4637 - val_loss: 2.4654 - val_accuracy: 0.4788\n",
      "Epoch 699/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4383 - accuracy: 0.4678 - val_loss: 2.4661 - val_accuracy: 0.4763\n",
      "Epoch 700/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4474 - accuracy: 0.4656 - val_loss: 2.4628 - val_accuracy: 0.4757\n",
      "Epoch 701/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4401 - accuracy: 0.4654 - val_loss: 2.4692 - val_accuracy: 0.4795\n",
      "Epoch 702/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4426 - accuracy: 0.4669 - val_loss: 2.4647 - val_accuracy: 0.4795\n",
      "Epoch 703/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4451 - accuracy: 0.4672 - val_loss: 2.4636 - val_accuracy: 0.4800\n",
      "Epoch 704/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4397 - accuracy: 0.4679 - val_loss: 2.4661 - val_accuracy: 0.4744\n",
      "Epoch 705/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4477 - accuracy: 0.4634 - val_loss: 2.4609 - val_accuracy: 0.4780\n",
      "Epoch 706/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4338 - accuracy: 0.4672 - val_loss: 2.4749 - val_accuracy: 0.4769\n",
      "Epoch 707/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4407 - accuracy: 0.4665 - val_loss: 2.4639 - val_accuracy: 0.4795\n",
      "Epoch 708/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4309 - accuracy: 0.4687 - val_loss: 2.4657 - val_accuracy: 0.4802\n",
      "Epoch 709/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4458 - accuracy: 0.4670 - val_loss: 2.4677 - val_accuracy: 0.4763\n",
      "Epoch 710/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4455 - accuracy: 0.4645 - val_loss: 2.4719 - val_accuracy: 0.4791\n",
      "Epoch 711/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4410 - accuracy: 0.4663 - val_loss: 2.4669 - val_accuracy: 0.4798\n",
      "Epoch 712/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4380 - accuracy: 0.4677 - val_loss: 2.4666 - val_accuracy: 0.4781\n",
      "Epoch 713/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4419 - accuracy: 0.4645 - val_loss: 2.4660 - val_accuracy: 0.4810\n",
      "Epoch 714/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4437 - accuracy: 0.4673 - val_loss: 2.4719 - val_accuracy: 0.4746\n",
      "Epoch 715/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4536 - accuracy: 0.4607 - val_loss: 2.4721 - val_accuracy: 0.4771\n",
      "Epoch 716/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4451 - accuracy: 0.4662 - val_loss: 2.4705 - val_accuracy: 0.4801\n",
      "Epoch 717/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4476 - accuracy: 0.4674 - val_loss: 2.4644 - val_accuracy: 0.4797\n",
      "Epoch 718/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4474 - accuracy: 0.4639 - val_loss: 2.4830 - val_accuracy: 0.4793\n",
      "Epoch 719/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4580 - accuracy: 0.4660 - val_loss: 2.4762 - val_accuracy: 0.4715\n",
      "Epoch 720/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4426 - accuracy: 0.4636 - val_loss: 2.4755 - val_accuracy: 0.4734\n",
      "Epoch 721/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4487 - accuracy: 0.4625 - val_loss: 2.4755 - val_accuracy: 0.4815\n",
      "Epoch 722/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4430 - accuracy: 0.4704 - val_loss: 2.4639 - val_accuracy: 0.4787\n",
      "Epoch 723/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4401 - accuracy: 0.4655 - val_loss: 2.4654 - val_accuracy: 0.4770\n",
      "Epoch 724/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4481 - accuracy: 0.4642 - val_loss: 2.4692 - val_accuracy: 0.4824\n",
      "Epoch 725/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4502 - accuracy: 0.4660 - val_loss: 2.4645 - val_accuracy: 0.4774\n",
      "Epoch 726/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4480 - accuracy: 0.4638 - val_loss: 2.4675 - val_accuracy: 0.4774\n",
      "Epoch 727/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4480 - accuracy: 0.4628 - val_loss: 2.4738 - val_accuracy: 0.4787\n",
      "Epoch 728/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4421 - accuracy: 0.4673 - val_loss: 2.4778 - val_accuracy: 0.4784\n",
      "Epoch 729/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4457 - accuracy: 0.4674 - val_loss: 2.4637 - val_accuracy: 0.4791\n",
      "Epoch 730/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4439 - accuracy: 0.4641 - val_loss: 2.4737 - val_accuracy: 0.4749\n",
      "Epoch 731/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4457 - accuracy: 0.4638 - val_loss: 2.4681 - val_accuracy: 0.4777\n",
      "Epoch 732/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4404 - accuracy: 0.4679 - val_loss: 2.4645 - val_accuracy: 0.4803\n",
      "Epoch 733/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4405 - accuracy: 0.4670 - val_loss: 2.4757 - val_accuracy: 0.4780\n",
      "Epoch 734/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4460 - accuracy: 0.4627 - val_loss: 2.4728 - val_accuracy: 0.4792\n",
      "Epoch 735/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4499 - accuracy: 0.4651 - val_loss: 2.4795 - val_accuracy: 0.4794\n",
      "Epoch 736/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4522 - accuracy: 0.4660 - val_loss: 2.4845 - val_accuracy: 0.4821\n",
      "Epoch 737/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4626 - accuracy: 0.4664 - val_loss: 2.4698 - val_accuracy: 0.4746\n",
      "Epoch 738/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4476 - accuracy: 0.4631 - val_loss: 2.4788 - val_accuracy: 0.4787\n",
      "Epoch 739/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4465 - accuracy: 0.4660 - val_loss: 2.4807 - val_accuracy: 0.4797\n",
      "Epoch 740/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4544 - accuracy: 0.4673 - val_loss: 2.4672 - val_accuracy: 0.4792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4347 - accuracy: 0.4670 - val_loss: 2.4715 - val_accuracy: 0.4765\n",
      "Epoch 742/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4463 - accuracy: 0.4671 - val_loss: 2.4716 - val_accuracy: 0.4805\n",
      "Epoch 743/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4381 - accuracy: 0.4708 - val_loss: 2.4671 - val_accuracy: 0.4764\n",
      "Epoch 744/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4445 - accuracy: 0.4656 - val_loss: 2.4597 - val_accuracy: 0.4767\n",
      "Epoch 745/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4401 - accuracy: 0.4667 - val_loss: 2.4620 - val_accuracy: 0.4805\n",
      "Epoch 746/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4343 - accuracy: 0.4674 - val_loss: 2.4608 - val_accuracy: 0.4822\n",
      "Epoch 747/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4325 - accuracy: 0.4721 - val_loss: 2.4627 - val_accuracy: 0.4792\n",
      "Epoch 748/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4433 - accuracy: 0.4660 - val_loss: 2.4592 - val_accuracy: 0.4810\n",
      "Epoch 749/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4373 - accuracy: 0.4674 - val_loss: 2.4603 - val_accuracy: 0.4804\n",
      "Epoch 750/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4323 - accuracy: 0.4658 - val_loss: 2.4578 - val_accuracy: 0.4800\n",
      "Epoch 751/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4258 - accuracy: 0.4680 - val_loss: 2.4666 - val_accuracy: 0.4777\n",
      "Epoch 752/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4304 - accuracy: 0.4696 - val_loss: 2.4630 - val_accuracy: 0.4800\n",
      "Epoch 753/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4325 - accuracy: 0.4678 - val_loss: 2.4614 - val_accuracy: 0.4829\n",
      "Epoch 754/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4362 - accuracy: 0.4677 - val_loss: 2.4524 - val_accuracy: 0.4803\n",
      "Epoch 755/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4312 - accuracy: 0.4672 - val_loss: 2.4589 - val_accuracy: 0.4807\n",
      "Epoch 756/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4239 - accuracy: 0.4689 - val_loss: 2.4708 - val_accuracy: 0.4786\n",
      "Epoch 757/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4347 - accuracy: 0.4698 - val_loss: 2.4610 - val_accuracy: 0.4781\n",
      "Epoch 758/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4289 - accuracy: 0.4686 - val_loss: 2.4592 - val_accuracy: 0.4770\n",
      "Epoch 759/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4344 - accuracy: 0.4649 - val_loss: 2.4676 - val_accuracy: 0.4842\n",
      "Epoch 760/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4270 - accuracy: 0.4735 - val_loss: 2.4589 - val_accuracy: 0.4806\n",
      "Epoch 761/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4359 - accuracy: 0.4669 - val_loss: 2.4541 - val_accuracy: 0.4771\n",
      "Epoch 762/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4232 - accuracy: 0.4683 - val_loss: 2.4664 - val_accuracy: 0.4827\n",
      "Epoch 763/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4317 - accuracy: 0.4714 - val_loss: 2.4597 - val_accuracy: 0.4788\n",
      "Epoch 764/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4341 - accuracy: 0.4690 - val_loss: 2.4583 - val_accuracy: 0.4771\n",
      "Epoch 765/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4249 - accuracy: 0.4677 - val_loss: 2.4619 - val_accuracy: 0.4815\n",
      "Epoch 766/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4354 - accuracy: 0.4705 - val_loss: 2.4497 - val_accuracy: 0.4812\n",
      "Epoch 767/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4262 - accuracy: 0.4697 - val_loss: 2.4540 - val_accuracy: 0.4778\n",
      "Epoch 768/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4308 - accuracy: 0.4663 - val_loss: 2.4558 - val_accuracy: 0.4808\n",
      "Epoch 769/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4315 - accuracy: 0.4680 - val_loss: 2.4570 - val_accuracy: 0.4823\n",
      "Epoch 770/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4292 - accuracy: 0.4711 - val_loss: 2.4640 - val_accuracy: 0.4798\n",
      "Epoch 771/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4277 - accuracy: 0.4707 - val_loss: 2.4581 - val_accuracy: 0.4777\n",
      "Epoch 772/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4282 - accuracy: 0.4674 - val_loss: 2.4584 - val_accuracy: 0.4811\n",
      "Epoch 773/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4161 - accuracy: 0.4716 - val_loss: 2.4575 - val_accuracy: 0.4793\n",
      "Epoch 774/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4322 - accuracy: 0.4672 - val_loss: 2.4561 - val_accuracy: 0.4791\n",
      "Epoch 775/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4238 - accuracy: 0.4689 - val_loss: 2.4558 - val_accuracy: 0.4775\n",
      "Epoch 776/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4260 - accuracy: 0.4684 - val_loss: 2.4587 - val_accuracy: 0.4790\n",
      "Epoch 777/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4282 - accuracy: 0.4684 - val_loss: 2.4613 - val_accuracy: 0.4831\n",
      "Epoch 778/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4259 - accuracy: 0.4710 - val_loss: 2.4586 - val_accuracy: 0.4793\n",
      "Epoch 779/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4292 - accuracy: 0.4685 - val_loss: 2.4594 - val_accuracy: 0.4846\n",
      "Epoch 780/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4244 - accuracy: 0.4706 - val_loss: 2.4540 - val_accuracy: 0.4817\n",
      "Epoch 781/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4287 - accuracy: 0.4693 - val_loss: 2.4557 - val_accuracy: 0.4818\n",
      "Epoch 782/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4245 - accuracy: 0.4695 - val_loss: 2.4552 - val_accuracy: 0.4783\n",
      "Epoch 783/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4300 - accuracy: 0.4678 - val_loss: 2.4537 - val_accuracy: 0.4832\n",
      "Epoch 784/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4224 - accuracy: 0.4698 - val_loss: 2.4538 - val_accuracy: 0.4839\n",
      "Epoch 785/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4232 - accuracy: 0.4703 - val_loss: 2.4551 - val_accuracy: 0.4773\n",
      "Epoch 786/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4222 - accuracy: 0.4684 - val_loss: 2.4568 - val_accuracy: 0.4800\n",
      "Epoch 787/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4209 - accuracy: 0.4702 - val_loss: 2.4532 - val_accuracy: 0.4789\n",
      "Epoch 788/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4291 - accuracy: 0.4668 - val_loss: 2.4512 - val_accuracy: 0.4797\n",
      "Epoch 789/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4240 - accuracy: 0.4687 - val_loss: 2.4535 - val_accuracy: 0.4785\n",
      "Epoch 790/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4273 - accuracy: 0.4679 - val_loss: 2.4521 - val_accuracy: 0.4804\n",
      "Epoch 791/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4194 - accuracy: 0.4705 - val_loss: 2.4570 - val_accuracy: 0.4780\n",
      "Epoch 792/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4234 - accuracy: 0.4692 - val_loss: 2.4541 - val_accuracy: 0.4798\n",
      "Epoch 793/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4226 - accuracy: 0.4691 - val_loss: 2.4595 - val_accuracy: 0.4806\n",
      "Epoch 794/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4307 - accuracy: 0.4715 - val_loss: 2.4636 - val_accuracy: 0.4806\n",
      "Epoch 795/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4269 - accuracy: 0.4703 - val_loss: 2.4556 - val_accuracy: 0.4780\n",
      "Epoch 796/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4182 - accuracy: 0.4673 - val_loss: 2.4553 - val_accuracy: 0.4813\n",
      "Epoch 797/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4202 - accuracy: 0.4715 - val_loss: 2.4576 - val_accuracy: 0.4822\n",
      "Epoch 798/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4248 - accuracy: 0.4708 - val_loss: 2.4485 - val_accuracy: 0.4805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4181 - accuracy: 0.4701 - val_loss: 2.4559 - val_accuracy: 0.4787\n",
      "Epoch 800/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4266 - accuracy: 0.4686 - val_loss: 2.4573 - val_accuracy: 0.4807\n",
      "Epoch 801/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4227 - accuracy: 0.4699 - val_loss: 2.4585 - val_accuracy: 0.4786\n",
      "Epoch 802/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4271 - accuracy: 0.4684 - val_loss: 2.4519 - val_accuracy: 0.4784\n",
      "Epoch 803/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4215 - accuracy: 0.4685 - val_loss: 2.4549 - val_accuracy: 0.4809\n",
      "Epoch 804/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4208 - accuracy: 0.4707 - val_loss: 2.4542 - val_accuracy: 0.4830\n",
      "Epoch 805/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4249 - accuracy: 0.4710 - val_loss: 2.4490 - val_accuracy: 0.4803\n",
      "Epoch 806/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4212 - accuracy: 0.4702 - val_loss: 2.4557 - val_accuracy: 0.4815\n",
      "Epoch 807/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4171 - accuracy: 0.4712 - val_loss: 2.4596 - val_accuracy: 0.4817\n",
      "Epoch 808/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4220 - accuracy: 0.4723 - val_loss: 2.4595 - val_accuracy: 0.4753\n",
      "Epoch 809/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4251 - accuracy: 0.4661 - val_loss: 2.4623 - val_accuracy: 0.4835\n",
      "Epoch 810/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4234 - accuracy: 0.4718 - val_loss: 2.4563 - val_accuracy: 0.4800\n",
      "Epoch 811/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4225 - accuracy: 0.4698 - val_loss: 2.4519 - val_accuracy: 0.4805\n",
      "Epoch 812/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4170 - accuracy: 0.4704 - val_loss: 2.4584 - val_accuracy: 0.4791\n",
      "Epoch 813/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4209 - accuracy: 0.4703 - val_loss: 2.4532 - val_accuracy: 0.4796\n",
      "Epoch 814/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4256 - accuracy: 0.4691 - val_loss: 2.4617 - val_accuracy: 0.4794\n",
      "Epoch 815/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4286 - accuracy: 0.4684 - val_loss: 2.4627 - val_accuracy: 0.4834\n",
      "Epoch 816/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4250 - accuracy: 0.4715 - val_loss: 2.4544 - val_accuracy: 0.4815\n",
      "Epoch 817/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4273 - accuracy: 0.4690 - val_loss: 2.4547 - val_accuracy: 0.4829\n",
      "Epoch 818/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4269 - accuracy: 0.4683 - val_loss: 2.4643 - val_accuracy: 0.4809\n",
      "Epoch 819/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4237 - accuracy: 0.4704 - val_loss: 2.4627 - val_accuracy: 0.4820\n",
      "Epoch 820/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4274 - accuracy: 0.4692 - val_loss: 2.4529 - val_accuracy: 0.4779\n",
      "Epoch 821/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4263 - accuracy: 0.4653 - val_loss: 2.4547 - val_accuracy: 0.4823\n",
      "Epoch 822/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4250 - accuracy: 0.4702 - val_loss: 2.4572 - val_accuracy: 0.4839\n",
      "Epoch 823/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4278 - accuracy: 0.4727 - val_loss: 2.4573 - val_accuracy: 0.4791\n",
      "Epoch 824/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4245 - accuracy: 0.4672 - val_loss: 2.4529 - val_accuracy: 0.4821\n",
      "Epoch 825/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4157 - accuracy: 0.4713 - val_loss: 2.4588 - val_accuracy: 0.4821\n",
      "Epoch 826/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4217 - accuracy: 0.4716 - val_loss: 2.4512 - val_accuracy: 0.4774\n",
      "Epoch 827/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4230 - accuracy: 0.4668 - val_loss: 2.4654 - val_accuracy: 0.4853\n",
      "Epoch 828/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4286 - accuracy: 0.4719 - val_loss: 2.4545 - val_accuracy: 0.4798\n",
      "Epoch 829/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4120 - accuracy: 0.4726 - val_loss: 2.4572 - val_accuracy: 0.4787\n",
      "Epoch 830/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4279 - accuracy: 0.4685 - val_loss: 2.4565 - val_accuracy: 0.4815\n",
      "Epoch 831/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4249 - accuracy: 0.4722 - val_loss: 2.4570 - val_accuracy: 0.4800\n",
      "Epoch 832/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4106 - accuracy: 0.4728 - val_loss: 2.4667 - val_accuracy: 0.4797\n",
      "Epoch 833/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4215 - accuracy: 0.4701 - val_loss: 2.4575 - val_accuracy: 0.4826\n",
      "Epoch 834/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4318 - accuracy: 0.4694 - val_loss: 2.4523 - val_accuracy: 0.4805\n",
      "Epoch 835/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4207 - accuracy: 0.4695 - val_loss: 2.4666 - val_accuracy: 0.4763\n",
      "Epoch 836/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4281 - accuracy: 0.4668 - val_loss: 2.4609 - val_accuracy: 0.4781\n",
      "Epoch 837/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4189 - accuracy: 0.4687 - val_loss: 2.4607 - val_accuracy: 0.4807\n",
      "Epoch 838/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4240 - accuracy: 0.4698 - val_loss: 2.4618 - val_accuracy: 0.4837\n",
      "Epoch 839/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4256 - accuracy: 0.4722 - val_loss: 2.4644 - val_accuracy: 0.4792\n",
      "Epoch 840/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4316 - accuracy: 0.4684 - val_loss: 2.4618 - val_accuracy: 0.4814\n",
      "Epoch 841/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4328 - accuracy: 0.4683 - val_loss: 2.4523 - val_accuracy: 0.4821\n",
      "Epoch 842/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4131 - accuracy: 0.4725 - val_loss: 2.4690 - val_accuracy: 0.4823\n",
      "Epoch 843/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4410 - accuracy: 0.4693 - val_loss: 2.4655 - val_accuracy: 0.4817\n",
      "Epoch 844/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4424 - accuracy: 0.4686 - val_loss: 2.4657 - val_accuracy: 0.4731\n",
      "Epoch 845/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4323 - accuracy: 0.4645 - val_loss: 2.4713 - val_accuracy: 0.4776\n",
      "Epoch 846/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4298 - accuracy: 0.4702 - val_loss: 2.4734 - val_accuracy: 0.4830\n",
      "Epoch 847/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4394 - accuracy: 0.4711 - val_loss: 2.4585 - val_accuracy: 0.4800\n",
      "Epoch 848/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4232 - accuracy: 0.4713 - val_loss: 2.4622 - val_accuracy: 0.4784\n",
      "Epoch 849/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4237 - accuracy: 0.4676 - val_loss: 2.4553 - val_accuracy: 0.4833\n",
      "Epoch 850/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4179 - accuracy: 0.4735 - val_loss: 2.4482 - val_accuracy: 0.4808\n",
      "Epoch 851/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4232 - accuracy: 0.4693 - val_loss: 2.4539 - val_accuracy: 0.4814\n",
      "Epoch 852/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4209 - accuracy: 0.4714 - val_loss: 2.4699 - val_accuracy: 0.4823\n",
      "Epoch 853/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4220 - accuracy: 0.4711 - val_loss: 2.4549 - val_accuracy: 0.4769\n",
      "Epoch 854/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4231 - accuracy: 0.4664 - val_loss: 2.4678 - val_accuracy: 0.4821\n",
      "Epoch 855/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4215 - accuracy: 0.4730 - val_loss: 2.4611 - val_accuracy: 0.4786\n",
      "Epoch 856/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4220 - accuracy: 0.4705 - val_loss: 2.4530 - val_accuracy: 0.4775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 857/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4177 - accuracy: 0.4697 - val_loss: 2.4501 - val_accuracy: 0.4841\n",
      "Epoch 858/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4193 - accuracy: 0.4712 - val_loss: 2.4527 - val_accuracy: 0.4830\n",
      "Epoch 859/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4175 - accuracy: 0.4712 - val_loss: 2.4524 - val_accuracy: 0.4794\n",
      "Epoch 860/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4141 - accuracy: 0.4712 - val_loss: 2.4529 - val_accuracy: 0.4806\n",
      "Epoch 861/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4090 - accuracy: 0.4731 - val_loss: 2.4530 - val_accuracy: 0.4816\n",
      "Epoch 862/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4198 - accuracy: 0.4719 - val_loss: 2.4462 - val_accuracy: 0.4807\n",
      "Epoch 863/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4129 - accuracy: 0.4700 - val_loss: 2.4571 - val_accuracy: 0.4792\n",
      "Epoch 864/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4161 - accuracy: 0.4705 - val_loss: 2.4515 - val_accuracy: 0.4854\n",
      "Epoch 865/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4139 - accuracy: 0.4738 - val_loss: 2.4539 - val_accuracy: 0.4819\n",
      "Epoch 866/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4202 - accuracy: 0.4716 - val_loss: 2.4511 - val_accuracy: 0.4787\n",
      "Epoch 867/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4106 - accuracy: 0.4707 - val_loss: 2.4586 - val_accuracy: 0.4816\n",
      "Epoch 868/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4103 - accuracy: 0.4730 - val_loss: 2.4528 - val_accuracy: 0.4829\n",
      "Epoch 869/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4087 - accuracy: 0.4754 - val_loss: 2.4497 - val_accuracy: 0.4825\n",
      "Epoch 870/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4119 - accuracy: 0.4725 - val_loss: 2.4487 - val_accuracy: 0.4809\n",
      "Epoch 871/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4011 - accuracy: 0.4735 - val_loss: 2.4495 - val_accuracy: 0.4799\n",
      "Epoch 872/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4103 - accuracy: 0.4714 - val_loss: 2.4471 - val_accuracy: 0.4842\n",
      "Epoch 873/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4091 - accuracy: 0.4747 - val_loss: 2.4490 - val_accuracy: 0.4777\n",
      "Epoch 874/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4092 - accuracy: 0.4705 - val_loss: 2.4501 - val_accuracy: 0.4814\n",
      "Epoch 875/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4095 - accuracy: 0.4730 - val_loss: 2.4580 - val_accuracy: 0.4830\n",
      "Epoch 876/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4115 - accuracy: 0.4737 - val_loss: 2.4452 - val_accuracy: 0.4777\n",
      "Epoch 877/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4110 - accuracy: 0.4695 - val_loss: 2.4497 - val_accuracy: 0.4831\n",
      "Epoch 878/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4178 - accuracy: 0.4718 - val_loss: 2.4470 - val_accuracy: 0.4837\n",
      "Epoch 879/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4113 - accuracy: 0.4728 - val_loss: 2.4535 - val_accuracy: 0.4815\n",
      "Epoch 880/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4070 - accuracy: 0.4718 - val_loss: 2.4680 - val_accuracy: 0.4867\n",
      "Epoch 881/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4172 - accuracy: 0.4741 - val_loss: 2.4527 - val_accuracy: 0.4800\n",
      "Epoch 882/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4139 - accuracy: 0.4711 - val_loss: 2.4464 - val_accuracy: 0.4792\n",
      "Epoch 883/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4118 - accuracy: 0.4718 - val_loss: 2.4554 - val_accuracy: 0.4844\n",
      "Epoch 884/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4089 - accuracy: 0.4745 - val_loss: 2.4409 - val_accuracy: 0.4820\n",
      "Epoch 885/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4050 - accuracy: 0.4742 - val_loss: 2.4434 - val_accuracy: 0.4785\n",
      "Epoch 886/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4061 - accuracy: 0.4711 - val_loss: 2.4483 - val_accuracy: 0.4861\n",
      "Epoch 887/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4071 - accuracy: 0.4751 - val_loss: 2.4495 - val_accuracy: 0.4851\n",
      "Epoch 888/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3973 - accuracy: 0.4754 - val_loss: 2.4449 - val_accuracy: 0.4784\n",
      "Epoch 889/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4093 - accuracy: 0.4694 - val_loss: 2.4508 - val_accuracy: 0.4842\n",
      "Epoch 890/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4112 - accuracy: 0.4745 - val_loss: 2.4649 - val_accuracy: 0.4801\n",
      "Epoch 891/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4212 - accuracy: 0.4700 - val_loss: 2.4606 - val_accuracy: 0.4834\n",
      "Epoch 892/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4235 - accuracy: 0.4730 - val_loss: 2.4527 - val_accuracy: 0.4811\n",
      "Epoch 893/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4073 - accuracy: 0.4719 - val_loss: 2.4510 - val_accuracy: 0.4810\n",
      "Epoch 894/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4075 - accuracy: 0.4720 - val_loss: 2.4451 - val_accuracy: 0.4838\n",
      "Epoch 895/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4059 - accuracy: 0.4728 - val_loss: 2.4492 - val_accuracy: 0.4788\n",
      "Epoch 896/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4095 - accuracy: 0.4707 - val_loss: 2.4488 - val_accuracy: 0.4809\n",
      "Epoch 897/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4040 - accuracy: 0.4733 - val_loss: 2.4507 - val_accuracy: 0.4818\n",
      "Epoch 898/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4064 - accuracy: 0.4734 - val_loss: 2.4481 - val_accuracy: 0.4809\n",
      "Epoch 899/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4003 - accuracy: 0.4735 - val_loss: 2.4512 - val_accuracy: 0.4842\n",
      "Epoch 900/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4040 - accuracy: 0.4768 - val_loss: 2.4485 - val_accuracy: 0.4807\n",
      "Epoch 901/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4119 - accuracy: 0.4722 - val_loss: 2.4482 - val_accuracy: 0.4850\n",
      "Epoch 902/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4087 - accuracy: 0.4733 - val_loss: 2.4499 - val_accuracy: 0.4840\n",
      "Epoch 903/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4081 - accuracy: 0.4734 - val_loss: 2.4520 - val_accuracy: 0.4833\n",
      "Epoch 904/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4097 - accuracy: 0.4740 - val_loss: 2.4478 - val_accuracy: 0.4840\n",
      "Epoch 905/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4023 - accuracy: 0.4724 - val_loss: 2.4472 - val_accuracy: 0.4859\n",
      "Epoch 906/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4049 - accuracy: 0.4733 - val_loss: 2.4489 - val_accuracy: 0.4830\n",
      "Epoch 907/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4058 - accuracy: 0.4717 - val_loss: 2.4548 - val_accuracy: 0.4828\n",
      "Epoch 908/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4130 - accuracy: 0.4752 - val_loss: 2.4546 - val_accuracy: 0.4758\n",
      "Epoch 909/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4136 - accuracy: 0.4712 - val_loss: 2.4580 - val_accuracy: 0.4754\n",
      "Epoch 910/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4186 - accuracy: 0.4685 - val_loss: 2.4499 - val_accuracy: 0.4846\n",
      "Epoch 911/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4025 - accuracy: 0.4759 - val_loss: 2.4540 - val_accuracy: 0.4817\n",
      "Epoch 912/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4090 - accuracy: 0.4725 - val_loss: 2.4484 - val_accuracy: 0.4807\n",
      "Epoch 913/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4008 - accuracy: 0.4728 - val_loss: 2.4592 - val_accuracy: 0.4819\n",
      "Epoch 914/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4131 - accuracy: 0.4746 - val_loss: 2.4535 - val_accuracy: 0.4779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4103 - accuracy: 0.4711 - val_loss: 2.4603 - val_accuracy: 0.4857\n",
      "Epoch 916/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4182 - accuracy: 0.4733 - val_loss: 2.4537 - val_accuracy: 0.4808\n",
      "Epoch 917/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4213 - accuracy: 0.4693 - val_loss: 2.4536 - val_accuracy: 0.4785\n",
      "Epoch 918/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4070 - accuracy: 0.4700 - val_loss: 2.4567 - val_accuracy: 0.4790\n",
      "Epoch 919/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4145 - accuracy: 0.4705 - val_loss: 2.4587 - val_accuracy: 0.4830\n",
      "Epoch 920/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4120 - accuracy: 0.4721 - val_loss: 2.4532 - val_accuracy: 0.4838\n",
      "Epoch 921/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4076 - accuracy: 0.4711 - val_loss: 2.4543 - val_accuracy: 0.4876\n",
      "Epoch 922/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4141 - accuracy: 0.4740 - val_loss: 2.4449 - val_accuracy: 0.4815\n",
      "Epoch 923/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4116 - accuracy: 0.4702 - val_loss: 2.4521 - val_accuracy: 0.4827\n",
      "Epoch 924/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4162 - accuracy: 0.4705 - val_loss: 2.4609 - val_accuracy: 0.4798\n",
      "Epoch 925/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4107 - accuracy: 0.4719 - val_loss: 2.4570 - val_accuracy: 0.4801\n",
      "Epoch 926/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4132 - accuracy: 0.4713 - val_loss: 2.4505 - val_accuracy: 0.4822\n",
      "Epoch 927/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4164 - accuracy: 0.4696 - val_loss: 2.4550 - val_accuracy: 0.4835\n",
      "Epoch 928/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4043 - accuracy: 0.4739 - val_loss: 2.4545 - val_accuracy: 0.4847\n",
      "Epoch 929/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4066 - accuracy: 0.4747 - val_loss: 2.4514 - val_accuracy: 0.4785\n",
      "Epoch 930/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4082 - accuracy: 0.4694 - val_loss: 2.4565 - val_accuracy: 0.4834\n",
      "Epoch 931/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4075 - accuracy: 0.4737 - val_loss: 2.4572 - val_accuracy: 0.4842\n",
      "Epoch 932/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4124 - accuracy: 0.4729 - val_loss: 2.4522 - val_accuracy: 0.4811\n",
      "Epoch 933/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4052 - accuracy: 0.4710 - val_loss: 2.4503 - val_accuracy: 0.4833\n",
      "Epoch 934/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4118 - accuracy: 0.4737 - val_loss: 2.4511 - val_accuracy: 0.4859\n",
      "Epoch 935/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4068 - accuracy: 0.4743 - val_loss: 2.4417 - val_accuracy: 0.4846\n",
      "Epoch 936/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4072 - accuracy: 0.4723 - val_loss: 2.4514 - val_accuracy: 0.4841\n",
      "Epoch 937/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4081 - accuracy: 0.4749 - val_loss: 2.4620 - val_accuracy: 0.4806\n",
      "Epoch 938/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4201 - accuracy: 0.4707 - val_loss: 2.4423 - val_accuracy: 0.4835\n",
      "Epoch 939/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4059 - accuracy: 0.4734 - val_loss: 2.4467 - val_accuracy: 0.4833\n",
      "Epoch 940/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4075 - accuracy: 0.4724 - val_loss: 2.4483 - val_accuracy: 0.4825\n",
      "Epoch 941/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4138 - accuracy: 0.4713 - val_loss: 2.4588 - val_accuracy: 0.4837\n",
      "Epoch 942/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4195 - accuracy: 0.4732 - val_loss: 2.4514 - val_accuracy: 0.4811\n",
      "Epoch 943/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4034 - accuracy: 0.4722 - val_loss: 2.4544 - val_accuracy: 0.4825\n",
      "Epoch 944/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4012 - accuracy: 0.4738 - val_loss: 2.4532 - val_accuracy: 0.4840\n",
      "Epoch 945/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4201 - accuracy: 0.4724 - val_loss: 2.4385 - val_accuracy: 0.4849\n",
      "Epoch 946/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4015 - accuracy: 0.4728 - val_loss: 2.4516 - val_accuracy: 0.4834\n",
      "Epoch 947/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3992 - accuracy: 0.4760 - val_loss: 2.4462 - val_accuracy: 0.4845\n",
      "Epoch 948/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3959 - accuracy: 0.4771 - val_loss: 2.4402 - val_accuracy: 0.4829\n",
      "Epoch 949/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4002 - accuracy: 0.4756 - val_loss: 2.4473 - val_accuracy: 0.4814\n",
      "Epoch 950/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4076 - accuracy: 0.4721 - val_loss: 2.4600 - val_accuracy: 0.4873\n",
      "Epoch 951/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4173 - accuracy: 0.4744 - val_loss: 2.4520 - val_accuracy: 0.4784\n",
      "Epoch 952/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4161 - accuracy: 0.4699 - val_loss: 2.4529 - val_accuracy: 0.4775\n",
      "Epoch 953/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4033 - accuracy: 0.4715 - val_loss: 2.4555 - val_accuracy: 0.4852\n",
      "Epoch 954/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4120 - accuracy: 0.4757 - val_loss: 2.4439 - val_accuracy: 0.4815\n",
      "Epoch 955/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4092 - accuracy: 0.4715 - val_loss: 2.4567 - val_accuracy: 0.4778\n",
      "Epoch 956/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4109 - accuracy: 0.4714 - val_loss: 2.4504 - val_accuracy: 0.4830\n",
      "Epoch 957/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4033 - accuracy: 0.4749 - val_loss: 2.4493 - val_accuracy: 0.4817\n",
      "Epoch 958/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4079 - accuracy: 0.4733 - val_loss: 2.4516 - val_accuracy: 0.4803\n",
      "Epoch 959/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3987 - accuracy: 0.4740 - val_loss: 2.4569 - val_accuracy: 0.4791\n",
      "Epoch 960/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4068 - accuracy: 0.4718 - val_loss: 2.4602 - val_accuracy: 0.4793\n",
      "Epoch 961/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4060 - accuracy: 0.4729 - val_loss: 2.4482 - val_accuracy: 0.4821\n",
      "Epoch 962/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4045 - accuracy: 0.4738 - val_loss: 2.4497 - val_accuracy: 0.4865\n",
      "Epoch 963/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3962 - accuracy: 0.4776 - val_loss: 2.4462 - val_accuracy: 0.4825\n",
      "Epoch 964/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4007 - accuracy: 0.4743 - val_loss: 2.4416 - val_accuracy: 0.4823\n",
      "Epoch 965/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4069 - accuracy: 0.4708 - val_loss: 2.4485 - val_accuracy: 0.4875\n",
      "Epoch 966/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4002 - accuracy: 0.4756 - val_loss: 2.4504 - val_accuracy: 0.4838\n",
      "Epoch 967/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3980 - accuracy: 0.4761 - val_loss: 2.4535 - val_accuracy: 0.4813\n",
      "Epoch 968/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4050 - accuracy: 0.4716 - val_loss: 2.4453 - val_accuracy: 0.4874\n",
      "Epoch 969/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4010 - accuracy: 0.4746 - val_loss: 2.4418 - val_accuracy: 0.4845\n",
      "Epoch 970/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3970 - accuracy: 0.4768 - val_loss: 2.4414 - val_accuracy: 0.4829\n",
      "Epoch 971/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3955 - accuracy: 0.4723 - val_loss: 2.4497 - val_accuracy: 0.4845\n",
      "Epoch 972/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4019 - accuracy: 0.4749 - val_loss: 2.4460 - val_accuracy: 0.4845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4004 - accuracy: 0.4742 - val_loss: 2.4408 - val_accuracy: 0.4810\n",
      "Epoch 974/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4072 - accuracy: 0.4705 - val_loss: 2.4464 - val_accuracy: 0.4859\n",
      "Epoch 975/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4064 - accuracy: 0.4749 - val_loss: 2.4518 - val_accuracy: 0.4859\n",
      "Epoch 976/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3989 - accuracy: 0.4760 - val_loss: 2.4625 - val_accuracy: 0.4764\n",
      "Epoch 977/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4156 - accuracy: 0.4688 - val_loss: 2.4571 - val_accuracy: 0.4820\n",
      "Epoch 978/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4057 - accuracy: 0.4752 - val_loss: 2.4505 - val_accuracy: 0.4818\n",
      "Epoch 979/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3994 - accuracy: 0.4757 - val_loss: 2.4475 - val_accuracy: 0.4826\n",
      "Epoch 980/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4038 - accuracy: 0.4728 - val_loss: 2.4399 - val_accuracy: 0.4850\n",
      "Epoch 981/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3944 - accuracy: 0.4731 - val_loss: 2.4524 - val_accuracy: 0.4875\n",
      "Epoch 982/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4100 - accuracy: 0.4754 - val_loss: 2.4437 - val_accuracy: 0.4855\n",
      "Epoch 983/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4007 - accuracy: 0.4754 - val_loss: 2.4526 - val_accuracy: 0.4788\n",
      "Epoch 984/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4096 - accuracy: 0.4680 - val_loss: 2.4458 - val_accuracy: 0.4843\n",
      "Epoch 985/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3971 - accuracy: 0.4750 - val_loss: 2.4584 - val_accuracy: 0.4838\n",
      "Epoch 986/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4049 - accuracy: 0.4759 - val_loss: 2.4558 - val_accuracy: 0.4797\n",
      "Epoch 987/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4088 - accuracy: 0.4734 - val_loss: 2.4466 - val_accuracy: 0.4833\n",
      "Epoch 988/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4108 - accuracy: 0.4710 - val_loss: 2.4521 - val_accuracy: 0.4858\n",
      "Epoch 989/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4027 - accuracy: 0.4755 - val_loss: 2.4442 - val_accuracy: 0.4849\n",
      "Epoch 990/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4022 - accuracy: 0.4745 - val_loss: 2.4384 - val_accuracy: 0.4840\n",
      "Epoch 991/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4026 - accuracy: 0.4725 - val_loss: 2.4488 - val_accuracy: 0.4827\n",
      "Epoch 992/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4018 - accuracy: 0.4728 - val_loss: 2.4503 - val_accuracy: 0.4876\n",
      "Epoch 993/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4017 - accuracy: 0.4775 - val_loss: 2.4435 - val_accuracy: 0.4807\n",
      "Epoch 994/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3945 - accuracy: 0.4724 - val_loss: 2.4437 - val_accuracy: 0.4819\n",
      "Epoch 995/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3946 - accuracy: 0.4729 - val_loss: 2.4556 - val_accuracy: 0.4871\n",
      "Epoch 996/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4099 - accuracy: 0.4760 - val_loss: 2.4475 - val_accuracy: 0.4832\n",
      "Epoch 997/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4086 - accuracy: 0.4721 - val_loss: 2.4432 - val_accuracy: 0.4860\n",
      "Epoch 998/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4015 - accuracy: 0.4740 - val_loss: 2.4492 - val_accuracy: 0.4841\n",
      "Epoch 999/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3975 - accuracy: 0.4745 - val_loss: 2.4570 - val_accuracy: 0.4823\n",
      "Epoch 1000/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4048 - accuracy: 0.4750 - val_loss: 2.4498 - val_accuracy: 0.4804\n",
      "Epoch 1001/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4001 - accuracy: 0.4719 - val_loss: 2.4484 - val_accuracy: 0.4838\n",
      "Epoch 1002/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3924 - accuracy: 0.4762 - val_loss: 2.4516 - val_accuracy: 0.4829\n",
      "Epoch 1003/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3952 - accuracy: 0.4753 - val_loss: 2.4380 - val_accuracy: 0.4830\n",
      "Epoch 1004/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3993 - accuracy: 0.4727 - val_loss: 2.4373 - val_accuracy: 0.4852\n",
      "Epoch 1005/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4051 - accuracy: 0.4732 - val_loss: 2.4425 - val_accuracy: 0.4843\n",
      "Epoch 1006/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3920 - accuracy: 0.4765 - val_loss: 2.4498 - val_accuracy: 0.4820\n",
      "Epoch 1007/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3982 - accuracy: 0.4742 - val_loss: 2.4540 - val_accuracy: 0.4848\n",
      "Epoch 1008/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4052 - accuracy: 0.4742 - val_loss: 2.4636 - val_accuracy: 0.4807\n",
      "Epoch 1009/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4130 - accuracy: 0.4730 - val_loss: 2.4476 - val_accuracy: 0.4828\n",
      "Epoch 1010/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3991 - accuracy: 0.4744 - val_loss: 2.4502 - val_accuracy: 0.4838\n",
      "Epoch 1011/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4005 - accuracy: 0.4751 - val_loss: 2.4558 - val_accuracy: 0.4812\n",
      "Epoch 1012/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4108 - accuracy: 0.4708 - val_loss: 2.4500 - val_accuracy: 0.4854\n",
      "Epoch 1013/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4084 - accuracy: 0.4729 - val_loss: 2.4565 - val_accuracy: 0.4867\n",
      "Epoch 1014/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4044 - accuracy: 0.4753 - val_loss: 2.4535 - val_accuracy: 0.4804\n",
      "Epoch 1015/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3999 - accuracy: 0.4739 - val_loss: 2.4484 - val_accuracy: 0.4838\n",
      "Epoch 1016/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4114 - accuracy: 0.4703 - val_loss: 2.4484 - val_accuracy: 0.4846\n",
      "Epoch 1017/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4115 - accuracy: 0.4707 - val_loss: 2.4572 - val_accuracy: 0.4825\n",
      "Epoch 1018/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4018 - accuracy: 0.4742 - val_loss: 2.4458 - val_accuracy: 0.4857\n",
      "Epoch 1019/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3958 - accuracy: 0.4729 - val_loss: 2.4520 - val_accuracy: 0.4892\n",
      "Epoch 1020/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4016 - accuracy: 0.4740 - val_loss: 2.4442 - val_accuracy: 0.4847\n",
      "Epoch 1021/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3999 - accuracy: 0.4717 - val_loss: 2.4491 - val_accuracy: 0.4817\n",
      "Epoch 1022/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4053 - accuracy: 0.4716 - val_loss: 2.4492 - val_accuracy: 0.4841\n",
      "Epoch 1023/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4002 - accuracy: 0.4756 - val_loss: 2.4399 - val_accuracy: 0.4865\n",
      "Epoch 1024/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3949 - accuracy: 0.4748 - val_loss: 2.4486 - val_accuracy: 0.4840\n",
      "Epoch 1025/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4000 - accuracy: 0.4730 - val_loss: 2.4495 - val_accuracy: 0.4839\n",
      "Epoch 1026/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3991 - accuracy: 0.4750 - val_loss: 2.4473 - val_accuracy: 0.4851\n",
      "Epoch 1027/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4046 - accuracy: 0.4732 - val_loss: 2.4480 - val_accuracy: 0.4812\n",
      "Epoch 1028/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3985 - accuracy: 0.4737 - val_loss: 2.4581 - val_accuracy: 0.4848\n",
      "Epoch 1029/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4008 - accuracy: 0.4755 - val_loss: 2.4489 - val_accuracy: 0.4825\n",
      "Epoch 1030/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3960 - accuracy: 0.4745 - val_loss: 2.4415 - val_accuracy: 0.4816\n",
      "Epoch 1031/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4045 - accuracy: 0.4703 - val_loss: 2.4446 - val_accuracy: 0.4811\n",
      "Epoch 1032/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4131 - accuracy: 0.4727 - val_loss: 2.4659 - val_accuracy: 0.4877\n",
      "Epoch 1033/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4213 - accuracy: 0.4761 - val_loss: 2.4645 - val_accuracy: 0.4761\n",
      "Epoch 1034/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4144 - accuracy: 0.4689 - val_loss: 2.4505 - val_accuracy: 0.4811\n",
      "Epoch 1035/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4089 - accuracy: 0.4713 - val_loss: 2.4505 - val_accuracy: 0.4846\n",
      "Epoch 1036/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4103 - accuracy: 0.4738 - val_loss: 2.4521 - val_accuracy: 0.4833\n",
      "Epoch 1037/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4098 - accuracy: 0.4741 - val_loss: 2.4467 - val_accuracy: 0.4838\n",
      "Epoch 1038/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4004 - accuracy: 0.4748 - val_loss: 2.4511 - val_accuracy: 0.4817\n",
      "Epoch 1039/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4032 - accuracy: 0.4738 - val_loss: 2.4439 - val_accuracy: 0.4816\n",
      "Epoch 1040/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4012 - accuracy: 0.4746 - val_loss: 2.4437 - val_accuracy: 0.4825\n",
      "Epoch 1041/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4029 - accuracy: 0.4727 - val_loss: 2.4506 - val_accuracy: 0.4844\n",
      "Epoch 1042/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4016 - accuracy: 0.4759 - val_loss: 2.4466 - val_accuracy: 0.4830\n",
      "Epoch 1043/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3985 - accuracy: 0.4727 - val_loss: 2.4446 - val_accuracy: 0.4862\n",
      "Epoch 1044/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3969 - accuracy: 0.4755 - val_loss: 2.4491 - val_accuracy: 0.4861\n",
      "Epoch 1045/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3992 - accuracy: 0.4750 - val_loss: 2.4399 - val_accuracy: 0.4833\n",
      "Epoch 1046/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3971 - accuracy: 0.4750 - val_loss: 2.4396 - val_accuracy: 0.4845\n",
      "Epoch 1047/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3993 - accuracy: 0.4741 - val_loss: 2.4511 - val_accuracy: 0.4854\n",
      "Epoch 1048/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3982 - accuracy: 0.4759 - val_loss: 2.4448 - val_accuracy: 0.4796\n",
      "Epoch 1049/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3890 - accuracy: 0.4746 - val_loss: 2.4399 - val_accuracy: 0.4812\n",
      "Epoch 1050/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3904 - accuracy: 0.4726 - val_loss: 2.4458 - val_accuracy: 0.4891\n",
      "Epoch 1051/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3917 - accuracy: 0.4789 - val_loss: 2.4473 - val_accuracy: 0.4832\n",
      "Epoch 1052/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3930 - accuracy: 0.4783 - val_loss: 2.4444 - val_accuracy: 0.4781\n",
      "Epoch 1053/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4060 - accuracy: 0.4708 - val_loss: 2.4545 - val_accuracy: 0.4853\n",
      "Epoch 1054/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4017 - accuracy: 0.4758 - val_loss: 2.4494 - val_accuracy: 0.4801\n",
      "Epoch 1055/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4057 - accuracy: 0.4724 - val_loss: 2.4519 - val_accuracy: 0.4784\n",
      "Epoch 1056/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4124 - accuracy: 0.4682 - val_loss: 2.4512 - val_accuracy: 0.4896\n",
      "Epoch 1057/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4154 - accuracy: 0.4754 - val_loss: 2.4397 - val_accuracy: 0.4887\n",
      "Epoch 1058/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4069 - accuracy: 0.4750 - val_loss: 2.4564 - val_accuracy: 0.4794\n",
      "Epoch 1059/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4121 - accuracy: 0.4701 - val_loss: 2.4650 - val_accuracy: 0.4830\n",
      "Epoch 1060/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4156 - accuracy: 0.4730 - val_loss: 2.4545 - val_accuracy: 0.4811\n",
      "Epoch 1061/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4074 - accuracy: 0.4730 - val_loss: 2.4472 - val_accuracy: 0.4828\n",
      "Epoch 1062/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4068 - accuracy: 0.4725 - val_loss: 2.4526 - val_accuracy: 0.4848\n",
      "Epoch 1063/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4096 - accuracy: 0.4748 - val_loss: 2.4500 - val_accuracy: 0.4830\n",
      "Epoch 1064/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4032 - accuracy: 0.4732 - val_loss: 2.4504 - val_accuracy: 0.4871\n",
      "Epoch 1065/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4045 - accuracy: 0.4760 - val_loss: 2.4492 - val_accuracy: 0.4828\n",
      "Epoch 1066/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4069 - accuracy: 0.4717 - val_loss: 2.4552 - val_accuracy: 0.4816\n",
      "Epoch 1067/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4039 - accuracy: 0.4728 - val_loss: 2.4535 - val_accuracy: 0.4824\n",
      "Epoch 1068/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4001 - accuracy: 0.4766 - val_loss: 2.4397 - val_accuracy: 0.4840\n",
      "Epoch 1069/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3990 - accuracy: 0.4734 - val_loss: 2.4417 - val_accuracy: 0.4880\n",
      "Epoch 1070/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3977 - accuracy: 0.4784 - val_loss: 2.4487 - val_accuracy: 0.4826\n",
      "Epoch 1071/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4022 - accuracy: 0.4729 - val_loss: 2.4520 - val_accuracy: 0.4784\n",
      "Epoch 1072/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4092 - accuracy: 0.4701 - val_loss: 2.4462 - val_accuracy: 0.4903\n",
      "Epoch 1073/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3983 - accuracy: 0.4775 - val_loss: 2.4466 - val_accuracy: 0.4873\n",
      "Epoch 1074/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3966 - accuracy: 0.4753 - val_loss: 2.4407 - val_accuracy: 0.4823\n",
      "Epoch 1075/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4046 - accuracy: 0.4699 - val_loss: 2.4531 - val_accuracy: 0.4855\n",
      "Epoch 1076/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4079 - accuracy: 0.4747 - val_loss: 2.4506 - val_accuracy: 0.4838\n",
      "Epoch 1077/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3973 - accuracy: 0.4751 - val_loss: 2.4420 - val_accuracy: 0.4843\n",
      "Epoch 1078/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3931 - accuracy: 0.4741 - val_loss: 2.4367 - val_accuracy: 0.4859\n",
      "Epoch 1079/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3867 - accuracy: 0.4761 - val_loss: 2.4472 - val_accuracy: 0.4870\n",
      "Epoch 1080/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3964 - accuracy: 0.4779 - val_loss: 2.4385 - val_accuracy: 0.4844\n",
      "Epoch 1081/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3908 - accuracy: 0.4750 - val_loss: 2.4399 - val_accuracy: 0.4857\n",
      "Epoch 1082/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3918 - accuracy: 0.4748 - val_loss: 2.4471 - val_accuracy: 0.4874\n",
      "Epoch 1083/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3926 - accuracy: 0.4792 - val_loss: 2.4359 - val_accuracy: 0.4879\n",
      "Epoch 1084/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3860 - accuracy: 0.4764 - val_loss: 2.4470 - val_accuracy: 0.4860\n",
      "Epoch 1085/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3917 - accuracy: 0.4774 - val_loss: 2.4437 - val_accuracy: 0.4847\n",
      "Epoch 1086/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3999 - accuracy: 0.4726 - val_loss: 2.4450 - val_accuracy: 0.4818\n",
      "Epoch 1087/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 2.4057 - accuracy: 0.4724 - val_loss: 2.4463 - val_accuracy: 0.4873\n",
      "Epoch 1088/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3972 - accuracy: 0.4764 - val_loss: 2.4430 - val_accuracy: 0.4854\n",
      "Epoch 1089/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3906 - accuracy: 0.4758 - val_loss: 2.4429 - val_accuracy: 0.4806\n",
      "Epoch 1090/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3959 - accuracy: 0.4718 - val_loss: 2.4382 - val_accuracy: 0.4877\n",
      "Epoch 1091/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3928 - accuracy: 0.4762 - val_loss: 2.4419 - val_accuracy: 0.4892\n",
      "Epoch 1092/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3909 - accuracy: 0.4785 - val_loss: 2.4375 - val_accuracy: 0.4837\n",
      "Epoch 1093/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3870 - accuracy: 0.4740 - val_loss: 2.4427 - val_accuracy: 0.4857\n",
      "Epoch 1094/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3946 - accuracy: 0.4741 - val_loss: 2.4515 - val_accuracy: 0.4841\n",
      "Epoch 1095/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3949 - accuracy: 0.4761 - val_loss: 2.4482 - val_accuracy: 0.4838\n",
      "Epoch 1096/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4125 - accuracy: 0.4746 - val_loss: 2.4457 - val_accuracy: 0.4820\n",
      "Epoch 1097/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3940 - accuracy: 0.4758 - val_loss: 2.4522 - val_accuracy: 0.4806\n",
      "Epoch 1098/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3920 - accuracy: 0.4752 - val_loss: 2.4437 - val_accuracy: 0.4853\n",
      "Epoch 1099/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4029 - accuracy: 0.4742 - val_loss: 2.4348 - val_accuracy: 0.4871\n",
      "Epoch 1100/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3956 - accuracy: 0.4758 - val_loss: 2.4381 - val_accuracy: 0.4884\n",
      "Epoch 1101/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3897 - accuracy: 0.4771 - val_loss: 2.4446 - val_accuracy: 0.4863\n",
      "Epoch 1102/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3924 - accuracy: 0.4773 - val_loss: 2.4479 - val_accuracy: 0.4786\n",
      "Epoch 1103/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3977 - accuracy: 0.4730 - val_loss: 2.4504 - val_accuracy: 0.4874\n",
      "Epoch 1104/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3975 - accuracy: 0.4767 - val_loss: 2.4406 - val_accuracy: 0.4850\n",
      "Epoch 1105/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3867 - accuracy: 0.4756 - val_loss: 2.4365 - val_accuracy: 0.4836\n",
      "Epoch 1106/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3853 - accuracy: 0.4760 - val_loss: 2.4464 - val_accuracy: 0.4869\n",
      "Epoch 1107/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3941 - accuracy: 0.4795 - val_loss: 2.4479 - val_accuracy: 0.4844\n",
      "Epoch 1108/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3990 - accuracy: 0.4726 - val_loss: 2.4371 - val_accuracy: 0.4885\n",
      "Epoch 1109/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3883 - accuracy: 0.4762 - val_loss: 2.4378 - val_accuracy: 0.4849\n",
      "Epoch 1110/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3802 - accuracy: 0.4774 - val_loss: 2.4351 - val_accuracy: 0.4862\n",
      "Epoch 1111/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3834 - accuracy: 0.4773 - val_loss: 2.4373 - val_accuracy: 0.4849\n",
      "Epoch 1112/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3882 - accuracy: 0.4765 - val_loss: 2.4356 - val_accuracy: 0.4856\n",
      "Epoch 1113/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3815 - accuracy: 0.4773 - val_loss: 2.4415 - val_accuracy: 0.4878\n",
      "Epoch 1114/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3948 - accuracy: 0.4767 - val_loss: 2.4399 - val_accuracy: 0.4876\n",
      "Epoch 1115/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3959 - accuracy: 0.4760 - val_loss: 2.4458 - val_accuracy: 0.4849\n",
      "Epoch 1116/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3915 - accuracy: 0.4758 - val_loss: 2.4431 - val_accuracy: 0.4854\n",
      "Epoch 1117/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3920 - accuracy: 0.4769 - val_loss: 2.4382 - val_accuracy: 0.4863\n",
      "Epoch 1118/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3883 - accuracy: 0.4754 - val_loss: 2.4378 - val_accuracy: 0.4830\n",
      "Epoch 1119/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3945 - accuracy: 0.4728 - val_loss: 2.4470 - val_accuracy: 0.4890\n",
      "Epoch 1120/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3948 - accuracy: 0.4771 - val_loss: 2.4448 - val_accuracy: 0.4839\n",
      "Epoch 1121/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3897 - accuracy: 0.4761 - val_loss: 2.4410 - val_accuracy: 0.4809\n",
      "Epoch 1122/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3928 - accuracy: 0.4738 - val_loss: 2.4393 - val_accuracy: 0.4879\n",
      "Epoch 1123/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3884 - accuracy: 0.4769 - val_loss: 2.4459 - val_accuracy: 0.4849\n",
      "Epoch 1124/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3956 - accuracy: 0.4757 - val_loss: 2.4367 - val_accuracy: 0.4871\n",
      "Epoch 1125/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3871 - accuracy: 0.4751 - val_loss: 2.4386 - val_accuracy: 0.4848\n",
      "Epoch 1126/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3821 - accuracy: 0.4768 - val_loss: 2.4447 - val_accuracy: 0.4863\n",
      "Epoch 1127/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3853 - accuracy: 0.4789 - val_loss: 2.4335 - val_accuracy: 0.4868\n",
      "Epoch 1128/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3855 - accuracy: 0.4777 - val_loss: 2.4373 - val_accuracy: 0.4839\n",
      "Epoch 1129/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3859 - accuracy: 0.4748 - val_loss: 2.4486 - val_accuracy: 0.4882\n",
      "Epoch 1130/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3902 - accuracy: 0.4798 - val_loss: 2.4425 - val_accuracy: 0.4815\n",
      "Epoch 1131/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3864 - accuracy: 0.4733 - val_loss: 2.4401 - val_accuracy: 0.4838\n",
      "Epoch 1132/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3837 - accuracy: 0.4744 - val_loss: 2.4406 - val_accuracy: 0.4889\n",
      "Epoch 1133/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3843 - accuracy: 0.4799 - val_loss: 2.4332 - val_accuracy: 0.4823\n",
      "Epoch 1134/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3863 - accuracy: 0.4734 - val_loss: 2.4377 - val_accuracy: 0.4816\n",
      "Epoch 1135/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3887 - accuracy: 0.4753 - val_loss: 2.4452 - val_accuracy: 0.4897\n",
      "Epoch 1136/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3892 - accuracy: 0.4786 - val_loss: 2.4360 - val_accuracy: 0.4863\n",
      "Epoch 1137/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3816 - accuracy: 0.4764 - val_loss: 2.4350 - val_accuracy: 0.4863\n",
      "Epoch 1138/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3766 - accuracy: 0.4780 - val_loss: 2.4437 - val_accuracy: 0.4904\n",
      "Epoch 1139/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3903 - accuracy: 0.4796 - val_loss: 2.4428 - val_accuracy: 0.4844\n",
      "Epoch 1140/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3759 - accuracy: 0.4781 - val_loss: 2.4405 - val_accuracy: 0.4818\n",
      "Epoch 1141/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3861 - accuracy: 0.4744 - val_loss: 2.4443 - val_accuracy: 0.4884\n",
      "Epoch 1142/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3900 - accuracy: 0.4795 - val_loss: 2.4536 - val_accuracy: 0.4827\n",
      "Epoch 1143/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3941 - accuracy: 0.4771 - val_loss: 2.4462 - val_accuracy: 0.4814\n",
      "Epoch 1144/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4077 - accuracy: 0.4712 - val_loss: 2.4514 - val_accuracy: 0.4845\n",
      "Epoch 1145/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3872 - accuracy: 0.4777 - val_loss: 2.4497 - val_accuracy: 0.4853\n",
      "Epoch 1146/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3954 - accuracy: 0.4767 - val_loss: 2.4448 - val_accuracy: 0.4835\n",
      "Epoch 1147/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4034 - accuracy: 0.4739 - val_loss: 2.4544 - val_accuracy: 0.4864\n",
      "Epoch 1148/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4048 - accuracy: 0.4763 - val_loss: 2.4470 - val_accuracy: 0.4861\n",
      "Epoch 1149/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3906 - accuracy: 0.4766 - val_loss: 2.4539 - val_accuracy: 0.4845\n",
      "Epoch 1150/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4114 - accuracy: 0.4751 - val_loss: 2.4425 - val_accuracy: 0.4819\n",
      "Epoch 1151/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3946 - accuracy: 0.4753 - val_loss: 2.4496 - val_accuracy: 0.4843\n",
      "Epoch 1152/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3996 - accuracy: 0.4769 - val_loss: 2.4436 - val_accuracy: 0.4842\n",
      "Epoch 1153/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3984 - accuracy: 0.4750 - val_loss: 2.4425 - val_accuracy: 0.4824\n",
      "Epoch 1154/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3969 - accuracy: 0.4726 - val_loss: 2.4563 - val_accuracy: 0.4839\n",
      "Epoch 1155/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3992 - accuracy: 0.4759 - val_loss: 2.4511 - val_accuracy: 0.4862\n",
      "Epoch 1156/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3962 - accuracy: 0.4765 - val_loss: 2.4397 - val_accuracy: 0.4795\n",
      "Epoch 1157/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3968 - accuracy: 0.4714 - val_loss: 2.4420 - val_accuracy: 0.4838\n",
      "Epoch 1158/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3929 - accuracy: 0.4738 - val_loss: 2.4583 - val_accuracy: 0.4892\n",
      "Epoch 1159/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3986 - accuracy: 0.4780 - val_loss: 2.4437 - val_accuracy: 0.4769\n",
      "Epoch 1160/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3995 - accuracy: 0.4705 - val_loss: 2.4402 - val_accuracy: 0.4857\n",
      "Epoch 1161/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3930 - accuracy: 0.4737 - val_loss: 2.4560 - val_accuracy: 0.4896\n",
      "Epoch 1162/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3901 - accuracy: 0.4796 - val_loss: 2.4443 - val_accuracy: 0.4866\n",
      "Epoch 1163/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3775 - accuracy: 0.4790 - val_loss: 2.4432 - val_accuracy: 0.4844\n",
      "Epoch 1164/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3993 - accuracy: 0.4734 - val_loss: 2.4482 - val_accuracy: 0.4810\n",
      "Epoch 1165/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3971 - accuracy: 0.4727 - val_loss: 2.4401 - val_accuracy: 0.4876\n",
      "Epoch 1166/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3890 - accuracy: 0.4782 - val_loss: 2.4384 - val_accuracy: 0.4851\n",
      "Epoch 1167/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3911 - accuracy: 0.4741 - val_loss: 2.4381 - val_accuracy: 0.4805\n",
      "Epoch 1168/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3903 - accuracy: 0.4734 - val_loss: 2.4407 - val_accuracy: 0.4850\n",
      "Epoch 1169/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3916 - accuracy: 0.4764 - val_loss: 2.4334 - val_accuracy: 0.4864\n",
      "Epoch 1170/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3819 - accuracy: 0.4772 - val_loss: 2.4482 - val_accuracy: 0.4843\n",
      "Epoch 1171/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3997 - accuracy: 0.4756 - val_loss: 2.4465 - val_accuracy: 0.4882\n",
      "Epoch 1172/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3954 - accuracy: 0.4778 - val_loss: 2.4425 - val_accuracy: 0.4810\n",
      "Epoch 1173/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3855 - accuracy: 0.4744 - val_loss: 2.4523 - val_accuracy: 0.4818\n",
      "Epoch 1174/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3918 - accuracy: 0.4751 - val_loss: 2.4582 - val_accuracy: 0.4885\n",
      "Epoch 1175/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4098 - accuracy: 0.4766 - val_loss: 2.4441 - val_accuracy: 0.4843\n",
      "Epoch 1176/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3896 - accuracy: 0.4739 - val_loss: 2.4589 - val_accuracy: 0.4825\n",
      "Epoch 1177/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3987 - accuracy: 0.4753 - val_loss: 2.4511 - val_accuracy: 0.4844\n",
      "Epoch 1178/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3992 - accuracy: 0.4760 - val_loss: 2.4429 - val_accuracy: 0.4860\n",
      "Epoch 1179/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3905 - accuracy: 0.4763 - val_loss: 2.4664 - val_accuracy: 0.4816\n",
      "Epoch 1180/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3989 - accuracy: 0.4760 - val_loss: 2.4426 - val_accuracy: 0.4846\n",
      "Epoch 1181/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3856 - accuracy: 0.4777 - val_loss: 2.4376 - val_accuracy: 0.4875\n",
      "Epoch 1182/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3849 - accuracy: 0.4774 - val_loss: 2.4444 - val_accuracy: 0.4879\n",
      "Epoch 1183/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3926 - accuracy: 0.4754 - val_loss: 2.4488 - val_accuracy: 0.4889\n",
      "Epoch 1184/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3832 - accuracy: 0.4809 - val_loss: 2.4421 - val_accuracy: 0.4805\n",
      "Epoch 1185/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3864 - accuracy: 0.4731 - val_loss: 2.4433 - val_accuracy: 0.4837\n",
      "Epoch 1186/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3874 - accuracy: 0.4746 - val_loss: 2.4424 - val_accuracy: 0.4879\n",
      "Epoch 1187/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3827 - accuracy: 0.4796 - val_loss: 2.4385 - val_accuracy: 0.4820\n",
      "Epoch 1188/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3884 - accuracy: 0.4742 - val_loss: 2.4499 - val_accuracy: 0.4843\n",
      "Epoch 1189/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3902 - accuracy: 0.4775 - val_loss: 2.4358 - val_accuracy: 0.4860\n",
      "Epoch 1190/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3830 - accuracy: 0.4769 - val_loss: 2.4362 - val_accuracy: 0.4826\n",
      "Epoch 1191/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3941 - accuracy: 0.4721 - val_loss: 2.4438 - val_accuracy: 0.4888\n",
      "Epoch 1192/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3943 - accuracy: 0.4775 - val_loss: 2.4407 - val_accuracy: 0.4813\n",
      "Epoch 1193/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3905 - accuracy: 0.4735 - val_loss: 2.4539 - val_accuracy: 0.4833\n",
      "Epoch 1194/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3918 - accuracy: 0.4757 - val_loss: 2.4481 - val_accuracy: 0.4866\n",
      "Epoch 1195/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3883 - accuracy: 0.4747 - val_loss: 2.4325 - val_accuracy: 0.4879\n",
      "Epoch 1196/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3786 - accuracy: 0.4795 - val_loss: 2.4362 - val_accuracy: 0.4847\n",
      "Epoch 1197/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3899 - accuracy: 0.4758 - val_loss: 2.4455 - val_accuracy: 0.4811\n",
      "Epoch 1198/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3915 - accuracy: 0.4750 - val_loss: 2.4392 - val_accuracy: 0.4870\n",
      "Epoch 1199/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3901 - accuracy: 0.4754 - val_loss: 2.4410 - val_accuracy: 0.4880\n",
      "Epoch 1200/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3941 - accuracy: 0.4749 - val_loss: 2.4417 - val_accuracy: 0.4852\n",
      "Epoch 1201/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 2.3837 - accuracy: 0.4769 - val_loss: 2.4433 - val_accuracy: 0.4800\n",
      "Epoch 1202/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3950 - accuracy: 0.4729 - val_loss: 2.4401 - val_accuracy: 0.4869\n",
      "Epoch 1203/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3845 - accuracy: 0.4764 - val_loss: 2.4447 - val_accuracy: 0.4877\n",
      "Epoch 1204/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3811 - accuracy: 0.4791 - val_loss: 2.4371 - val_accuracy: 0.4863\n",
      "Epoch 1205/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3899 - accuracy: 0.4754 - val_loss: 2.4449 - val_accuracy: 0.4833\n",
      "Epoch 1206/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3901 - accuracy: 0.4739 - val_loss: 2.4415 - val_accuracy: 0.4881\n",
      "Epoch 1207/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3838 - accuracy: 0.4792 - val_loss: 2.4426 - val_accuracy: 0.4861\n",
      "Epoch 1208/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3959 - accuracy: 0.4757 - val_loss: 2.4339 - val_accuracy: 0.4860\n",
      "Epoch 1209/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3842 - accuracy: 0.4773 - val_loss: 2.4358 - val_accuracy: 0.4854\n",
      "Epoch 1210/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3803 - accuracy: 0.4775 - val_loss: 2.4399 - val_accuracy: 0.4838\n",
      "Epoch 1211/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3899 - accuracy: 0.4747 - val_loss: 2.4421 - val_accuracy: 0.4874\n",
      "Epoch 1212/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3858 - accuracy: 0.4784 - val_loss: 2.4379 - val_accuracy: 0.4837\n",
      "Epoch 1213/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3810 - accuracy: 0.4763 - val_loss: 2.4332 - val_accuracy: 0.4827\n",
      "Epoch 1214/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3815 - accuracy: 0.4757 - val_loss: 2.4409 - val_accuracy: 0.4894\n",
      "Epoch 1215/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3869 - accuracy: 0.4805 - val_loss: 2.4364 - val_accuracy: 0.4869\n",
      "Epoch 1216/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3858 - accuracy: 0.4775 - val_loss: 2.4319 - val_accuracy: 0.4833\n",
      "Epoch 1217/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3825 - accuracy: 0.4756 - val_loss: 2.4386 - val_accuracy: 0.4882\n",
      "Epoch 1218/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3812 - accuracy: 0.4773 - val_loss: 2.4428 - val_accuracy: 0.4863\n",
      "Epoch 1219/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3788 - accuracy: 0.4794 - val_loss: 2.4357 - val_accuracy: 0.4815\n",
      "Epoch 1220/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3837 - accuracy: 0.4766 - val_loss: 2.4352 - val_accuracy: 0.4860\n",
      "Epoch 1221/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3840 - accuracy: 0.4785 - val_loss: 2.4363 - val_accuracy: 0.4900\n",
      "Epoch 1222/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3848 - accuracy: 0.4780 - val_loss: 2.4375 - val_accuracy: 0.4857\n",
      "Epoch 1223/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3808 - accuracy: 0.4776 - val_loss: 2.4370 - val_accuracy: 0.4837\n",
      "Epoch 1224/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3867 - accuracy: 0.4743 - val_loss: 2.4417 - val_accuracy: 0.4884\n",
      "Epoch 1225/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3778 - accuracy: 0.4795 - val_loss: 2.4349 - val_accuracy: 0.4878\n",
      "Epoch 1226/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3809 - accuracy: 0.4792 - val_loss: 2.4291 - val_accuracy: 0.4839\n",
      "Epoch 1227/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3836 - accuracy: 0.4741 - val_loss: 2.4381 - val_accuracy: 0.4884\n",
      "Epoch 1228/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4792 - val_loss: 2.4389 - val_accuracy: 0.4878\n",
      "Epoch 1229/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3830 - accuracy: 0.4783 - val_loss: 2.4342 - val_accuracy: 0.4889\n",
      "Epoch 1230/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3755 - accuracy: 0.4786 - val_loss: 2.4368 - val_accuracy: 0.4891\n",
      "Epoch 1231/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3821 - accuracy: 0.4789 - val_loss: 2.4346 - val_accuracy: 0.4872\n",
      "Epoch 1232/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3843 - accuracy: 0.4770 - val_loss: 2.4318 - val_accuracy: 0.4854\n",
      "Epoch 1233/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3817 - accuracy: 0.4753 - val_loss: 2.4381 - val_accuracy: 0.4879\n",
      "Epoch 1234/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3822 - accuracy: 0.4789 - val_loss: 2.4486 - val_accuracy: 0.4805\n",
      "Epoch 1235/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3867 - accuracy: 0.4761 - val_loss: 2.4402 - val_accuracy: 0.4854\n",
      "Epoch 1236/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3851 - accuracy: 0.4778 - val_loss: 2.4412 - val_accuracy: 0.4855\n",
      "Epoch 1237/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3859 - accuracy: 0.4755 - val_loss: 2.4407 - val_accuracy: 0.4854\n",
      "Epoch 1238/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3781 - accuracy: 0.4782 - val_loss: 2.4310 - val_accuracy: 0.4843\n",
      "Epoch 1239/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3852 - accuracy: 0.4750 - val_loss: 2.4381 - val_accuracy: 0.4891\n",
      "Epoch 1240/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3775 - accuracy: 0.4820 - val_loss: 2.4331 - val_accuracy: 0.4882\n",
      "Epoch 1241/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3836 - accuracy: 0.4776 - val_loss: 2.4350 - val_accuracy: 0.4827\n",
      "Epoch 1242/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3843 - accuracy: 0.4746 - val_loss: 2.4423 - val_accuracy: 0.4879\n",
      "Epoch 1243/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3770 - accuracy: 0.4793 - val_loss: 2.4433 - val_accuracy: 0.4861\n",
      "Epoch 1244/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3780 - accuracy: 0.4790 - val_loss: 2.4329 - val_accuracy: 0.4833\n",
      "Epoch 1245/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3807 - accuracy: 0.4746 - val_loss: 2.4446 - val_accuracy: 0.4863\n",
      "Epoch 1246/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3889 - accuracy: 0.4768 - val_loss: 2.4384 - val_accuracy: 0.4867\n",
      "Epoch 1247/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3791 - accuracy: 0.4787 - val_loss: 2.4350 - val_accuracy: 0.4862\n",
      "Epoch 1248/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3881 - accuracy: 0.4749 - val_loss: 2.4386 - val_accuracy: 0.4874\n",
      "Epoch 1249/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3816 - accuracy: 0.4772 - val_loss: 2.4405 - val_accuracy: 0.4867\n",
      "Epoch 1250/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3800 - accuracy: 0.4793 - val_loss: 2.4372 - val_accuracy: 0.4846\n",
      "Epoch 1251/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3829 - accuracy: 0.4775 - val_loss: 2.4325 - val_accuracy: 0.4859\n",
      "Epoch 1252/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3819 - accuracy: 0.4767 - val_loss: 2.4381 - val_accuracy: 0.4896\n",
      "Epoch 1253/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3840 - accuracy: 0.4798 - val_loss: 2.4334 - val_accuracy: 0.4854\n",
      "Epoch 1254/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3772 - accuracy: 0.4784 - val_loss: 2.4377 - val_accuracy: 0.4823\n",
      "Epoch 1255/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3879 - accuracy: 0.4737 - val_loss: 2.4481 - val_accuracy: 0.4889\n",
      "Epoch 1256/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3791 - accuracy: 0.4799 - val_loss: 2.4362 - val_accuracy: 0.4840\n",
      "Epoch 1257/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3824 - accuracy: 0.4762 - val_loss: 2.4377 - val_accuracy: 0.4875\n",
      "Epoch 1258/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3864 - accuracy: 0.4783 - val_loss: 2.4279 - val_accuracy: 0.4870\n",
      "Epoch 1259/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3781 - accuracy: 0.4775 - val_loss: 2.4304 - val_accuracy: 0.4872\n",
      "Epoch 1260/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3830 - accuracy: 0.4769 - val_loss: 2.4469 - val_accuracy: 0.4882\n",
      "Epoch 1261/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3858 - accuracy: 0.4765 - val_loss: 2.4353 - val_accuracy: 0.4869\n",
      "Epoch 1262/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3731 - accuracy: 0.4777 - val_loss: 2.4387 - val_accuracy: 0.4834\n",
      "Epoch 1263/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3845 - accuracy: 0.4756 - val_loss: 2.4515 - val_accuracy: 0.4892\n",
      "Epoch 1264/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3809 - accuracy: 0.4799 - val_loss: 2.4409 - val_accuracy: 0.4812\n",
      "Epoch 1265/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3793 - accuracy: 0.4767 - val_loss: 2.4358 - val_accuracy: 0.4822\n",
      "Epoch 1266/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3829 - accuracy: 0.4734 - val_loss: 2.4452 - val_accuracy: 0.4906\n",
      "Epoch 1267/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3852 - accuracy: 0.4810 - val_loss: 2.4318 - val_accuracy: 0.4874\n",
      "Epoch 1268/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3777 - accuracy: 0.4768 - val_loss: 2.4349 - val_accuracy: 0.4823\n",
      "Epoch 1269/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3929 - accuracy: 0.4706 - val_loss: 2.4547 - val_accuracy: 0.4878\n",
      "Epoch 1270/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3840 - accuracy: 0.4813 - val_loss: 2.4432 - val_accuracy: 0.4850\n",
      "Epoch 1271/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3872 - accuracy: 0.4760 - val_loss: 2.4457 - val_accuracy: 0.4863\n",
      "Epoch 1272/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3999 - accuracy: 0.4755 - val_loss: 2.4450 - val_accuracy: 0.4884\n",
      "Epoch 1273/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3782 - accuracy: 0.4809 - val_loss: 2.4454 - val_accuracy: 0.4855\n",
      "Epoch 1274/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3847 - accuracy: 0.4776 - val_loss: 2.4387 - val_accuracy: 0.4851\n",
      "Epoch 1275/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3900 - accuracy: 0.4777 - val_loss: 2.4376 - val_accuracy: 0.4877\n",
      "Epoch 1276/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3859 - accuracy: 0.4792 - val_loss: 2.4462 - val_accuracy: 0.4879\n",
      "Epoch 1277/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3820 - accuracy: 0.4783 - val_loss: 2.4432 - val_accuracy: 0.4854\n",
      "Epoch 1278/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3887 - accuracy: 0.4760 - val_loss: 2.4457 - val_accuracy: 0.4835\n",
      "Epoch 1279/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3844 - accuracy: 0.4767 - val_loss: 2.4395 - val_accuracy: 0.4862\n",
      "Epoch 1280/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3727 - accuracy: 0.4794 - val_loss: 2.4439 - val_accuracy: 0.4872\n",
      "Epoch 1281/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3871 - accuracy: 0.4776 - val_loss: 2.4343 - val_accuracy: 0.4856\n",
      "Epoch 1282/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3799 - accuracy: 0.4773 - val_loss: 2.4444 - val_accuracy: 0.4877\n",
      "Epoch 1283/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3806 - accuracy: 0.4794 - val_loss: 2.4333 - val_accuracy: 0.4883\n",
      "Epoch 1284/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3777 - accuracy: 0.4802 - val_loss: 2.4373 - val_accuracy: 0.4829\n",
      "Epoch 1285/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3818 - accuracy: 0.4748 - val_loss: 2.4389 - val_accuracy: 0.4889\n",
      "Epoch 1286/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3875 - accuracy: 0.4781 - val_loss: 2.4357 - val_accuracy: 0.4869\n",
      "Epoch 1287/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3766 - accuracy: 0.4791 - val_loss: 2.4357 - val_accuracy: 0.4820\n",
      "Epoch 1288/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3773 - accuracy: 0.4754 - val_loss: 2.4425 - val_accuracy: 0.4891\n",
      "Epoch 1289/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3826 - accuracy: 0.4792 - val_loss: 2.4345 - val_accuracy: 0.4888\n",
      "Epoch 1290/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3733 - accuracy: 0.4791 - val_loss: 2.4387 - val_accuracy: 0.4826\n",
      "Epoch 1291/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3796 - accuracy: 0.4754 - val_loss: 2.4428 - val_accuracy: 0.4875\n",
      "Epoch 1292/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3825 - accuracy: 0.4797 - val_loss: 2.4383 - val_accuracy: 0.4859\n",
      "Epoch 1293/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3775 - accuracy: 0.4787 - val_loss: 2.4343 - val_accuracy: 0.4860\n",
      "Epoch 1294/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3701 - accuracy: 0.4805 - val_loss: 2.4342 - val_accuracy: 0.4851\n",
      "Epoch 1295/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3711 - accuracy: 0.4798 - val_loss: 2.4306 - val_accuracy: 0.4884\n",
      "Epoch 1296/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3722 - accuracy: 0.4790 - val_loss: 2.4377 - val_accuracy: 0.4882\n",
      "Epoch 1297/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4793 - val_loss: 2.4370 - val_accuracy: 0.4835\n",
      "Epoch 1298/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3757 - accuracy: 0.4755 - val_loss: 2.4343 - val_accuracy: 0.4872\n",
      "Epoch 1299/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3809 - accuracy: 0.4759 - val_loss: 2.4407 - val_accuracy: 0.4892\n",
      "Epoch 1300/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3874 - accuracy: 0.4773 - val_loss: 2.4377 - val_accuracy: 0.4838\n",
      "Epoch 1301/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4758 - val_loss: 2.4398 - val_accuracy: 0.4863\n",
      "Epoch 1302/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3805 - accuracy: 0.4757 - val_loss: 2.4412 - val_accuracy: 0.4903\n",
      "Epoch 1303/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3796 - accuracy: 0.4787 - val_loss: 2.4337 - val_accuracy: 0.4887\n",
      "Epoch 1304/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3823 - accuracy: 0.4761 - val_loss: 2.4371 - val_accuracy: 0.4865\n",
      "Epoch 1305/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3779 - accuracy: 0.4799 - val_loss: 2.4400 - val_accuracy: 0.4856\n",
      "Epoch 1306/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3811 - accuracy: 0.4776 - val_loss: 2.4337 - val_accuracy: 0.4865\n",
      "Epoch 1307/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3842 - accuracy: 0.4763 - val_loss: 2.4362 - val_accuracy: 0.4875\n",
      "Epoch 1308/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3769 - accuracy: 0.4778 - val_loss: 2.4360 - val_accuracy: 0.4860\n",
      "Epoch 1309/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3752 - accuracy: 0.4774 - val_loss: 2.4287 - val_accuracy: 0.4857\n",
      "Epoch 1310/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3836 - accuracy: 0.4768 - val_loss: 2.4287 - val_accuracy: 0.4892\n",
      "Epoch 1311/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3698 - accuracy: 0.4811 - val_loss: 2.4293 - val_accuracy: 0.4892\n",
      "Epoch 1312/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3747 - accuracy: 0.4790 - val_loss: 2.4356 - val_accuracy: 0.4886\n",
      "Epoch 1313/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3800 - accuracy: 0.4793 - val_loss: 2.4408 - val_accuracy: 0.4836\n",
      "Epoch 1314/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3813 - accuracy: 0.4763 - val_loss: 2.4362 - val_accuracy: 0.4890\n",
      "Epoch 1315/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 2.3710 - accuracy: 0.4813 - val_loss: 2.4349 - val_accuracy: 0.4884\n",
      "Epoch 1316/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3778 - accuracy: 0.4778 - val_loss: 2.4309 - val_accuracy: 0.4862\n",
      "Epoch 1317/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3746 - accuracy: 0.4774 - val_loss: 2.4375 - val_accuracy: 0.4873\n",
      "Epoch 1318/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3749 - accuracy: 0.4780 - val_loss: 2.4429 - val_accuracy: 0.4871\n",
      "Epoch 1319/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3737 - accuracy: 0.4800 - val_loss: 2.4341 - val_accuracy: 0.4862\n",
      "Epoch 1320/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3755 - accuracy: 0.4772 - val_loss: 2.4386 - val_accuracy: 0.4913\n",
      "Epoch 1321/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3791 - accuracy: 0.4799 - val_loss: 2.4293 - val_accuracy: 0.4879\n",
      "Epoch 1322/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3745 - accuracy: 0.4795 - val_loss: 2.4396 - val_accuracy: 0.4856\n",
      "Epoch 1323/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3810 - accuracy: 0.4770 - val_loss: 2.4501 - val_accuracy: 0.4916\n",
      "Epoch 1324/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3882 - accuracy: 0.4808 - val_loss: 2.4404 - val_accuracy: 0.4826\n",
      "Epoch 1325/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3850 - accuracy: 0.4745 - val_loss: 2.4444 - val_accuracy: 0.4830\n",
      "Epoch 1326/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3884 - accuracy: 0.4758 - val_loss: 2.4408 - val_accuracy: 0.4904\n",
      "Epoch 1327/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3776 - accuracy: 0.4814 - val_loss: 2.4386 - val_accuracy: 0.4837\n",
      "Epoch 1328/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3848 - accuracy: 0.4757 - val_loss: 2.4297 - val_accuracy: 0.4854\n",
      "Epoch 1329/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3750 - accuracy: 0.4771 - val_loss: 2.4417 - val_accuracy: 0.4877\n",
      "Epoch 1330/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3882 - accuracy: 0.4788 - val_loss: 2.4314 - val_accuracy: 0.4861\n",
      "Epoch 1331/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3787 - accuracy: 0.4772 - val_loss: 2.4406 - val_accuracy: 0.4826\n",
      "Epoch 1332/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3952 - accuracy: 0.4715 - val_loss: 2.4447 - val_accuracy: 0.4892\n",
      "Epoch 1333/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3870 - accuracy: 0.4777 - val_loss: 2.4484 - val_accuracy: 0.4872\n",
      "Epoch 1334/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3982 - accuracy: 0.4769 - val_loss: 2.4384 - val_accuracy: 0.4855\n",
      "Epoch 1335/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3965 - accuracy: 0.4730 - val_loss: 2.4509 - val_accuracy: 0.4880\n",
      "Epoch 1336/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3953 - accuracy: 0.4778 - val_loss: 2.4377 - val_accuracy: 0.4830\n",
      "Epoch 1337/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3878 - accuracy: 0.4732 - val_loss: 2.4420 - val_accuracy: 0.4830\n",
      "Epoch 1338/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3920 - accuracy: 0.4749 - val_loss: 2.4510 - val_accuracy: 0.4877\n",
      "Epoch 1339/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3872 - accuracy: 0.4777 - val_loss: 2.4311 - val_accuracy: 0.4853\n",
      "Epoch 1340/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3853 - accuracy: 0.4744 - val_loss: 2.4354 - val_accuracy: 0.4833\n",
      "Epoch 1341/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3802 - accuracy: 0.4765 - val_loss: 2.4439 - val_accuracy: 0.4866\n",
      "Epoch 1342/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3787 - accuracy: 0.4805 - val_loss: 2.4354 - val_accuracy: 0.4893\n",
      "Epoch 1343/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3881 - accuracy: 0.4767 - val_loss: 2.4285 - val_accuracy: 0.4868\n",
      "Epoch 1344/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3731 - accuracy: 0.4784 - val_loss: 2.4405 - val_accuracy: 0.4895\n",
      "Epoch 1345/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3832 - accuracy: 0.4798 - val_loss: 2.4322 - val_accuracy: 0.4870\n",
      "Epoch 1346/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3816 - accuracy: 0.4772 - val_loss: 2.4357 - val_accuracy: 0.4865\n",
      "Epoch 1347/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3685 - accuracy: 0.4792 - val_loss: 2.4395 - val_accuracy: 0.4854\n",
      "Epoch 1348/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3838 - accuracy: 0.4760 - val_loss: 2.4305 - val_accuracy: 0.4884\n",
      "Epoch 1349/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3735 - accuracy: 0.4790 - val_loss: 2.4352 - val_accuracy: 0.4858\n",
      "Epoch 1350/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3831 - accuracy: 0.4757 - val_loss: 2.4453 - val_accuracy: 0.4926\n",
      "Epoch 1351/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3862 - accuracy: 0.4825 - val_loss: 2.4329 - val_accuracy: 0.4876\n",
      "Epoch 1352/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3794 - accuracy: 0.4754 - val_loss: 2.4280 - val_accuracy: 0.4869\n",
      "Epoch 1353/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3736 - accuracy: 0.4773 - val_loss: 2.4357 - val_accuracy: 0.4924\n",
      "Epoch 1354/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3824 - accuracy: 0.4794 - val_loss: 2.4320 - val_accuracy: 0.4861\n",
      "Epoch 1355/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3732 - accuracy: 0.4776 - val_loss: 2.4342 - val_accuracy: 0.4868\n",
      "Epoch 1356/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3762 - accuracy: 0.4783 - val_loss: 2.4332 - val_accuracy: 0.4885\n",
      "Epoch 1357/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3748 - accuracy: 0.4798 - val_loss: 2.4341 - val_accuracy: 0.4861\n",
      "Epoch 1358/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3860 - accuracy: 0.4750 - val_loss: 2.4281 - val_accuracy: 0.4878\n",
      "Epoch 1359/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3664 - accuracy: 0.4790 - val_loss: 2.4341 - val_accuracy: 0.4877\n",
      "Epoch 1360/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3717 - accuracy: 0.4784 - val_loss: 2.4272 - val_accuracy: 0.4902\n",
      "Epoch 1361/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3702 - accuracy: 0.4801 - val_loss: 2.4264 - val_accuracy: 0.4882\n",
      "Epoch 1362/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3689 - accuracy: 0.4795 - val_loss: 2.4229 - val_accuracy: 0.4918\n",
      "Epoch 1363/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3738 - accuracy: 0.4810 - val_loss: 2.4289 - val_accuracy: 0.4865\n",
      "Epoch 1364/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3764 - accuracy: 0.4780 - val_loss: 2.4388 - val_accuracy: 0.4872\n",
      "Epoch 1365/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3817 - accuracy: 0.4794 - val_loss: 2.4294 - val_accuracy: 0.4878\n",
      "Epoch 1366/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3719 - accuracy: 0.4779 - val_loss: 2.4289 - val_accuracy: 0.4922\n",
      "Epoch 1367/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3654 - accuracy: 0.4818 - val_loss: 2.4288 - val_accuracy: 0.4883\n",
      "Epoch 1368/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3652 - accuracy: 0.4803 - val_loss: 2.4323 - val_accuracy: 0.4862\n",
      "Epoch 1369/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3713 - accuracy: 0.4767 - val_loss: 2.4320 - val_accuracy: 0.4878\n",
      "Epoch 1370/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3717 - accuracy: 0.4797 - val_loss: 2.4316 - val_accuracy: 0.4889\n",
      "Epoch 1371/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3727 - accuracy: 0.4792 - val_loss: 2.4371 - val_accuracy: 0.4874\n",
      "Epoch 1372/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3734 - accuracy: 0.4778 - val_loss: 2.4406 - val_accuracy: 0.4914\n",
      "Epoch 1373/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3793 - accuracy: 0.4820 - val_loss: 2.4420 - val_accuracy: 0.4833\n",
      "Epoch 1374/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3766 - accuracy: 0.4777 - val_loss: 2.4361 - val_accuracy: 0.4866\n",
      "Epoch 1375/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3775 - accuracy: 0.4779 - val_loss: 2.4315 - val_accuracy: 0.4867\n",
      "Epoch 1376/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3747 - accuracy: 0.4802 - val_loss: 2.4299 - val_accuracy: 0.4861\n",
      "Epoch 1377/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3683 - accuracy: 0.4771 - val_loss: 2.4316 - val_accuracy: 0.4857\n",
      "Epoch 1378/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3840 - accuracy: 0.4746 - val_loss: 2.4353 - val_accuracy: 0.4914\n",
      "Epoch 1379/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3747 - accuracy: 0.4804 - val_loss: 2.4425 - val_accuracy: 0.4839\n",
      "Epoch 1380/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3796 - accuracy: 0.4771 - val_loss: 2.4393 - val_accuracy: 0.4861\n",
      "Epoch 1381/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3789 - accuracy: 0.4783 - val_loss: 2.4417 - val_accuracy: 0.4844\n",
      "Epoch 1382/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3781 - accuracy: 0.4763 - val_loss: 2.4405 - val_accuracy: 0.4887\n",
      "Epoch 1383/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3749 - accuracy: 0.4802 - val_loss: 2.4326 - val_accuracy: 0.4882\n",
      "Epoch 1384/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3842 - accuracy: 0.4767 - val_loss: 2.4266 - val_accuracy: 0.4889\n",
      "Epoch 1385/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3771 - accuracy: 0.4773 - val_loss: 2.4378 - val_accuracy: 0.4886\n",
      "Epoch 1386/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3877 - accuracy: 0.4786 - val_loss: 2.4256 - val_accuracy: 0.4856\n",
      "Epoch 1387/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3719 - accuracy: 0.4797 - val_loss: 2.4343 - val_accuracy: 0.4871\n",
      "Epoch 1388/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3722 - accuracy: 0.4785 - val_loss: 2.4328 - val_accuracy: 0.4895\n",
      "Epoch 1389/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3714 - accuracy: 0.4819 - val_loss: 2.4358 - val_accuracy: 0.4864\n",
      "Epoch 1390/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3742 - accuracy: 0.4770 - val_loss: 2.4329 - val_accuracy: 0.4879\n",
      "Epoch 1391/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3685 - accuracy: 0.4792 - val_loss: 2.4279 - val_accuracy: 0.4861\n",
      "Epoch 1392/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3674 - accuracy: 0.4785 - val_loss: 2.4266 - val_accuracy: 0.4880\n",
      "Epoch 1393/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3675 - accuracy: 0.4792 - val_loss: 2.4328 - val_accuracy: 0.4902\n",
      "Epoch 1394/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3749 - accuracy: 0.4811 - val_loss: 2.4273 - val_accuracy: 0.4875\n",
      "Epoch 1395/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3756 - accuracy: 0.4791 - val_loss: 2.4230 - val_accuracy: 0.4894\n",
      "Epoch 1396/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3728 - accuracy: 0.4771 - val_loss: 2.4293 - val_accuracy: 0.4915\n",
      "Epoch 1397/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3699 - accuracy: 0.4819 - val_loss: 2.4340 - val_accuracy: 0.4844\n",
      "Epoch 1398/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3677 - accuracy: 0.4779 - val_loss: 2.4296 - val_accuracy: 0.4869\n",
      "Epoch 1399/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3716 - accuracy: 0.4784 - val_loss: 2.4324 - val_accuracy: 0.4887\n",
      "Epoch 1400/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3692 - accuracy: 0.4808 - val_loss: 2.4288 - val_accuracy: 0.4850\n",
      "Epoch 1401/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3702 - accuracy: 0.4764 - val_loss: 2.4290 - val_accuracy: 0.4891\n",
      "Epoch 1402/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3754 - accuracy: 0.4787 - val_loss: 2.4306 - val_accuracy: 0.4915\n",
      "Epoch 1403/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3744 - accuracy: 0.4787 - val_loss: 2.4270 - val_accuracy: 0.4881\n",
      "Epoch 1404/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3704 - accuracy: 0.4792 - val_loss: 2.4282 - val_accuracy: 0.4922\n",
      "Epoch 1405/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3728 - accuracy: 0.4808 - val_loss: 2.4275 - val_accuracy: 0.4879\n",
      "Epoch 1406/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3689 - accuracy: 0.4787 - val_loss: 2.4304 - val_accuracy: 0.4866\n",
      "Epoch 1407/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3679 - accuracy: 0.4800 - val_loss: 2.4337 - val_accuracy: 0.4913\n",
      "Epoch 1408/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3622 - accuracy: 0.4837 - val_loss: 2.4270 - val_accuracy: 0.4883\n",
      "Epoch 1409/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3686 - accuracy: 0.4780 - val_loss: 2.4225 - val_accuracy: 0.4901\n",
      "Epoch 1410/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3714 - accuracy: 0.4774 - val_loss: 2.4381 - val_accuracy: 0.4882\n",
      "Epoch 1411/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3702 - accuracy: 0.4819 - val_loss: 2.4354 - val_accuracy: 0.4816\n",
      "Epoch 1412/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3746 - accuracy: 0.4763 - val_loss: 2.4394 - val_accuracy: 0.4888\n",
      "Epoch 1413/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3815 - accuracy: 0.4796 - val_loss: 2.4440 - val_accuracy: 0.4868\n",
      "Epoch 1414/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3752 - accuracy: 0.4791 - val_loss: 2.4343 - val_accuracy: 0.4844\n",
      "Epoch 1415/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3891 - accuracy: 0.4743 - val_loss: 2.4239 - val_accuracy: 0.4898\n",
      "Epoch 1416/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3735 - accuracy: 0.4775 - val_loss: 2.4435 - val_accuracy: 0.4919\n",
      "Epoch 1417/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3872 - accuracy: 0.4793 - val_loss: 2.4302 - val_accuracy: 0.4888\n",
      "Epoch 1418/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3819 - accuracy: 0.4774 - val_loss: 2.4404 - val_accuracy: 0.4837\n",
      "Epoch 1419/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3852 - accuracy: 0.4757 - val_loss: 2.4381 - val_accuracy: 0.4890\n",
      "Epoch 1420/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3760 - accuracy: 0.4812 - val_loss: 2.4360 - val_accuracy: 0.4867\n",
      "Epoch 1421/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3893 - accuracy: 0.4774 - val_loss: 2.4395 - val_accuracy: 0.4853\n",
      "Epoch 1422/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3785 - accuracy: 0.4790 - val_loss: 2.4345 - val_accuracy: 0.4873\n",
      "Epoch 1423/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3705 - accuracy: 0.4795 - val_loss: 2.4292 - val_accuracy: 0.4878\n",
      "Epoch 1424/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3722 - accuracy: 0.4785 - val_loss: 2.4295 - val_accuracy: 0.4915\n",
      "Epoch 1425/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3721 - accuracy: 0.4792 - val_loss: 2.4307 - val_accuracy: 0.4893\n",
      "Epoch 1426/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3776 - accuracy: 0.4790 - val_loss: 2.4279 - val_accuracy: 0.4893\n",
      "Epoch 1427/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3801 - accuracy: 0.4759 - val_loss: 2.4284 - val_accuracy: 0.4907\n",
      "Epoch 1428/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3749 - accuracy: 0.4794 - val_loss: 2.4397 - val_accuracy: 0.4892\n",
      "Epoch 1429/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 2.3793 - accuracy: 0.4792 - val_loss: 2.4307 - val_accuracy: 0.4870\n",
      "Epoch 1430/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3758 - accuracy: 0.4773 - val_loss: 2.4423 - val_accuracy: 0.4875\n",
      "Epoch 1431/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3831 - accuracy: 0.4799 - val_loss: 2.4514 - val_accuracy: 0.4846\n",
      "Epoch 1432/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3867 - accuracy: 0.4759 - val_loss: 2.4378 - val_accuracy: 0.4883\n",
      "Epoch 1433/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3850 - accuracy: 0.4783 - val_loss: 2.4560 - val_accuracy: 0.4834\n",
      "Epoch 1434/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3976 - accuracy: 0.4744 - val_loss: 2.4412 - val_accuracy: 0.4872\n",
      "Epoch 1435/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3824 - accuracy: 0.4781 - val_loss: 2.4441 - val_accuracy: 0.4861\n",
      "Epoch 1436/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3819 - accuracy: 0.4791 - val_loss: 2.4330 - val_accuracy: 0.4879\n",
      "Epoch 1437/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3837 - accuracy: 0.4768 - val_loss: 2.4429 - val_accuracy: 0.4877\n",
      "Epoch 1438/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3897 - accuracy: 0.4753 - val_loss: 2.4545 - val_accuracy: 0.4854\n",
      "Epoch 1439/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3842 - accuracy: 0.4766 - val_loss: 2.4433 - val_accuracy: 0.4884\n",
      "Epoch 1440/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3873 - accuracy: 0.4761 - val_loss: 2.4393 - val_accuracy: 0.4892\n",
      "Epoch 1441/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3790 - accuracy: 0.4785 - val_loss: 2.4543 - val_accuracy: 0.4880\n",
      "Epoch 1442/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3875 - accuracy: 0.4788 - val_loss: 2.4485 - val_accuracy: 0.4906\n",
      "Epoch 1443/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3705 - accuracy: 0.4822 - val_loss: 2.4337 - val_accuracy: 0.4821\n",
      "Epoch 1444/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3819 - accuracy: 0.4734 - val_loss: 2.4512 - val_accuracy: 0.4860\n",
      "Epoch 1445/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3832 - accuracy: 0.4785 - val_loss: 2.4454 - val_accuracy: 0.4885\n",
      "Epoch 1446/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3856 - accuracy: 0.4800 - val_loss: 2.4303 - val_accuracy: 0.4811\n",
      "Epoch 1447/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3759 - accuracy: 0.4753 - val_loss: 2.4518 - val_accuracy: 0.4896\n",
      "Epoch 1448/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3857 - accuracy: 0.4805 - val_loss: 2.4662 - val_accuracy: 0.4830\n",
      "Epoch 1449/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4051 - accuracy: 0.4741 - val_loss: 2.4788 - val_accuracy: 0.4813\n",
      "Epoch 1450/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4388 - accuracy: 0.4686 - val_loss: 2.5063 - val_accuracy: 0.4754\n",
      "Epoch 1451/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4377 - accuracy: 0.4705 - val_loss: 2.4646 - val_accuracy: 0.4796\n",
      "Epoch 1452/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4180 - accuracy: 0.4731 - val_loss: 2.4427 - val_accuracy: 0.4821\n",
      "Epoch 1453/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4066 - accuracy: 0.4729 - val_loss: 2.4697 - val_accuracy: 0.4858\n",
      "Epoch 1454/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4217 - accuracy: 0.4730 - val_loss: 2.4878 - val_accuracy: 0.4900\n",
      "Epoch 1455/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4453 - accuracy: 0.4743 - val_loss: 2.4795 - val_accuracy: 0.4746\n",
      "Epoch 1456/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4359 - accuracy: 0.4631 - val_loss: 2.5726 - val_accuracy: 0.4653\n",
      "Epoch 1457/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5579 - accuracy: 0.4493 - val_loss: 2.8413 - val_accuracy: 0.4314\n",
      "Epoch 1458/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8385 - accuracy: 0.4127 - val_loss: 3.7802 - val_accuracy: 0.2793\n",
      "Epoch 1459/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0339 - accuracy: 0.2555 - val_loss: 5.6773 - val_accuracy: 0.1345\n",
      "Epoch 1460/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 6.1306 - accuracy: 0.1175 - val_loss: 11.7804 - val_accuracy: 0.0667\n",
      "Epoch 1461/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.1500 - accuracy: 0.0511 - val_loss: 10.9170 - val_accuracy: 0.0854\n",
      "Epoch 1462/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2448 - accuracy: 0.0802 - val_loss: 10.5070 - val_accuracy: 0.2041\n",
      "Epoch 1463/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 10.6261 - accuracy: 0.1989 - val_loss: 11.2278 - val_accuracy: 0.0975\n",
      "Epoch 1464/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.2975 - accuracy: 0.0953 - val_loss: 10.8324 - val_accuracy: 0.2086\n",
      "Epoch 1465/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 10.8794 - accuracy: 0.2034 - val_loss: 10.8383 - val_accuracy: 0.2100\n",
      "Epoch 1466/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 10.8967 - accuracy: 0.2060 - val_loss: 10.5529 - val_accuracy: 0.1863\n",
      "Epoch 1467/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 10.6193 - accuracy: 0.1717 - val_loss: 9.8250 - val_accuracy: 0.2073\n",
      "Epoch 1468/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 9.9285 - accuracy: 0.1992 - val_loss: 7.6324 - val_accuracy: 0.1393\n",
      "Epoch 1469/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 7.9696 - accuracy: 0.1579 - val_loss: 5.0047 - val_accuracy: 0.2054\n",
      "Epoch 1470/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.1425 - accuracy: 0.2066 - val_loss: 4.6386 - val_accuracy: 0.2065\n",
      "Epoch 1471/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.7220 - accuracy: 0.2076 - val_loss: 4.5169 - val_accuracy: 0.2069\n",
      "Epoch 1472/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.5544 - accuracy: 0.2080 - val_loss: 4.4566 - val_accuracy: 0.2072\n",
      "Epoch 1473/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.4690 - accuracy: 0.2088 - val_loss: 4.4170 - val_accuracy: 0.2078\n",
      "Epoch 1474/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.4358 - accuracy: 0.2084 - val_loss: 4.3917 - val_accuracy: 0.2080\n",
      "Epoch 1475/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.4198 - accuracy: 0.2085 - val_loss: 4.3786 - val_accuracy: 0.2084\n",
      "Epoch 1476/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.3903 - accuracy: 0.2093 - val_loss: 4.3739 - val_accuracy: 0.2085\n",
      "Epoch 1477/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.3823 - accuracy: 0.2090 - val_loss: 4.3728 - val_accuracy: 0.2086\n",
      "Epoch 1478/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.3810 - accuracy: 0.2101 - val_loss: 4.3718 - val_accuracy: 0.2087\n",
      "Epoch 1479/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.3759 - accuracy: 0.2101 - val_loss: 4.3683 - val_accuracy: 0.2089\n",
      "Epoch 1480/12000\n",
      "1/1 [==============================] - 18s 18s/step - loss: 4.3773 - accuracy: 0.2099 - val_loss: 4.3623 - val_accuracy: 0.2095\n",
      "Epoch 1481/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 4.3699 - accuracy: 0.2106 - val_loss: 4.3543 - val_accuracy: 0.2101\n",
      "Epoch 1482/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.3620 - accuracy: 0.2113 - val_loss: 4.3452 - val_accuracy: 0.2105\n",
      "Epoch 1483/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3537 - accuracy: 0.2116 - val_loss: 4.3357 - val_accuracy: 0.2116\n",
      "Epoch 1484/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3470 - accuracy: 0.2112 - val_loss: 4.3261 - val_accuracy: 0.2122\n",
      "Epoch 1485/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3341 - accuracy: 0.2122 - val_loss: 4.3210 - val_accuracy: 0.2120\n",
      "Epoch 1486/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3405 - accuracy: 0.2119 - val_loss: 4.3100 - val_accuracy: 0.2124\n",
      "Epoch 1487/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3221 - accuracy: 0.2123 - val_loss: 4.3055 - val_accuracy: 0.2128\n",
      "Epoch 1488/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3208 - accuracy: 0.2124 - val_loss: 4.2991 - val_accuracy: 0.2132\n",
      "Epoch 1489/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3078 - accuracy: 0.2134 - val_loss: 4.2926 - val_accuracy: 0.2132\n",
      "Epoch 1490/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3040 - accuracy: 0.2140 - val_loss: 4.2873 - val_accuracy: 0.2130\n",
      "Epoch 1491/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3015 - accuracy: 0.2137 - val_loss: 4.2832 - val_accuracy: 0.2132\n",
      "Epoch 1492/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3033 - accuracy: 0.2138 - val_loss: 4.2799 - val_accuracy: 0.2135\n",
      "Epoch 1493/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2925 - accuracy: 0.2136 - val_loss: 4.2769 - val_accuracy: 0.2142\n",
      "Epoch 1494/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2878 - accuracy: 0.2146 - val_loss: 4.2737 - val_accuracy: 0.2150\n",
      "Epoch 1495/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2859 - accuracy: 0.2148 - val_loss: 4.2701 - val_accuracy: 0.2162\n",
      "Epoch 1496/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2809 - accuracy: 0.2153 - val_loss: 4.2685 - val_accuracy: 0.2163\n",
      "Epoch 1497/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2840 - accuracy: 0.2151 - val_loss: 4.2672 - val_accuracy: 0.2165\n",
      "Epoch 1498/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2806 - accuracy: 0.2150 - val_loss: 4.2655 - val_accuracy: 0.2165\n",
      "Epoch 1499/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2834 - accuracy: 0.2154 - val_loss: 4.2643 - val_accuracy: 0.2162\n",
      "Epoch 1500/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2797 - accuracy: 0.2151 - val_loss: 4.2618 - val_accuracy: 0.2162\n",
      "Epoch 1501/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2753 - accuracy: 0.2152 - val_loss: 4.2597 - val_accuracy: 0.2164\n",
      "Epoch 1502/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2760 - accuracy: 0.2154 - val_loss: 4.2576 - val_accuracy: 0.2164\n",
      "Epoch 1503/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2750 - accuracy: 0.2152 - val_loss: 4.2565 - val_accuracy: 0.2164\n",
      "Epoch 1504/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2719 - accuracy: 0.2155 - val_loss: 4.2553 - val_accuracy: 0.2166\n",
      "Epoch 1505/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2701 - accuracy: 0.2155 - val_loss: 4.2545 - val_accuracy: 0.2172\n",
      "Epoch 1506/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2717 - accuracy: 0.2153 - val_loss: 4.2539 - val_accuracy: 0.2170\n",
      "Epoch 1507/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2678 - accuracy: 0.2156 - val_loss: 4.2538 - val_accuracy: 0.2170\n",
      "Epoch 1508/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2700 - accuracy: 0.2155 - val_loss: 4.2537 - val_accuracy: 0.2171\n",
      "Epoch 1509/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2671 - accuracy: 0.2153 - val_loss: 4.2534 - val_accuracy: 0.2170\n",
      "Epoch 1510/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2653 - accuracy: 0.2154 - val_loss: 4.2518 - val_accuracy: 0.2170\n",
      "Epoch 1511/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2734 - accuracy: 0.2152 - val_loss: 4.2500 - val_accuracy: 0.2179\n",
      "Epoch 1512/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2653 - accuracy: 0.2156 - val_loss: 4.2490 - val_accuracy: 0.2179\n",
      "Epoch 1513/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2649 - accuracy: 0.2156 - val_loss: 4.2488 - val_accuracy: 0.2181\n",
      "Epoch 1514/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2658 - accuracy: 0.2154 - val_loss: 4.2485 - val_accuracy: 0.2174\n",
      "Epoch 1515/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2628 - accuracy: 0.2155 - val_loss: 4.2481 - val_accuracy: 0.2175\n",
      "Epoch 1516/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2642 - accuracy: 0.2158 - val_loss: 4.2479 - val_accuracy: 0.2175\n",
      "Epoch 1517/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2634 - accuracy: 0.2158 - val_loss: 4.2473 - val_accuracy: 0.2177\n",
      "Epoch 1518/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.2616 - accuracy: 0.2155 - val_loss: 4.2461 - val_accuracy: 0.2179\n",
      "Epoch 1519/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2588 - accuracy: 0.2160 - val_loss: 4.2450 - val_accuracy: 0.2183\n",
      "Epoch 1520/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.2579 - accuracy: 0.2163 - val_loss: 4.2438 - val_accuracy: 0.2184\n",
      "Epoch 1521/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.2565 - accuracy: 0.2164 - val_loss: 4.2431 - val_accuracy: 0.2182\n",
      "Epoch 1522/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2553 - accuracy: 0.2168 - val_loss: 4.2425 - val_accuracy: 0.2182\n",
      "Epoch 1523/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2636 - accuracy: 0.2162 - val_loss: 4.2422 - val_accuracy: 0.2185\n",
      "Epoch 1524/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2597 - accuracy: 0.2160 - val_loss: 4.2423 - val_accuracy: 0.2182\n",
      "Epoch 1525/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2564 - accuracy: 0.2163 - val_loss: 4.2425 - val_accuracy: 0.2174\n",
      "Epoch 1526/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2568 - accuracy: 0.2168 - val_loss: 4.2424 - val_accuracy: 0.2173\n",
      "Epoch 1527/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2558 - accuracy: 0.2172 - val_loss: 4.2416 - val_accuracy: 0.2181\n",
      "Epoch 1528/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2564 - accuracy: 0.2171 - val_loss: 4.2412 - val_accuracy: 0.2181\n",
      "Epoch 1529/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2556 - accuracy: 0.2171 - val_loss: 4.2411 - val_accuracy: 0.2183\n",
      "Epoch 1530/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2540 - accuracy: 0.2172 - val_loss: 4.2412 - val_accuracy: 0.2186\n",
      "Epoch 1531/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2532 - accuracy: 0.2175 - val_loss: 4.2402 - val_accuracy: 0.2188\n",
      "Epoch 1532/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2542 - accuracy: 0.2167 - val_loss: 4.2383 - val_accuracy: 0.2189\n",
      "Epoch 1533/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2557 - accuracy: 0.2171 - val_loss: 4.2372 - val_accuracy: 0.2194\n",
      "Epoch 1534/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2567 - accuracy: 0.2168 - val_loss: 4.2365 - val_accuracy: 0.2194\n",
      "Epoch 1535/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2502 - accuracy: 0.2176 - val_loss: 4.2355 - val_accuracy: 0.2194\n",
      "Epoch 1536/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2526 - accuracy: 0.2176 - val_loss: 4.2348 - val_accuracy: 0.2196\n",
      "Epoch 1537/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2498 - accuracy: 0.2179 - val_loss: 4.2343 - val_accuracy: 0.2193\n",
      "Epoch 1538/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2507 - accuracy: 0.2175 - val_loss: 4.2338 - val_accuracy: 0.2191\n",
      "Epoch 1539/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2509 - accuracy: 0.2176 - val_loss: 4.2341 - val_accuracy: 0.2189\n",
      "Epoch 1540/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2486 - accuracy: 0.2179 - val_loss: 4.2345 - val_accuracy: 0.2198\n",
      "Epoch 1541/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2496 - accuracy: 0.2175 - val_loss: 4.2346 - val_accuracy: 0.2197\n",
      "Epoch 1542/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2441 - accuracy: 0.2182 - val_loss: 4.2340 - val_accuracy: 0.2200\n",
      "Epoch 1543/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 4.2479 - accuracy: 0.2179 - val_loss: 4.2329 - val_accuracy: 0.2203\n",
      "Epoch 1544/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2485 - accuracy: 0.2179 - val_loss: 4.2319 - val_accuracy: 0.2204\n",
      "Epoch 1545/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2510 - accuracy: 0.2181 - val_loss: 4.2309 - val_accuracy: 0.2204\n",
      "Epoch 1546/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2441 - accuracy: 0.2187 - val_loss: 4.2302 - val_accuracy: 0.2201\n",
      "Epoch 1547/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2478 - accuracy: 0.2183 - val_loss: 4.2297 - val_accuracy: 0.2199\n",
      "Epoch 1548/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2494 - accuracy: 0.2181 - val_loss: 4.2289 - val_accuracy: 0.2207\n",
      "Epoch 1549/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2434 - accuracy: 0.2186 - val_loss: 4.2279 - val_accuracy: 0.2217\n",
      "Epoch 1550/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2491 - accuracy: 0.2186 - val_loss: 4.2269 - val_accuracy: 0.2215\n",
      "Epoch 1551/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2462 - accuracy: 0.2185 - val_loss: 4.2266 - val_accuracy: 0.2218\n",
      "Epoch 1552/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2438 - accuracy: 0.2188 - val_loss: 4.2267 - val_accuracy: 0.2213\n",
      "Epoch 1553/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2489 - accuracy: 0.2184 - val_loss: 4.2270 - val_accuracy: 0.2211\n",
      "Epoch 1554/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2426 - accuracy: 0.2185 - val_loss: 4.2272 - val_accuracy: 0.2217\n",
      "Epoch 1555/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2404 - accuracy: 0.2186 - val_loss: 4.2271 - val_accuracy: 0.2222\n",
      "Epoch 1556/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2470 - accuracy: 0.2180 - val_loss: 4.2269 - val_accuracy: 0.2220\n",
      "Epoch 1557/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2432 - accuracy: 0.2190 - val_loss: 4.2268 - val_accuracy: 0.2221\n",
      "Epoch 1558/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2430 - accuracy: 0.2186 - val_loss: 4.2267 - val_accuracy: 0.2220\n",
      "Epoch 1559/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2419 - accuracy: 0.2189 - val_loss: 4.2266 - val_accuracy: 0.2215\n",
      "Epoch 1560/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2405 - accuracy: 0.2188 - val_loss: 4.2262 - val_accuracy: 0.2216\n",
      "Epoch 1561/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2414 - accuracy: 0.2186 - val_loss: 4.2256 - val_accuracy: 0.2213\n",
      "Epoch 1562/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2410 - accuracy: 0.2190 - val_loss: 4.2250 - val_accuracy: 0.2216\n",
      "Epoch 1563/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2401 - accuracy: 0.2191 - val_loss: 4.2246 - val_accuracy: 0.2211\n",
      "Epoch 1564/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2412 - accuracy: 0.2187 - val_loss: 4.2240 - val_accuracy: 0.2214\n",
      "Epoch 1565/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2363 - accuracy: 0.2190 - val_loss: 4.2235 - val_accuracy: 0.2217\n",
      "Epoch 1566/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2388 - accuracy: 0.2187 - val_loss: 4.2233 - val_accuracy: 0.2221\n",
      "Epoch 1567/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2361 - accuracy: 0.2193 - val_loss: 4.2233 - val_accuracy: 0.2226\n",
      "Epoch 1568/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2380 - accuracy: 0.2195 - val_loss: 4.2232 - val_accuracy: 0.2224\n",
      "Epoch 1569/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2400 - accuracy: 0.2189 - val_loss: 4.2228 - val_accuracy: 0.2225\n",
      "Epoch 1570/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2378 - accuracy: 0.2195 - val_loss: 4.2225 - val_accuracy: 0.2232\n",
      "Epoch 1571/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2376 - accuracy: 0.2196 - val_loss: 4.2222 - val_accuracy: 0.2227\n",
      "Epoch 1572/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2342 - accuracy: 0.2195 - val_loss: 4.2245 - val_accuracy: 0.2224\n",
      "Epoch 1573/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2359 - accuracy: 0.2200 - val_loss: 4.2218 - val_accuracy: 0.2223\n",
      "Epoch 1574/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2369 - accuracy: 0.2193 - val_loss: 4.2213 - val_accuracy: 0.2225\n",
      "Epoch 1575/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2369 - accuracy: 0.2192 - val_loss: 4.2206 - val_accuracy: 0.2232\n",
      "Epoch 1576/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2358 - accuracy: 0.2194 - val_loss: 4.2196 - val_accuracy: 0.2237\n",
      "Epoch 1577/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2366 - accuracy: 0.2197 - val_loss: 4.2185 - val_accuracy: 0.2241\n",
      "Epoch 1578/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2352 - accuracy: 0.2197 - val_loss: 4.2175 - val_accuracy: 0.2238\n",
      "Epoch 1579/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2350 - accuracy: 0.2195 - val_loss: 4.2169 - val_accuracy: 0.2239\n",
      "Epoch 1580/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2323 - accuracy: 0.2193 - val_loss: 4.2165 - val_accuracy: 0.2237\n",
      "Epoch 1581/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2334 - accuracy: 0.2192 - val_loss: 4.2163 - val_accuracy: 0.2245\n",
      "Epoch 1582/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2314 - accuracy: 0.2203 - val_loss: 4.2165 - val_accuracy: 0.2242\n",
      "Epoch 1583/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2322 - accuracy: 0.2201 - val_loss: 4.2168 - val_accuracy: 0.2234\n",
      "Epoch 1584/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2351 - accuracy: 0.2194 - val_loss: 4.2170 - val_accuracy: 0.2235\n",
      "Epoch 1585/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2322 - accuracy: 0.2196 - val_loss: 4.2167 - val_accuracy: 0.2237\n",
      "Epoch 1586/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2316 - accuracy: 0.2200 - val_loss: 4.2158 - val_accuracy: 0.2234\n",
      "Epoch 1587/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2314 - accuracy: 0.2201 - val_loss: 4.2150 - val_accuracy: 0.2242\n",
      "Epoch 1588/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2316 - accuracy: 0.2199 - val_loss: 4.2142 - val_accuracy: 0.2245\n",
      "Epoch 1589/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.2332 - accuracy: 0.2203 - val_loss: 4.2132 - val_accuracy: 0.2244\n",
      "Epoch 1590/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.2285 - accuracy: 0.2206 - val_loss: 4.2125 - val_accuracy: 0.2245\n",
      "Epoch 1591/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2319 - accuracy: 0.2200 - val_loss: 4.2122 - val_accuracy: 0.2243\n",
      "Epoch 1592/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2286 - accuracy: 0.2205 - val_loss: 4.2122 - val_accuracy: 0.2240\n",
      "Epoch 1593/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2289 - accuracy: 0.2208 - val_loss: 4.2123 - val_accuracy: 0.2240\n",
      "Epoch 1594/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2271 - accuracy: 0.2207 - val_loss: 4.2123 - val_accuracy: 0.2242\n",
      "Epoch 1595/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2284 - accuracy: 0.2202 - val_loss: 4.2120 - val_accuracy: 0.2242\n",
      "Epoch 1596/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2272 - accuracy: 0.2204 - val_loss: 4.2117 - val_accuracy: 0.2240\n",
      "Epoch 1597/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2281 - accuracy: 0.2202 - val_loss: 4.2113 - val_accuracy: 0.2244\n",
      "Epoch 1598/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2287 - accuracy: 0.2207 - val_loss: 4.2107 - val_accuracy: 0.2246\n",
      "Epoch 1599/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2250 - accuracy: 0.2210 - val_loss: 4.2100 - val_accuracy: 0.2254\n",
      "Epoch 1600/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2280 - accuracy: 0.2209 - val_loss: 4.2092 - val_accuracy: 0.2261\n",
      "Epoch 1601/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2253 - accuracy: 0.2208 - val_loss: 4.2088 - val_accuracy: 0.2254\n",
      "Epoch 1602/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2263 - accuracy: 0.2207 - val_loss: 4.2084 - val_accuracy: 0.2255\n",
      "Epoch 1603/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2242 - accuracy: 0.2211 - val_loss: 4.2080 - val_accuracy: 0.2255\n",
      "Epoch 1604/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2198 - accuracy: 0.2219 - val_loss: 4.2074 - val_accuracy: 0.2259\n",
      "Epoch 1605/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2225 - accuracy: 0.2214 - val_loss: 4.2069 - val_accuracy: 0.2261\n",
      "Epoch 1606/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2231 - accuracy: 0.2210 - val_loss: 4.2067 - val_accuracy: 0.2254\n",
      "Epoch 1607/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2240 - accuracy: 0.2207 - val_loss: 4.2065 - val_accuracy: 0.2254\n",
      "Epoch 1608/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2243 - accuracy: 0.2207 - val_loss: 4.2067 - val_accuracy: 0.2250\n",
      "Epoch 1609/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2216 - accuracy: 0.2212 - val_loss: 4.2067 - val_accuracy: 0.2247\n",
      "Epoch 1/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 5.4326 - accuracy: 0.0031 - val_loss: 10.3207 - val_accuracy: 0.1958\n",
      "Epoch 2/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 10.2785 - accuracy: 0.1975 - val_loss: 5.0592 - val_accuracy: 0.0302\n",
      "Epoch 3/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.0577 - accuracy: 0.0288 - val_loss: 5.4585 - val_accuracy: 0.0275\n",
      "Epoch 4/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.4606 - accuracy: 0.0274 - val_loss: 5.1012 - val_accuracy: 0.0179\n",
      "Epoch 5/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.1236 - accuracy: 0.0181 - val_loss: 4.9709 - val_accuracy: 0.0429\n",
      "Epoch 6/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.9620 - accuracy: 0.0427 - val_loss: 4.8539 - val_accuracy: 0.0396\n",
      "Epoch 7/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.8522 - accuracy: 0.0434 - val_loss: 4.7426 - val_accuracy: 0.0506\n",
      "Epoch 8/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.7436 - accuracy: 0.0496 - val_loss: 4.6020 - val_accuracy: 0.0520\n",
      "Epoch 9/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.6053 - accuracy: 0.0529 - val_loss: 4.4992 - val_accuracy: 0.0598\n",
      "Epoch 10/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.5072 - accuracy: 0.0613 - val_loss: 4.4280 - val_accuracy: 0.0783\n",
      "Epoch 11/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.4380 - accuracy: 0.0816 - val_loss: 4.3491 - val_accuracy: 0.1615\n",
      "Epoch 12/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3651 - accuracy: 0.1544 - val_loss: 4.2895 - val_accuracy: 0.1841\n",
      "Epoch 13/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2966 - accuracy: 0.1817 - val_loss: 4.2726 - val_accuracy: 0.1962\n",
      "Epoch 14/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2828 - accuracy: 0.1978 - val_loss: 4.2232 - val_accuracy: 0.2249\n",
      "Epoch 15/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2416 - accuracy: 0.2149 - val_loss: 4.2030 - val_accuracy: 0.2350\n",
      "Epoch 16/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2304 - accuracy: 0.2247 - val_loss: 4.1689 - val_accuracy: 0.2330\n",
      "Epoch 17/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1764 - accuracy: 0.2261 - val_loss: 4.1384 - val_accuracy: 0.2343\n",
      "Epoch 18/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1512 - accuracy: 0.2289 - val_loss: 4.1065 - val_accuracy: 0.2351\n",
      "Epoch 19/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1257 - accuracy: 0.2295 - val_loss: 4.0814 - val_accuracy: 0.2353\n",
      "Epoch 20/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.0998 - accuracy: 0.2308 - val_loss: 4.1044 - val_accuracy: 0.2360\n",
      "Epoch 21/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1275 - accuracy: 0.2318 - val_loss: 4.0709 - val_accuracy: 0.2375\n",
      "Epoch 22/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0910 - accuracy: 0.2325 - val_loss: 4.0645 - val_accuracy: 0.2386\n",
      "Epoch 23/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0855 - accuracy: 0.2347 - val_loss: 4.0458 - val_accuracy: 0.2419\n",
      "Epoch 24/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0709 - accuracy: 0.2390 - val_loss: 4.0321 - val_accuracy: 0.2434\n",
      "Epoch 25/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0620 - accuracy: 0.2394 - val_loss: 4.0121 - val_accuracy: 0.2417\n",
      "Epoch 26/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0392 - accuracy: 0.2385 - val_loss: 3.9949 - val_accuracy: 0.2397\n",
      "Epoch 27/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0132 - accuracy: 0.2381 - val_loss: 3.9782 - val_accuracy: 0.2409\n",
      "Epoch 28/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9943 - accuracy: 0.2383 - val_loss: 3.9454 - val_accuracy: 0.2445\n",
      "Epoch 29/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9713 - accuracy: 0.2411 - val_loss: 3.9283 - val_accuracy: 0.2426\n",
      "Epoch 30/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9607 - accuracy: 0.2408 - val_loss: 4.0802 - val_accuracy: 0.2379\n",
      "Epoch 31/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1168 - accuracy: 0.2359 - val_loss: 3.9441 - val_accuracy: 0.2404\n",
      "Epoch 32/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9647 - accuracy: 0.2395 - val_loss: 3.9176 - val_accuracy: 0.2402\n",
      "Epoch 33/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9447 - accuracy: 0.2389 - val_loss: 3.8650 - val_accuracy: 0.2487\n",
      "Epoch 34/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8947 - accuracy: 0.2457 - val_loss: 3.8455 - val_accuracy: 0.2499\n",
      "Epoch 35/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8813 - accuracy: 0.2471 - val_loss: 3.8106 - val_accuracy: 0.2494\n",
      "Epoch 36/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8331 - accuracy: 0.2491 - val_loss: 3.7600 - val_accuracy: 0.2594\n",
      "Epoch 37/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7871 - accuracy: 0.2578 - val_loss: 3.7010 - val_accuracy: 0.2752\n",
      "Epoch 38/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7434 - accuracy: 0.2700 - val_loss: 3.6641 - val_accuracy: 0.2776\n",
      "Epoch 39/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7128 - accuracy: 0.2729 - val_loss: 3.6400 - val_accuracy: 0.2700\n",
      "Epoch 40/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6792 - accuracy: 0.2666 - val_loss: 3.6184 - val_accuracy: 0.2672\n",
      "Epoch 41/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6505 - accuracy: 0.2637 - val_loss: 3.6386 - val_accuracy: 0.2747\n",
      "Epoch 42/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7004 - accuracy: 0.2688 - val_loss: 3.6790 - val_accuracy: 0.2654\n",
      "Epoch 43/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6796 - accuracy: 0.2652 - val_loss: 3.6467 - val_accuracy: 0.2690\n",
      "Epoch 44/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6555 - accuracy: 0.2702 - val_loss: 3.5701 - val_accuracy: 0.2803\n",
      "Epoch 45/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6101 - accuracy: 0.2782 - val_loss: 3.5001 - val_accuracy: 0.2927\n",
      "Epoch 46/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5628 - accuracy: 0.2878 - val_loss: 3.4984 - val_accuracy: 0.2951\n",
      "Epoch 47/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5531 - accuracy: 0.2895 - val_loss: 3.4493 - val_accuracy: 0.2911\n",
      "Epoch 48/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4982 - accuracy: 0.2892 - val_loss: 3.4374 - val_accuracy: 0.2927\n",
      "Epoch 49/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 3.4829 - accuracy: 0.2928 - val_loss: 3.4093 - val_accuracy: 0.3017\n",
      "Epoch 50/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4606 - accuracy: 0.2948 - val_loss: 3.3768 - val_accuracy: 0.3074\n",
      "Epoch 51/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4286 - accuracy: 0.3064 - val_loss: 3.3235 - val_accuracy: 0.3196\n",
      "Epoch 52/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3799 - accuracy: 0.3139 - val_loss: 3.2994 - val_accuracy: 0.3288\n",
      "Epoch 53/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3530 - accuracy: 0.3193 - val_loss: 3.2435 - val_accuracy: 0.3361\n",
      "Epoch 54/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3222 - accuracy: 0.3224 - val_loss: 3.2074 - val_accuracy: 0.3418\n",
      "Epoch 55/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2688 - accuracy: 0.3338 - val_loss: 3.1819 - val_accuracy: 0.3472\n",
      "Epoch 56/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2366 - accuracy: 0.3364 - val_loss: 3.1628 - val_accuracy: 0.3497\n",
      "Epoch 57/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2134 - accuracy: 0.3393 - val_loss: 3.1413 - val_accuracy: 0.3556\n",
      "Epoch 58/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1947 - accuracy: 0.3472 - val_loss: 3.1276 - val_accuracy: 0.3642\n",
      "Epoch 59/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1973 - accuracy: 0.3493 - val_loss: 3.1380 - val_accuracy: 0.3532\n",
      "Epoch 60/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1951 - accuracy: 0.3446 - val_loss: 3.1142 - val_accuracy: 0.3542\n",
      "Epoch 61/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1564 - accuracy: 0.3474 - val_loss: 3.0814 - val_accuracy: 0.3649\n",
      "Epoch 62/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.1416 - accuracy: 0.3534 - val_loss: 3.0266 - val_accuracy: 0.3720\n",
      "Epoch 63/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0875 - accuracy: 0.3610 - val_loss: 3.0255 - val_accuracy: 0.3710\n",
      "Epoch 64/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0990 - accuracy: 0.3567 - val_loss: 3.0308 - val_accuracy: 0.3685\n",
      "Epoch 65/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0743 - accuracy: 0.3605 - val_loss: 3.0076 - val_accuracy: 0.3732\n",
      "Epoch 66/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0507 - accuracy: 0.3650 - val_loss: 2.9580 - val_accuracy: 0.3840\n",
      "Epoch 67/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0230 - accuracy: 0.3720 - val_loss: 2.9517 - val_accuracy: 0.3839\n",
      "Epoch 68/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0224 - accuracy: 0.3713 - val_loss: 2.9246 - val_accuracy: 0.3824\n",
      "Epoch 69/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9793 - accuracy: 0.3731 - val_loss: 2.9137 - val_accuracy: 0.3921\n",
      "Epoch 70/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9695 - accuracy: 0.3777 - val_loss: 2.8855 - val_accuracy: 0.3967\n",
      "Epoch 71/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9453 - accuracy: 0.3811 - val_loss: 2.8635 - val_accuracy: 0.3973\n",
      "Epoch 72/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9370 - accuracy: 0.3845 - val_loss: 2.8452 - val_accuracy: 0.4029\n",
      "Epoch 73/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9123 - accuracy: 0.3886 - val_loss: 2.8260 - val_accuracy: 0.4085\n",
      "Epoch 74/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9016 - accuracy: 0.3920 - val_loss: 2.8193 - val_accuracy: 0.4022\n",
      "Epoch 75/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8850 - accuracy: 0.3897 - val_loss: 2.8070 - val_accuracy: 0.4083\n",
      "Epoch 76/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8735 - accuracy: 0.3887 - val_loss: 2.7986 - val_accuracy: 0.4117\n",
      "Epoch 77/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8595 - accuracy: 0.3950 - val_loss: 2.7838 - val_accuracy: 0.4147\n",
      "Epoch 78/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8528 - accuracy: 0.3991 - val_loss: 2.7733 - val_accuracy: 0.4095\n",
      "Epoch 79/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8445 - accuracy: 0.3961 - val_loss: 2.7516 - val_accuracy: 0.4193\n",
      "Epoch 80/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8268 - accuracy: 0.3987 - val_loss: 2.7693 - val_accuracy: 0.4182\n",
      "Epoch 81/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8259 - accuracy: 0.4046 - val_loss: 2.7415 - val_accuracy: 0.4142\n",
      "Epoch 82/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8057 - accuracy: 0.4017 - val_loss: 2.7242 - val_accuracy: 0.4221\n",
      "Epoch 83/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8044 - accuracy: 0.4022 - val_loss: 2.7336 - val_accuracy: 0.4188\n",
      "Epoch 84/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7911 - accuracy: 0.4027 - val_loss: 2.7288 - val_accuracy: 0.4198\n",
      "Epoch 85/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7858 - accuracy: 0.4024 - val_loss: 2.6975 - val_accuracy: 0.4304\n",
      "Epoch 86/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7774 - accuracy: 0.4103 - val_loss: 2.7136 - val_accuracy: 0.4275\n",
      "Epoch 87/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7717 - accuracy: 0.4084 - val_loss: 2.7365 - val_accuracy: 0.4164\n",
      "Epoch 88/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8218 - accuracy: 0.3995 - val_loss: 2.8163 - val_accuracy: 0.4193\n",
      "Epoch 89/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8401 - accuracy: 0.4066 - val_loss: 2.7490 - val_accuracy: 0.4312\n",
      "Epoch 90/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8008 - accuracy: 0.4133 - val_loss: 2.7271 - val_accuracy: 0.4247\n",
      "Epoch 91/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7780 - accuracy: 0.4127 - val_loss: 2.7303 - val_accuracy: 0.4134\n",
      "Epoch 92/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7880 - accuracy: 0.3989 - val_loss: 2.7067 - val_accuracy: 0.4221\n",
      "Epoch 93/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7590 - accuracy: 0.4054 - val_loss: 2.6904 - val_accuracy: 0.4291\n",
      "Epoch 94/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7447 - accuracy: 0.4131 - val_loss: 2.6906 - val_accuracy: 0.4268\n",
      "Epoch 95/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7385 - accuracy: 0.4149 - val_loss: 2.6831 - val_accuracy: 0.4297\n",
      "Epoch 96/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7222 - accuracy: 0.4163 - val_loss: 2.6586 - val_accuracy: 0.4424\n",
      "Epoch 97/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7214 - accuracy: 0.4213 - val_loss: 2.6568 - val_accuracy: 0.4385\n",
      "Epoch 98/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7070 - accuracy: 0.4203 - val_loss: 2.6566 - val_accuracy: 0.4357\n",
      "Epoch 99/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7027 - accuracy: 0.4185 - val_loss: 2.6453 - val_accuracy: 0.4482\n",
      "Epoch 100/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7008 - accuracy: 0.4248 - val_loss: 2.6598 - val_accuracy: 0.4362\n",
      "Epoch 101/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6969 - accuracy: 0.4199 - val_loss: 2.6340 - val_accuracy: 0.4444\n",
      "Epoch 102/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6791 - accuracy: 0.4276 - val_loss: 2.6257 - val_accuracy: 0.4471\n",
      "Epoch 103/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6784 - accuracy: 0.4275 - val_loss: 2.6441 - val_accuracy: 0.4375\n",
      "Epoch 104/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6781 - accuracy: 0.4196 - val_loss: 2.6200 - val_accuracy: 0.4485\n",
      "Epoch 105/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6656 - accuracy: 0.4298 - val_loss: 2.6150 - val_accuracy: 0.4453\n",
      "Epoch 106/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6526 - accuracy: 0.4306 - val_loss: 2.6070 - val_accuracy: 0.4460\n",
      "Epoch 107/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6528 - accuracy: 0.4286 - val_loss: 2.6049 - val_accuracy: 0.4518\n",
      "Epoch 108/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6549 - accuracy: 0.4305 - val_loss: 2.6189 - val_accuracy: 0.4495\n",
      "Epoch 109/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6514 - accuracy: 0.4300 - val_loss: 2.5971 - val_accuracy: 0.4536\n",
      "Epoch 110/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6347 - accuracy: 0.4370 - val_loss: 2.5892 - val_accuracy: 0.4520\n",
      "Epoch 111/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6343 - accuracy: 0.4364 - val_loss: 2.6114 - val_accuracy: 0.4465\n",
      "Epoch 112/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6341 - accuracy: 0.4330 - val_loss: 2.5856 - val_accuracy: 0.4514\n",
      "Epoch 113/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6154 - accuracy: 0.4365 - val_loss: 2.5767 - val_accuracy: 0.4536\n",
      "Epoch 114/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6214 - accuracy: 0.4374 - val_loss: 2.5865 - val_accuracy: 0.4537\n",
      "Epoch 115/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6200 - accuracy: 0.4370 - val_loss: 2.5770 - val_accuracy: 0.4584\n",
      "Epoch 116/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6072 - accuracy: 0.4390 - val_loss: 2.5731 - val_accuracy: 0.4546\n",
      "Epoch 117/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6132 - accuracy: 0.4359 - val_loss: 2.5736 - val_accuracy: 0.4641\n",
      "Epoch 118/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6035 - accuracy: 0.4422 - val_loss: 2.5655 - val_accuracy: 0.4593\n",
      "Epoch 119/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5920 - accuracy: 0.4419 - val_loss: 2.5802 - val_accuracy: 0.4465\n",
      "Epoch 120/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6070 - accuracy: 0.4340 - val_loss: 2.5642 - val_accuracy: 0.4582\n",
      "Epoch 121/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5897 - accuracy: 0.4414 - val_loss: 2.5674 - val_accuracy: 0.4645\n",
      "Epoch 122/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5927 - accuracy: 0.4467 - val_loss: 2.5701 - val_accuracy: 0.4497\n",
      "Epoch 123/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5921 - accuracy: 0.4367 - val_loss: 2.5567 - val_accuracy: 0.4598\n",
      "Epoch 124/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5842 - accuracy: 0.4406 - val_loss: 2.5636 - val_accuracy: 0.4680\n",
      "Epoch 125/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5807 - accuracy: 0.4471 - val_loss: 2.5511 - val_accuracy: 0.4626\n",
      "Epoch 126/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5789 - accuracy: 0.4416 - val_loss: 2.5499 - val_accuracy: 0.4618\n",
      "Epoch 127/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5822 - accuracy: 0.4424 - val_loss: 2.5653 - val_accuracy: 0.4586\n",
      "Epoch 128/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5775 - accuracy: 0.4419 - val_loss: 2.5545 - val_accuracy: 0.4687\n",
      "Epoch 129/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5710 - accuracy: 0.4476 - val_loss: 2.5426 - val_accuracy: 0.4654\n",
      "Epoch 130/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5580 - accuracy: 0.4463 - val_loss: 2.5478 - val_accuracy: 0.4632\n",
      "Epoch 131/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5651 - accuracy: 0.4436 - val_loss: 2.5469 - val_accuracy: 0.4694\n",
      "Epoch 132/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5639 - accuracy: 0.4500 - val_loss: 2.5541 - val_accuracy: 0.4564\n",
      "Epoch 133/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5734 - accuracy: 0.4393 - val_loss: 2.5359 - val_accuracy: 0.4672\n",
      "Epoch 134/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5465 - accuracy: 0.4482 - val_loss: 2.5448 - val_accuracy: 0.4696\n",
      "Epoch 135/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5516 - accuracy: 0.4520 - val_loss: 2.5604 - val_accuracy: 0.4524\n",
      "Epoch 136/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5781 - accuracy: 0.4348 - val_loss: 2.5344 - val_accuracy: 0.4701\n",
      "Epoch 137/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5485 - accuracy: 0.4506 - val_loss: 2.5499 - val_accuracy: 0.4742\n",
      "Epoch 138/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5519 - accuracy: 0.4527 - val_loss: 2.5473 - val_accuracy: 0.4633\n",
      "Epoch 139/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5451 - accuracy: 0.4475 - val_loss: 2.5350 - val_accuracy: 0.4656\n",
      "Epoch 140/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5526 - accuracy: 0.4464 - val_loss: 2.5355 - val_accuracy: 0.4736\n",
      "Epoch 141/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5442 - accuracy: 0.4509 - val_loss: 2.5347 - val_accuracy: 0.4742\n",
      "Epoch 142/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5374 - accuracy: 0.4512 - val_loss: 2.5205 - val_accuracy: 0.4704\n",
      "Epoch 143/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5339 - accuracy: 0.4507 - val_loss: 2.5323 - val_accuracy: 0.4679\n",
      "Epoch 144/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5392 - accuracy: 0.4489 - val_loss: 2.5355 - val_accuracy: 0.4666\n",
      "Epoch 145/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5310 - accuracy: 0.4500 - val_loss: 2.5204 - val_accuracy: 0.4738\n",
      "Epoch 146/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5170 - accuracy: 0.4529 - val_loss: 2.5134 - val_accuracy: 0.4734\n",
      "Epoch 147/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5213 - accuracy: 0.4527 - val_loss: 2.5175 - val_accuracy: 0.4711\n",
      "Epoch 148/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5172 - accuracy: 0.4515 - val_loss: 2.5205 - val_accuracy: 0.4756\n",
      "Epoch 149/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5158 - accuracy: 0.4565 - val_loss: 2.5179 - val_accuracy: 0.4725\n",
      "Epoch 150/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5086 - accuracy: 0.4559 - val_loss: 2.5168 - val_accuracy: 0.4684\n",
      "Epoch 151/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5127 - accuracy: 0.4488 - val_loss: 2.5148 - val_accuracy: 0.4766\n",
      "Epoch 152/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5024 - accuracy: 0.4583 - val_loss: 2.5096 - val_accuracy: 0.4762\n",
      "Epoch 153/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4960 - accuracy: 0.4579 - val_loss: 2.5071 - val_accuracy: 0.4730\n",
      "Epoch 154/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5048 - accuracy: 0.4542 - val_loss: 2.5098 - val_accuracy: 0.4782\n",
      "Epoch 155/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4969 - accuracy: 0.4587 - val_loss: 2.5076 - val_accuracy: 0.4746\n",
      "Epoch 156/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4973 - accuracy: 0.4555 - val_loss: 2.5105 - val_accuracy: 0.4738\n",
      "Epoch 157/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4947 - accuracy: 0.4570 - val_loss: 2.5142 - val_accuracy: 0.4744\n",
      "Epoch 158/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4881 - accuracy: 0.4566 - val_loss: 2.5052 - val_accuracy: 0.4798\n",
      "Epoch 159/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4861 - accuracy: 0.4619 - val_loss: 2.5059 - val_accuracy: 0.4766\n",
      "Epoch 160/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4848 - accuracy: 0.4580 - val_loss: 2.5079 - val_accuracy: 0.4750\n",
      "Epoch 161/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4859 - accuracy: 0.4569 - val_loss: 2.5015 - val_accuracy: 0.4791\n",
      "Epoch 162/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4806 - accuracy: 0.4606 - val_loss: 2.5062 - val_accuracy: 0.4798\n",
      "Epoch 163/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4744 - accuracy: 0.4624 - val_loss: 2.4971 - val_accuracy: 0.4765\n",
      "Epoch 164/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4776 - accuracy: 0.4581 - val_loss: 2.5053 - val_accuracy: 0.4818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4855 - accuracy: 0.4581 - val_loss: 2.5085 - val_accuracy: 0.4692\n",
      "Epoch 166/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4923 - accuracy: 0.4517 - val_loss: 2.5290 - val_accuracy: 0.4780\n",
      "Epoch 167/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5005 - accuracy: 0.4592 - val_loss: 2.5154 - val_accuracy: 0.4731\n",
      "Epoch 168/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4918 - accuracy: 0.4584 - val_loss: 2.5057 - val_accuracy: 0.4724\n",
      "Epoch 169/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4857 - accuracy: 0.4539 - val_loss: 2.5061 - val_accuracy: 0.4797\n",
      "Epoch 170/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4733 - accuracy: 0.4622 - val_loss: 2.4962 - val_accuracy: 0.4794\n",
      "Epoch 171/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4668 - accuracy: 0.4611 - val_loss: 2.5039 - val_accuracy: 0.4770\n",
      "Epoch 172/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4774 - accuracy: 0.4616 - val_loss: 2.4914 - val_accuracy: 0.4803\n",
      "Epoch 173/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4744 - accuracy: 0.4614 - val_loss: 2.5018 - val_accuracy: 0.4843\n",
      "Epoch 174/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4687 - accuracy: 0.4621 - val_loss: 2.4950 - val_accuracy: 0.4816\n",
      "Epoch 175/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4563 - accuracy: 0.4648 - val_loss: 2.5019 - val_accuracy: 0.4821\n",
      "Epoch 176/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4683 - accuracy: 0.4635 - val_loss: 2.4962 - val_accuracy: 0.4770\n",
      "Epoch 177/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4661 - accuracy: 0.4573 - val_loss: 2.4970 - val_accuracy: 0.4838\n",
      "Epoch 178/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4624 - accuracy: 0.4652 - val_loss: 2.4927 - val_accuracy: 0.4822\n",
      "Epoch 179/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4618 - accuracy: 0.4617 - val_loss: 2.4946 - val_accuracy: 0.4798\n",
      "Epoch 180/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4569 - accuracy: 0.4630 - val_loss: 2.4871 - val_accuracy: 0.4821\n",
      "Epoch 181/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4533 - accuracy: 0.4639 - val_loss: 2.4835 - val_accuracy: 0.4830\n",
      "Epoch 182/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4503 - accuracy: 0.4653 - val_loss: 2.4781 - val_accuracy: 0.4808\n",
      "Epoch 183/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4460 - accuracy: 0.4652 - val_loss: 2.4920 - val_accuracy: 0.4852\n",
      "Epoch 184/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4522 - accuracy: 0.4678 - val_loss: 2.4836 - val_accuracy: 0.4816\n",
      "Epoch 185/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4528 - accuracy: 0.4637 - val_loss: 2.5271 - val_accuracy: 0.4754\n",
      "Epoch 186/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4875 - accuracy: 0.4594 - val_loss: 2.5077 - val_accuracy: 0.4814\n",
      "Epoch 187/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4675 - accuracy: 0.4633 - val_loss: 2.5003 - val_accuracy: 0.4774\n",
      "Epoch 188/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4748 - accuracy: 0.4577 - val_loss: 2.4965 - val_accuracy: 0.4780\n",
      "Epoch 189/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4640 - accuracy: 0.4616 - val_loss: 2.4960 - val_accuracy: 0.4847\n",
      "Epoch 190/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4693 - accuracy: 0.4646 - val_loss: 2.4890 - val_accuracy: 0.4811\n",
      "Epoch 191/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4597 - accuracy: 0.4619 - val_loss: 2.4962 - val_accuracy: 0.4838\n",
      "Epoch 192/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4701 - accuracy: 0.4643 - val_loss: 2.4889 - val_accuracy: 0.4810\n",
      "Epoch 193/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4578 - accuracy: 0.4646 - val_loss: 2.4922 - val_accuracy: 0.4798\n",
      "Epoch 194/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4669 - accuracy: 0.4599 - val_loss: 2.4882 - val_accuracy: 0.4831\n",
      "Epoch 195/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4546 - accuracy: 0.4651 - val_loss: 2.5163 - val_accuracy: 0.4792\n",
      "Epoch 196/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4618 - accuracy: 0.4647 - val_loss: 2.5031 - val_accuracy: 0.4787\n",
      "Epoch 197/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4558 - accuracy: 0.4639 - val_loss: 2.4961 - val_accuracy: 0.4854\n",
      "Epoch 198/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4546 - accuracy: 0.4648 - val_loss: 2.4913 - val_accuracy: 0.4795\n",
      "Epoch 199/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4619 - accuracy: 0.4633 - val_loss: 2.4856 - val_accuracy: 0.4797\n",
      "Epoch 200/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4403 - accuracy: 0.4641 - val_loss: 2.5042 - val_accuracy: 0.4834\n",
      "Epoch 201/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4473 - accuracy: 0.4662 - val_loss: 2.4821 - val_accuracy: 0.4838\n",
      "Epoch 202/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4358 - accuracy: 0.4673 - val_loss: 2.4881 - val_accuracy: 0.4876\n",
      "Epoch 203/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4360 - accuracy: 0.4700 - val_loss: 2.4788 - val_accuracy: 0.4848\n",
      "Epoch 204/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4352 - accuracy: 0.4671 - val_loss: 2.4779 - val_accuracy: 0.4844\n",
      "Epoch 205/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4288 - accuracy: 0.4701 - val_loss: 2.4961 - val_accuracy: 0.4854\n",
      "Epoch 206/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4367 - accuracy: 0.4677 - val_loss: 2.4755 - val_accuracy: 0.4839\n",
      "Epoch 207/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4234 - accuracy: 0.4681 - val_loss: 2.4791 - val_accuracy: 0.4875\n",
      "Epoch 208/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4188 - accuracy: 0.4700 - val_loss: 2.4801 - val_accuracy: 0.4885\n",
      "Epoch 209/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4219 - accuracy: 0.4695 - val_loss: 2.4745 - val_accuracy: 0.4860\n",
      "Epoch 210/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4207 - accuracy: 0.4709 - val_loss: 2.4853 - val_accuracy: 0.4895\n",
      "Epoch 211/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4231 - accuracy: 0.4725 - val_loss: 2.4811 - val_accuracy: 0.4831\n",
      "Epoch 212/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4258 - accuracy: 0.4671 - val_loss: 2.4884 - val_accuracy: 0.4884\n",
      "Epoch 213/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4270 - accuracy: 0.4709 - val_loss: 2.4786 - val_accuracy: 0.4854\n",
      "Epoch 214/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.4266 - accuracy: 0.4687 - val_loss: 2.4915 - val_accuracy: 0.4793\n",
      "Epoch 215/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4407 - accuracy: 0.4653 - val_loss: 2.4906 - val_accuracy: 0.4877\n",
      "Epoch 216/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4358 - accuracy: 0.4729 - val_loss: 2.4952 - val_accuracy: 0.4822\n",
      "Epoch 217/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4364 - accuracy: 0.4685 - val_loss: 2.4971 - val_accuracy: 0.4803\n",
      "Epoch 218/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4465 - accuracy: 0.4643 - val_loss: 2.5072 - val_accuracy: 0.4843\n",
      "Epoch 219/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4528 - accuracy: 0.4659 - val_loss: 2.4913 - val_accuracy: 0.4850\n",
      "Epoch 220/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4352 - accuracy: 0.4681 - val_loss: 2.4960 - val_accuracy: 0.4848\n",
      "Epoch 221/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4470 - accuracy: 0.4652 - val_loss: 2.4959 - val_accuracy: 0.4804\n",
      "Epoch 222/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4349 - accuracy: 0.4670 - val_loss: 2.4815 - val_accuracy: 0.4871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4256 - accuracy: 0.4715 - val_loss: 2.4769 - val_accuracy: 0.4905\n",
      "Epoch 224/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4180 - accuracy: 0.4731 - val_loss: 2.4785 - val_accuracy: 0.4795\n",
      "Epoch 225/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4300 - accuracy: 0.4634 - val_loss: 2.4896 - val_accuracy: 0.4892\n",
      "Epoch 226/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4151 - accuracy: 0.4757 - val_loss: 2.4640 - val_accuracy: 0.4835\n",
      "Epoch 227/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4176 - accuracy: 0.4667 - val_loss: 2.4679 - val_accuracy: 0.4855\n",
      "Epoch 228/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4117 - accuracy: 0.4705 - val_loss: 2.4921 - val_accuracy: 0.4884\n",
      "Epoch 229/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4116 - accuracy: 0.4747 - val_loss: 2.4678 - val_accuracy: 0.4841\n",
      "Epoch 230/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4181 - accuracy: 0.4668 - val_loss: 2.4745 - val_accuracy: 0.4884\n",
      "Epoch 231/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4121 - accuracy: 0.4705 - val_loss: 2.4763 - val_accuracy: 0.4908\n",
      "Epoch 232/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4088 - accuracy: 0.4742 - val_loss: 2.4664 - val_accuracy: 0.4817\n",
      "Epoch 233/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4081 - accuracy: 0.4673 - val_loss: 2.4718 - val_accuracy: 0.4881\n",
      "Epoch 234/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3947 - accuracy: 0.4740 - val_loss: 2.4757 - val_accuracy: 0.4878\n",
      "Epoch 235/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4106 - accuracy: 0.4733 - val_loss: 2.4708 - val_accuracy: 0.4837\n",
      "Epoch 236/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4082 - accuracy: 0.4689 - val_loss: 2.4725 - val_accuracy: 0.4875\n",
      "Epoch 237/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4017 - accuracy: 0.4736 - val_loss: 2.4711 - val_accuracy: 0.4902\n",
      "Epoch 238/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3930 - accuracy: 0.4760 - val_loss: 2.4621 - val_accuracy: 0.4849\n",
      "Epoch 239/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3994 - accuracy: 0.4707 - val_loss: 2.4772 - val_accuracy: 0.4906\n",
      "Epoch 240/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4010 - accuracy: 0.4757 - val_loss: 2.4736 - val_accuracy: 0.4882\n",
      "Epoch 241/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3986 - accuracy: 0.4730 - val_loss: 2.4595 - val_accuracy: 0.4880\n",
      "Epoch 242/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3943 - accuracy: 0.4723 - val_loss: 2.4690 - val_accuracy: 0.4896\n",
      "Epoch 243/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3906 - accuracy: 0.4763 - val_loss: 2.4617 - val_accuracy: 0.4885\n",
      "Epoch 244/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3875 - accuracy: 0.4735 - val_loss: 2.4583 - val_accuracy: 0.4942\n",
      "Epoch 245/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3893 - accuracy: 0.4767 - val_loss: 2.4658 - val_accuracy: 0.4895\n",
      "Epoch 246/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3925 - accuracy: 0.4736 - val_loss: 2.4688 - val_accuracy: 0.4873\n",
      "Epoch 247/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3878 - accuracy: 0.4748 - val_loss: 2.4620 - val_accuracy: 0.4898\n",
      "Epoch 248/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3951 - accuracy: 0.4739 - val_loss: 2.4653 - val_accuracy: 0.4899\n",
      "Epoch 249/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3939 - accuracy: 0.4742 - val_loss: 2.4666 - val_accuracy: 0.4858\n",
      "Epoch 250/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3896 - accuracy: 0.4751 - val_loss: 2.4885 - val_accuracy: 0.4900\n",
      "Epoch 251/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4037 - accuracy: 0.4765 - val_loss: 2.4728 - val_accuracy: 0.4805\n",
      "Epoch 252/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4066 - accuracy: 0.4686 - val_loss: 2.4937 - val_accuracy: 0.4937\n",
      "Epoch 253/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4042 - accuracy: 0.4783 - val_loss: 2.4764 - val_accuracy: 0.4823\n",
      "Epoch 254/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4237 - accuracy: 0.4669 - val_loss: 2.4865 - val_accuracy: 0.4878\n",
      "Epoch 255/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4080 - accuracy: 0.4757 - val_loss: 2.4697 - val_accuracy: 0.4837\n",
      "Epoch 256/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3992 - accuracy: 0.4727 - val_loss: 2.4758 - val_accuracy: 0.4866\n",
      "Epoch 257/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4043 - accuracy: 0.4731 - val_loss: 2.4772 - val_accuracy: 0.4899\n",
      "Epoch 258/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4118 - accuracy: 0.4738 - val_loss: 2.5001 - val_accuracy: 0.4888\n",
      "Epoch 259/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4237 - accuracy: 0.4758 - val_loss: 2.4697 - val_accuracy: 0.4819\n",
      "Epoch 260/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3960 - accuracy: 0.4718 - val_loss: 2.4873 - val_accuracy: 0.4863\n",
      "Epoch 261/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4206 - accuracy: 0.4730 - val_loss: 2.5164 - val_accuracy: 0.4867\n",
      "Epoch 262/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4360 - accuracy: 0.4737 - val_loss: 2.4807 - val_accuracy: 0.4784\n",
      "Epoch 263/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4160 - accuracy: 0.4648 - val_loss: 2.4981 - val_accuracy: 0.4892\n",
      "Epoch 264/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4278 - accuracy: 0.4730 - val_loss: 2.4842 - val_accuracy: 0.4879\n",
      "Epoch 265/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4145 - accuracy: 0.4733 - val_loss: 2.4823 - val_accuracy: 0.4691\n",
      "Epoch 266/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4208 - accuracy: 0.4620 - val_loss: 2.5322 - val_accuracy: 0.4844\n",
      "Epoch 267/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4391 - accuracy: 0.4761 - val_loss: 2.4860 - val_accuracy: 0.4841\n",
      "Epoch 268/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4107 - accuracy: 0.4714 - val_loss: 2.4646 - val_accuracy: 0.4821\n",
      "Epoch 269/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4099 - accuracy: 0.4679 - val_loss: 2.4858 - val_accuracy: 0.4935\n",
      "Epoch 270/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4182 - accuracy: 0.4793 - val_loss: 2.4637 - val_accuracy: 0.4889\n",
      "Epoch 271/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3864 - accuracy: 0.4774 - val_loss: 2.4669 - val_accuracy: 0.4819\n",
      "Epoch 272/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3961 - accuracy: 0.4689 - val_loss: 2.4689 - val_accuracy: 0.4892\n",
      "Epoch 273/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3823 - accuracy: 0.4784 - val_loss: 2.4717 - val_accuracy: 0.4899\n",
      "Epoch 274/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3857 - accuracy: 0.4790 - val_loss: 2.4568 - val_accuracy: 0.4897\n",
      "Epoch 275/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3851 - accuracy: 0.4745 - val_loss: 2.4670 - val_accuracy: 0.4947\n",
      "Epoch 276/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3874 - accuracy: 0.4779 - val_loss: 2.4742 - val_accuracy: 0.4907\n",
      "Epoch 277/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3832 - accuracy: 0.4780 - val_loss: 2.4598 - val_accuracy: 0.4884\n",
      "Epoch 278/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3761 - accuracy: 0.4762 - val_loss: 2.4542 - val_accuracy: 0.4891\n",
      "Epoch 279/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3697 - accuracy: 0.4771 - val_loss: 2.4635 - val_accuracy: 0.4938\n",
      "Epoch 280/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3728 - accuracy: 0.4804 - val_loss: 2.4665 - val_accuracy: 0.4931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3723 - accuracy: 0.4802 - val_loss: 2.4555 - val_accuracy: 0.4866\n",
      "Epoch 282/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3753 - accuracy: 0.4732 - val_loss: 2.4701 - val_accuracy: 0.4969\n",
      "Epoch 283/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3729 - accuracy: 0.4831 - val_loss: 2.4449 - val_accuracy: 0.4900\n",
      "Epoch 284/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3687 - accuracy: 0.4775 - val_loss: 2.4470 - val_accuracy: 0.4922\n",
      "Epoch 285/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3690 - accuracy: 0.4777 - val_loss: 2.4676 - val_accuracy: 0.4917\n",
      "Epoch 286/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3700 - accuracy: 0.4812 - val_loss: 2.4512 - val_accuracy: 0.4920\n",
      "Epoch 287/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3627 - accuracy: 0.4791 - val_loss: 2.4501 - val_accuracy: 0.4889\n",
      "Epoch 288/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3640 - accuracy: 0.4760 - val_loss: 2.4749 - val_accuracy: 0.4920\n",
      "Epoch 289/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3720 - accuracy: 0.4811 - val_loss: 2.4513 - val_accuracy: 0.4913\n",
      "Epoch 290/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3630 - accuracy: 0.4781 - val_loss: 2.4485 - val_accuracy: 0.4882\n",
      "Epoch 291/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3581 - accuracy: 0.4779 - val_loss: 2.4654 - val_accuracy: 0.4955\n",
      "Epoch 292/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3543 - accuracy: 0.4846 - val_loss: 2.4570 - val_accuracy: 0.4914\n",
      "Epoch 293/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3573 - accuracy: 0.4813 - val_loss: 2.4559 - val_accuracy: 0.4927\n",
      "Epoch 294/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3671 - accuracy: 0.4782 - val_loss: 2.4675 - val_accuracy: 0.4886\n",
      "Epoch 295/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3627 - accuracy: 0.4815 - val_loss: 2.4541 - val_accuracy: 0.4906\n",
      "Epoch 296/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3591 - accuracy: 0.4807 - val_loss: 2.4580 - val_accuracy: 0.4899\n",
      "Epoch 297/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3584 - accuracy: 0.4797 - val_loss: 2.4537 - val_accuracy: 0.4937\n",
      "Epoch 298/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3592 - accuracy: 0.4817 - val_loss: 2.4542 - val_accuracy: 0.4912\n",
      "Epoch 299/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3528 - accuracy: 0.4824 - val_loss: 2.4562 - val_accuracy: 0.4886\n",
      "Epoch 300/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3581 - accuracy: 0.4789 - val_loss: 2.4586 - val_accuracy: 0.4939\n",
      "Epoch 301/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3571 - accuracy: 0.4838 - val_loss: 2.4559 - val_accuracy: 0.4898\n",
      "Epoch 302/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3578 - accuracy: 0.4805 - val_loss: 2.4639 - val_accuracy: 0.4943\n",
      "Epoch 303/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3560 - accuracy: 0.4842 - val_loss: 2.4557 - val_accuracy: 0.4909\n",
      "Epoch 304/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3557 - accuracy: 0.4808 - val_loss: 2.4520 - val_accuracy: 0.4890\n",
      "Epoch 305/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3507 - accuracy: 0.4795 - val_loss: 2.4655 - val_accuracy: 0.4961\n",
      "Epoch 306/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3609 - accuracy: 0.4839 - val_loss: 2.4624 - val_accuracy: 0.4872\n",
      "Epoch 307/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3556 - accuracy: 0.4799 - val_loss: 2.4640 - val_accuracy: 0.4926\n",
      "Epoch 308/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3570 - accuracy: 0.4804 - val_loss: 2.4697 - val_accuracy: 0.4911\n",
      "Epoch 309/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3708 - accuracy: 0.4816 - val_loss: 2.4653 - val_accuracy: 0.4871\n",
      "Epoch 310/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3564 - accuracy: 0.4808 - val_loss: 2.4583 - val_accuracy: 0.4915\n",
      "Epoch 311/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3575 - accuracy: 0.4804 - val_loss: 2.4551 - val_accuracy: 0.4949\n",
      "Epoch 312/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3477 - accuracy: 0.4834 - val_loss: 2.4615 - val_accuracy: 0.4919\n",
      "Epoch 313/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3627 - accuracy: 0.4809 - val_loss: 2.4562 - val_accuracy: 0.4925\n",
      "Epoch 314/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3466 - accuracy: 0.4854 - val_loss: 2.4547 - val_accuracy: 0.4891\n",
      "Epoch 315/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3537 - accuracy: 0.4800 - val_loss: 2.4541 - val_accuracy: 0.4946\n",
      "Epoch 316/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3388 - accuracy: 0.4849 - val_loss: 2.4532 - val_accuracy: 0.4961\n",
      "Epoch 317/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3407 - accuracy: 0.4840 - val_loss: 2.4508 - val_accuracy: 0.4920\n",
      "Epoch 318/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3531 - accuracy: 0.4805 - val_loss: 2.4566 - val_accuracy: 0.4935\n",
      "Epoch 319/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3441 - accuracy: 0.4844 - val_loss: 2.4528 - val_accuracy: 0.4897\n",
      "Epoch 320/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3435 - accuracy: 0.4833 - val_loss: 2.4568 - val_accuracy: 0.4882\n",
      "Epoch 321/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3518 - accuracy: 0.4796 - val_loss: 2.4573 - val_accuracy: 0.4976\n",
      "Epoch 322/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3422 - accuracy: 0.4867 - val_loss: 2.4662 - val_accuracy: 0.4930\n",
      "Epoch 323/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3440 - accuracy: 0.4859 - val_loss: 2.4494 - val_accuracy: 0.4900\n",
      "Epoch 324/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3470 - accuracy: 0.4792 - val_loss: 2.4606 - val_accuracy: 0.4969\n",
      "Epoch 325/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3432 - accuracy: 0.4840 - val_loss: 2.4621 - val_accuracy: 0.4937\n",
      "Epoch 326/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3517 - accuracy: 0.4833 - val_loss: 2.4516 - val_accuracy: 0.4943\n",
      "Epoch 327/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3551 - accuracy: 0.4828 - val_loss: 2.4674 - val_accuracy: 0.4900\n",
      "Epoch 328/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3542 - accuracy: 0.4828 - val_loss: 2.4554 - val_accuracy: 0.4948\n",
      "Epoch 329/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3369 - accuracy: 0.4849 - val_loss: 2.4479 - val_accuracy: 0.4908\n",
      "Epoch 330/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3544 - accuracy: 0.4812 - val_loss: 2.4606 - val_accuracy: 0.4898\n",
      "Epoch 331/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3489 - accuracy: 0.4843 - val_loss: 2.4647 - val_accuracy: 0.4932\n",
      "Epoch 332/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3496 - accuracy: 0.4835 - val_loss: 2.4513 - val_accuracy: 0.4931\n",
      "Epoch 333/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3528 - accuracy: 0.4817 - val_loss: 2.4474 - val_accuracy: 0.4948\n",
      "Epoch 334/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3423 - accuracy: 0.4846 - val_loss: 2.4686 - val_accuracy: 0.4932\n",
      "Epoch 335/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3534 - accuracy: 0.4837 - val_loss: 2.4574 - val_accuracy: 0.4915\n",
      "Epoch 336/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3523 - accuracy: 0.4785 - val_loss: 2.4618 - val_accuracy: 0.4920\n",
      "Epoch 337/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3525 - accuracy: 0.4829 - val_loss: 2.4541 - val_accuracy: 0.4880\n",
      "Epoch 338/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3531 - accuracy: 0.4776 - val_loss: 2.4634 - val_accuracy: 0.4935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3499 - accuracy: 0.4828 - val_loss: 2.4650 - val_accuracy: 0.4961\n",
      "Epoch 340/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3381 - accuracy: 0.4880 - val_loss: 2.4582 - val_accuracy: 0.4876\n",
      "Epoch 341/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3484 - accuracy: 0.4786 - val_loss: 2.4667 - val_accuracy: 0.4923\n",
      "Epoch 342/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3459 - accuracy: 0.4832 - val_loss: 2.4623 - val_accuracy: 0.4900\n",
      "Epoch 343/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3408 - accuracy: 0.4833 - val_loss: 2.4451 - val_accuracy: 0.4889\n",
      "Epoch 344/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3473 - accuracy: 0.4785 - val_loss: 2.4715 - val_accuracy: 0.4974\n",
      "Epoch 345/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3551 - accuracy: 0.4863 - val_loss: 2.4551 - val_accuracy: 0.4889\n",
      "Epoch 346/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3427 - accuracy: 0.4831 - val_loss: 2.4528 - val_accuracy: 0.4887\n",
      "Epoch 347/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3496 - accuracy: 0.4805 - val_loss: 2.4687 - val_accuracy: 0.4969\n",
      "Epoch 348/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3468 - accuracy: 0.4860 - val_loss: 2.4525 - val_accuracy: 0.4892\n",
      "Epoch 349/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3465 - accuracy: 0.4813 - val_loss: 2.4546 - val_accuracy: 0.4898\n",
      "Epoch 350/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3437 - accuracy: 0.4839 - val_loss: 2.4698 - val_accuracy: 0.4926\n",
      "Epoch 351/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3549 - accuracy: 0.4839 - val_loss: 2.4661 - val_accuracy: 0.4923\n",
      "Epoch 352/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3355 - accuracy: 0.4865 - val_loss: 2.4614 - val_accuracy: 0.4912\n",
      "Epoch 353/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3311 - accuracy: 0.4853 - val_loss: 2.4543 - val_accuracy: 0.4888\n",
      "Epoch 354/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3396 - accuracy: 0.4811 - val_loss: 2.4771 - val_accuracy: 0.4946\n",
      "Epoch 355/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3385 - accuracy: 0.4878 - val_loss: 2.4657 - val_accuracy: 0.4869\n",
      "Epoch 356/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3388 - accuracy: 0.4817 - val_loss: 2.4612 - val_accuracy: 0.4934\n",
      "Epoch 357/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3296 - accuracy: 0.4862 - val_loss: 2.4670 - val_accuracy: 0.4944\n",
      "Epoch 358/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3397 - accuracy: 0.4861 - val_loss: 2.4584 - val_accuracy: 0.4923\n",
      "Epoch 359/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3362 - accuracy: 0.4844 - val_loss: 2.4735 - val_accuracy: 0.4921\n",
      "Epoch 360/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3398 - accuracy: 0.4855 - val_loss: 2.4613 - val_accuracy: 0.4935\n",
      "Epoch 361/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3312 - accuracy: 0.4860 - val_loss: 2.4512 - val_accuracy: 0.4917\n",
      "Epoch 362/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3396 - accuracy: 0.4819 - val_loss: 2.4742 - val_accuracy: 0.4974\n",
      "Epoch 363/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3380 - accuracy: 0.4874 - val_loss: 2.4518 - val_accuracy: 0.4947\n",
      "Epoch 364/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3281 - accuracy: 0.4842 - val_loss: 2.4630 - val_accuracy: 0.4962\n",
      "Epoch 365/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3371 - accuracy: 0.4846 - val_loss: 2.4587 - val_accuracy: 0.4923\n",
      "Epoch 366/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3281 - accuracy: 0.4847 - val_loss: 2.4427 - val_accuracy: 0.4918\n",
      "Epoch 367/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3247 - accuracy: 0.4855 - val_loss: 2.4502 - val_accuracy: 0.4937\n",
      "Epoch 368/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3261 - accuracy: 0.4880 - val_loss: 2.4602 - val_accuracy: 0.4925\n",
      "Epoch 369/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3295 - accuracy: 0.4826 - val_loss: 2.4521 - val_accuracy: 0.4971\n",
      "Epoch 370/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3174 - accuracy: 0.4884 - val_loss: 2.4471 - val_accuracy: 0.4928\n",
      "Epoch 371/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3298 - accuracy: 0.4850 - val_loss: 2.4438 - val_accuracy: 0.4970\n",
      "Epoch 372/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3114 - accuracy: 0.4887 - val_loss: 2.4637 - val_accuracy: 0.4992\n",
      "Epoch 373/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3227 - accuracy: 0.4892 - val_loss: 2.4404 - val_accuracy: 0.4966\n",
      "Epoch 374/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3156 - accuracy: 0.4857 - val_loss: 2.4485 - val_accuracy: 0.4969\n",
      "Epoch 375/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3213 - accuracy: 0.4878 - val_loss: 2.4625 - val_accuracy: 0.4924\n",
      "Epoch 376/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3291 - accuracy: 0.4867 - val_loss: 2.4526 - val_accuracy: 0.4933\n",
      "Epoch 377/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3187 - accuracy: 0.4880 - val_loss: 2.4607 - val_accuracy: 0.4946\n",
      "Epoch 378/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3178 - accuracy: 0.4883 - val_loss: 2.4545 - val_accuracy: 0.4978\n",
      "Epoch 379/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3188 - accuracy: 0.4900 - val_loss: 2.4507 - val_accuracy: 0.4923\n",
      "Epoch 380/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3238 - accuracy: 0.4868 - val_loss: 2.4515 - val_accuracy: 0.4931\n",
      "Epoch 381/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3153 - accuracy: 0.4882 - val_loss: 2.4668 - val_accuracy: 0.4947\n",
      "Epoch 382/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3274 - accuracy: 0.4866 - val_loss: 2.4519 - val_accuracy: 0.4902\n",
      "Epoch 383/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3284 - accuracy: 0.4814 - val_loss: 2.4697 - val_accuracy: 0.4961\n",
      "Epoch 384/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3262 - accuracy: 0.4913 - val_loss: 2.4510 - val_accuracy: 0.4925\n",
      "Epoch 385/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3243 - accuracy: 0.4854 - val_loss: 2.4630 - val_accuracy: 0.4981\n",
      "Epoch 386/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3333 - accuracy: 0.4871 - val_loss: 2.4566 - val_accuracy: 0.4971\n",
      "Epoch 387/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3247 - accuracy: 0.4873 - val_loss: 2.4530 - val_accuracy: 0.4907\n",
      "Epoch 388/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3165 - accuracy: 0.4871 - val_loss: 2.4496 - val_accuracy: 0.4920\n",
      "Epoch 389/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3242 - accuracy: 0.4840 - val_loss: 2.4633 - val_accuracy: 0.4950\n",
      "Epoch 390/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3177 - accuracy: 0.4903 - val_loss: 2.4498 - val_accuracy: 0.4931\n",
      "Epoch 391/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3250 - accuracy: 0.4836 - val_loss: 2.4661 - val_accuracy: 0.4908\n",
      "Epoch 392/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3256 - accuracy: 0.4862 - val_loss: 2.4578 - val_accuracy: 0.4954\n",
      "Epoch 393/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3200 - accuracy: 0.4874 - val_loss: 2.4467 - val_accuracy: 0.4926\n",
      "Epoch 394/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3111 - accuracy: 0.4874 - val_loss: 2.4582 - val_accuracy: 0.4927\n",
      "Epoch 395/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3222 - accuracy: 0.4861 - val_loss: 2.4557 - val_accuracy: 0.4951\n",
      "Epoch 396/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3081 - accuracy: 0.4902 - val_loss: 2.4595 - val_accuracy: 0.4882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3217 - accuracy: 0.4855 - val_loss: 2.4556 - val_accuracy: 0.4933\n",
      "Epoch 398/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3232 - accuracy: 0.4873 - val_loss: 2.4498 - val_accuracy: 0.4917\n",
      "Epoch 399/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3184 - accuracy: 0.4854 - val_loss: 2.4495 - val_accuracy: 0.4909\n",
      "Epoch 400/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3121 - accuracy: 0.4873 - val_loss: 2.4479 - val_accuracy: 0.4966\n",
      "Epoch 401/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3108 - accuracy: 0.4910 - val_loss: 2.4513 - val_accuracy: 0.4961\n",
      "Epoch 402/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3216 - accuracy: 0.4877 - val_loss: 2.4478 - val_accuracy: 0.4935\n",
      "Epoch 403/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3123 - accuracy: 0.4890 - val_loss: 2.4566 - val_accuracy: 0.4890\n",
      "Epoch 404/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3185 - accuracy: 0.4860 - val_loss: 2.4616 - val_accuracy: 0.4944\n",
      "Epoch 405/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3142 - accuracy: 0.4886 - val_loss: 2.4446 - val_accuracy: 0.4962\n",
      "Epoch 406/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3103 - accuracy: 0.4880 - val_loss: 2.4549 - val_accuracy: 0.4968\n",
      "Epoch 407/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3092 - accuracy: 0.4908 - val_loss: 2.4517 - val_accuracy: 0.4939\n",
      "Epoch 408/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3001 - accuracy: 0.4919 - val_loss: 2.4542 - val_accuracy: 0.4910\n",
      "Epoch 409/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3081 - accuracy: 0.4895 - val_loss: 2.4539 - val_accuracy: 0.4920\n",
      "Epoch 410/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3184 - accuracy: 0.4851 - val_loss: 2.4627 - val_accuracy: 0.4916\n",
      "Epoch 411/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3112 - accuracy: 0.4871 - val_loss: 2.4585 - val_accuracy: 0.4885\n",
      "Epoch 412/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3129 - accuracy: 0.4849 - val_loss: 2.4710 - val_accuracy: 0.4963\n",
      "Epoch 413/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3202 - accuracy: 0.4914 - val_loss: 2.4475 - val_accuracy: 0.4917\n",
      "Epoch 414/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3153 - accuracy: 0.4857 - val_loss: 2.4549 - val_accuracy: 0.4925\n",
      "Epoch 415/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3108 - accuracy: 0.4880 - val_loss: 2.4631 - val_accuracy: 0.4922\n",
      "Epoch 416/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3202 - accuracy: 0.4854 - val_loss: 2.4538 - val_accuracy: 0.4887\n",
      "Epoch 417/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3109 - accuracy: 0.4852 - val_loss: 2.4631 - val_accuracy: 0.4918\n",
      "Epoch 418/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3123 - accuracy: 0.4881 - val_loss: 2.4590 - val_accuracy: 0.4905\n",
      "Epoch 419/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3188 - accuracy: 0.4843 - val_loss: 2.4791 - val_accuracy: 0.4937\n",
      "Epoch 420/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3214 - accuracy: 0.4902 - val_loss: 2.4571 - val_accuracy: 0.4901\n",
      "Epoch 421/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3218 - accuracy: 0.4849 - val_loss: 2.4532 - val_accuracy: 0.4945\n",
      "Epoch 422/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3129 - accuracy: 0.4879 - val_loss: 2.4590 - val_accuracy: 0.4936\n",
      "Epoch 423/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3081 - accuracy: 0.4907 - val_loss: 2.4630 - val_accuracy: 0.4898\n",
      "Epoch 424/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3165 - accuracy: 0.4848 - val_loss: 2.4618 - val_accuracy: 0.4979\n",
      "Epoch 425/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3040 - accuracy: 0.4917 - val_loss: 2.4580 - val_accuracy: 0.4950\n",
      "Epoch 426/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3093 - accuracy: 0.4897 - val_loss: 2.4606 - val_accuracy: 0.4915\n",
      "Epoch 427/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3101 - accuracy: 0.4875 - val_loss: 2.4586 - val_accuracy: 0.4941\n",
      "Epoch 428/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3056 - accuracy: 0.4912 - val_loss: 2.4495 - val_accuracy: 0.4934\n",
      "Epoch 429/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3187 - accuracy: 0.4861 - val_loss: 2.4629 - val_accuracy: 0.4977\n",
      "Epoch 430/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3099 - accuracy: 0.4920 - val_loss: 2.4491 - val_accuracy: 0.4877\n",
      "Epoch 431/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3154 - accuracy: 0.4839 - val_loss: 2.4594 - val_accuracy: 0.4971\n",
      "Epoch 432/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3070 - accuracy: 0.4925 - val_loss: 2.4540 - val_accuracy: 0.4931\n",
      "Epoch 433/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3227 - accuracy: 0.4868 - val_loss: 2.4696 - val_accuracy: 0.4877\n",
      "Epoch 434/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3194 - accuracy: 0.4864 - val_loss: 2.4702 - val_accuracy: 0.4970\n",
      "Epoch 435/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3181 - accuracy: 0.4919 - val_loss: 2.4536 - val_accuracy: 0.4902\n",
      "Epoch 436/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3123 - accuracy: 0.4875 - val_loss: 2.4663 - val_accuracy: 0.4953\n",
      "Epoch 437/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3044 - accuracy: 0.4904 - val_loss: 2.4611 - val_accuracy: 0.4948\n",
      "Epoch 438/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2995 - accuracy: 0.4926 - val_loss: 2.4617 - val_accuracy: 0.4919\n",
      "Epoch 439/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3189 - accuracy: 0.4863 - val_loss: 2.4520 - val_accuracy: 0.4964\n",
      "Epoch 440/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3020 - accuracy: 0.4906 - val_loss: 2.4542 - val_accuracy: 0.4942\n",
      "Epoch 441/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2989 - accuracy: 0.4917 - val_loss: 2.4619 - val_accuracy: 0.4900\n",
      "Epoch 442/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3087 - accuracy: 0.4887 - val_loss: 2.4520 - val_accuracy: 0.4922\n",
      "Epoch 443/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3025 - accuracy: 0.4908 - val_loss: 2.4505 - val_accuracy: 0.4960\n",
      "Epoch 444/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2998 - accuracy: 0.4916 - val_loss: 2.4443 - val_accuracy: 0.4913\n",
      "Epoch 445/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3013 - accuracy: 0.4886 - val_loss: 2.4552 - val_accuracy: 0.4961\n",
      "Epoch 446/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2963 - accuracy: 0.4917 - val_loss: 2.4552 - val_accuracy: 0.4985\n",
      "Epoch 447/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3002 - accuracy: 0.4911 - val_loss: 2.4490 - val_accuracy: 0.4978\n",
      "Epoch 448/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2987 - accuracy: 0.4927 - val_loss: 2.4536 - val_accuracy: 0.4902\n",
      "Epoch 449/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3032 - accuracy: 0.4898 - val_loss: 2.4522 - val_accuracy: 0.4930\n",
      "Epoch 450/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3010 - accuracy: 0.4896 - val_loss: 2.4608 - val_accuracy: 0.4955\n",
      "Epoch 451/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3021 - accuracy: 0.4905 - val_loss: 2.4498 - val_accuracy: 0.4936\n",
      "Epoch 452/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3000 - accuracy: 0.4885 - val_loss: 2.4605 - val_accuracy: 0.4969\n",
      "Epoch 453/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3069 - accuracy: 0.4923 - val_loss: 2.4590 - val_accuracy: 0.4895\n",
      "Epoch 454/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3107 - accuracy: 0.4857 - val_loss: 2.4954 - val_accuracy: 0.4955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3207 - accuracy: 0.4935 - val_loss: 2.4631 - val_accuracy: 0.4958\n",
      "Epoch 456/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3044 - accuracy: 0.4924 - val_loss: 2.4592 - val_accuracy: 0.4900\n",
      "Epoch 457/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3247 - accuracy: 0.4829 - val_loss: 2.5007 - val_accuracy: 0.4942\n",
      "Epoch 458/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3379 - accuracy: 0.4884 - val_loss: 2.4839 - val_accuracy: 0.4922\n",
      "Epoch 459/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3184 - accuracy: 0.4884 - val_loss: 2.4686 - val_accuracy: 0.4850\n",
      "Epoch 460/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3475 - accuracy: 0.4796 - val_loss: 2.4905 - val_accuracy: 0.4879\n",
      "Epoch 461/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3458 - accuracy: 0.4838 - val_loss: 2.4800 - val_accuracy: 0.4868\n",
      "Epoch 462/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3276 - accuracy: 0.4861 - val_loss: 2.4901 - val_accuracy: 0.4881\n",
      "Epoch 463/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3529 - accuracy: 0.4811 - val_loss: 2.4685 - val_accuracy: 0.4892\n",
      "Epoch 464/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3409 - accuracy: 0.4850 - val_loss: 2.4810 - val_accuracy: 0.4915\n",
      "Epoch 465/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3405 - accuracy: 0.4878 - val_loss: 2.4620 - val_accuracy: 0.4880\n",
      "Epoch 466/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3369 - accuracy: 0.4824 - val_loss: 2.4893 - val_accuracy: 0.4910\n",
      "Epoch 467/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3438 - accuracy: 0.4884 - val_loss: 2.5085 - val_accuracy: 0.4930\n",
      "Epoch 468/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3531 - accuracy: 0.4862 - val_loss: 2.4618 - val_accuracy: 0.4852\n",
      "Epoch 469/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3468 - accuracy: 0.4782 - val_loss: 2.4722 - val_accuracy: 0.4864\n",
      "Epoch 470/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3309 - accuracy: 0.4845 - val_loss: 2.4940 - val_accuracy: 0.4895\n",
      "Epoch 471/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3278 - accuracy: 0.4879 - val_loss: 2.4700 - val_accuracy: 0.4907\n",
      "Epoch 472/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3305 - accuracy: 0.4842 - val_loss: 2.4767 - val_accuracy: 0.4944\n",
      "Epoch 473/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3206 - accuracy: 0.4889 - val_loss: 2.4822 - val_accuracy: 0.4872\n",
      "Epoch 474/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3222 - accuracy: 0.4854 - val_loss: 2.4726 - val_accuracy: 0.4890\n",
      "Epoch 475/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3318 - accuracy: 0.4850 - val_loss: 2.4700 - val_accuracy: 0.4895\n",
      "Epoch 476/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3226 - accuracy: 0.4857 - val_loss: 2.4561 - val_accuracy: 0.4893\n",
      "Epoch 477/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3007 - accuracy: 0.4902 - val_loss: 2.4654 - val_accuracy: 0.4921\n",
      "Epoch 478/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3075 - accuracy: 0.4889 - val_loss: 2.4543 - val_accuracy: 0.4942\n",
      "Epoch 479/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3067 - accuracy: 0.4895 - val_loss: 2.4552 - val_accuracy: 0.4959\n",
      "Epoch 480/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3050 - accuracy: 0.4897 - val_loss: 2.4642 - val_accuracy: 0.4929\n",
      "Epoch 481/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3065 - accuracy: 0.4915 - val_loss: 2.4569 - val_accuracy: 0.4928\n",
      "Epoch 482/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2974 - accuracy: 0.4893 - val_loss: 2.4571 - val_accuracy: 0.4973\n",
      "Epoch 483/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2996 - accuracy: 0.4921 - val_loss: 2.4573 - val_accuracy: 0.4954\n",
      "Epoch 484/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2963 - accuracy: 0.4909 - val_loss: 2.4586 - val_accuracy: 0.4943\n",
      "Epoch 485/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2860 - accuracy: 0.4919 - val_loss: 2.4639 - val_accuracy: 0.4972\n",
      "Epoch 486/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3054 - accuracy: 0.4930 - val_loss: 2.4474 - val_accuracy: 0.4901\n",
      "Epoch 487/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3057 - accuracy: 0.4840 - val_loss: 2.4702 - val_accuracy: 0.5006\n",
      "Epoch 488/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2997 - accuracy: 0.4955 - val_loss: 2.4505 - val_accuracy: 0.4919\n",
      "Epoch 489/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2960 - accuracy: 0.4881 - val_loss: 2.4680 - val_accuracy: 0.4935\n",
      "Epoch 490/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2934 - accuracy: 0.4934 - val_loss: 2.4629 - val_accuracy: 0.4920\n",
      "Epoch 491/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2923 - accuracy: 0.4927 - val_loss: 2.4469 - val_accuracy: 0.4927\n",
      "Epoch 492/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2944 - accuracy: 0.4891 - val_loss: 2.4662 - val_accuracy: 0.4978\n",
      "Epoch 493/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2908 - accuracy: 0.4961 - val_loss: 2.4467 - val_accuracy: 0.4926\n",
      "Epoch 494/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2967 - accuracy: 0.4899 - val_loss: 2.4592 - val_accuracy: 0.4928\n",
      "Epoch 495/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2941 - accuracy: 0.4913 - val_loss: 2.4556 - val_accuracy: 0.4977\n",
      "Epoch 496/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2818 - accuracy: 0.4958 - val_loss: 2.4415 - val_accuracy: 0.4948\n",
      "Epoch 497/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2879 - accuracy: 0.4901 - val_loss: 2.4766 - val_accuracy: 0.4958\n",
      "Epoch 498/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2902 - accuracy: 0.4955 - val_loss: 2.4589 - val_accuracy: 0.4938\n",
      "Epoch 499/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2933 - accuracy: 0.4929 - val_loss: 2.4581 - val_accuracy: 0.4961\n",
      "Epoch 500/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2856 - accuracy: 0.4939 - val_loss: 2.4572 - val_accuracy: 0.4994\n",
      "Epoch 501/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2833 - accuracy: 0.4948 - val_loss: 2.4543 - val_accuracy: 0.4962\n",
      "Epoch 502/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2945 - accuracy: 0.4928 - val_loss: 2.4589 - val_accuracy: 0.4920\n",
      "Epoch 503/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2851 - accuracy: 0.4923 - val_loss: 2.4625 - val_accuracy: 0.4980\n",
      "Epoch 504/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2911 - accuracy: 0.4948 - val_loss: 2.4489 - val_accuracy: 0.4961\n",
      "Epoch 505/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2828 - accuracy: 0.4925 - val_loss: 2.4500 - val_accuracy: 0.4940\n",
      "Epoch 506/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2780 - accuracy: 0.4950 - val_loss: 2.4508 - val_accuracy: 0.4957\n",
      "Epoch 507/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2851 - accuracy: 0.4927 - val_loss: 2.4562 - val_accuracy: 0.4990\n",
      "Epoch 508/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2847 - accuracy: 0.4959 - val_loss: 2.4492 - val_accuracy: 0.4925\n",
      "Epoch 509/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2784 - accuracy: 0.4923 - val_loss: 2.4651 - val_accuracy: 0.4929\n",
      "Epoch 510/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2885 - accuracy: 0.4939 - val_loss: 2.4522 - val_accuracy: 0.4921\n",
      "Epoch 511/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2966 - accuracy: 0.4897 - val_loss: 2.4567 - val_accuracy: 0.4971\n",
      "Epoch 512/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2832 - accuracy: 0.4931 - val_loss: 2.4640 - val_accuracy: 0.4950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2903 - accuracy: 0.4933 - val_loss: 2.4481 - val_accuracy: 0.4953\n",
      "Epoch 514/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2832 - accuracy: 0.4919 - val_loss: 2.4627 - val_accuracy: 0.4968\n",
      "Epoch 515/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2840 - accuracy: 0.4947 - val_loss: 2.4542 - val_accuracy: 0.4951\n",
      "Epoch 516/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2847 - accuracy: 0.4944 - val_loss: 2.4538 - val_accuracy: 0.4933\n",
      "Epoch 517/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2853 - accuracy: 0.4915 - val_loss: 2.4703 - val_accuracy: 0.5006\n",
      "Epoch 518/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2789 - accuracy: 0.4982 - val_loss: 2.4590 - val_accuracy: 0.4900\n",
      "Epoch 519/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2980 - accuracy: 0.4873 - val_loss: 2.4619 - val_accuracy: 0.4957\n",
      "Epoch 520/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2767 - accuracy: 0.4960 - val_loss: 2.4679 - val_accuracy: 0.4967\n",
      "Epoch 521/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2878 - accuracy: 0.4914 - val_loss: 2.4580 - val_accuracy: 0.4963\n",
      "Epoch 522/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2802 - accuracy: 0.4919 - val_loss: 2.4595 - val_accuracy: 0.4953\n",
      "Epoch 523/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2833 - accuracy: 0.4934 - val_loss: 2.4582 - val_accuracy: 0.4973\n",
      "Epoch 524/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2811 - accuracy: 0.4940 - val_loss: 2.4593 - val_accuracy: 0.4982\n",
      "Epoch 525/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2725 - accuracy: 0.4962 - val_loss: 2.4471 - val_accuracy: 0.4920\n",
      "Epoch 526/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2795 - accuracy: 0.4916 - val_loss: 2.4673 - val_accuracy: 0.4948\n",
      "Epoch 527/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2877 - accuracy: 0.4972 - val_loss: 2.4558 - val_accuracy: 0.4903\n",
      "Epoch 528/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2882 - accuracy: 0.4894 - val_loss: 2.4808 - val_accuracy: 0.4931\n",
      "Epoch 529/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2917 - accuracy: 0.4943 - val_loss: 2.4572 - val_accuracy: 0.4937\n",
      "Epoch 530/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2811 - accuracy: 0.4937 - val_loss: 2.4494 - val_accuracy: 0.4966\n",
      "Epoch 531/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2842 - accuracy: 0.4916 - val_loss: 2.4804 - val_accuracy: 0.5002\n",
      "Epoch 532/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2911 - accuracy: 0.4952 - val_loss: 2.4505 - val_accuracy: 0.4958\n",
      "Epoch 533/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2812 - accuracy: 0.4919 - val_loss: 2.4526 - val_accuracy: 0.4956\n",
      "Epoch 534/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2755 - accuracy: 0.4946 - val_loss: 2.4633 - val_accuracy: 0.5008\n",
      "Epoch 535/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2821 - accuracy: 0.4964 - val_loss: 2.4627 - val_accuracy: 0.4952\n",
      "Epoch 536/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2837 - accuracy: 0.4921 - val_loss: 2.4655 - val_accuracy: 0.4920\n",
      "Epoch 537/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2853 - accuracy: 0.4912 - val_loss: 2.4797 - val_accuracy: 0.4931\n",
      "Epoch 538/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3005 - accuracy: 0.4941 - val_loss: 2.4605 - val_accuracy: 0.4895\n",
      "Epoch 539/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2952 - accuracy: 0.4893 - val_loss: 2.4626 - val_accuracy: 0.4954\n",
      "Epoch 540/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2840 - accuracy: 0.4941 - val_loss: 2.4762 - val_accuracy: 0.4945\n",
      "Epoch 541/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2914 - accuracy: 0.4937 - val_loss: 2.4553 - val_accuracy: 0.4923\n",
      "Epoch 542/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2902 - accuracy: 0.4904 - val_loss: 2.4675 - val_accuracy: 0.4968\n",
      "Epoch 543/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2917 - accuracy: 0.4942 - val_loss: 2.4587 - val_accuracy: 0.4956\n",
      "Epoch 544/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2849 - accuracy: 0.4927 - val_loss: 2.4750 - val_accuracy: 0.4946\n",
      "Epoch 545/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2837 - accuracy: 0.4944 - val_loss: 2.4550 - val_accuracy: 0.4931\n",
      "Epoch 546/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2837 - accuracy: 0.4932 - val_loss: 2.4609 - val_accuracy: 0.4961\n",
      "Epoch 547/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2804 - accuracy: 0.4955 - val_loss: 2.4568 - val_accuracy: 0.4967\n",
      "Epoch 548/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2821 - accuracy: 0.4939 - val_loss: 2.4522 - val_accuracy: 0.4956\n",
      "Epoch 549/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2690 - accuracy: 0.4948 - val_loss: 2.4547 - val_accuracy: 0.4954\n",
      "Epoch 550/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2781 - accuracy: 0.4939 - val_loss: 2.4536 - val_accuracy: 0.4957\n",
      "Epoch 551/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2766 - accuracy: 0.4959 - val_loss: 2.4563 - val_accuracy: 0.4935\n",
      "Epoch 552/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2776 - accuracy: 0.4933 - val_loss: 2.4656 - val_accuracy: 0.4949\n",
      "Epoch 553/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2968 - accuracy: 0.4924 - val_loss: 2.4812 - val_accuracy: 0.4932\n",
      "Epoch 554/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2978 - accuracy: 0.4918 - val_loss: 2.4836 - val_accuracy: 0.4912\n",
      "Epoch 555/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3092 - accuracy: 0.4924 - val_loss: 2.4636 - val_accuracy: 0.4943\n",
      "Epoch 556/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2852 - accuracy: 0.4943 - val_loss: 2.4582 - val_accuracy: 0.4912\n",
      "Epoch 557/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2959 - accuracy: 0.4905 - val_loss: 2.4637 - val_accuracy: 0.4915\n",
      "Epoch 558/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2878 - accuracy: 0.4933 - val_loss: 2.4806 - val_accuracy: 0.4926\n",
      "Epoch 559/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2894 - accuracy: 0.4924 - val_loss: 2.4529 - val_accuracy: 0.4933\n",
      "Epoch 560/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2892 - accuracy: 0.4894 - val_loss: 2.4991 - val_accuracy: 0.4945\n",
      "Epoch 561/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3007 - accuracy: 0.4960 - val_loss: 2.4610 - val_accuracy: 0.4882\n",
      "Epoch 562/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2957 - accuracy: 0.4879 - val_loss: 2.4656 - val_accuracy: 0.4909\n",
      "Epoch 563/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2950 - accuracy: 0.4939 - val_loss: 2.4805 - val_accuracy: 0.4938\n",
      "Epoch 564/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3001 - accuracy: 0.4931 - val_loss: 2.4520 - val_accuracy: 0.4925\n",
      "Epoch 565/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2928 - accuracy: 0.4885 - val_loss: 2.4808 - val_accuracy: 0.4946\n",
      "Epoch 566/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.2962 - accuracy: 0.4927 - val_loss: 2.4797 - val_accuracy: 0.4889\n",
      "Epoch 567/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3014 - accuracy: 0.4893 - val_loss: 2.5102 - val_accuracy: 0.4949\n",
      "Epoch 568/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3331 - accuracy: 0.4914 - val_loss: 2.4862 - val_accuracy: 0.4931\n",
      "Epoch 569/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3067 - accuracy: 0.4880 - val_loss: 2.4665 - val_accuracy: 0.4915\n",
      "Epoch 570/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3012 - accuracy: 0.4887 - val_loss: 2.4988 - val_accuracy: 0.4933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3191 - accuracy: 0.4923 - val_loss: 2.4849 - val_accuracy: 0.4894\n",
      "Epoch 572/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3169 - accuracy: 0.4855 - val_loss: 2.4613 - val_accuracy: 0.4862\n",
      "Epoch 573/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3037 - accuracy: 0.4857 - val_loss: 2.4737 - val_accuracy: 0.4926\n",
      "Epoch 1/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 5.4326 - accuracy: 0.0030 - val_loss: 9.6745 - val_accuracy: 0.2011\n",
      "Epoch 2/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 9.6108 - accuracy: 0.1989 - val_loss: 5.1438 - val_accuracy: 0.0291\n",
      "Epoch 3/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.1405 - accuracy: 0.0293 - val_loss: 6.2237 - val_accuracy: 0.0273\n",
      "Epoch 4/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 6.3098 - accuracy: 0.0243 - val_loss: 5.1349 - val_accuracy: 0.0342\n",
      "Epoch 5/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.1333 - accuracy: 0.0356 - val_loss: 5.0106 - val_accuracy: 0.0375\n",
      "Epoch 6/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.0139 - accuracy: 0.0369 - val_loss: 4.8503 - val_accuracy: 0.0358\n",
      "Epoch 7/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.8658 - accuracy: 0.0361 - val_loss: 4.6436 - val_accuracy: 0.0579\n",
      "Epoch 8/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.6843 - accuracy: 0.0575 - val_loss: 4.5910 - val_accuracy: 0.1137\n",
      "Epoch 9/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.5914 - accuracy: 0.1151 - val_loss: 4.3757 - val_accuracy: 0.1677\n",
      "Epoch 10/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3934 - accuracy: 0.1579 - val_loss: 4.8991 - val_accuracy: 0.2308\n",
      "Epoch 11/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.0048 - accuracy: 0.2131 - val_loss: 4.3100 - val_accuracy: 0.2247\n",
      "Epoch 12/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3254 - accuracy: 0.2190 - val_loss: 4.3531 - val_accuracy: 0.2147\n",
      "Epoch 13/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3644 - accuracy: 0.2130 - val_loss: 4.3440 - val_accuracy: 0.2112\n",
      "Epoch 14/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3565 - accuracy: 0.2112 - val_loss: 4.3122 - val_accuracy: 0.2118\n",
      "Epoch 15/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3300 - accuracy: 0.2115 - val_loss: 4.2988 - val_accuracy: 0.2140\n",
      "Epoch 16/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.3263 - accuracy: 0.2128 - val_loss: 4.2621 - val_accuracy: 0.2158\n",
      "Epoch 17/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2849 - accuracy: 0.2145 - val_loss: 4.2345 - val_accuracy: 0.2191\n",
      "Epoch 18/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2694 - accuracy: 0.2174 - val_loss: 4.2061 - val_accuracy: 0.2267\n",
      "Epoch 19/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2324 - accuracy: 0.2210 - val_loss: 4.2187 - val_accuracy: 0.2286\n",
      "Epoch 20/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2526 - accuracy: 0.2215 - val_loss: 4.1792 - val_accuracy: 0.2332\n",
      "Epoch 21/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2033 - accuracy: 0.2296 - val_loss: 4.1874 - val_accuracy: 0.2392\n",
      "Epoch 22/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2192 - accuracy: 0.2346 - val_loss: 4.2011 - val_accuracy: 0.2269\n",
      "Epoch 23/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.2110 - accuracy: 0.2254 - val_loss: 4.1738 - val_accuracy: 0.2261\n",
      "Epoch 24/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1787 - accuracy: 0.2268 - val_loss: 4.1146 - val_accuracy: 0.2370\n",
      "Epoch 25/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1184 - accuracy: 0.2358 - val_loss: 4.1413 - val_accuracy: 0.2362\n",
      "Epoch 26/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1843 - accuracy: 0.2278 - val_loss: 4.0798 - val_accuracy: 0.2379\n",
      "Epoch 27/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0890 - accuracy: 0.2344 - val_loss: 4.0894 - val_accuracy: 0.2276\n",
      "Epoch 28/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0910 - accuracy: 0.2273 - val_loss: 4.0992 - val_accuracy: 0.2265\n",
      "Epoch 29/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1015 - accuracy: 0.2259 - val_loss: 4.0347 - val_accuracy: 0.2318\n",
      "Epoch 30/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0413 - accuracy: 0.2334 - val_loss: 3.9863 - val_accuracy: 0.2415\n",
      "Epoch 31/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0127 - accuracy: 0.2405 - val_loss: 3.9866 - val_accuracy: 0.2449\n",
      "Epoch 32/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0268 - accuracy: 0.2406 - val_loss: 3.9658 - val_accuracy: 0.2434\n",
      "Epoch 33/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.0015 - accuracy: 0.2404 - val_loss: 3.9418 - val_accuracy: 0.2424\n",
      "Epoch 34/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9647 - accuracy: 0.2387 - val_loss: 3.9382 - val_accuracy: 0.2371\n",
      "Epoch 35/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9447 - accuracy: 0.2352 - val_loss: 3.9368 - val_accuracy: 0.2354\n",
      "Epoch 36/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9418 - accuracy: 0.2342 - val_loss: 3.8992 - val_accuracy: 0.2396\n",
      "Epoch 37/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.9054 - accuracy: 0.2381 - val_loss: 3.8660 - val_accuracy: 0.2462\n",
      "Epoch 38/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8807 - accuracy: 0.2428 - val_loss: 3.8552 - val_accuracy: 0.2494\n",
      "Epoch 39/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8784 - accuracy: 0.2451 - val_loss: 3.8353 - val_accuracy: 0.2479\n",
      "Epoch 40/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8510 - accuracy: 0.2462 - val_loss: 3.8268 - val_accuracy: 0.2477\n",
      "Epoch 41/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8374 - accuracy: 0.2431 - val_loss: 3.8053 - val_accuracy: 0.2486\n",
      "Epoch 42/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8181 - accuracy: 0.2437 - val_loss: 3.7958 - val_accuracy: 0.2512\n",
      "Epoch 43/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8083 - accuracy: 0.2480 - val_loss: 3.7732 - val_accuracy: 0.2514\n",
      "Epoch 44/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7826 - accuracy: 0.2492 - val_loss: 3.7542 - val_accuracy: 0.2565\n",
      "Epoch 45/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7614 - accuracy: 0.2538 - val_loss: 3.7297 - val_accuracy: 0.2622\n",
      "Epoch 46/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7533 - accuracy: 0.2559 - val_loss: 3.7524 - val_accuracy: 0.2616\n",
      "Epoch 47/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7521 - accuracy: 0.2563 - val_loss: 3.7101 - val_accuracy: 0.2632\n",
      "Epoch 48/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7342 - accuracy: 0.2569 - val_loss: 3.7179 - val_accuracy: 0.2631\n",
      "Epoch 49/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7408 - accuracy: 0.2559 - val_loss: 3.6823 - val_accuracy: 0.2602\n",
      "Epoch 50/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7008 - accuracy: 0.2544 - val_loss: 3.6885 - val_accuracy: 0.2546\n",
      "Epoch 51/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7045 - accuracy: 0.2488 - val_loss: 3.6515 - val_accuracy: 0.2610\n",
      "Epoch 52/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6821 - accuracy: 0.2549 - val_loss: 3.6501 - val_accuracy: 0.2656\n",
      "Epoch 53/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6810 - accuracy: 0.2574 - val_loss: 3.6998 - val_accuracy: 0.2647\n",
      "Epoch 54/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7527 - accuracy: 0.2530 - val_loss: 3.8620 - val_accuracy: 0.2333\n",
      "Epoch 55/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8286 - accuracy: 0.2373 - val_loss: 3.9919 - val_accuracy: 0.2484\n",
      "Epoch 56/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1250 - accuracy: 0.2397 - val_loss: 3.7548 - val_accuracy: 0.2517\n",
      "Epoch 57/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7861 - accuracy: 0.2477 - val_loss: 3.7831 - val_accuracy: 0.2520\n",
      "Epoch 58/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.8166 - accuracy: 0.2491 - val_loss: 3.7274 - val_accuracy: 0.2585\n",
      "Epoch 59/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7524 - accuracy: 0.2542 - val_loss: 3.7572 - val_accuracy: 0.2594\n",
      "Epoch 60/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7784 - accuracy: 0.2537 - val_loss: 3.7049 - val_accuracy: 0.2643\n",
      "Epoch 61/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7402 - accuracy: 0.2591 - val_loss: 3.6890 - val_accuracy: 0.2658\n",
      "Epoch 62/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7253 - accuracy: 0.2586 - val_loss: 3.6902 - val_accuracy: 0.2627\n",
      "Epoch 63/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.7171 - accuracy: 0.2604 - val_loss: 3.6511 - val_accuracy: 0.2663\n",
      "Epoch 64/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6856 - accuracy: 0.2615 - val_loss: 3.6442 - val_accuracy: 0.2699\n",
      "Epoch 65/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6789 - accuracy: 0.2642 - val_loss: 3.6316 - val_accuracy: 0.2736\n",
      "Epoch 66/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6671 - accuracy: 0.2665 - val_loss: 3.6026 - val_accuracy: 0.2702\n",
      "Epoch 67/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6366 - accuracy: 0.2668 - val_loss: 3.6530 - val_accuracy: 0.2661\n",
      "Epoch 68/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6989 - accuracy: 0.2644 - val_loss: 3.5972 - val_accuracy: 0.2694\n",
      "Epoch 69/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6238 - accuracy: 0.2661 - val_loss: 3.5768 - val_accuracy: 0.2753\n",
      "Epoch 70/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6222 - accuracy: 0.2705 - val_loss: 3.5733 - val_accuracy: 0.2764\n",
      "Epoch 71/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6172 - accuracy: 0.2698 - val_loss: 3.5577 - val_accuracy: 0.2764\n",
      "Epoch 72/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6118 - accuracy: 0.2713 - val_loss: 3.5848 - val_accuracy: 0.2744\n",
      "Epoch 73/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6053 - accuracy: 0.2695 - val_loss: 3.5563 - val_accuracy: 0.2746\n",
      "Epoch 74/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6018 - accuracy: 0.2698 - val_loss: 3.5613 - val_accuracy: 0.2710\n",
      "Epoch 75/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5889 - accuracy: 0.2681 - val_loss: 3.5228 - val_accuracy: 0.2754\n",
      "Epoch 76/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5652 - accuracy: 0.2708 - val_loss: 3.5111 - val_accuracy: 0.2811\n",
      "Epoch 77/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5535 - accuracy: 0.2743 - val_loss: 3.5008 - val_accuracy: 0.2797\n",
      "Epoch 78/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5359 - accuracy: 0.2729 - val_loss: 3.4950 - val_accuracy: 0.2805\n",
      "Epoch 79/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5447 - accuracy: 0.2724 - val_loss: 3.5162 - val_accuracy: 0.2791\n",
      "Epoch 80/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5399 - accuracy: 0.2741 - val_loss: 3.5242 - val_accuracy: 0.2787\n",
      "Epoch 81/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5701 - accuracy: 0.2731 - val_loss: 3.6481 - val_accuracy: 0.2619\n",
      "Epoch 82/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6466 - accuracy: 0.2605 - val_loss: 3.5100 - val_accuracy: 0.2837\n",
      "Epoch 83/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5568 - accuracy: 0.2741 - val_loss: 3.4775 - val_accuracy: 0.2818\n",
      "Epoch 84/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5244 - accuracy: 0.2751 - val_loss: 3.4999 - val_accuracy: 0.2798\n",
      "Epoch 85/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.5339 - accuracy: 0.2738 - val_loss: 3.4560 - val_accuracy: 0.2859\n",
      "Epoch 86/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4954 - accuracy: 0.2799 - val_loss: 3.4562 - val_accuracy: 0.2891\n",
      "Epoch 87/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4993 - accuracy: 0.2809 - val_loss: 3.4517 - val_accuracy: 0.2885\n",
      "Epoch 88/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4912 - accuracy: 0.2817 - val_loss: 3.4539 - val_accuracy: 0.2866\n",
      "Epoch 89/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4859 - accuracy: 0.2808 - val_loss: 3.4373 - val_accuracy: 0.2923\n",
      "Epoch 90/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4884 - accuracy: 0.2835 - val_loss: 3.4375 - val_accuracy: 0.2895\n",
      "Epoch 91/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4753 - accuracy: 0.2834 - val_loss: 3.4499 - val_accuracy: 0.2870\n",
      "Epoch 92/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4823 - accuracy: 0.2813 - val_loss: 3.4314 - val_accuracy: 0.2880\n",
      "Epoch 93/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4691 - accuracy: 0.2827 - val_loss: 3.4285 - val_accuracy: 0.2909\n",
      "Epoch 94/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4631 - accuracy: 0.2839 - val_loss: 3.4273 - val_accuracy: 0.2919\n",
      "Epoch 95/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4723 - accuracy: 0.2848 - val_loss: 3.4231 - val_accuracy: 0.2920\n",
      "Epoch 96/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4517 - accuracy: 0.2882 - val_loss: 3.4170 - val_accuracy: 0.2911\n",
      "Epoch 97/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4487 - accuracy: 0.2859 - val_loss: 3.4148 - val_accuracy: 0.2922\n",
      "Epoch 98/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4491 - accuracy: 0.2851 - val_loss: 3.4106 - val_accuracy: 0.2916\n",
      "Epoch 99/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4450 - accuracy: 0.2874 - val_loss: 3.3972 - val_accuracy: 0.2948\n",
      "Epoch 100/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4510 - accuracy: 0.2869 - val_loss: 3.3859 - val_accuracy: 0.2959\n",
      "Epoch 101/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4299 - accuracy: 0.2875 - val_loss: 3.4003 - val_accuracy: 0.2972\n",
      "Epoch 102/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4392 - accuracy: 0.2900 - val_loss: 3.3819 - val_accuracy: 0.2993\n",
      "Epoch 103/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4144 - accuracy: 0.2940 - val_loss: 3.3911 - val_accuracy: 0.2949\n",
      "Epoch 104/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4180 - accuracy: 0.2893 - val_loss: 3.3940 - val_accuracy: 0.2965\n",
      "Epoch 105/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.4110 - accuracy: 0.2924 - val_loss: 3.3732 - val_accuracy: 0.3032\n",
      "Epoch 106/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.4043 - accuracy: 0.2957 - val_loss: 3.3695 - val_accuracy: 0.3033\n",
      "Epoch 107/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3984 - accuracy: 0.2940 - val_loss: 3.3657 - val_accuracy: 0.3020\n",
      "Epoch 108/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3957 - accuracy: 0.2936 - val_loss: 3.3351 - val_accuracy: 0.3041\n",
      "Epoch 109/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3756 - accuracy: 0.2976 - val_loss: 3.3409 - val_accuracy: 0.3038\n",
      "Epoch 110/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3868 - accuracy: 0.2967 - val_loss: 3.3337 - val_accuracy: 0.3054\n",
      "Epoch 111/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3772 - accuracy: 0.2985 - val_loss: 3.3316 - val_accuracy: 0.3066\n",
      "Epoch 112/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3714 - accuracy: 0.2971 - val_loss: 3.3295 - val_accuracy: 0.3098\n",
      "Epoch 113/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3579 - accuracy: 0.3036 - val_loss: 3.3131 - val_accuracy: 0.3157\n",
      "Epoch 114/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 3.3569 - accuracy: 0.3044 - val_loss: 3.3086 - val_accuracy: 0.3080\n",
      "Epoch 115/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3464 - accuracy: 0.3035 - val_loss: 3.2986 - val_accuracy: 0.3118\n",
      "Epoch 116/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3415 - accuracy: 0.3033 - val_loss: 3.3028 - val_accuracy: 0.3127\n",
      "Epoch 117/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3361 - accuracy: 0.3058 - val_loss: 3.3155 - val_accuracy: 0.3083\n",
      "Epoch 118/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.3397 - accuracy: 0.3038 - val_loss: 3.2728 - val_accuracy: 0.3139\n",
      "Epoch 119/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3113 - accuracy: 0.3065 - val_loss: 3.2871 - val_accuracy: 0.3060\n",
      "Epoch 120/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3155 - accuracy: 0.3038 - val_loss: 3.2696 - val_accuracy: 0.3121\n",
      "Epoch 121/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3028 - accuracy: 0.3066 - val_loss: 3.2457 - val_accuracy: 0.3177\n",
      "Epoch 122/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2921 - accuracy: 0.3078 - val_loss: 3.2462 - val_accuracy: 0.3187\n",
      "Epoch 123/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2881 - accuracy: 0.3099 - val_loss: 3.2431 - val_accuracy: 0.3229\n",
      "Epoch 124/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2838 - accuracy: 0.3129 - val_loss: 3.2589 - val_accuracy: 0.3153\n",
      "Epoch 125/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2901 - accuracy: 0.3090 - val_loss: 3.2532 - val_accuracy: 0.3274\n",
      "Epoch 126/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2922 - accuracy: 0.3129 - val_loss: 3.3091 - val_accuracy: 0.3138\n",
      "Epoch 127/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3391 - accuracy: 0.3046 - val_loss: 3.2863 - val_accuracy: 0.3213\n",
      "Epoch 128/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3334 - accuracy: 0.3111 - val_loss: 3.2769 - val_accuracy: 0.3138\n",
      "Epoch 129/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2928 - accuracy: 0.3081 - val_loss: 3.2806 - val_accuracy: 0.3159\n",
      "Epoch 130/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2954 - accuracy: 0.3071 - val_loss: 3.2718 - val_accuracy: 0.3204\n",
      "Epoch 131/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3046 - accuracy: 0.3102 - val_loss: 3.2508 - val_accuracy: 0.3263\n",
      "Epoch 132/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2871 - accuracy: 0.3133 - val_loss: 3.2417 - val_accuracy: 0.3213\n",
      "Epoch 133/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2751 - accuracy: 0.3116 - val_loss: 3.2261 - val_accuracy: 0.3263\n",
      "Epoch 134/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2656 - accuracy: 0.3165 - val_loss: 3.2280 - val_accuracy: 0.3277\n",
      "Epoch 135/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2649 - accuracy: 0.3182 - val_loss: 3.2282 - val_accuracy: 0.3251\n",
      "Epoch 136/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2623 - accuracy: 0.3183 - val_loss: 3.2164 - val_accuracy: 0.3247\n",
      "Epoch 137/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2503 - accuracy: 0.3193 - val_loss: 3.2006 - val_accuracy: 0.3288\n",
      "Epoch 138/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2415 - accuracy: 0.3208 - val_loss: 3.1882 - val_accuracy: 0.3290\n",
      "Epoch 139/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2250 - accuracy: 0.3221 - val_loss: 3.1877 - val_accuracy: 0.3310\n",
      "Epoch 140/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2278 - accuracy: 0.3241 - val_loss: 3.1754 - val_accuracy: 0.3330\n",
      "Epoch 141/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2222 - accuracy: 0.3260 - val_loss: 3.1741 - val_accuracy: 0.3309\n",
      "Epoch 142/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2119 - accuracy: 0.3259 - val_loss: 3.1694 - val_accuracy: 0.3335\n",
      "Epoch 143/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.2118 - accuracy: 0.3234 - val_loss: 3.1569 - val_accuracy: 0.3342\n",
      "Epoch 144/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1936 - accuracy: 0.3266 - val_loss: 3.1522 - val_accuracy: 0.3369\n",
      "Epoch 145/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1836 - accuracy: 0.3306 - val_loss: 3.1341 - val_accuracy: 0.3421\n",
      "Epoch 146/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1769 - accuracy: 0.3337 - val_loss: 3.1362 - val_accuracy: 0.3398\n",
      "Epoch 147/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1764 - accuracy: 0.3297 - val_loss: 3.1273 - val_accuracy: 0.3421\n",
      "Epoch 148/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1650 - accuracy: 0.3339 - val_loss: 3.1223 - val_accuracy: 0.3403\n",
      "Epoch 149/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1601 - accuracy: 0.3328 - val_loss: 3.1175 - val_accuracy: 0.3424\n",
      "Epoch 150/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1560 - accuracy: 0.3345 - val_loss: 3.1371 - val_accuracy: 0.3475\n",
      "Epoch 151/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1823 - accuracy: 0.3337 - val_loss: 3.1553 - val_accuracy: 0.3343\n",
      "Epoch 152/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1917 - accuracy: 0.3279 - val_loss: 3.1247 - val_accuracy: 0.3441\n",
      "Epoch 153/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1582 - accuracy: 0.3351 - val_loss: 3.1131 - val_accuracy: 0.3471\n",
      "Epoch 154/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1545 - accuracy: 0.3365 - val_loss: 3.1378 - val_accuracy: 0.3413\n",
      "Epoch 155/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1692 - accuracy: 0.3309 - val_loss: 3.0901 - val_accuracy: 0.3473\n",
      "Epoch 156/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1312 - accuracy: 0.3395 - val_loss: 3.1105 - val_accuracy: 0.3512\n",
      "Epoch 157/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1498 - accuracy: 0.3407 - val_loss: 3.0926 - val_accuracy: 0.3448\n",
      "Epoch 158/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1241 - accuracy: 0.3381 - val_loss: 3.0913 - val_accuracy: 0.3471\n",
      "Epoch 159/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1326 - accuracy: 0.3381 - val_loss: 3.0709 - val_accuracy: 0.3586\n",
      "Epoch 160/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1222 - accuracy: 0.3438 - val_loss: 3.0518 - val_accuracy: 0.3562\n",
      "Epoch 161/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0889 - accuracy: 0.3474 - val_loss: 3.0520 - val_accuracy: 0.3527\n",
      "Epoch 162/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0853 - accuracy: 0.3447 - val_loss: 3.0259 - val_accuracy: 0.3619\n",
      "Epoch 163/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0781 - accuracy: 0.3488 - val_loss: 3.0145 - val_accuracy: 0.3657\n",
      "Epoch 164/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0695 - accuracy: 0.3535 - val_loss: 3.0298 - val_accuracy: 0.3592\n",
      "Epoch 165/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0659 - accuracy: 0.3487 - val_loss: 3.0345 - val_accuracy: 0.3585\n",
      "Epoch 166/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0688 - accuracy: 0.3486 - val_loss: 3.0094 - val_accuracy: 0.3666\n",
      "Epoch 167/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0609 - accuracy: 0.3525 - val_loss: 3.0057 - val_accuracy: 0.3705\n",
      "Epoch 168/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0577 - accuracy: 0.3587 - val_loss: 3.0739 - val_accuracy: 0.3551\n",
      "Epoch 169/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1207 - accuracy: 0.3417 - val_loss: 3.0682 - val_accuracy: 0.3489\n",
      "Epoch 170/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1130 - accuracy: 0.3395 - val_loss: 3.0509 - val_accuracy: 0.3579\n",
      "Epoch 171/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1054 - accuracy: 0.3471 - val_loss: 3.0411 - val_accuracy: 0.3665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0980 - accuracy: 0.3501 - val_loss: 3.0169 - val_accuracy: 0.3628\n",
      "Epoch 173/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0637 - accuracy: 0.3484 - val_loss: 3.0295 - val_accuracy: 0.3575\n",
      "Epoch 174/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0776 - accuracy: 0.3464 - val_loss: 3.0007 - val_accuracy: 0.3673\n",
      "Epoch 175/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0616 - accuracy: 0.3526 - val_loss: 2.9902 - val_accuracy: 0.3770\n",
      "Epoch 176/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0576 - accuracy: 0.3581 - val_loss: 2.9819 - val_accuracy: 0.3708\n",
      "Epoch 177/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0423 - accuracy: 0.3577 - val_loss: 2.9759 - val_accuracy: 0.3697\n",
      "Epoch 178/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.0299 - accuracy: 0.3582 - val_loss: 2.9624 - val_accuracy: 0.3735\n",
      "Epoch 179/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0104 - accuracy: 0.3608 - val_loss: 2.9575 - val_accuracy: 0.3755\n",
      "Epoch 180/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0172 - accuracy: 0.3605 - val_loss: 2.9503 - val_accuracy: 0.3762\n",
      "Epoch 181/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0031 - accuracy: 0.3636 - val_loss: 2.9559 - val_accuracy: 0.3765\n",
      "Epoch 182/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0009 - accuracy: 0.3652 - val_loss: 2.9379 - val_accuracy: 0.3720\n",
      "Epoch 183/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9852 - accuracy: 0.3638 - val_loss: 2.9329 - val_accuracy: 0.3786\n",
      "Epoch 184/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9998 - accuracy: 0.3643 - val_loss: 2.9261 - val_accuracy: 0.3805\n",
      "Epoch 185/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9831 - accuracy: 0.3665 - val_loss: 2.9114 - val_accuracy: 0.3860\n",
      "Epoch 186/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9722 - accuracy: 0.3701 - val_loss: 2.9352 - val_accuracy: 0.3744\n",
      "Epoch 187/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9929 - accuracy: 0.3597 - val_loss: 2.8918 - val_accuracy: 0.3890\n",
      "Epoch 188/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9483 - accuracy: 0.3726 - val_loss: 2.8884 - val_accuracy: 0.3971\n",
      "Epoch 189/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9504 - accuracy: 0.3814 - val_loss: 2.8839 - val_accuracy: 0.3887\n",
      "Epoch 190/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9434 - accuracy: 0.3743 - val_loss: 2.8741 - val_accuracy: 0.3871\n",
      "Epoch 191/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9338 - accuracy: 0.3717 - val_loss: 2.8591 - val_accuracy: 0.4002\n",
      "Epoch 192/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9127 - accuracy: 0.3822 - val_loss: 2.8505 - val_accuracy: 0.3998\n",
      "Epoch 193/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9077 - accuracy: 0.3861 - val_loss: 2.8580 - val_accuracy: 0.3847\n",
      "Epoch 194/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9131 - accuracy: 0.3751 - val_loss: 2.8330 - val_accuracy: 0.3967\n",
      "Epoch 195/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8814 - accuracy: 0.3841 - val_loss: 2.8310 - val_accuracy: 0.4052\n",
      "Epoch 196/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8955 - accuracy: 0.3885 - val_loss: 2.8199 - val_accuracy: 0.4013\n",
      "Epoch 197/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8822 - accuracy: 0.3856 - val_loss: 2.8260 - val_accuracy: 0.3956\n",
      "Epoch 198/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8887 - accuracy: 0.3787 - val_loss: 2.8094 - val_accuracy: 0.4017\n",
      "Epoch 199/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8711 - accuracy: 0.3864 - val_loss: 2.8103 - val_accuracy: 0.4073\n",
      "Epoch 200/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8628 - accuracy: 0.3918 - val_loss: 2.7887 - val_accuracy: 0.4101\n",
      "Epoch 201/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8455 - accuracy: 0.3935 - val_loss: 2.7847 - val_accuracy: 0.4078\n",
      "Epoch 202/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8490 - accuracy: 0.3912 - val_loss: 2.7764 - val_accuracy: 0.4135\n",
      "Epoch 203/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8303 - accuracy: 0.3964 - val_loss: 2.7776 - val_accuracy: 0.4155\n",
      "Epoch 204/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8311 - accuracy: 0.3942 - val_loss: 2.7872 - val_accuracy: 0.4106\n",
      "Epoch 205/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8628 - accuracy: 0.3933 - val_loss: 2.8684 - val_accuracy: 0.4002\n",
      "Epoch 206/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9243 - accuracy: 0.3821 - val_loss: 2.8457 - val_accuracy: 0.4027\n",
      "Epoch 207/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9017 - accuracy: 0.3862 - val_loss: 2.8456 - val_accuracy: 0.4003\n",
      "Epoch 208/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9180 - accuracy: 0.3851 - val_loss: 2.8431 - val_accuracy: 0.3877\n",
      "Epoch 209/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8948 - accuracy: 0.3751 - val_loss: 2.8363 - val_accuracy: 0.4010\n",
      "Epoch 210/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8946 - accuracy: 0.3862 - val_loss: 2.8398 - val_accuracy: 0.4070\n",
      "Epoch 211/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9055 - accuracy: 0.3887 - val_loss: 2.8340 - val_accuracy: 0.4012\n",
      "Epoch 212/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8823 - accuracy: 0.3887 - val_loss: 2.8193 - val_accuracy: 0.4007\n",
      "Epoch 213/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8757 - accuracy: 0.3868 - val_loss: 2.8288 - val_accuracy: 0.4114\n",
      "Epoch 214/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.8952 - accuracy: 0.3934 - val_loss: 2.9110 - val_accuracy: 0.3906\n",
      "Epoch 215/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9789 - accuracy: 0.3759 - val_loss: 2.9128 - val_accuracy: 0.3880\n",
      "Epoch 216/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.9787 - accuracy: 0.3690 - val_loss: 2.9222 - val_accuracy: 0.3930\n",
      "Epoch 217/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9960 - accuracy: 0.3758 - val_loss: 2.8899 - val_accuracy: 0.3910\n",
      "Epoch 218/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9591 - accuracy: 0.3753 - val_loss: 2.9015 - val_accuracy: 0.3898\n",
      "Epoch 219/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9689 - accuracy: 0.3740 - val_loss: 2.8890 - val_accuracy: 0.3897\n",
      "Epoch 220/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9401 - accuracy: 0.3770 - val_loss: 2.8779 - val_accuracy: 0.3923\n",
      "Epoch 221/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9382 - accuracy: 0.3762 - val_loss: 2.8604 - val_accuracy: 0.3967\n",
      "Epoch 222/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.9164 - accuracy: 0.3811 - val_loss: 2.8442 - val_accuracy: 0.4029\n",
      "Epoch 223/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8960 - accuracy: 0.3877 - val_loss: 2.8276 - val_accuracy: 0.4012\n",
      "Epoch 224/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8793 - accuracy: 0.3880 - val_loss: 2.8057 - val_accuracy: 0.4103\n",
      "Epoch 225/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8660 - accuracy: 0.3944 - val_loss: 2.7871 - val_accuracy: 0.4152\n",
      "Epoch 226/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8612 - accuracy: 0.3954 - val_loss: 2.7811 - val_accuracy: 0.4071\n",
      "Epoch 227/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8516 - accuracy: 0.3913 - val_loss: 2.7682 - val_accuracy: 0.4113\n",
      "Epoch 228/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8346 - accuracy: 0.3961 - val_loss: 2.7772 - val_accuracy: 0.4173\n",
      "Epoch 229/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8441 - accuracy: 0.3963 - val_loss: 2.7796 - val_accuracy: 0.4070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8341 - accuracy: 0.3909 - val_loss: 2.7629 - val_accuracy: 0.4133\n",
      "Epoch 231/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8248 - accuracy: 0.3948 - val_loss: 2.7545 - val_accuracy: 0.4142\n",
      "Epoch 232/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8171 - accuracy: 0.3979 - val_loss: 2.7588 - val_accuracy: 0.4154\n",
      "Epoch 233/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8105 - accuracy: 0.3999 - val_loss: 2.7306 - val_accuracy: 0.4165\n",
      "Epoch 234/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7921 - accuracy: 0.4010 - val_loss: 2.7349 - val_accuracy: 0.4196\n",
      "Epoch 235/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8108 - accuracy: 0.4003 - val_loss: 2.7451 - val_accuracy: 0.4115\n",
      "Epoch 236/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7981 - accuracy: 0.3937 - val_loss: 2.7509 - val_accuracy: 0.4275\n",
      "Epoch 237/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.8099 - accuracy: 0.4063 - val_loss: 2.7248 - val_accuracy: 0.4235\n",
      "Epoch 238/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7894 - accuracy: 0.4043 - val_loss: 2.7223 - val_accuracy: 0.4180\n",
      "Epoch 239/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7940 - accuracy: 0.4010 - val_loss: 2.7452 - val_accuracy: 0.4228\n",
      "Epoch 240/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7984 - accuracy: 0.4059 - val_loss: 2.7305 - val_accuracy: 0.4244\n",
      "Epoch 241/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7790 - accuracy: 0.4067 - val_loss: 2.7369 - val_accuracy: 0.4206\n",
      "Epoch 242/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7780 - accuracy: 0.4078 - val_loss: 2.7158 - val_accuracy: 0.4190\n",
      "Epoch 243/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7588 - accuracy: 0.4045 - val_loss: 2.7123 - val_accuracy: 0.4260\n",
      "Epoch 244/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7555 - accuracy: 0.4092 - val_loss: 2.6985 - val_accuracy: 0.4312\n",
      "Epoch 245/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7576 - accuracy: 0.4075 - val_loss: 2.6904 - val_accuracy: 0.4352\n",
      "Epoch 246/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7441 - accuracy: 0.4142 - val_loss: 2.6949 - val_accuracy: 0.4284\n",
      "Epoch 247/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7307 - accuracy: 0.4109 - val_loss: 2.6949 - val_accuracy: 0.4277\n",
      "Epoch 248/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7368 - accuracy: 0.4108 - val_loss: 2.6869 - val_accuracy: 0.4334\n",
      "Epoch 249/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7231 - accuracy: 0.4160 - val_loss: 2.6689 - val_accuracy: 0.4295\n",
      "Epoch 250/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7136 - accuracy: 0.4137 - val_loss: 2.6686 - val_accuracy: 0.4329\n",
      "Epoch 251/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7129 - accuracy: 0.4149 - val_loss: 2.6552 - val_accuracy: 0.4334\n",
      "Epoch 252/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7169 - accuracy: 0.4161 - val_loss: 2.6619 - val_accuracy: 0.4368\n",
      "Epoch 253/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7080 - accuracy: 0.4188 - val_loss: 2.6454 - val_accuracy: 0.4344\n",
      "Epoch 254/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7038 - accuracy: 0.4154 - val_loss: 2.6453 - val_accuracy: 0.4397\n",
      "Epoch 255/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6959 - accuracy: 0.4190 - val_loss: 2.6481 - val_accuracy: 0.4368\n",
      "Epoch 256/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6932 - accuracy: 0.4195 - val_loss: 2.6577 - val_accuracy: 0.4436\n",
      "Epoch 257/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6950 - accuracy: 0.4210 - val_loss: 2.6452 - val_accuracy: 0.4395\n",
      "Epoch 258/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7127 - accuracy: 0.4176 - val_loss: 2.7238 - val_accuracy: 0.4369\n",
      "Epoch 259/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7633 - accuracy: 0.4168 - val_loss: 2.7133 - val_accuracy: 0.4320\n",
      "Epoch 260/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7510 - accuracy: 0.4153 - val_loss: 2.6821 - val_accuracy: 0.4392\n",
      "Epoch 261/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7361 - accuracy: 0.4177 - val_loss: 2.6898 - val_accuracy: 0.4300\n",
      "Epoch 262/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7368 - accuracy: 0.4130 - val_loss: 2.6836 - val_accuracy: 0.4260\n",
      "Epoch 263/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7280 - accuracy: 0.4123 - val_loss: 2.6707 - val_accuracy: 0.4303\n",
      "Epoch 264/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7151 - accuracy: 0.4159 - val_loss: 2.6630 - val_accuracy: 0.4377\n",
      "Epoch 265/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7188 - accuracy: 0.4166 - val_loss: 2.6542 - val_accuracy: 0.4355\n",
      "Epoch 266/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7059 - accuracy: 0.4170 - val_loss: 2.6534 - val_accuracy: 0.4420\n",
      "Epoch 267/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.7024 - accuracy: 0.4226 - val_loss: 2.6553 - val_accuracy: 0.4440\n",
      "Epoch 268/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6949 - accuracy: 0.4224 - val_loss: 2.6485 - val_accuracy: 0.4421\n",
      "Epoch 269/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6907 - accuracy: 0.4211 - val_loss: 2.6438 - val_accuracy: 0.4423\n",
      "Epoch 270/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6838 - accuracy: 0.4211 - val_loss: 2.6478 - val_accuracy: 0.4358\n",
      "Epoch 271/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6806 - accuracy: 0.4181 - val_loss: 2.6350 - val_accuracy: 0.4452\n",
      "Epoch 272/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6715 - accuracy: 0.4250 - val_loss: 2.6289 - val_accuracy: 0.4413\n",
      "Epoch 273/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6723 - accuracy: 0.4207 - val_loss: 2.6417 - val_accuracy: 0.4352\n",
      "Epoch 274/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6832 - accuracy: 0.4177 - val_loss: 2.6378 - val_accuracy: 0.4489\n",
      "Epoch 275/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6810 - accuracy: 0.4258 - val_loss: 2.6456 - val_accuracy: 0.4396\n",
      "Epoch 276/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6825 - accuracy: 0.4196 - val_loss: 2.6200 - val_accuracy: 0.4436\n",
      "Epoch 277/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6610 - accuracy: 0.4274 - val_loss: 2.6256 - val_accuracy: 0.4505\n",
      "Epoch 278/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6702 - accuracy: 0.4304 - val_loss: 2.6201 - val_accuracy: 0.4403\n",
      "Epoch 279/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6630 - accuracy: 0.4210 - val_loss: 2.6179 - val_accuracy: 0.4463\n",
      "Epoch 280/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6541 - accuracy: 0.4286 - val_loss: 2.6279 - val_accuracy: 0.4440\n",
      "Epoch 281/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6603 - accuracy: 0.4268 - val_loss: 2.6199 - val_accuracy: 0.4440\n",
      "Epoch 282/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6587 - accuracy: 0.4244 - val_loss: 2.6223 - val_accuracy: 0.4463\n",
      "Epoch 283/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6470 - accuracy: 0.4287 - val_loss: 2.6130 - val_accuracy: 0.4462\n",
      "Epoch 284/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6392 - accuracy: 0.4278 - val_loss: 2.6151 - val_accuracy: 0.4481\n",
      "Epoch 285/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6444 - accuracy: 0.4290 - val_loss: 2.5997 - val_accuracy: 0.4518\n",
      "Epoch 286/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6387 - accuracy: 0.4303 - val_loss: 2.6021 - val_accuracy: 0.4485\n",
      "Epoch 287/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6340 - accuracy: 0.4311 - val_loss: 2.5983 - val_accuracy: 0.4475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6243 - accuracy: 0.4311 - val_loss: 2.6052 - val_accuracy: 0.4521\n",
      "Epoch 289/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6352 - accuracy: 0.4332 - val_loss: 2.5936 - val_accuracy: 0.4498\n",
      "Epoch 290/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6264 - accuracy: 0.4302 - val_loss: 2.5906 - val_accuracy: 0.4532\n",
      "Epoch 291/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6163 - accuracy: 0.4327 - val_loss: 2.5896 - val_accuracy: 0.4532\n",
      "Epoch 292/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6189 - accuracy: 0.4330 - val_loss: 2.5950 - val_accuracy: 0.4521\n",
      "Epoch 293/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6242 - accuracy: 0.4325 - val_loss: 2.5875 - val_accuracy: 0.4543\n",
      "Epoch 294/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6155 - accuracy: 0.4320 - val_loss: 2.5845 - val_accuracy: 0.4584\n",
      "Epoch 295/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6215 - accuracy: 0.4361 - val_loss: 2.5838 - val_accuracy: 0.4490\n",
      "Epoch 296/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6179 - accuracy: 0.4304 - val_loss: 2.5980 - val_accuracy: 0.4600\n",
      "Epoch 297/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6253 - accuracy: 0.4373 - val_loss: 2.6132 - val_accuracy: 0.4393\n",
      "Epoch 298/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6449 - accuracy: 0.4223 - val_loss: 2.6149 - val_accuracy: 0.4532\n",
      "Epoch 299/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6380 - accuracy: 0.4323 - val_loss: 2.6002 - val_accuracy: 0.4511\n",
      "Epoch 300/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6298 - accuracy: 0.4303 - val_loss: 2.5947 - val_accuracy: 0.4517\n",
      "Epoch 301/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6383 - accuracy: 0.4304 - val_loss: 2.6024 - val_accuracy: 0.4512\n",
      "Epoch 302/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6118 - accuracy: 0.4353 - val_loss: 2.6099 - val_accuracy: 0.4489\n",
      "Epoch 303/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6254 - accuracy: 0.4325 - val_loss: 2.5974 - val_accuracy: 0.4537\n",
      "Epoch 304/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6178 - accuracy: 0.4337 - val_loss: 2.5819 - val_accuracy: 0.4545\n",
      "Epoch 305/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6012 - accuracy: 0.4343 - val_loss: 2.5873 - val_accuracy: 0.4526\n",
      "Epoch 306/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6063 - accuracy: 0.4334 - val_loss: 2.5828 - val_accuracy: 0.4510\n",
      "Epoch 307/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6078 - accuracy: 0.4362 - val_loss: 2.5839 - val_accuracy: 0.4592\n",
      "Epoch 308/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6091 - accuracy: 0.4374 - val_loss: 2.5752 - val_accuracy: 0.4568\n",
      "Epoch 309/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5997 - accuracy: 0.4347 - val_loss: 2.5731 - val_accuracy: 0.4551\n",
      "Epoch 310/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5966 - accuracy: 0.4360 - val_loss: 2.5824 - val_accuracy: 0.4546\n",
      "Epoch 311/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6046 - accuracy: 0.4368 - val_loss: 2.5733 - val_accuracy: 0.4524\n",
      "Epoch 312/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5934 - accuracy: 0.4346 - val_loss: 2.5716 - val_accuracy: 0.4532\n",
      "Epoch 313/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5933 - accuracy: 0.4338 - val_loss: 2.5723 - val_accuracy: 0.4601\n",
      "Epoch 314/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5852 - accuracy: 0.4400 - val_loss: 2.5599 - val_accuracy: 0.4565\n",
      "Epoch 315/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5785 - accuracy: 0.4405 - val_loss: 2.5603 - val_accuracy: 0.4576\n",
      "Epoch 316/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5766 - accuracy: 0.4388 - val_loss: 2.5639 - val_accuracy: 0.4614\n",
      "Epoch 317/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5767 - accuracy: 0.4434 - val_loss: 2.5544 - val_accuracy: 0.4561\n",
      "Epoch 318/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5687 - accuracy: 0.4394 - val_loss: 2.5549 - val_accuracy: 0.4568\n",
      "Epoch 319/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5694 - accuracy: 0.4416 - val_loss: 2.5506 - val_accuracy: 0.4572\n",
      "Epoch 320/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5668 - accuracy: 0.4426 - val_loss: 2.5502 - val_accuracy: 0.4609\n",
      "Epoch 321/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5673 - accuracy: 0.4420 - val_loss: 2.5568 - val_accuracy: 0.4624\n",
      "Epoch 322/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5710 - accuracy: 0.4402 - val_loss: 2.5525 - val_accuracy: 0.4612\n",
      "Epoch 323/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5714 - accuracy: 0.4425 - val_loss: 2.5389 - val_accuracy: 0.4571\n",
      "Epoch 324/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5612 - accuracy: 0.4406 - val_loss: 2.5504 - val_accuracy: 0.4642\n",
      "Epoch 325/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5683 - accuracy: 0.4449 - val_loss: 2.5530 - val_accuracy: 0.4623\n",
      "Epoch 326/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5667 - accuracy: 0.4431 - val_loss: 2.5445 - val_accuracy: 0.4602\n",
      "Epoch 327/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5546 - accuracy: 0.4418 - val_loss: 2.5462 - val_accuracy: 0.4656\n",
      "Epoch 328/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5642 - accuracy: 0.4454 - val_loss: 2.5391 - val_accuracy: 0.4655\n",
      "Epoch 329/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5511 - accuracy: 0.4453 - val_loss: 2.5396 - val_accuracy: 0.4628\n",
      "Epoch 330/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5589 - accuracy: 0.4395 - val_loss: 2.5477 - val_accuracy: 0.4653\n",
      "Epoch 331/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5483 - accuracy: 0.4469 - val_loss: 2.5393 - val_accuracy: 0.4630\n",
      "Epoch 332/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5461 - accuracy: 0.4451 - val_loss: 2.5346 - val_accuracy: 0.4673\n",
      "Epoch 333/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5482 - accuracy: 0.4469 - val_loss: 2.5367 - val_accuracy: 0.4625\n",
      "Epoch 334/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5531 - accuracy: 0.4436 - val_loss: 2.5378 - val_accuracy: 0.4658\n",
      "Epoch 335/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5430 - accuracy: 0.4475 - val_loss: 2.5319 - val_accuracy: 0.4664\n",
      "Epoch 336/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5459 - accuracy: 0.4451 - val_loss: 2.5321 - val_accuracy: 0.4668\n",
      "Epoch 337/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5400 - accuracy: 0.4487 - val_loss: 2.5383 - val_accuracy: 0.4654\n",
      "Epoch 338/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5474 - accuracy: 0.4461 - val_loss: 2.5572 - val_accuracy: 0.4629\n",
      "Epoch 339/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5508 - accuracy: 0.4459 - val_loss: 2.5419 - val_accuracy: 0.4607\n",
      "Epoch 340/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5617 - accuracy: 0.4404 - val_loss: 2.5470 - val_accuracy: 0.4738\n",
      "Epoch 341/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5566 - accuracy: 0.4502 - val_loss: 2.5516 - val_accuracy: 0.4589\n",
      "Epoch 342/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5674 - accuracy: 0.4404 - val_loss: 2.5379 - val_accuracy: 0.4606\n",
      "Epoch 343/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5529 - accuracy: 0.4434 - val_loss: 2.5505 - val_accuracy: 0.4641\n",
      "Epoch 344/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5601 - accuracy: 0.4447 - val_loss: 2.5473 - val_accuracy: 0.4661\n",
      "Epoch 345/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5485 - accuracy: 0.4473 - val_loss: 2.5390 - val_accuracy: 0.4653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5448 - accuracy: 0.4445 - val_loss: 2.5367 - val_accuracy: 0.4668\n",
      "Epoch 347/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5508 - accuracy: 0.4476 - val_loss: 2.5351 - val_accuracy: 0.4621\n",
      "Epoch 348/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5432 - accuracy: 0.4449 - val_loss: 2.5412 - val_accuracy: 0.4667\n",
      "Epoch 349/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5486 - accuracy: 0.4461 - val_loss: 2.5573 - val_accuracy: 0.4673\n",
      "Epoch 350/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5491 - accuracy: 0.4523 - val_loss: 2.5425 - val_accuracy: 0.4586\n",
      "Epoch 351/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5501 - accuracy: 0.4410 - val_loss: 2.5305 - val_accuracy: 0.4714\n",
      "Epoch 352/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5377 - accuracy: 0.4511 - val_loss: 2.5334 - val_accuracy: 0.4704\n",
      "Epoch 353/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5385 - accuracy: 0.4515 - val_loss: 2.5335 - val_accuracy: 0.4608\n",
      "Epoch 354/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5366 - accuracy: 0.4423 - val_loss: 2.5454 - val_accuracy: 0.4684\n",
      "Epoch 355/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5381 - accuracy: 0.4527 - val_loss: 2.5211 - val_accuracy: 0.4678\n",
      "Epoch 356/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5228 - accuracy: 0.4474 - val_loss: 2.5280 - val_accuracy: 0.4681\n",
      "Epoch 357/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5289 - accuracy: 0.4486 - val_loss: 2.5277 - val_accuracy: 0.4732\n",
      "Epoch 358/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5204 - accuracy: 0.4521 - val_loss: 2.5139 - val_accuracy: 0.4739\n",
      "Epoch 359/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5148 - accuracy: 0.4528 - val_loss: 2.5228 - val_accuracy: 0.4687\n",
      "Epoch 360/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5288 - accuracy: 0.4486 - val_loss: 2.5295 - val_accuracy: 0.4688\n",
      "Epoch 361/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5308 - accuracy: 0.4499 - val_loss: 2.5243 - val_accuracy: 0.4701\n",
      "Epoch 362/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5156 - accuracy: 0.4514 - val_loss: 2.5444 - val_accuracy: 0.4635\n",
      "Epoch 363/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5601 - accuracy: 0.4443 - val_loss: 2.5705 - val_accuracy: 0.4620\n",
      "Epoch 364/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5782 - accuracy: 0.4420 - val_loss: 2.5634 - val_accuracy: 0.4573\n",
      "Epoch 365/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5671 - accuracy: 0.4398 - val_loss: 2.5618 - val_accuracy: 0.4663\n",
      "Epoch 366/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5602 - accuracy: 0.4512 - val_loss: 2.5526 - val_accuracy: 0.4591\n",
      "Epoch 367/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5698 - accuracy: 0.4387 - val_loss: 2.5401 - val_accuracy: 0.4662\n",
      "Epoch 368/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5417 - accuracy: 0.4493 - val_loss: 2.5395 - val_accuracy: 0.4700\n",
      "Epoch 369/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5410 - accuracy: 0.4513 - val_loss: 2.5304 - val_accuracy: 0.4651\n",
      "Epoch 370/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5362 - accuracy: 0.4466 - val_loss: 2.5257 - val_accuracy: 0.4676\n",
      "Epoch 371/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5274 - accuracy: 0.4510 - val_loss: 2.5259 - val_accuracy: 0.4693\n",
      "Epoch 372/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5230 - accuracy: 0.4527 - val_loss: 2.5216 - val_accuracy: 0.4653\n",
      "Epoch 373/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.5261 - accuracy: 0.4475 - val_loss: 2.5185 - val_accuracy: 0.4761\n",
      "Epoch 374/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5126 - accuracy: 0.4562 - val_loss: 2.5199 - val_accuracy: 0.4777\n",
      "Epoch 375/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5169 - accuracy: 0.4533 - val_loss: 2.5107 - val_accuracy: 0.4699\n",
      "Epoch 376/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5130 - accuracy: 0.4505 - val_loss: 2.5177 - val_accuracy: 0.4698\n",
      "Epoch 377/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5241 - accuracy: 0.4510 - val_loss: 2.5285 - val_accuracy: 0.4651\n",
      "Epoch 378/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5662 - accuracy: 0.4443 - val_loss: 2.6557 - val_accuracy: 0.4574\n",
      "Epoch 379/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6537 - accuracy: 0.4393 - val_loss: 2.6145 - val_accuracy: 0.4585\n",
      "Epoch 380/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6213 - accuracy: 0.4419 - val_loss: 2.6122 - val_accuracy: 0.4572\n",
      "Epoch 381/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6375 - accuracy: 0.4354 - val_loss: 2.5886 - val_accuracy: 0.4577\n",
      "Epoch 382/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6116 - accuracy: 0.4366 - val_loss: 2.5780 - val_accuracy: 0.4494\n",
      "Epoch 383/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6001 - accuracy: 0.4342 - val_loss: 2.5623 - val_accuracy: 0.4595\n",
      "Epoch 384/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5816 - accuracy: 0.4431 - val_loss: 2.5696 - val_accuracy: 0.4690\n",
      "Epoch 385/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5921 - accuracy: 0.4451 - val_loss: 2.5613 - val_accuracy: 0.4572\n",
      "Epoch 386/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5797 - accuracy: 0.4376 - val_loss: 2.5511 - val_accuracy: 0.4658\n",
      "Epoch 387/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5608 - accuracy: 0.4470 - val_loss: 2.5451 - val_accuracy: 0.4678\n",
      "Epoch 388/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5579 - accuracy: 0.4489 - val_loss: 2.5481 - val_accuracy: 0.4559\n",
      "Epoch 389/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5537 - accuracy: 0.4407 - val_loss: 2.5523 - val_accuracy: 0.4621\n",
      "Epoch 390/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5507 - accuracy: 0.4456 - val_loss: 2.5580 - val_accuracy: 0.4611\n",
      "Epoch 391/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5576 - accuracy: 0.4440 - val_loss: 2.5508 - val_accuracy: 0.4637\n",
      "Epoch 392/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5569 - accuracy: 0.4440 - val_loss: 2.5288 - val_accuracy: 0.4677\n",
      "Epoch 393/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5370 - accuracy: 0.4468 - val_loss: 2.5335 - val_accuracy: 0.4723\n",
      "Epoch 394/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5365 - accuracy: 0.4539 - val_loss: 2.5401 - val_accuracy: 0.4635\n",
      "Epoch 395/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5318 - accuracy: 0.4462 - val_loss: 2.5333 - val_accuracy: 0.4679\n",
      "Epoch 396/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5240 - accuracy: 0.4509 - val_loss: 2.5317 - val_accuracy: 0.4694\n",
      "Epoch 397/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5301 - accuracy: 0.4523 - val_loss: 2.5232 - val_accuracy: 0.4696\n",
      "Epoch 398/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5239 - accuracy: 0.4498 - val_loss: 2.5212 - val_accuracy: 0.4704\n",
      "Epoch 399/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5201 - accuracy: 0.4496 - val_loss: 2.5162 - val_accuracy: 0.4705\n",
      "Epoch 400/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5064 - accuracy: 0.4535 - val_loss: 2.5235 - val_accuracy: 0.4724\n",
      "Epoch 401/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5129 - accuracy: 0.4554 - val_loss: 2.5111 - val_accuracy: 0.4684\n",
      "Epoch 402/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5088 - accuracy: 0.4509 - val_loss: 2.5114 - val_accuracy: 0.4736\n",
      "Epoch 403/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4967 - accuracy: 0.4571 - val_loss: 2.5146 - val_accuracy: 0.4718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5073 - accuracy: 0.4543 - val_loss: 2.5166 - val_accuracy: 0.4669\n",
      "Epoch 405/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5093 - accuracy: 0.4505 - val_loss: 2.5367 - val_accuracy: 0.4711\n",
      "Epoch 406/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5365 - accuracy: 0.4513 - val_loss: 2.5773 - val_accuracy: 0.4624\n",
      "Epoch 407/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5744 - accuracy: 0.4443 - val_loss: 2.6026 - val_accuracy: 0.4530\n",
      "Epoch 408/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6087 - accuracy: 0.4355 - val_loss: 2.6226 - val_accuracy: 0.4524\n",
      "Epoch 409/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6279 - accuracy: 0.4363 - val_loss: 2.6169 - val_accuracy: 0.4509\n",
      "Epoch 410/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6286 - accuracy: 0.4332 - val_loss: 2.6039 - val_accuracy: 0.4572\n",
      "Epoch 411/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6127 - accuracy: 0.4387 - val_loss: 2.5942 - val_accuracy: 0.4534\n",
      "Epoch 412/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.6012 - accuracy: 0.4375 - val_loss: 2.5765 - val_accuracy: 0.4607\n",
      "Epoch 413/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5969 - accuracy: 0.4415 - val_loss: 2.5630 - val_accuracy: 0.4664\n",
      "Epoch 414/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5808 - accuracy: 0.4449 - val_loss: 2.5562 - val_accuracy: 0.4595\n",
      "Epoch 415/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5721 - accuracy: 0.4383 - val_loss: 2.5605 - val_accuracy: 0.4631\n",
      "Epoch 416/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5598 - accuracy: 0.4437 - val_loss: 2.5609 - val_accuracy: 0.4668\n",
      "Epoch 417/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5516 - accuracy: 0.4492 - val_loss: 2.5525 - val_accuracy: 0.4653\n",
      "Epoch 418/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5472 - accuracy: 0.4494 - val_loss: 2.5419 - val_accuracy: 0.4642\n",
      "Epoch 419/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5453 - accuracy: 0.4451 - val_loss: 2.5399 - val_accuracy: 0.4714\n",
      "Epoch 420/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5254 - accuracy: 0.4558 - val_loss: 2.5413 - val_accuracy: 0.4675\n",
      "Epoch 421/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5292 - accuracy: 0.4502 - val_loss: 2.5250 - val_accuracy: 0.4672\n",
      "Epoch 422/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5221 - accuracy: 0.4481 - val_loss: 2.5149 - val_accuracy: 0.4722\n",
      "Epoch 423/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5166 - accuracy: 0.4520 - val_loss: 2.5095 - val_accuracy: 0.4746\n",
      "Epoch 424/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5061 - accuracy: 0.4538 - val_loss: 2.5124 - val_accuracy: 0.4746\n",
      "Epoch 425/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5050 - accuracy: 0.4556 - val_loss: 2.5157 - val_accuracy: 0.4737\n",
      "Epoch 426/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5135 - accuracy: 0.4539 - val_loss: 2.5056 - val_accuracy: 0.4761\n",
      "Epoch 427/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5068 - accuracy: 0.4539 - val_loss: 2.5235 - val_accuracy: 0.4770\n",
      "Epoch 428/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5088 - accuracy: 0.4580 - val_loss: 2.5078 - val_accuracy: 0.4633\n",
      "Epoch 429/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5073 - accuracy: 0.4474 - val_loss: 2.5142 - val_accuracy: 0.4755\n",
      "Epoch 430/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5062 - accuracy: 0.4598 - val_loss: 2.5050 - val_accuracy: 0.4726\n",
      "Epoch 431/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5045 - accuracy: 0.4520 - val_loss: 2.5080 - val_accuracy: 0.4750\n",
      "Epoch 432/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4969 - accuracy: 0.4550 - val_loss: 2.5074 - val_accuracy: 0.4784\n",
      "Epoch 433/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4983 - accuracy: 0.4571 - val_loss: 2.4979 - val_accuracy: 0.4755\n",
      "Epoch 434/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4893 - accuracy: 0.4568 - val_loss: 2.4977 - val_accuracy: 0.4756\n",
      "Epoch 435/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4798 - accuracy: 0.4590 - val_loss: 2.5025 - val_accuracy: 0.4745\n",
      "Epoch 436/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4822 - accuracy: 0.4604 - val_loss: 2.4998 - val_accuracy: 0.4728\n",
      "Epoch 437/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4850 - accuracy: 0.4572 - val_loss: 2.4952 - val_accuracy: 0.4774\n",
      "Epoch 438/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4745 - accuracy: 0.4609 - val_loss: 2.4897 - val_accuracy: 0.4766\n",
      "Epoch 439/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4818 - accuracy: 0.4539 - val_loss: 2.4886 - val_accuracy: 0.4764\n",
      "Epoch 440/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4772 - accuracy: 0.4552 - val_loss: 2.4938 - val_accuracy: 0.4795\n",
      "Epoch 441/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4721 - accuracy: 0.4612 - val_loss: 2.4868 - val_accuracy: 0.4788\n",
      "Epoch 442/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4749 - accuracy: 0.4570 - val_loss: 2.4922 - val_accuracy: 0.4783\n",
      "Epoch 443/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4744 - accuracy: 0.4598 - val_loss: 2.5012 - val_accuracy: 0.4764\n",
      "Epoch 444/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4881 - accuracy: 0.4567 - val_loss: 2.4917 - val_accuracy: 0.4802\n",
      "Epoch 445/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4742 - accuracy: 0.4590 - val_loss: 2.4984 - val_accuracy: 0.4808\n",
      "Epoch 446/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4710 - accuracy: 0.4614 - val_loss: 2.4857 - val_accuracy: 0.4767\n",
      "Epoch 447/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4719 - accuracy: 0.4582 - val_loss: 2.4890 - val_accuracy: 0.4840\n",
      "Epoch 448/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4768 - accuracy: 0.4625 - val_loss: 2.5014 - val_accuracy: 0.4792\n",
      "Epoch 449/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4791 - accuracy: 0.4604 - val_loss: 2.4980 - val_accuracy: 0.4699\n",
      "Epoch 450/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4770 - accuracy: 0.4537 - val_loss: 2.4932 - val_accuracy: 0.4800\n",
      "Epoch 451/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4801 - accuracy: 0.4604 - val_loss: 2.5018 - val_accuracy: 0.4751\n",
      "Epoch 452/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4982 - accuracy: 0.4565 - val_loss: 2.5029 - val_accuracy: 0.4699\n",
      "Epoch 453/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4917 - accuracy: 0.4514 - val_loss: 2.5196 - val_accuracy: 0.4782\n",
      "Epoch 454/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4968 - accuracy: 0.4589 - val_loss: 2.4952 - val_accuracy: 0.4772\n",
      "Epoch 455/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4722 - accuracy: 0.4597 - val_loss: 2.5001 - val_accuracy: 0.4722\n",
      "Epoch 456/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4893 - accuracy: 0.4571 - val_loss: 2.4923 - val_accuracy: 0.4815\n",
      "Epoch 457/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4765 - accuracy: 0.4628 - val_loss: 2.4952 - val_accuracy: 0.4828\n",
      "Epoch 458/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4758 - accuracy: 0.4620 - val_loss: 2.4893 - val_accuracy: 0.4753\n",
      "Epoch 459/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4651 - accuracy: 0.4606 - val_loss: 2.4921 - val_accuracy: 0.4766\n",
      "Epoch 460/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4673 - accuracy: 0.4591 - val_loss: 2.4800 - val_accuracy: 0.4824\n",
      "Epoch 461/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4601 - accuracy: 0.4632 - val_loss: 2.4858 - val_accuracy: 0.4812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4626 - accuracy: 0.4637 - val_loss: 2.4783 - val_accuracy: 0.4790\n",
      "Epoch 463/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4581 - accuracy: 0.4622 - val_loss: 2.4868 - val_accuracy: 0.4774\n",
      "Epoch 464/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4639 - accuracy: 0.4603 - val_loss: 2.4841 - val_accuracy: 0.4797\n",
      "Epoch 465/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4586 - accuracy: 0.4631 - val_loss: 2.4844 - val_accuracy: 0.4808\n",
      "Epoch 466/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4615 - accuracy: 0.4622 - val_loss: 2.4866 - val_accuracy: 0.4853\n",
      "Epoch 467/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4698 - accuracy: 0.4635 - val_loss: 2.4872 - val_accuracy: 0.4736\n",
      "Epoch 468/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4667 - accuracy: 0.4543 - val_loss: 2.5017 - val_accuracy: 0.4842\n",
      "Epoch 469/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4665 - accuracy: 0.4679 - val_loss: 2.4884 - val_accuracy: 0.4802\n",
      "Epoch 470/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4627 - accuracy: 0.4632 - val_loss: 2.4812 - val_accuracy: 0.4728\n",
      "Epoch 471/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4637 - accuracy: 0.4545 - val_loss: 2.4903 - val_accuracy: 0.4844\n",
      "Epoch 472/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4637 - accuracy: 0.4653 - val_loss: 2.4817 - val_accuracy: 0.4826\n",
      "Epoch 473/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4642 - accuracy: 0.4623 - val_loss: 2.4791 - val_accuracy: 0.4753\n",
      "Epoch 474/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4544 - accuracy: 0.4604 - val_loss: 2.4970 - val_accuracy: 0.4784\n",
      "Epoch 475/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4599 - accuracy: 0.4647 - val_loss: 2.4784 - val_accuracy: 0.4773\n",
      "Epoch 476/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4531 - accuracy: 0.4630 - val_loss: 2.4797 - val_accuracy: 0.4812\n",
      "Epoch 477/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4540 - accuracy: 0.4618 - val_loss: 2.4895 - val_accuracy: 0.4825\n",
      "Epoch 478/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4498 - accuracy: 0.4658 - val_loss: 2.4748 - val_accuracy: 0.4820\n",
      "Epoch 479/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4407 - accuracy: 0.4639 - val_loss: 2.4799 - val_accuracy: 0.4752\n",
      "Epoch 480/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4548 - accuracy: 0.4590 - val_loss: 2.4860 - val_accuracy: 0.4859\n",
      "Epoch 481/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4505 - accuracy: 0.4668 - val_loss: 2.4792 - val_accuracy: 0.4790\n",
      "Epoch 482/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4545 - accuracy: 0.4622 - val_loss: 2.4831 - val_accuracy: 0.4786\n",
      "Epoch 483/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4621 - accuracy: 0.4601 - val_loss: 2.4938 - val_accuracy: 0.4781\n",
      "Epoch 484/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4734 - accuracy: 0.4603 - val_loss: 2.4963 - val_accuracy: 0.4796\n",
      "Epoch 485/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4790 - accuracy: 0.4588 - val_loss: 2.4807 - val_accuracy: 0.4777\n",
      "Epoch 486/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4654 - accuracy: 0.4596 - val_loss: 2.4967 - val_accuracy: 0.4789\n",
      "Epoch 487/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4753 - accuracy: 0.4602 - val_loss: 2.4849 - val_accuracy: 0.4805\n",
      "Epoch 488/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4596 - accuracy: 0.4638 - val_loss: 2.4809 - val_accuracy: 0.4793\n",
      "Epoch 489/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4585 - accuracy: 0.4618 - val_loss: 2.4744 - val_accuracy: 0.4790\n",
      "Epoch 490/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4493 - accuracy: 0.4641 - val_loss: 2.4750 - val_accuracy: 0.4806\n",
      "Epoch 491/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4434 - accuracy: 0.4656 - val_loss: 2.4716 - val_accuracy: 0.4815\n",
      "Epoch 492/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4503 - accuracy: 0.4624 - val_loss: 2.4763 - val_accuracy: 0.4843\n",
      "Epoch 493/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4437 - accuracy: 0.4671 - val_loss: 2.4805 - val_accuracy: 0.4844\n",
      "Epoch 494/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4429 - accuracy: 0.4671 - val_loss: 2.4764 - val_accuracy: 0.4769\n",
      "Epoch 495/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4470 - accuracy: 0.4619 - val_loss: 2.4815 - val_accuracy: 0.4819\n",
      "Epoch 496/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4446 - accuracy: 0.4677 - val_loss: 2.4667 - val_accuracy: 0.4802\n",
      "Epoch 497/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4404 - accuracy: 0.4616 - val_loss: 2.4731 - val_accuracy: 0.4833\n",
      "Epoch 498/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4367 - accuracy: 0.4680 - val_loss: 2.4726 - val_accuracy: 0.4835\n",
      "Epoch 499/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4379 - accuracy: 0.4677 - val_loss: 2.4634 - val_accuracy: 0.4813\n",
      "Epoch 500/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4383 - accuracy: 0.4637 - val_loss: 2.4741 - val_accuracy: 0.4855\n",
      "Epoch 501/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4334 - accuracy: 0.4678 - val_loss: 2.4735 - val_accuracy: 0.4818\n",
      "Epoch 502/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4344 - accuracy: 0.4671 - val_loss: 2.4685 - val_accuracy: 0.4800\n",
      "Epoch 503/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4305 - accuracy: 0.4646 - val_loss: 2.4750 - val_accuracy: 0.4846\n",
      "Epoch 504/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4384 - accuracy: 0.4683 - val_loss: 2.4621 - val_accuracy: 0.4835\n",
      "Epoch 505/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4381 - accuracy: 0.4648 - val_loss: 2.4636 - val_accuracy: 0.4826\n",
      "Epoch 506/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4234 - accuracy: 0.4686 - val_loss: 2.4701 - val_accuracy: 0.4834\n",
      "Epoch 507/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4232 - accuracy: 0.4706 - val_loss: 2.4639 - val_accuracy: 0.4838\n",
      "Epoch 508/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4272 - accuracy: 0.4665 - val_loss: 2.4636 - val_accuracy: 0.4816\n",
      "Epoch 509/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4289 - accuracy: 0.4672 - val_loss: 2.4731 - val_accuracy: 0.4850\n",
      "Epoch 510/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4247 - accuracy: 0.4724 - val_loss: 2.4621 - val_accuracy: 0.4818\n",
      "Epoch 511/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4313 - accuracy: 0.4654 - val_loss: 2.4639 - val_accuracy: 0.4838\n",
      "Epoch 512/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4322 - accuracy: 0.4632 - val_loss: 2.4730 - val_accuracy: 0.4865\n",
      "Epoch 513/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4293 - accuracy: 0.4700 - val_loss: 2.4642 - val_accuracy: 0.4827\n",
      "Epoch 514/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4406 - accuracy: 0.4629 - val_loss: 2.4709 - val_accuracy: 0.4824\n",
      "Epoch 515/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4340 - accuracy: 0.4669 - val_loss: 2.4804 - val_accuracy: 0.4857\n",
      "Epoch 516/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4409 - accuracy: 0.4661 - val_loss: 2.4912 - val_accuracy: 0.4843\n",
      "Epoch 517/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4536 - accuracy: 0.4660 - val_loss: 2.4676 - val_accuracy: 0.4828\n",
      "Epoch 518/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4374 - accuracy: 0.4654 - val_loss: 2.4760 - val_accuracy: 0.4859\n",
      "Epoch 519/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4508 - accuracy: 0.4655 - val_loss: 2.4649 - val_accuracy: 0.4829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4305 - accuracy: 0.4659 - val_loss: 2.4759 - val_accuracy: 0.4814\n",
      "Epoch 521/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4449 - accuracy: 0.4644 - val_loss: 2.4668 - val_accuracy: 0.4846\n",
      "Epoch 522/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4266 - accuracy: 0.4678 - val_loss: 2.4715 - val_accuracy: 0.4847\n",
      "Epoch 523/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4349 - accuracy: 0.4666 - val_loss: 2.4601 - val_accuracy: 0.4838\n",
      "Epoch 524/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4250 - accuracy: 0.4673 - val_loss: 2.4599 - val_accuracy: 0.4864\n",
      "Epoch 525/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4170 - accuracy: 0.4712 - val_loss: 2.4624 - val_accuracy: 0.4843\n",
      "Epoch 526/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4309 - accuracy: 0.4665 - val_loss: 2.4615 - val_accuracy: 0.4859\n",
      "Epoch 527/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4150 - accuracy: 0.4720 - val_loss: 2.4645 - val_accuracy: 0.4841\n",
      "Epoch 528/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4260 - accuracy: 0.4683 - val_loss: 2.4680 - val_accuracy: 0.4856\n",
      "Epoch 529/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4211 - accuracy: 0.4696 - val_loss: 2.4604 - val_accuracy: 0.4847\n",
      "Epoch 530/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4193 - accuracy: 0.4673 - val_loss: 2.4618 - val_accuracy: 0.4854\n",
      "Epoch 531/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4176 - accuracy: 0.4713 - val_loss: 2.4551 - val_accuracy: 0.4889\n",
      "Epoch 532/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4155 - accuracy: 0.4709 - val_loss: 2.4538 - val_accuracy: 0.4855\n",
      "Epoch 533/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4153 - accuracy: 0.4694 - val_loss: 2.4555 - val_accuracy: 0.4858\n",
      "Epoch 534/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4136 - accuracy: 0.4721 - val_loss: 2.4548 - val_accuracy: 0.4863\n",
      "Epoch 535/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4208 - accuracy: 0.4668 - val_loss: 2.4774 - val_accuracy: 0.4874\n",
      "Epoch 536/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4238 - accuracy: 0.4729 - val_loss: 2.4587 - val_accuracy: 0.4792\n",
      "Epoch 537/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4238 - accuracy: 0.4624 - val_loss: 2.4668 - val_accuracy: 0.4859\n",
      "Epoch 538/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4202 - accuracy: 0.4710 - val_loss: 2.4643 - val_accuracy: 0.4869\n",
      "Epoch 539/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4167 - accuracy: 0.4716 - val_loss: 2.4527 - val_accuracy: 0.4833\n",
      "Epoch 540/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4186 - accuracy: 0.4676 - val_loss: 2.4751 - val_accuracy: 0.4848\n",
      "Epoch 541/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4235 - accuracy: 0.4711 - val_loss: 2.4571 - val_accuracy: 0.4828\n",
      "Epoch 542/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4106 - accuracy: 0.4697 - val_loss: 2.4593 - val_accuracy: 0.4854\n",
      "Epoch 543/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4162 - accuracy: 0.4693 - val_loss: 2.4680 - val_accuracy: 0.4887\n",
      "Epoch 544/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4222 - accuracy: 0.4688 - val_loss: 2.4655 - val_accuracy: 0.4889\n",
      "Epoch 545/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4211 - accuracy: 0.4712 - val_loss: 2.4542 - val_accuracy: 0.4815\n",
      "Epoch 546/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4247 - accuracy: 0.4636 - val_loss: 2.4714 - val_accuracy: 0.4892\n",
      "Epoch 547/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4159 - accuracy: 0.4758 - val_loss: 2.4515 - val_accuracy: 0.4851\n",
      "Epoch 548/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4059 - accuracy: 0.4694 - val_loss: 2.4499 - val_accuracy: 0.4831\n",
      "Epoch 549/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4149 - accuracy: 0.4683 - val_loss: 2.4589 - val_accuracy: 0.4893\n",
      "Epoch 550/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4179 - accuracy: 0.4734 - val_loss: 2.4485 - val_accuracy: 0.4879\n",
      "Epoch 551/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4118 - accuracy: 0.4708 - val_loss: 2.4586 - val_accuracy: 0.4883\n",
      "Epoch 552/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4122 - accuracy: 0.4721 - val_loss: 2.4576 - val_accuracy: 0.4877\n",
      "Epoch 553/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.4157 - accuracy: 0.4699 - val_loss: 2.4561 - val_accuracy: 0.4869\n",
      "Epoch 554/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4117 - accuracy: 0.4686 - val_loss: 2.4624 - val_accuracy: 0.4888\n",
      "Epoch 555/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4086 - accuracy: 0.4738 - val_loss: 2.4600 - val_accuracy: 0.4869\n",
      "Epoch 556/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4075 - accuracy: 0.4734 - val_loss: 2.4478 - val_accuracy: 0.4846\n",
      "Epoch 557/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4083 - accuracy: 0.4677 - val_loss: 2.4593 - val_accuracy: 0.4873\n",
      "Epoch 558/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4053 - accuracy: 0.4729 - val_loss: 2.4533 - val_accuracy: 0.4849\n",
      "Epoch 559/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4049 - accuracy: 0.4722 - val_loss: 2.4531 - val_accuracy: 0.4835\n",
      "Epoch 560/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4093 - accuracy: 0.4702 - val_loss: 2.4648 - val_accuracy: 0.4924\n",
      "Epoch 561/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4135 - accuracy: 0.4740 - val_loss: 2.4514 - val_accuracy: 0.4846\n",
      "Epoch 562/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4131 - accuracy: 0.4664 - val_loss: 2.4621 - val_accuracy: 0.4891\n",
      "Epoch 563/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4235 - accuracy: 0.4699 - val_loss: 2.4569 - val_accuracy: 0.4883\n",
      "Epoch 564/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4091 - accuracy: 0.4722 - val_loss: 2.4649 - val_accuracy: 0.4835\n",
      "Epoch 565/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4205 - accuracy: 0.4678 - val_loss: 2.4642 - val_accuracy: 0.4823\n",
      "Epoch 566/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4217 - accuracy: 0.4700 - val_loss: 2.4614 - val_accuracy: 0.4877\n",
      "Epoch 567/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4130 - accuracy: 0.4704 - val_loss: 2.4508 - val_accuracy: 0.4873\n",
      "Epoch 568/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4163 - accuracy: 0.4676 - val_loss: 2.4536 - val_accuracy: 0.4868\n",
      "Epoch 569/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4014 - accuracy: 0.4733 - val_loss: 2.4701 - val_accuracy: 0.4841\n",
      "Epoch 570/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4213 - accuracy: 0.4707 - val_loss: 2.4684 - val_accuracy: 0.4853\n",
      "Epoch 571/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4277 - accuracy: 0.4694 - val_loss: 2.4570 - val_accuracy: 0.4870\n",
      "Epoch 572/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4252 - accuracy: 0.4672 - val_loss: 2.4588 - val_accuracy: 0.4881\n",
      "Epoch 573/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4145 - accuracy: 0.4709 - val_loss: 2.4582 - val_accuracy: 0.4818\n",
      "Epoch 574/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4152 - accuracy: 0.4692 - val_loss: 2.4614 - val_accuracy: 0.4821\n",
      "Epoch 575/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4123 - accuracy: 0.4682 - val_loss: 2.4602 - val_accuracy: 0.4892\n",
      "Epoch 576/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4155 - accuracy: 0.4722 - val_loss: 2.4699 - val_accuracy: 0.4869\n",
      "Epoch 577/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4299 - accuracy: 0.4716 - val_loss: 2.4546 - val_accuracy: 0.4790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4227 - accuracy: 0.4631 - val_loss: 2.4760 - val_accuracy: 0.4872\n",
      "Epoch 579/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4172 - accuracy: 0.4729 - val_loss: 2.4764 - val_accuracy: 0.4881\n",
      "Epoch 580/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4233 - accuracy: 0.4726 - val_loss: 2.4609 - val_accuracy: 0.4811\n",
      "Epoch 581/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4154 - accuracy: 0.4640 - val_loss: 2.4718 - val_accuracy: 0.4901\n",
      "Epoch 582/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4217 - accuracy: 0.4741 - val_loss: 2.4528 - val_accuracy: 0.4823\n",
      "Epoch 583/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4150 - accuracy: 0.4680 - val_loss: 2.4544 - val_accuracy: 0.4851\n",
      "Epoch 584/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4074 - accuracy: 0.4717 - val_loss: 2.4651 - val_accuracy: 0.4873\n",
      "Epoch 585/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4172 - accuracy: 0.4722 - val_loss: 2.4511 - val_accuracy: 0.4846\n",
      "Epoch 586/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4081 - accuracy: 0.4721 - val_loss: 2.4520 - val_accuracy: 0.4835\n",
      "Epoch 587/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4064 - accuracy: 0.4684 - val_loss: 2.4635 - val_accuracy: 0.4884\n",
      "Epoch 588/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4073 - accuracy: 0.4718 - val_loss: 2.4540 - val_accuracy: 0.4841\n",
      "Epoch 589/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4059 - accuracy: 0.4691 - val_loss: 2.4588 - val_accuracy: 0.4843\n",
      "Epoch 590/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4161 - accuracy: 0.4666 - val_loss: 2.4659 - val_accuracy: 0.4914\n",
      "Epoch 591/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4079 - accuracy: 0.4757 - val_loss: 2.4530 - val_accuracy: 0.4844\n",
      "Epoch 592/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4066 - accuracy: 0.4695 - val_loss: 2.4523 - val_accuracy: 0.4837\n",
      "Epoch 593/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4042 - accuracy: 0.4686 - val_loss: 2.4609 - val_accuracy: 0.4865\n",
      "Epoch 594/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4085 - accuracy: 0.4740 - val_loss: 2.4468 - val_accuracy: 0.4862\n",
      "Epoch 595/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4063 - accuracy: 0.4689 - val_loss: 2.4427 - val_accuracy: 0.4882\n",
      "Epoch 596/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4066 - accuracy: 0.4691 - val_loss: 2.4566 - val_accuracy: 0.4901\n",
      "Epoch 597/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4030 - accuracy: 0.4770 - val_loss: 2.4626 - val_accuracy: 0.4827\n",
      "Epoch 598/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4173 - accuracy: 0.4670 - val_loss: 2.4846 - val_accuracy: 0.4868\n",
      "Epoch 599/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4174 - accuracy: 0.4750 - val_loss: 2.4557 - val_accuracy: 0.4854\n",
      "Epoch 600/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4002 - accuracy: 0.4737 - val_loss: 2.4583 - val_accuracy: 0.4803\n",
      "Epoch 601/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4107 - accuracy: 0.4675 - val_loss: 2.4750 - val_accuracy: 0.4883\n",
      "Epoch 602/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4167 - accuracy: 0.4751 - val_loss: 2.4569 - val_accuracy: 0.4900\n",
      "Epoch 603/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4018 - accuracy: 0.4746 - val_loss: 2.4546 - val_accuracy: 0.4836\n",
      "Epoch 604/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4177 - accuracy: 0.4660 - val_loss: 2.4673 - val_accuracy: 0.4877\n",
      "Epoch 605/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4166 - accuracy: 0.4734 - val_loss: 2.4589 - val_accuracy: 0.4834\n",
      "Epoch 606/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4114 - accuracy: 0.4670 - val_loss: 2.4530 - val_accuracy: 0.4847\n",
      "Epoch 607/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3976 - accuracy: 0.4727 - val_loss: 2.4697 - val_accuracy: 0.4897\n",
      "Epoch 608/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4155 - accuracy: 0.4725 - val_loss: 2.4492 - val_accuracy: 0.4837\n",
      "Epoch 609/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4047 - accuracy: 0.4682 - val_loss: 2.4581 - val_accuracy: 0.4845\n",
      "Epoch 610/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4025 - accuracy: 0.4733 - val_loss: 2.4529 - val_accuracy: 0.4896\n",
      "Epoch 611/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3956 - accuracy: 0.4754 - val_loss: 2.4443 - val_accuracy: 0.4891\n",
      "Epoch 612/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3945 - accuracy: 0.4733 - val_loss: 2.4449 - val_accuracy: 0.4857\n",
      "Epoch 613/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3931 - accuracy: 0.4723 - val_loss: 2.4715 - val_accuracy: 0.4890\n",
      "Epoch 614/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4072 - accuracy: 0.4768 - val_loss: 2.4507 - val_accuracy: 0.4838\n",
      "Epoch 615/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4079 - accuracy: 0.4674 - val_loss: 2.4520 - val_accuracy: 0.4851\n",
      "Epoch 616/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4056 - accuracy: 0.4735 - val_loss: 2.4593 - val_accuracy: 0.4885\n",
      "Epoch 617/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4069 - accuracy: 0.4758 - val_loss: 2.4572 - val_accuracy: 0.4845\n",
      "Epoch 618/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4010 - accuracy: 0.4714 - val_loss: 2.4534 - val_accuracy: 0.4873\n",
      "Epoch 619/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3973 - accuracy: 0.4703 - val_loss: 2.4625 - val_accuracy: 0.4911\n",
      "Epoch 620/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4015 - accuracy: 0.4748 - val_loss: 2.4470 - val_accuracy: 0.4864\n",
      "Epoch 621/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3935 - accuracy: 0.4715 - val_loss: 2.4508 - val_accuracy: 0.4846\n",
      "Epoch 622/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3968 - accuracy: 0.4715 - val_loss: 2.4495 - val_accuracy: 0.4914\n",
      "Epoch 623/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3948 - accuracy: 0.4759 - val_loss: 2.4386 - val_accuracy: 0.4865\n",
      "Epoch 624/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3979 - accuracy: 0.4695 - val_loss: 2.4471 - val_accuracy: 0.4910\n",
      "Epoch 625/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4001 - accuracy: 0.4725 - val_loss: 2.4644 - val_accuracy: 0.4923\n",
      "Epoch 626/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4074 - accuracy: 0.4753 - val_loss: 2.4433 - val_accuracy: 0.4819\n",
      "Epoch 627/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4015 - accuracy: 0.4694 - val_loss: 2.4562 - val_accuracy: 0.4868\n",
      "Epoch 628/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4064 - accuracy: 0.4727 - val_loss: 2.4593 - val_accuracy: 0.4914\n",
      "Epoch 629/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3956 - accuracy: 0.4783 - val_loss: 2.4507 - val_accuracy: 0.4839\n",
      "Epoch 630/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4050 - accuracy: 0.4690 - val_loss: 2.4507 - val_accuracy: 0.4867\n",
      "Epoch 631/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3985 - accuracy: 0.4711 - val_loss: 2.4707 - val_accuracy: 0.4913\n",
      "Epoch 632/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4135 - accuracy: 0.4749 - val_loss: 2.4520 - val_accuracy: 0.4831\n",
      "Epoch 633/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4068 - accuracy: 0.4681 - val_loss: 2.4507 - val_accuracy: 0.4892\n",
      "Epoch 634/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3991 - accuracy: 0.4734 - val_loss: 2.4473 - val_accuracy: 0.4909\n",
      "Epoch 635/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3905 - accuracy: 0.4760 - val_loss: 2.4441 - val_accuracy: 0.4863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3888 - accuracy: 0.4740 - val_loss: 2.4487 - val_accuracy: 0.4892\n",
      "Epoch 637/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3919 - accuracy: 0.4751 - val_loss: 2.4536 - val_accuracy: 0.4917\n",
      "Epoch 638/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3898 - accuracy: 0.4774 - val_loss: 2.4470 - val_accuracy: 0.4871\n",
      "Epoch 639/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4046 - accuracy: 0.4699 - val_loss: 2.4481 - val_accuracy: 0.4923\n",
      "Epoch 640/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3984 - accuracy: 0.4732 - val_loss: 2.4509 - val_accuracy: 0.4871\n",
      "Epoch 641/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3975 - accuracy: 0.4721 - val_loss: 2.4436 - val_accuracy: 0.4896\n",
      "Epoch 642/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3887 - accuracy: 0.4746 - val_loss: 2.4430 - val_accuracy: 0.4915\n",
      "Epoch 643/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3930 - accuracy: 0.4744 - val_loss: 2.4483 - val_accuracy: 0.4898\n",
      "Epoch 644/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3970 - accuracy: 0.4729 - val_loss: 2.4487 - val_accuracy: 0.4895\n",
      "Epoch 645/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3843 - accuracy: 0.4759 - val_loss: 2.4548 - val_accuracy: 0.4841\n",
      "Epoch 646/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3950 - accuracy: 0.4718 - val_loss: 2.4499 - val_accuracy: 0.4885\n",
      "Epoch 647/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3862 - accuracy: 0.4765 - val_loss: 2.4398 - val_accuracy: 0.4880\n",
      "Epoch 648/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3863 - accuracy: 0.4732 - val_loss: 2.4392 - val_accuracy: 0.4917\n",
      "Epoch 649/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3863 - accuracy: 0.4760 - val_loss: 2.4445 - val_accuracy: 0.4908\n",
      "Epoch 650/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3867 - accuracy: 0.4749 - val_loss: 2.4481 - val_accuracy: 0.4877\n",
      "Epoch 651/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3939 - accuracy: 0.4747 - val_loss: 2.4354 - val_accuracy: 0.4882\n",
      "Epoch 652/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3829 - accuracy: 0.4731 - val_loss: 2.4563 - val_accuracy: 0.4919\n",
      "Epoch 653/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3906 - accuracy: 0.4762 - val_loss: 2.4450 - val_accuracy: 0.4871\n",
      "Epoch 654/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3900 - accuracy: 0.4719 - val_loss: 2.4488 - val_accuracy: 0.4907\n",
      "Epoch 655/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3852 - accuracy: 0.4761 - val_loss: 2.4410 - val_accuracy: 0.4899\n",
      "Epoch 656/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3950 - accuracy: 0.4732 - val_loss: 2.4347 - val_accuracy: 0.4881\n",
      "Epoch 657/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3785 - accuracy: 0.4742 - val_loss: 2.4445 - val_accuracy: 0.4887\n",
      "Epoch 658/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3867 - accuracy: 0.4742 - val_loss: 2.4531 - val_accuracy: 0.4931\n",
      "Epoch 659/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3810 - accuracy: 0.4794 - val_loss: 2.4432 - val_accuracy: 0.4883\n",
      "Epoch 660/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3932 - accuracy: 0.4721 - val_loss: 2.4437 - val_accuracy: 0.4918\n",
      "Epoch 661/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3915 - accuracy: 0.4741 - val_loss: 2.4530 - val_accuracy: 0.4920\n",
      "Epoch 662/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3824 - accuracy: 0.4770 - val_loss: 2.4395 - val_accuracy: 0.4878\n",
      "Epoch 663/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3884 - accuracy: 0.4729 - val_loss: 2.4472 - val_accuracy: 0.4889\n",
      "Epoch 664/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3837 - accuracy: 0.4763 - val_loss: 2.4430 - val_accuracy: 0.4908\n",
      "Epoch 665/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3805 - accuracy: 0.4771 - val_loss: 2.4379 - val_accuracy: 0.4915\n",
      "Epoch 666/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3777 - accuracy: 0.4774 - val_loss: 2.4384 - val_accuracy: 0.4913\n",
      "Epoch 667/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3765 - accuracy: 0.4760 - val_loss: 2.4455 - val_accuracy: 0.4908\n",
      "Epoch 668/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3826 - accuracy: 0.4760 - val_loss: 2.4352 - val_accuracy: 0.4907\n",
      "Epoch 669/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3716 - accuracy: 0.4777 - val_loss: 2.4383 - val_accuracy: 0.4874\n",
      "Epoch 670/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3843 - accuracy: 0.4752 - val_loss: 2.4341 - val_accuracy: 0.4918\n",
      "Epoch 671/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3820 - accuracy: 0.4756 - val_loss: 2.4341 - val_accuracy: 0.4913\n",
      "Epoch 672/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3721 - accuracy: 0.4760 - val_loss: 2.4375 - val_accuracy: 0.4889\n",
      "Epoch 673/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3815 - accuracy: 0.4746 - val_loss: 2.4429 - val_accuracy: 0.4915\n",
      "Epoch 674/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3720 - accuracy: 0.4787 - val_loss: 2.4414 - val_accuracy: 0.4896\n",
      "Epoch 675/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3791 - accuracy: 0.4771 - val_loss: 2.4385 - val_accuracy: 0.4903\n",
      "Epoch 676/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3741 - accuracy: 0.4759 - val_loss: 2.4387 - val_accuracy: 0.4903\n",
      "Epoch 677/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3749 - accuracy: 0.4778 - val_loss: 2.4405 - val_accuracy: 0.4917\n",
      "Epoch 678/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3764 - accuracy: 0.4789 - val_loss: 2.4388 - val_accuracy: 0.4923\n",
      "Epoch 679/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3812 - accuracy: 0.4762 - val_loss: 2.4340 - val_accuracy: 0.4911\n",
      "Epoch 680/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3779 - accuracy: 0.4747 - val_loss: 2.4406 - val_accuracy: 0.4920\n",
      "Epoch 681/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3776 - accuracy: 0.4783 - val_loss: 2.4393 - val_accuracy: 0.4874\n",
      "Epoch 682/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3775 - accuracy: 0.4741 - val_loss: 2.4492 - val_accuracy: 0.4931\n",
      "Epoch 683/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3788 - accuracy: 0.4804 - val_loss: 2.4399 - val_accuracy: 0.4883\n",
      "Epoch 684/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3838 - accuracy: 0.4744 - val_loss: 2.4396 - val_accuracy: 0.4889\n",
      "Epoch 685/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3837 - accuracy: 0.4726 - val_loss: 2.4534 - val_accuracy: 0.4938\n",
      "Epoch 686/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3828 - accuracy: 0.4793 - val_loss: 2.4440 - val_accuracy: 0.4902\n",
      "Epoch 687/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3849 - accuracy: 0.4741 - val_loss: 2.4339 - val_accuracy: 0.4885\n",
      "Epoch 688/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3803 - accuracy: 0.4738 - val_loss: 2.4488 - val_accuracy: 0.4898\n",
      "Epoch 689/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3818 - accuracy: 0.4797 - val_loss: 2.4512 - val_accuracy: 0.4886\n",
      "Epoch 690/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3994 - accuracy: 0.4691 - val_loss: 2.4476 - val_accuracy: 0.4906\n",
      "Epoch 691/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3873 - accuracy: 0.4753 - val_loss: 2.4378 - val_accuracy: 0.4920\n",
      "Epoch 692/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3809 - accuracy: 0.4751 - val_loss: 2.4354 - val_accuracy: 0.4899\n",
      "Epoch 693/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3761 - accuracy: 0.4752 - val_loss: 2.4414 - val_accuracy: 0.4968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3839 - accuracy: 0.4778 - val_loss: 2.4399 - val_accuracy: 0.4915\n",
      "Epoch 695/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4765 - val_loss: 2.4404 - val_accuracy: 0.4893\n",
      "Epoch 696/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3912 - accuracy: 0.4717 - val_loss: 2.4443 - val_accuracy: 0.4914\n",
      "Epoch 697/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3761 - accuracy: 0.4772 - val_loss: 2.4511 - val_accuracy: 0.4888\n",
      "Epoch 698/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3913 - accuracy: 0.4745 - val_loss: 2.4383 - val_accuracy: 0.4894\n",
      "Epoch 699/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3801 - accuracy: 0.4755 - val_loss: 2.4550 - val_accuracy: 0.4919\n",
      "Epoch 700/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3916 - accuracy: 0.4779 - val_loss: 2.4390 - val_accuracy: 0.4850\n",
      "Epoch 701/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3934 - accuracy: 0.4695 - val_loss: 2.4490 - val_accuracy: 0.4912\n",
      "Epoch 702/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3906 - accuracy: 0.4793 - val_loss: 2.4434 - val_accuracy: 0.4910\n",
      "Epoch 703/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3822 - accuracy: 0.4753 - val_loss: 2.4355 - val_accuracy: 0.4920\n",
      "Epoch 704/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3776 - accuracy: 0.4770 - val_loss: 2.4421 - val_accuracy: 0.4931\n",
      "Epoch 705/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3823 - accuracy: 0.4767 - val_loss: 2.4442 - val_accuracy: 0.4882\n",
      "Epoch 706/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3820 - accuracy: 0.4729 - val_loss: 2.4427 - val_accuracy: 0.4931\n",
      "Epoch 707/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3860 - accuracy: 0.4746 - val_loss: 2.4423 - val_accuracy: 0.4895\n",
      "Epoch 708/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3759 - accuracy: 0.4770 - val_loss: 2.4428 - val_accuracy: 0.4897\n",
      "Epoch 709/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3789 - accuracy: 0.4763 - val_loss: 2.4415 - val_accuracy: 0.4897\n",
      "Epoch 710/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3718 - accuracy: 0.4797 - val_loss: 2.4396 - val_accuracy: 0.4894\n",
      "Epoch 711/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3783 - accuracy: 0.4752 - val_loss: 2.4401 - val_accuracy: 0.4901\n",
      "Epoch 712/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3784 - accuracy: 0.4767 - val_loss: 2.4430 - val_accuracy: 0.4903\n",
      "Epoch 713/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3700 - accuracy: 0.4782 - val_loss: 2.4385 - val_accuracy: 0.4907\n",
      "Epoch 714/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3769 - accuracy: 0.4763 - val_loss: 2.4394 - val_accuracy: 0.4916\n",
      "Epoch 715/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3732 - accuracy: 0.4773 - val_loss: 2.4544 - val_accuracy: 0.4941\n",
      "Epoch 716/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3868 - accuracy: 0.4785 - val_loss: 2.4355 - val_accuracy: 0.4862\n",
      "Epoch 717/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3785 - accuracy: 0.4736 - val_loss: 2.4330 - val_accuracy: 0.4899\n",
      "Epoch 718/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3710 - accuracy: 0.4770 - val_loss: 2.4447 - val_accuracy: 0.4926\n",
      "Epoch 719/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3870 - accuracy: 0.4781 - val_loss: 2.4374 - val_accuracy: 0.4888\n",
      "Epoch 720/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3806 - accuracy: 0.4731 - val_loss: 2.4455 - val_accuracy: 0.4893\n",
      "Epoch 721/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3765 - accuracy: 0.4751 - val_loss: 2.4491 - val_accuracy: 0.4919\n",
      "Epoch 722/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3826 - accuracy: 0.4778 - val_loss: 2.4337 - val_accuracy: 0.4903\n",
      "Epoch 723/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3771 - accuracy: 0.4756 - val_loss: 2.4343 - val_accuracy: 0.4938\n",
      "Epoch 724/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3778 - accuracy: 0.4770 - val_loss: 2.4405 - val_accuracy: 0.4911\n",
      "Epoch 725/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3910 - accuracy: 0.4752 - val_loss: 2.4362 - val_accuracy: 0.4879\n",
      "Epoch 726/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3733 - accuracy: 0.4757 - val_loss: 2.4542 - val_accuracy: 0.4891\n",
      "Epoch 727/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3834 - accuracy: 0.4793 - val_loss: 2.4453 - val_accuracy: 0.4857\n",
      "Epoch 728/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3878 - accuracy: 0.4727 - val_loss: 2.4457 - val_accuracy: 0.4919\n",
      "Epoch 729/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3882 - accuracy: 0.4766 - val_loss: 2.4588 - val_accuracy: 0.4900\n",
      "Epoch 730/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3949 - accuracy: 0.4757 - val_loss: 2.4406 - val_accuracy: 0.4876\n",
      "Epoch 731/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3715 - accuracy: 0.4761 - val_loss: 2.4420 - val_accuracy: 0.4871\n",
      "Epoch 732/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3800 - accuracy: 0.4754 - val_loss: 2.4448 - val_accuracy: 0.4928\n",
      "Epoch 733/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3693 - accuracy: 0.4806 - val_loss: 2.4349 - val_accuracy: 0.4919\n",
      "Epoch 734/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3736 - accuracy: 0.4756 - val_loss: 2.4425 - val_accuracy: 0.4950\n",
      "Epoch 735/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3813 - accuracy: 0.4792 - val_loss: 2.4494 - val_accuracy: 0.4907\n",
      "Epoch 736/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3798 - accuracy: 0.4760 - val_loss: 2.4473 - val_accuracy: 0.4907\n",
      "Epoch 737/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3813 - accuracy: 0.4782 - val_loss: 2.4358 - val_accuracy: 0.4826\n",
      "Epoch 738/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3878 - accuracy: 0.4695 - val_loss: 2.4596 - val_accuracy: 0.4925\n",
      "Epoch 739/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3876 - accuracy: 0.4800 - val_loss: 2.4421 - val_accuracy: 0.4856\n",
      "Epoch 740/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3736 - accuracy: 0.4742 - val_loss: 2.4424 - val_accuracy: 0.4874\n",
      "Epoch 741/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3735 - accuracy: 0.4758 - val_loss: 2.4412 - val_accuracy: 0.4937\n",
      "Epoch 742/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3776 - accuracy: 0.4794 - val_loss: 2.4310 - val_accuracy: 0.4941\n",
      "Epoch 743/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3672 - accuracy: 0.4790 - val_loss: 2.4330 - val_accuracy: 0.4915\n",
      "Epoch 744/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3707 - accuracy: 0.4768 - val_loss: 2.4471 - val_accuracy: 0.4931\n",
      "Epoch 745/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3683 - accuracy: 0.4794 - val_loss: 2.4307 - val_accuracy: 0.4922\n",
      "Epoch 746/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3615 - accuracy: 0.4794 - val_loss: 2.4291 - val_accuracy: 0.4911\n",
      "Epoch 747/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3668 - accuracy: 0.4765 - val_loss: 2.4454 - val_accuracy: 0.4931\n",
      "Epoch 748/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3713 - accuracy: 0.4806 - val_loss: 2.4386 - val_accuracy: 0.4894\n",
      "Epoch 749/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3706 - accuracy: 0.4761 - val_loss: 2.4287 - val_accuracy: 0.4916\n",
      "Epoch 750/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3620 - accuracy: 0.4795 - val_loss: 2.4312 - val_accuracy: 0.4946\n",
      "Epoch 751/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3672 - accuracy: 0.4807 - val_loss: 2.4255 - val_accuracy: 0.4901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 752/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3645 - accuracy: 0.4779 - val_loss: 2.4286 - val_accuracy: 0.4923\n",
      "Epoch 753/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3642 - accuracy: 0.4775 - val_loss: 2.4385 - val_accuracy: 0.4924\n",
      "Epoch 754/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3671 - accuracy: 0.4794 - val_loss: 2.4264 - val_accuracy: 0.4895\n",
      "Epoch 755/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3657 - accuracy: 0.4778 - val_loss: 2.4345 - val_accuracy: 0.4923\n",
      "Epoch 756/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3567 - accuracy: 0.4799 - val_loss: 2.4356 - val_accuracy: 0.4934\n",
      "Epoch 757/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3681 - accuracy: 0.4786 - val_loss: 2.4313 - val_accuracy: 0.4885\n",
      "Epoch 758/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3594 - accuracy: 0.4780 - val_loss: 2.4273 - val_accuracy: 0.4913\n",
      "Epoch 759/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3620 - accuracy: 0.4771 - val_loss: 2.4298 - val_accuracy: 0.4923\n",
      "Epoch 760/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3541 - accuracy: 0.4813 - val_loss: 2.4303 - val_accuracy: 0.4939\n",
      "Epoch 761/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3607 - accuracy: 0.4817 - val_loss: 2.4304 - val_accuracy: 0.4921\n",
      "Epoch 762/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3616 - accuracy: 0.4781 - val_loss: 2.4410 - val_accuracy: 0.4909\n",
      "Epoch 763/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3663 - accuracy: 0.4798 - val_loss: 2.4336 - val_accuracy: 0.4909\n",
      "Epoch 764/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3566 - accuracy: 0.4798 - val_loss: 2.4336 - val_accuracy: 0.4952\n",
      "Epoch 765/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3649 - accuracy: 0.4789 - val_loss: 2.4339 - val_accuracy: 0.4927\n",
      "Epoch 766/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3600 - accuracy: 0.4796 - val_loss: 2.4379 - val_accuracy: 0.4927\n",
      "Epoch 767/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3578 - accuracy: 0.4812 - val_loss: 2.4279 - val_accuracy: 0.4891\n",
      "Epoch 768/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3605 - accuracy: 0.4761 - val_loss: 2.4325 - val_accuracy: 0.4952\n",
      "Epoch 769/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3677 - accuracy: 0.4805 - val_loss: 2.4278 - val_accuracy: 0.4938\n",
      "Epoch 770/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3604 - accuracy: 0.4806 - val_loss: 2.4312 - val_accuracy: 0.4900\n",
      "Epoch 771/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3616 - accuracy: 0.4796 - val_loss: 2.4355 - val_accuracy: 0.4934\n",
      "Epoch 772/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3629 - accuracy: 0.4793 - val_loss: 2.4292 - val_accuracy: 0.4938\n",
      "Epoch 773/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3533 - accuracy: 0.4810 - val_loss: 2.4250 - val_accuracy: 0.4914\n",
      "Epoch 774/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3577 - accuracy: 0.4778 - val_loss: 2.4408 - val_accuracy: 0.4929\n",
      "Epoch 775/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3552 - accuracy: 0.4834 - val_loss: 2.4325 - val_accuracy: 0.4877\n",
      "Epoch 776/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3608 - accuracy: 0.4766 - val_loss: 2.4434 - val_accuracy: 0.4955\n",
      "Epoch 777/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3670 - accuracy: 0.4813 - val_loss: 2.4297 - val_accuracy: 0.4941\n",
      "Epoch 778/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3588 - accuracy: 0.4801 - val_loss: 2.4319 - val_accuracy: 0.4898\n",
      "Epoch 779/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3686 - accuracy: 0.4760 - val_loss: 2.4686 - val_accuracy: 0.4933\n",
      "Epoch 780/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4024 - accuracy: 0.4799 - val_loss: 2.4443 - val_accuracy: 0.4869\n",
      "Epoch 781/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3868 - accuracy: 0.4729 - val_loss: 2.4412 - val_accuracy: 0.4881\n",
      "Epoch 782/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3712 - accuracy: 0.4777 - val_loss: 2.4589 - val_accuracy: 0.4926\n",
      "Epoch 783/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3955 - accuracy: 0.4758 - val_loss: 2.4364 - val_accuracy: 0.4854\n",
      "Epoch 784/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3824 - accuracy: 0.4718 - val_loss: 2.4546 - val_accuracy: 0.4883\n",
      "Epoch 785/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3893 - accuracy: 0.4759 - val_loss: 2.4508 - val_accuracy: 0.4896\n",
      "Epoch 786/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3808 - accuracy: 0.4779 - val_loss: 2.4346 - val_accuracy: 0.4877\n",
      "Epoch 787/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3735 - accuracy: 0.4744 - val_loss: 2.4388 - val_accuracy: 0.4884\n",
      "Epoch 788/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3752 - accuracy: 0.4768 - val_loss: 2.4435 - val_accuracy: 0.4921\n",
      "Epoch 789/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3763 - accuracy: 0.4799 - val_loss: 2.4399 - val_accuracy: 0.4892\n",
      "Epoch 790/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3742 - accuracy: 0.4752 - val_loss: 2.4432 - val_accuracy: 0.4914\n",
      "Epoch 791/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3684 - accuracy: 0.4797 - val_loss: 2.4346 - val_accuracy: 0.4857\n",
      "Epoch 792/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3686 - accuracy: 0.4763 - val_loss: 2.4386 - val_accuracy: 0.4863\n",
      "Epoch 793/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3740 - accuracy: 0.4754 - val_loss: 2.4291 - val_accuracy: 0.4910\n",
      "Epoch 794/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3598 - accuracy: 0.4787 - val_loss: 2.4455 - val_accuracy: 0.4888\n",
      "Epoch 795/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3768 - accuracy: 0.4763 - val_loss: 2.4315 - val_accuracy: 0.4863\n",
      "Epoch 796/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3729 - accuracy: 0.4742 - val_loss: 2.4369 - val_accuracy: 0.4919\n",
      "Epoch 797/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3675 - accuracy: 0.4786 - val_loss: 2.4455 - val_accuracy: 0.4962\n",
      "Epoch 798/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3756 - accuracy: 0.4837 - val_loss: 2.4392 - val_accuracy: 0.4812\n",
      "Epoch 799/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3924 - accuracy: 0.4665 - val_loss: 2.4581 - val_accuracy: 0.4932\n",
      "Epoch 800/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3830 - accuracy: 0.4806 - val_loss: 2.4528 - val_accuracy: 0.4910\n",
      "Epoch 801/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3767 - accuracy: 0.4803 - val_loss: 2.4333 - val_accuracy: 0.4848\n",
      "Epoch 802/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3813 - accuracy: 0.4702 - val_loss: 2.4248 - val_accuracy: 0.4931\n",
      "Epoch 803/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3575 - accuracy: 0.4808 - val_loss: 2.4551 - val_accuracy: 0.4966\n",
      "Epoch 804/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3809 - accuracy: 0.4837 - val_loss: 2.4334 - val_accuracy: 0.4869\n",
      "Epoch 805/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3862 - accuracy: 0.4699 - val_loss: 2.4335 - val_accuracy: 0.4896\n",
      "Epoch 806/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3724 - accuracy: 0.4785 - val_loss: 2.4527 - val_accuracy: 0.4912\n",
      "Epoch 807/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3813 - accuracy: 0.4770 - val_loss: 2.4406 - val_accuracy: 0.4884\n",
      "Epoch 808/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3803 - accuracy: 0.4753 - val_loss: 2.4405 - val_accuracy: 0.4908\n",
      "Epoch 809/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3787 - accuracy: 0.4754 - val_loss: 2.4494 - val_accuracy: 0.4950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 810/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3690 - accuracy: 0.4841 - val_loss: 2.4309 - val_accuracy: 0.4892\n",
      "Epoch 811/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3628 - accuracy: 0.4780 - val_loss: 2.4317 - val_accuracy: 0.4873\n",
      "Epoch 812/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3658 - accuracy: 0.4762 - val_loss: 2.4416 - val_accuracy: 0.4936\n",
      "Epoch 813/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3545 - accuracy: 0.4833 - val_loss: 2.4329 - val_accuracy: 0.4933\n",
      "Epoch 814/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3646 - accuracy: 0.4798 - val_loss: 2.4248 - val_accuracy: 0.4922\n",
      "Epoch 815/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3658 - accuracy: 0.4778 - val_loss: 2.4326 - val_accuracy: 0.4913\n",
      "Epoch 816/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3567 - accuracy: 0.4795 - val_loss: 2.4291 - val_accuracy: 0.4942\n",
      "Epoch 817/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3638 - accuracy: 0.4807 - val_loss: 2.4330 - val_accuracy: 0.4903\n",
      "Epoch 818/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3649 - accuracy: 0.4772 - val_loss: 2.4415 - val_accuracy: 0.4972\n",
      "Epoch 819/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3643 - accuracy: 0.4838 - val_loss: 2.4385 - val_accuracy: 0.4862\n",
      "Epoch 820/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3773 - accuracy: 0.4710 - val_loss: 2.4474 - val_accuracy: 0.4954\n",
      "Epoch 821/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3850 - accuracy: 0.4812 - val_loss: 2.4357 - val_accuracy: 0.4927\n",
      "Epoch 822/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3723 - accuracy: 0.4768 - val_loss: 2.4348 - val_accuracy: 0.4872\n",
      "Epoch 823/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3727 - accuracy: 0.4737 - val_loss: 2.4313 - val_accuracy: 0.4928\n",
      "Epoch 824/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3667 - accuracy: 0.4817 - val_loss: 2.4299 - val_accuracy: 0.4897\n",
      "Epoch 825/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3601 - accuracy: 0.4793 - val_loss: 2.4265 - val_accuracy: 0.4908\n",
      "Epoch 826/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3644 - accuracy: 0.4753 - val_loss: 2.4324 - val_accuracy: 0.4946\n",
      "Epoch 827/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3596 - accuracy: 0.4809 - val_loss: 2.4358 - val_accuracy: 0.4966\n",
      "Epoch 828/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3618 - accuracy: 0.4804 - val_loss: 2.4265 - val_accuracy: 0.4933\n",
      "Epoch 829/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3589 - accuracy: 0.4802 - val_loss: 2.4320 - val_accuracy: 0.4952\n",
      "Epoch 830/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3626 - accuracy: 0.4795 - val_loss: 2.4493 - val_accuracy: 0.4961\n",
      "Epoch 831/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3774 - accuracy: 0.4819 - val_loss: 2.4519 - val_accuracy: 0.4840\n",
      "Epoch 832/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3965 - accuracy: 0.4681 - val_loss: 2.4746 - val_accuracy: 0.4935\n",
      "Epoch 833/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4080 - accuracy: 0.4797 - val_loss: 2.4718 - val_accuracy: 0.4947\n",
      "Epoch 834/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3931 - accuracy: 0.4817 - val_loss: 2.4461 - val_accuracy: 0.4819\n",
      "Epoch 835/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4004 - accuracy: 0.4655 - val_loss: 2.4428 - val_accuracy: 0.4849\n",
      "Epoch 836/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3995 - accuracy: 0.4715 - val_loss: 2.4580 - val_accuracy: 0.4928\n",
      "Epoch 837/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3869 - accuracy: 0.4802 - val_loss: 2.4600 - val_accuracy: 0.4852\n",
      "Epoch 838/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3879 - accuracy: 0.4740 - val_loss: 2.4476 - val_accuracy: 0.4828\n",
      "Epoch 839/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4032 - accuracy: 0.4681 - val_loss: 2.4620 - val_accuracy: 0.4906\n",
      "Epoch 840/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3928 - accuracy: 0.4795 - val_loss: 2.4693 - val_accuracy: 0.4935\n",
      "Epoch 841/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4049 - accuracy: 0.4803 - val_loss: 2.4585 - val_accuracy: 0.4781\n",
      "Epoch 842/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4122 - accuracy: 0.4656 - val_loss: 2.4503 - val_accuracy: 0.4875\n",
      "Epoch 843/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3967 - accuracy: 0.4734 - val_loss: 2.4714 - val_accuracy: 0.4922\n",
      "Epoch 844/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4033 - accuracy: 0.4761 - val_loss: 2.4446 - val_accuracy: 0.4886\n",
      "Epoch 845/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3801 - accuracy: 0.4786 - val_loss: 2.4441 - val_accuracy: 0.4837\n",
      "Epoch 846/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3898 - accuracy: 0.4717 - val_loss: 2.4439 - val_accuracy: 0.4892\n",
      "Epoch 847/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3711 - accuracy: 0.4774 - val_loss: 2.4542 - val_accuracy: 0.4927\n",
      "Epoch 848/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3724 - accuracy: 0.4835 - val_loss: 2.4333 - val_accuracy: 0.4881\n",
      "Epoch 849/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3742 - accuracy: 0.4741 - val_loss: 2.4330 - val_accuracy: 0.4872\n",
      "Epoch 850/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3726 - accuracy: 0.4743 - val_loss: 2.4484 - val_accuracy: 0.4927\n",
      "Epoch 851/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3734 - accuracy: 0.4798 - val_loss: 2.4425 - val_accuracy: 0.4900\n",
      "Epoch 852/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3626 - accuracy: 0.4803 - val_loss: 2.4296 - val_accuracy: 0.4911\n",
      "Epoch 853/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3556 - accuracy: 0.4799 - val_loss: 2.4304 - val_accuracy: 0.4909\n",
      "Epoch 854/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3632 - accuracy: 0.4782 - val_loss: 2.4425 - val_accuracy: 0.4931\n",
      "Epoch 855/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3632 - accuracy: 0.4812 - val_loss: 2.4271 - val_accuracy: 0.4929\n",
      "Epoch 856/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3612 - accuracy: 0.4807 - val_loss: 2.4239 - val_accuracy: 0.4884\n",
      "Epoch 857/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3617 - accuracy: 0.4779 - val_loss: 2.4282 - val_accuracy: 0.4892\n",
      "Epoch 858/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3601 - accuracy: 0.4769 - val_loss: 2.4291 - val_accuracy: 0.4962\n",
      "Epoch 859/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3584 - accuracy: 0.4822 - val_loss: 2.4264 - val_accuracy: 0.4918\n",
      "Epoch 860/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3557 - accuracy: 0.4795 - val_loss: 2.4327 - val_accuracy: 0.4933\n",
      "Epoch 861/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3600 - accuracy: 0.4790 - val_loss: 2.4271 - val_accuracy: 0.4956\n",
      "Epoch 862/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3604 - accuracy: 0.4810 - val_loss: 2.4227 - val_accuracy: 0.4917\n",
      "Epoch 863/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3584 - accuracy: 0.4788 - val_loss: 2.4250 - val_accuracy: 0.4915\n",
      "Epoch 864/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3495 - accuracy: 0.4809 - val_loss: 2.4307 - val_accuracy: 0.4953\n",
      "Epoch 865/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3554 - accuracy: 0.4811 - val_loss: 2.4218 - val_accuracy: 0.4940\n",
      "Epoch 866/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3595 - accuracy: 0.4797 - val_loss: 2.4155 - val_accuracy: 0.4934\n",
      "Epoch 867/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3474 - accuracy: 0.4796 - val_loss: 2.4324 - val_accuracy: 0.4950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3535 - accuracy: 0.4826 - val_loss: 2.4354 - val_accuracy: 0.4918\n",
      "Epoch 869/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3512 - accuracy: 0.4818 - val_loss: 2.4291 - val_accuracy: 0.4938\n",
      "Epoch 870/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3552 - accuracy: 0.4801 - val_loss: 2.4282 - val_accuracy: 0.4905\n",
      "Epoch 871/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3549 - accuracy: 0.4769 - val_loss: 2.4335 - val_accuracy: 0.4927\n",
      "Epoch 872/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3550 - accuracy: 0.4811 - val_loss: 2.4287 - val_accuracy: 0.4944\n",
      "Epoch 873/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3550 - accuracy: 0.4801 - val_loss: 2.4267 - val_accuracy: 0.4953\n",
      "Epoch 874/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3432 - accuracy: 0.4820 - val_loss: 2.4247 - val_accuracy: 0.4949\n",
      "Epoch 875/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3534 - accuracy: 0.4802 - val_loss: 2.4277 - val_accuracy: 0.4949\n",
      "Epoch 876/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3540 - accuracy: 0.4807 - val_loss: 2.4255 - val_accuracy: 0.4928\n",
      "Epoch 877/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3484 - accuracy: 0.4818 - val_loss: 2.4273 - val_accuracy: 0.4896\n",
      "Epoch 878/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3541 - accuracy: 0.4811 - val_loss: 2.4233 - val_accuracy: 0.4901\n",
      "Epoch 879/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3499 - accuracy: 0.4788 - val_loss: 2.4309 - val_accuracy: 0.4943\n",
      "Epoch 880/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3496 - accuracy: 0.4834 - val_loss: 2.4365 - val_accuracy: 0.4946\n",
      "Epoch 881/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3491 - accuracy: 0.4809 - val_loss: 2.4247 - val_accuracy: 0.4931\n",
      "Epoch 882/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3513 - accuracy: 0.4781 - val_loss: 2.4317 - val_accuracy: 0.4963\n",
      "Epoch 883/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3549 - accuracy: 0.4835 - val_loss: 2.4272 - val_accuracy: 0.4926\n",
      "Epoch 884/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3576 - accuracy: 0.4787 - val_loss: 2.4371 - val_accuracy: 0.4918\n",
      "Epoch 885/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3608 - accuracy: 0.4786 - val_loss: 2.4330 - val_accuracy: 0.4905\n",
      "Epoch 886/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3525 - accuracy: 0.4811 - val_loss: 2.4279 - val_accuracy: 0.4921\n",
      "Epoch 887/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3576 - accuracy: 0.4792 - val_loss: 2.4271 - val_accuracy: 0.4970\n",
      "Epoch 888/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3557 - accuracy: 0.4826 - val_loss: 2.4291 - val_accuracy: 0.4917\n",
      "Epoch 889/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3581 - accuracy: 0.4780 - val_loss: 2.4257 - val_accuracy: 0.4941\n",
      "Epoch 890/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3486 - accuracy: 0.4840 - val_loss: 2.4206 - val_accuracy: 0.4932\n",
      "Epoch 891/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3440 - accuracy: 0.4826 - val_loss: 2.4239 - val_accuracy: 0.4953\n",
      "Epoch 892/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3504 - accuracy: 0.4821 - val_loss: 2.4202 - val_accuracy: 0.4932\n",
      "Epoch 893/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3439 - accuracy: 0.4824 - val_loss: 2.4237 - val_accuracy: 0.4926\n",
      "Epoch 894/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3525 - accuracy: 0.4811 - val_loss: 2.4237 - val_accuracy: 0.4917\n",
      "Epoch 895/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3528 - accuracy: 0.4816 - val_loss: 2.4319 - val_accuracy: 0.4949\n",
      "Epoch 896/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3540 - accuracy: 0.4830 - val_loss: 2.4168 - val_accuracy: 0.4900\n",
      "Epoch 897/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3552 - accuracy: 0.4774 - val_loss: 2.4256 - val_accuracy: 0.4935\n",
      "Epoch 898/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3440 - accuracy: 0.4834 - val_loss: 2.4377 - val_accuracy: 0.4937\n",
      "Epoch 899/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3456 - accuracy: 0.4843 - val_loss: 2.4200 - val_accuracy: 0.4941\n",
      "Epoch 900/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3525 - accuracy: 0.4818 - val_loss: 2.4148 - val_accuracy: 0.4915\n",
      "Epoch 901/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3554 - accuracy: 0.4753 - val_loss: 2.4411 - val_accuracy: 0.4974\n",
      "Epoch 902/12000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.3616 - accuracy: 0.4853 - val_loss: 2.4359 - val_accuracy: 0.4901\n",
      "Epoch 903/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3638 - accuracy: 0.4778 - val_loss: 2.4214 - val_accuracy: 0.4895\n",
      "Epoch 904/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3537 - accuracy: 0.4784 - val_loss: 2.4286 - val_accuracy: 0.4941\n",
      "Epoch 905/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3516 - accuracy: 0.4825 - val_loss: 2.4250 - val_accuracy: 0.4947\n",
      "Epoch 906/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3549 - accuracy: 0.4803 - val_loss: 2.4221 - val_accuracy: 0.4935\n",
      "Epoch 907/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3468 - accuracy: 0.4824 - val_loss: 2.4273 - val_accuracy: 0.4923\n",
      "Epoch 908/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3513 - accuracy: 0.4843 - val_loss: 2.4293 - val_accuracy: 0.4905\n",
      "Epoch 909/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3469 - accuracy: 0.4824 - val_loss: 2.4186 - val_accuracy: 0.4906\n",
      "Epoch 910/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3477 - accuracy: 0.4795 - val_loss: 2.4250 - val_accuracy: 0.4972\n",
      "Epoch 911/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3484 - accuracy: 0.4842 - val_loss: 2.4231 - val_accuracy: 0.4943\n",
      "Epoch 912/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3440 - accuracy: 0.4824 - val_loss: 2.4351 - val_accuracy: 0.4954\n",
      "Epoch 913/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3435 - accuracy: 0.4834 - val_loss: 2.4168 - val_accuracy: 0.4940\n",
      "Epoch 914/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3355 - accuracy: 0.4834 - val_loss: 2.4214 - val_accuracy: 0.4946\n",
      "Epoch 915/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3455 - accuracy: 0.4815 - val_loss: 2.4264 - val_accuracy: 0.4977\n",
      "Epoch 916/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3465 - accuracy: 0.4855 - val_loss: 2.4314 - val_accuracy: 0.4925\n",
      "Epoch 917/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3564 - accuracy: 0.4767 - val_loss: 2.4214 - val_accuracy: 0.4939\n",
      "Epoch 918/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3439 - accuracy: 0.4826 - val_loss: 2.4206 - val_accuracy: 0.4949\n",
      "Epoch 919/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3475 - accuracy: 0.4832 - val_loss: 2.4363 - val_accuracy: 0.4908\n",
      "Epoch 920/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3554 - accuracy: 0.4798 - val_loss: 2.4378 - val_accuracy: 0.4931\n",
      "Epoch 921/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3618 - accuracy: 0.4817 - val_loss: 2.4200 - val_accuracy: 0.4915\n",
      "Epoch 922/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3516 - accuracy: 0.4780 - val_loss: 2.4224 - val_accuracy: 0.4969\n",
      "Epoch 923/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3355 - accuracy: 0.4859 - val_loss: 2.4367 - val_accuracy: 0.4953\n",
      "Epoch 924/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3602 - accuracy: 0.4840 - val_loss: 2.4250 - val_accuracy: 0.4894\n",
      "Epoch 925/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3581 - accuracy: 0.4782 - val_loss: 2.4276 - val_accuracy: 0.4922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3533 - accuracy: 0.4817 - val_loss: 2.4233 - val_accuracy: 0.4957\n",
      "Epoch 927/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3508 - accuracy: 0.4837 - val_loss: 2.4296 - val_accuracy: 0.4947\n",
      "Epoch 928/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3519 - accuracy: 0.4800 - val_loss: 2.4241 - val_accuracy: 0.4936\n",
      "Epoch 929/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3428 - accuracy: 0.4818 - val_loss: 2.4266 - val_accuracy: 0.4931\n",
      "Epoch 930/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3428 - accuracy: 0.4826 - val_loss: 2.4274 - val_accuracy: 0.4916\n",
      "Epoch 931/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3464 - accuracy: 0.4814 - val_loss: 2.4252 - val_accuracy: 0.4906\n",
      "Epoch 932/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3448 - accuracy: 0.4823 - val_loss: 2.4232 - val_accuracy: 0.4931\n",
      "Epoch 933/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3416 - accuracy: 0.4829 - val_loss: 2.4249 - val_accuracy: 0.4937\n",
      "Epoch 934/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3421 - accuracy: 0.4833 - val_loss: 2.4225 - val_accuracy: 0.4930\n",
      "Epoch 935/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3431 - accuracy: 0.4827 - val_loss: 2.4208 - val_accuracy: 0.4944\n",
      "Epoch 936/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3499 - accuracy: 0.4816 - val_loss: 2.4282 - val_accuracy: 0.4951\n",
      "Epoch 937/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3372 - accuracy: 0.4847 - val_loss: 2.4318 - val_accuracy: 0.4931\n",
      "Epoch 938/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3463 - accuracy: 0.4838 - val_loss: 2.4208 - val_accuracy: 0.4923\n",
      "Epoch 939/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3464 - accuracy: 0.4779 - val_loss: 2.4326 - val_accuracy: 0.4975\n",
      "Epoch 940/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3519 - accuracy: 0.4845 - val_loss: 2.4291 - val_accuracy: 0.4906\n",
      "Epoch 941/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3503 - accuracy: 0.4787 - val_loss: 2.4242 - val_accuracy: 0.4916\n",
      "Epoch 942/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3478 - accuracy: 0.4823 - val_loss: 2.4308 - val_accuracy: 0.4940\n",
      "Epoch 943/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3529 - accuracy: 0.4822 - val_loss: 2.4236 - val_accuracy: 0.4929\n",
      "Epoch 944/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3396 - accuracy: 0.4824 - val_loss: 2.4308 - val_accuracy: 0.4959\n",
      "Epoch 945/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3509 - accuracy: 0.4836 - val_loss: 2.4256 - val_accuracy: 0.4904\n",
      "Epoch 946/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3455 - accuracy: 0.4783 - val_loss: 2.4303 - val_accuracy: 0.4959\n",
      "Epoch 947/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3499 - accuracy: 0.4827 - val_loss: 2.4320 - val_accuracy: 0.4954\n",
      "Epoch 948/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3523 - accuracy: 0.4824 - val_loss: 2.4240 - val_accuracy: 0.4940\n",
      "Epoch 949/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3405 - accuracy: 0.4837 - val_loss: 2.4277 - val_accuracy: 0.4892\n",
      "Epoch 950/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3501 - accuracy: 0.4791 - val_loss: 2.4474 - val_accuracy: 0.4960\n",
      "Epoch 951/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3609 - accuracy: 0.4850 - val_loss: 2.4305 - val_accuracy: 0.4871\n",
      "Epoch 952/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3617 - accuracy: 0.4740 - val_loss: 2.4279 - val_accuracy: 0.4930\n",
      "Epoch 953/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3497 - accuracy: 0.4814 - val_loss: 2.4217 - val_accuracy: 0.4941\n",
      "Epoch 954/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3515 - accuracy: 0.4837 - val_loss: 2.4175 - val_accuracy: 0.4894\n",
      "Epoch 955/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3591 - accuracy: 0.4758 - val_loss: 2.4335 - val_accuracy: 0.4954\n",
      "Epoch 956/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3499 - accuracy: 0.4845 - val_loss: 2.4316 - val_accuracy: 0.4939\n",
      "Epoch 957/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3524 - accuracy: 0.4797 - val_loss: 2.4219 - val_accuracy: 0.4927\n",
      "Epoch 958/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3498 - accuracy: 0.4805 - val_loss: 2.4254 - val_accuracy: 0.4948\n",
      "Epoch 959/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3399 - accuracy: 0.4833 - val_loss: 2.4370 - val_accuracy: 0.4918\n",
      "Epoch 960/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3542 - accuracy: 0.4811 - val_loss: 2.4279 - val_accuracy: 0.4938\n",
      "Epoch 961/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3469 - accuracy: 0.4835 - val_loss: 2.4225 - val_accuracy: 0.4943\n",
      "Epoch 962/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3445 - accuracy: 0.4821 - val_loss: 2.4349 - val_accuracy: 0.4956\n",
      "Epoch 963/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3484 - accuracy: 0.4820 - val_loss: 2.4292 - val_accuracy: 0.4950\n",
      "Epoch 964/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3551 - accuracy: 0.4817 - val_loss: 2.4256 - val_accuracy: 0.4909\n",
      "Epoch 965/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3479 - accuracy: 0.4788 - val_loss: 2.4301 - val_accuracy: 0.4972\n",
      "Epoch 966/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3456 - accuracy: 0.4838 - val_loss: 2.4259 - val_accuracy: 0.4956\n",
      "Epoch 967/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3452 - accuracy: 0.4843 - val_loss: 2.4166 - val_accuracy: 0.4891\n",
      "Epoch 968/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3528 - accuracy: 0.4770 - val_loss: 2.4344 - val_accuracy: 0.4961\n",
      "Epoch 969/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3482 - accuracy: 0.4832 - val_loss: 2.4320 - val_accuracy: 0.4933\n",
      "Epoch 970/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3485 - accuracy: 0.4826 - val_loss: 2.4284 - val_accuracy: 0.4921\n",
      "Epoch 971/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3499 - accuracy: 0.4770 - val_loss: 2.4234 - val_accuracy: 0.4934\n",
      "Epoch 972/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3430 - accuracy: 0.4817 - val_loss: 2.4252 - val_accuracy: 0.4963\n",
      "Epoch 973/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3469 - accuracy: 0.4841 - val_loss: 2.4216 - val_accuracy: 0.4923\n",
      "Epoch 974/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3541 - accuracy: 0.4783 - val_loss: 2.4285 - val_accuracy: 0.4941\n",
      "Epoch 975/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3457 - accuracy: 0.4831 - val_loss: 2.4390 - val_accuracy: 0.4942\n",
      "Epoch 976/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3484 - accuracy: 0.4825 - val_loss: 2.4248 - val_accuracy: 0.4900\n",
      "Epoch 977/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3526 - accuracy: 0.4759 - val_loss: 2.4353 - val_accuracy: 0.4981\n",
      "Epoch 978/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3514 - accuracy: 0.4839 - val_loss: 2.4376 - val_accuracy: 0.4931\n",
      "Epoch 979/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3570 - accuracy: 0.4804 - val_loss: 2.4359 - val_accuracy: 0.4904\n",
      "Epoch 980/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3475 - accuracy: 0.4819 - val_loss: 2.4286 - val_accuracy: 0.4921\n",
      "Epoch 981/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3420 - accuracy: 0.4811 - val_loss: 2.4369 - val_accuracy: 0.4926\n",
      "Epoch 982/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3637 - accuracy: 0.4759 - val_loss: 2.4471 - val_accuracy: 0.4973\n",
      "Epoch 983/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3708 - accuracy: 0.4843 - val_loss: 2.4493 - val_accuracy: 0.4846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3870 - accuracy: 0.4721 - val_loss: 2.4532 - val_accuracy: 0.4916\n",
      "Epoch 985/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3665 - accuracy: 0.4810 - val_loss: 2.4485 - val_accuracy: 0.4896\n",
      "Epoch 986/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3638 - accuracy: 0.4790 - val_loss: 2.4303 - val_accuracy: 0.4868\n",
      "Epoch 987/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3534 - accuracy: 0.4799 - val_loss: 2.4296 - val_accuracy: 0.4942\n",
      "Epoch 988/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3582 - accuracy: 0.4804 - val_loss: 2.4309 - val_accuracy: 0.4969\n",
      "Epoch 989/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3560 - accuracy: 0.4814 - val_loss: 2.4328 - val_accuracy: 0.4925\n",
      "Epoch 990/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3573 - accuracy: 0.4795 - val_loss: 2.4270 - val_accuracy: 0.4952\n",
      "Epoch 991/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3561 - accuracy: 0.4807 - val_loss: 2.4313 - val_accuracy: 0.4957\n",
      "Epoch 992/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3501 - accuracy: 0.4829 - val_loss: 2.4304 - val_accuracy: 0.4960\n",
      "Epoch 993/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3539 - accuracy: 0.4824 - val_loss: 2.4313 - val_accuracy: 0.4926\n",
      "Epoch 994/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3434 - accuracy: 0.4810 - val_loss: 2.4364 - val_accuracy: 0.4928\n",
      "Epoch 995/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3482 - accuracy: 0.4818 - val_loss: 2.4238 - val_accuracy: 0.4865\n",
      "Epoch 996/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3536 - accuracy: 0.4751 - val_loss: 2.4302 - val_accuracy: 0.4931\n",
      "Epoch 997/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3438 - accuracy: 0.4837 - val_loss: 2.4280 - val_accuracy: 0.4929\n",
      "Epoch 998/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3498 - accuracy: 0.4813 - val_loss: 2.4259 - val_accuracy: 0.4924\n",
      "Epoch 999/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3458 - accuracy: 0.4809 - val_loss: 2.4227 - val_accuracy: 0.4931\n",
      "Epoch 1000/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3473 - accuracy: 0.4814 - val_loss: 2.4278 - val_accuracy: 0.4920\n",
      "Epoch 1001/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3432 - accuracy: 0.4822 - val_loss: 2.4225 - val_accuracy: 0.4938\n",
      "Epoch 1002/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3352 - accuracy: 0.4846 - val_loss: 2.4290 - val_accuracy: 0.4946\n",
      "Epoch 1003/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3399 - accuracy: 0.4836 - val_loss: 2.4305 - val_accuracy: 0.4988\n",
      "Epoch 1004/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3427 - accuracy: 0.4849 - val_loss: 2.4214 - val_accuracy: 0.4959\n",
      "Epoch 1005/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3368 - accuracy: 0.4820 - val_loss: 2.4248 - val_accuracy: 0.4952\n",
      "Epoch 1006/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3493 - accuracy: 0.4823 - val_loss: 2.4315 - val_accuracy: 0.4923\n",
      "Epoch 1007/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3412 - accuracy: 0.4826 - val_loss: 2.4479 - val_accuracy: 0.4933\n",
      "Epoch 1008/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3507 - accuracy: 0.4843 - val_loss: 2.4303 - val_accuracy: 0.4881\n",
      "Epoch 1009/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3494 - accuracy: 0.4767 - val_loss: 2.4399 - val_accuracy: 0.4956\n",
      "Epoch 1010/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3479 - accuracy: 0.4846 - val_loss: 2.4214 - val_accuracy: 0.4954\n",
      "Epoch 1011/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3461 - accuracy: 0.4818 - val_loss: 2.4309 - val_accuracy: 0.4930\n",
      "Epoch 1012/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3410 - accuracy: 0.4807 - val_loss: 2.4506 - val_accuracy: 0.4978\n",
      "Epoch 1013/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3516 - accuracy: 0.4862 - val_loss: 2.4327 - val_accuracy: 0.4920\n",
      "Epoch 1014/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3471 - accuracy: 0.4796 - val_loss: 2.4385 - val_accuracy: 0.4934\n",
      "Epoch 1015/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3516 - accuracy: 0.4809 - val_loss: 2.4443 - val_accuracy: 0.4957\n",
      "Epoch 1016/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3593 - accuracy: 0.4840 - val_loss: 2.4290 - val_accuracy: 0.4912\n",
      "Epoch 1017/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3563 - accuracy: 0.4775 - val_loss: 2.4328 - val_accuracy: 0.4917\n",
      "Epoch 1018/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3503 - accuracy: 0.4793 - val_loss: 2.4276 - val_accuracy: 0.4961\n",
      "Epoch 1019/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3372 - accuracy: 0.4854 - val_loss: 2.4317 - val_accuracy: 0.4936\n",
      "Epoch 1020/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3463 - accuracy: 0.4817 - val_loss: 2.4391 - val_accuracy: 0.4911\n",
      "Epoch 1021/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3483 - accuracy: 0.4810 - val_loss: 2.4351 - val_accuracy: 0.4932\n",
      "Epoch 1022/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3497 - accuracy: 0.4847 - val_loss: 2.4287 - val_accuracy: 0.4909\n",
      "Epoch 1023/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3461 - accuracy: 0.4800 - val_loss: 2.4240 - val_accuracy: 0.4900\n",
      "Epoch 1024/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3405 - accuracy: 0.4798 - val_loss: 2.4355 - val_accuracy: 0.4933\n",
      "Epoch 1025/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3487 - accuracy: 0.4826 - val_loss: 2.4329 - val_accuracy: 0.4913\n",
      "Epoch 1026/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3376 - accuracy: 0.4837 - val_loss: 2.4327 - val_accuracy: 0.4944\n",
      "Epoch 1027/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3442 - accuracy: 0.4839 - val_loss: 2.4247 - val_accuracy: 0.4953\n",
      "Epoch 1028/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3319 - accuracy: 0.4841 - val_loss: 2.4308 - val_accuracy: 0.4976\n",
      "Epoch 1029/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3471 - accuracy: 0.4834 - val_loss: 2.4173 - val_accuracy: 0.4940\n",
      "Epoch 1030/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3293 - accuracy: 0.4821 - val_loss: 2.4311 - val_accuracy: 0.4952\n",
      "Epoch 1031/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3499 - accuracy: 0.4833 - val_loss: 2.4207 - val_accuracy: 0.4931\n",
      "Epoch 1032/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3418 - accuracy: 0.4808 - val_loss: 2.4311 - val_accuracy: 0.4983\n",
      "Epoch 1033/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3420 - accuracy: 0.4863 - val_loss: 2.4243 - val_accuracy: 0.4922\n",
      "Epoch 1034/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3490 - accuracy: 0.4795 - val_loss: 2.4215 - val_accuracy: 0.4926\n",
      "Epoch 1035/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3389 - accuracy: 0.4818 - val_loss: 2.4304 - val_accuracy: 0.4923\n",
      "Epoch 1036/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3458 - accuracy: 0.4796 - val_loss: 2.4286 - val_accuracy: 0.4911\n",
      "Epoch 1037/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3360 - accuracy: 0.4826 - val_loss: 2.4232 - val_accuracy: 0.4947\n",
      "Epoch 1038/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3302 - accuracy: 0.4851 - val_loss: 2.4257 - val_accuracy: 0.4945\n",
      "Epoch 1039/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3374 - accuracy: 0.4838 - val_loss: 2.4299 - val_accuracy: 0.4938\n",
      "Epoch 1040/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3408 - accuracy: 0.4833 - val_loss: 2.4303 - val_accuracy: 0.4945\n",
      "Epoch 1041/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3393 - accuracy: 0.4847 - val_loss: 2.4292 - val_accuracy: 0.4931\n",
      "Epoch 1042/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3374 - accuracy: 0.4819 - val_loss: 2.4249 - val_accuracy: 0.4939\n",
      "Epoch 1043/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3364 - accuracy: 0.4808 - val_loss: 2.4277 - val_accuracy: 0.4957\n",
      "Epoch 1044/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3371 - accuracy: 0.4852 - val_loss: 2.4300 - val_accuracy: 0.4932\n",
      "Epoch 1045/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3376 - accuracy: 0.4838 - val_loss: 2.4284 - val_accuracy: 0.4938\n",
      "Epoch 1046/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3298 - accuracy: 0.4846 - val_loss: 2.4187 - val_accuracy: 0.4940\n",
      "Epoch 1047/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3317 - accuracy: 0.4841 - val_loss: 2.4206 - val_accuracy: 0.4960\n",
      "Epoch 1048/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3409 - accuracy: 0.4822 - val_loss: 2.4246 - val_accuracy: 0.4942\n",
      "Epoch 1049/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3375 - accuracy: 0.4836 - val_loss: 2.4261 - val_accuracy: 0.4937\n",
      "Epoch 1050/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3331 - accuracy: 0.4835 - val_loss: 2.4239 - val_accuracy: 0.4946\n",
      "Epoch 1051/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3386 - accuracy: 0.4843 - val_loss: 2.4209 - val_accuracy: 0.4954\n",
      "Epoch 1052/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3342 - accuracy: 0.4848 - val_loss: 2.4193 - val_accuracy: 0.4927\n",
      "Epoch 1053/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3328 - accuracy: 0.4813 - val_loss: 2.4397 - val_accuracy: 0.4961\n",
      "Epoch 1054/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3384 - accuracy: 0.4878 - val_loss: 2.4189 - val_accuracy: 0.4917\n",
      "Epoch 1055/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3309 - accuracy: 0.4839 - val_loss: 2.4207 - val_accuracy: 0.4918\n",
      "Epoch 1056/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3427 - accuracy: 0.4792 - val_loss: 2.4402 - val_accuracy: 0.4984\n",
      "Epoch 1057/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3475 - accuracy: 0.4876 - val_loss: 2.4295 - val_accuracy: 0.4900\n",
      "Epoch 1058/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3526 - accuracy: 0.4790 - val_loss: 2.4283 - val_accuracy: 0.4971\n",
      "Epoch 1059/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3416 - accuracy: 0.4836 - val_loss: 2.4252 - val_accuracy: 0.4971\n",
      "Epoch 1060/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3402 - accuracy: 0.4839 - val_loss: 2.4197 - val_accuracy: 0.4937\n",
      "Epoch 1061/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3318 - accuracy: 0.4843 - val_loss: 2.4222 - val_accuracy: 0.4959\n",
      "Epoch 1062/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3307 - accuracy: 0.4857 - val_loss: 2.4222 - val_accuracy: 0.4969\n",
      "Epoch 1063/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3309 - accuracy: 0.4876 - val_loss: 2.4228 - val_accuracy: 0.4919\n",
      "Epoch 1064/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3320 - accuracy: 0.4823 - val_loss: 2.4284 - val_accuracy: 0.4943\n",
      "Epoch 1065/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3385 - accuracy: 0.4845 - val_loss: 2.4294 - val_accuracy: 0.4893\n",
      "Epoch 1066/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3476 - accuracy: 0.4776 - val_loss: 2.4350 - val_accuracy: 0.4961\n",
      "Epoch 1067/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3410 - accuracy: 0.4863 - val_loss: 2.4298 - val_accuracy: 0.4970\n",
      "Epoch 1068/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3399 - accuracy: 0.4840 - val_loss: 2.4283 - val_accuracy: 0.4920\n",
      "Epoch 1069/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3423 - accuracy: 0.4802 - val_loss: 2.4410 - val_accuracy: 0.4948\n",
      "Epoch 1070/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3586 - accuracy: 0.4854 - val_loss: 2.4232 - val_accuracy: 0.4933\n",
      "Epoch 1071/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3470 - accuracy: 0.4790 - val_loss: 2.4445 - val_accuracy: 0.4906\n",
      "Epoch 1072/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3598 - accuracy: 0.4780 - val_loss: 2.4314 - val_accuracy: 0.4954\n",
      "Epoch 1073/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3506 - accuracy: 0.4853 - val_loss: 2.4284 - val_accuracy: 0.4955\n",
      "Epoch 1074/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3468 - accuracy: 0.4825 - val_loss: 2.4403 - val_accuracy: 0.4878\n",
      "Epoch 1075/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3551 - accuracy: 0.4751 - val_loss: 2.4513 - val_accuracy: 0.4945\n",
      "Epoch 1076/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3542 - accuracy: 0.4858 - val_loss: 2.4381 - val_accuracy: 0.4900\n",
      "Epoch 1077/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3451 - accuracy: 0.4822 - val_loss: 2.4249 - val_accuracy: 0.4919\n",
      "Epoch 1078/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3343 - accuracy: 0.4815 - val_loss: 2.4349 - val_accuracy: 0.4951\n",
      "Epoch 1079/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3537 - accuracy: 0.4841 - val_loss: 2.4254 - val_accuracy: 0.4915\n",
      "Epoch 1080/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3341 - accuracy: 0.4819 - val_loss: 2.4373 - val_accuracy: 0.4940\n",
      "Epoch 1081/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3467 - accuracy: 0.4850 - val_loss: 2.4229 - val_accuracy: 0.4887\n",
      "Epoch 1082/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3421 - accuracy: 0.4817 - val_loss: 2.4237 - val_accuracy: 0.4948\n",
      "Epoch 1083/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3416 - accuracy: 0.4832 - val_loss: 2.4313 - val_accuracy: 0.4951\n",
      "Epoch 1084/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3331 - accuracy: 0.4848 - val_loss: 2.4204 - val_accuracy: 0.4934\n",
      "Epoch 1085/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3377 - accuracy: 0.4837 - val_loss: 2.4168 - val_accuracy: 0.4931\n",
      "Epoch 1086/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3313 - accuracy: 0.4829 - val_loss: 2.4252 - val_accuracy: 0.4977\n",
      "Epoch 1087/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3397 - accuracy: 0.4859 - val_loss: 2.4200 - val_accuracy: 0.4955\n",
      "Epoch 1088/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3300 - accuracy: 0.4822 - val_loss: 2.4226 - val_accuracy: 0.4944\n",
      "Epoch 1089/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3392 - accuracy: 0.4818 - val_loss: 2.4298 - val_accuracy: 0.4969\n",
      "Epoch 1090/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3448 - accuracy: 0.4859 - val_loss: 2.4329 - val_accuracy: 0.4968\n",
      "Epoch 1091/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3448 - accuracy: 0.4823 - val_loss: 2.4313 - val_accuracy: 0.4970\n",
      "Epoch 1092/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3409 - accuracy: 0.4858 - val_loss: 2.4267 - val_accuracy: 0.4895\n",
      "Epoch 1093/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3350 - accuracy: 0.4819 - val_loss: 2.4235 - val_accuracy: 0.4907\n",
      "Epoch 1094/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3406 - accuracy: 0.4816 - val_loss: 2.4191 - val_accuracy: 0.4970\n",
      "Epoch 1095/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3326 - accuracy: 0.4852 - val_loss: 2.4102 - val_accuracy: 0.4975\n",
      "Epoch 1096/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3310 - accuracy: 0.4845 - val_loss: 2.4220 - val_accuracy: 0.4920\n",
      "Epoch 1097/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3293 - accuracy: 0.4831 - val_loss: 2.4346 - val_accuracy: 0.4966\n",
      "Epoch 1098/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 2.3348 - accuracy: 0.4884 - val_loss: 2.4224 - val_accuracy: 0.4919\n",
      "Epoch 1099/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3371 - accuracy: 0.4819 - val_loss: 2.4326 - val_accuracy: 0.4923\n",
      "Epoch 1100/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3530 - accuracy: 0.4790 - val_loss: 2.4311 - val_accuracy: 0.4912\n",
      "Epoch 1101/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3428 - accuracy: 0.4850 - val_loss: 2.4368 - val_accuracy: 0.4891\n",
      "Epoch 1102/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3493 - accuracy: 0.4802 - val_loss: 2.4319 - val_accuracy: 0.4948\n",
      "Epoch 1103/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3401 - accuracy: 0.4848 - val_loss: 2.4336 - val_accuracy: 0.4948\n",
      "Epoch 1104/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3558 - accuracy: 0.4815 - val_loss: 2.4271 - val_accuracy: 0.4923\n",
      "Epoch 1105/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3388 - accuracy: 0.4807 - val_loss: 2.4299 - val_accuracy: 0.4922\n",
      "Epoch 1106/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3376 - accuracy: 0.4838 - val_loss: 2.4328 - val_accuracy: 0.4960\n",
      "Epoch 1107/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3440 - accuracy: 0.4859 - val_loss: 2.4250 - val_accuracy: 0.4914\n",
      "Epoch 1108/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3588 - accuracy: 0.4767 - val_loss: 2.4386 - val_accuracy: 0.4960\n",
      "Epoch 1109/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3449 - accuracy: 0.4842 - val_loss: 2.4348 - val_accuracy: 0.4926\n",
      "Epoch 1110/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3343 - accuracy: 0.4852 - val_loss: 2.4307 - val_accuracy: 0.4875\n",
      "Epoch 1111/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3469 - accuracy: 0.4798 - val_loss: 2.4244 - val_accuracy: 0.4942\n",
      "Epoch 1112/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3403 - accuracy: 0.4845 - val_loss: 2.4239 - val_accuracy: 0.5004\n",
      "Epoch 1113/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3332 - accuracy: 0.4887 - val_loss: 2.4154 - val_accuracy: 0.4956\n",
      "Epoch 1114/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3345 - accuracy: 0.4830 - val_loss: 2.4267 - val_accuracy: 0.4953\n",
      "Epoch 1115/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3425 - accuracy: 0.4836 - val_loss: 2.4499 - val_accuracy: 0.4885\n",
      "Epoch 1116/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3639 - accuracy: 0.4769 - val_loss: 2.4813 - val_accuracy: 0.4862\n",
      "Epoch 1117/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.4092 - accuracy: 0.4787 - val_loss: 2.4497 - val_accuracy: 0.4882\n",
      "Epoch 1118/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3721 - accuracy: 0.4764 - val_loss: 2.4458 - val_accuracy: 0.4900\n",
      "Epoch 1119/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3747 - accuracy: 0.4752 - val_loss: 2.4295 - val_accuracy: 0.4898\n",
      "Epoch 1120/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.3553 - accuracy: 0.4818 - val_loss: 2.4490 - val_accuracy: 0.4928\n",
      "Epoch 1121/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3673 - accuracy: 0.4815 - val_loss: 2.4329 - val_accuracy: 0.4907\n",
      "Epoch 1122/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3515 - accuracy: 0.4774 - val_loss: 2.4582 - val_accuracy: 0.4985\n",
      "Epoch 1123/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3763 - accuracy: 0.4825 - val_loss: 2.4891 - val_accuracy: 0.4830\n",
      "Epoch 1124/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4077 - accuracy: 0.4674 - val_loss: 2.6878 - val_accuracy: 0.4465\n",
      "Epoch 1125/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6554 - accuracy: 0.4198 - val_loss: 2.6881 - val_accuracy: 0.4406\n",
      "Epoch 1126/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.6686 - accuracy: 0.4213 - val_loss: 2.7547 - val_accuracy: 0.4461\n",
      "Epoch 1127/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.7892 - accuracy: 0.4258 - val_loss: 2.9179 - val_accuracy: 0.3908\n",
      "Epoch 1128/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.0019 - accuracy: 0.3711 - val_loss: 3.0900 - val_accuracy: 0.3742\n",
      "Epoch 1129/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1661 - accuracy: 0.3546 - val_loss: 3.1061 - val_accuracy: 0.3776\n",
      "Epoch 1130/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.1747 - accuracy: 0.3598 - val_loss: 3.3139 - val_accuracy: 0.3715\n",
      "Epoch 1131/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3675 - accuracy: 0.3608 - val_loss: 3.2592 - val_accuracy: 0.3417\n",
      "Epoch 1132/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.3488 - accuracy: 0.3272 - val_loss: 3.4223 - val_accuracy: 0.3383\n",
      "Epoch 1133/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3.6452 - accuracy: 0.3184 - val_loss: 5.3300 - val_accuracy: 0.1988\n",
      "Epoch 1134/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 5.5226 - accuracy: 0.1778 - val_loss: 13.3679 - val_accuracy: 0.0631\n",
      "Epoch 1135/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.4514 - accuracy: 0.0474 - val_loss: 13.4729 - val_accuracy: 0.0582\n",
      "Epoch 1136/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.5725 - accuracy: 0.0415 - val_loss: 13.2271 - val_accuracy: 0.0577\n",
      "Epoch 1137/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.3709 - accuracy: 0.0389 - val_loss: 12.2156 - val_accuracy: 0.0665\n",
      "Epoch 1138/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.5103 - accuracy: 0.0492 - val_loss: 8.1118 - val_accuracy: 0.1039\n",
      "Epoch 1139/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 8.6258 - accuracy: 0.0892 - val_loss: 4.9756 - val_accuracy: 0.2146\n",
      "Epoch 1140/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.1104 - accuracy: 0.2062 - val_loss: 4.5315 - val_accuracy: 0.2150\n",
      "Epoch 1141/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.6048 - accuracy: 0.2152 - val_loss: 4.4255 - val_accuracy: 0.2125\n",
      "Epoch 1142/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4838 - accuracy: 0.2148 - val_loss: 4.3611 - val_accuracy: 0.2122\n",
      "Epoch 1143/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.4154 - accuracy: 0.2144 - val_loss: 4.3180 - val_accuracy: 0.2129\n",
      "Epoch 1144/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3801 - accuracy: 0.2136 - val_loss: 4.2800 - val_accuracy: 0.2127\n",
      "Epoch 1145/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3240 - accuracy: 0.2152 - val_loss: 4.2716 - val_accuracy: 0.2120\n",
      "Epoch 1146/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3053 - accuracy: 0.2154 - val_loss: 4.2728 - val_accuracy: 0.2122\n",
      "Epoch 1147/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2937 - accuracy: 0.2161 - val_loss: 4.2809 - val_accuracy: 0.2117\n",
      "Epoch 1148/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3033 - accuracy: 0.2163 - val_loss: 4.2903 - val_accuracy: 0.2118\n",
      "Epoch 1149/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3123 - accuracy: 0.2165 - val_loss: 4.2976 - val_accuracy: 0.2129\n",
      "Epoch 1150/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3213 - accuracy: 0.2171 - val_loss: 4.2948 - val_accuracy: 0.2146\n",
      "Epoch 1151/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3334 - accuracy: 0.2181 - val_loss: 4.2873 - val_accuracy: 0.2161\n",
      "Epoch 1152/12000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.3105 - accuracy: 0.2178 - val_loss: 4.2762 - val_accuracy: 0.2186\n",
      "Epoch 1153/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.3028 - accuracy: 0.2188 - val_loss: 4.2645 - val_accuracy: 0.2211\n",
      "Epoch 1154/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2960 - accuracy: 0.2189 - val_loss: 4.2533 - val_accuracy: 0.2238\n",
      "Epoch 1155/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2839 - accuracy: 0.2195 - val_loss: 4.2435 - val_accuracy: 0.2254\n",
      "Epoch 1156/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2776 - accuracy: 0.2203 - val_loss: 4.2373 - val_accuracy: 0.2255\n",
      "Epoch 1157/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2733 - accuracy: 0.2202 - val_loss: 4.2330 - val_accuracy: 0.2257\n",
      "Epoch 1158/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2650 - accuracy: 0.2207 - val_loss: 4.2292 - val_accuracy: 0.2261\n",
      "Epoch 1159/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2569 - accuracy: 0.2208 - val_loss: 4.2266 - val_accuracy: 0.2263\n",
      "Epoch 1160/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2513 - accuracy: 0.2214 - val_loss: 4.2233 - val_accuracy: 0.2266\n",
      "Epoch 1161/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2562 - accuracy: 0.2206 - val_loss: 4.2151 - val_accuracy: 0.2264\n",
      "Epoch 1162/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2459 - accuracy: 0.2211 - val_loss: 4.2101 - val_accuracy: 0.2264\n",
      "Epoch 1163/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2359 - accuracy: 0.2223 - val_loss: 4.2056 - val_accuracy: 0.2266\n",
      "Epoch 1164/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2368 - accuracy: 0.2215 - val_loss: 4.2018 - val_accuracy: 0.2259\n",
      "Epoch 1165/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2312 - accuracy: 0.2218 - val_loss: 4.1990 - val_accuracy: 0.2254\n",
      "Epoch 1166/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2252 - accuracy: 0.2223 - val_loss: 4.1970 - val_accuracy: 0.2250\n",
      "Epoch 1167/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2261 - accuracy: 0.2220 - val_loss: 4.1963 - val_accuracy: 0.2244\n",
      "Epoch 1168/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2210 - accuracy: 0.2226 - val_loss: 4.1963 - val_accuracy: 0.2242\n",
      "Epoch 1169/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2190 - accuracy: 0.2226 - val_loss: 4.1963 - val_accuracy: 0.2240\n",
      "Epoch 1170/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2182 - accuracy: 0.2228 - val_loss: 4.1965 - val_accuracy: 0.2240\n",
      "Epoch 1171/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2162 - accuracy: 0.2226 - val_loss: 4.1936 - val_accuracy: 0.2243\n",
      "Epoch 1172/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2162 - accuracy: 0.2232 - val_loss: 4.1911 - val_accuracy: 0.2247\n",
      "Epoch 1173/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2167 - accuracy: 0.2227 - val_loss: 4.1877 - val_accuracy: 0.2249\n",
      "Epoch 1174/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2114 - accuracy: 0.2234 - val_loss: 4.1847 - val_accuracy: 0.2257\n",
      "Epoch 1175/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2123 - accuracy: 0.2231 - val_loss: 4.1819 - val_accuracy: 0.2264\n",
      "Epoch 1176/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2113 - accuracy: 0.2234 - val_loss: 4.1794 - val_accuracy: 0.2269\n",
      "Epoch 1177/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2088 - accuracy: 0.2237 - val_loss: 4.1775 - val_accuracy: 0.2271\n",
      "Epoch 1178/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2062 - accuracy: 0.2242 - val_loss: 4.1761 - val_accuracy: 0.2273\n",
      "Epoch 1179/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2044 - accuracy: 0.2241 - val_loss: 4.1752 - val_accuracy: 0.2274\n",
      "Epoch 1180/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2033 - accuracy: 0.2235 - val_loss: 4.1744 - val_accuracy: 0.2279\n",
      "Epoch 1181/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2029 - accuracy: 0.2244 - val_loss: 4.1730 - val_accuracy: 0.2286\n",
      "Epoch 1182/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2029 - accuracy: 0.2243 - val_loss: 4.1710 - val_accuracy: 0.2287\n",
      "Epoch 1183/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2000 - accuracy: 0.2246 - val_loss: 4.1694 - val_accuracy: 0.2292\n",
      "Epoch 1184/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.2003 - accuracy: 0.2248 - val_loss: 4.1684 - val_accuracy: 0.2292\n",
      "Epoch 1185/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1994 - accuracy: 0.2250 - val_loss: 4.1683 - val_accuracy: 0.2294\n",
      "Epoch 1186/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1998 - accuracy: 0.2248 - val_loss: 4.1683 - val_accuracy: 0.2292\n",
      "Epoch 1187/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1983 - accuracy: 0.2248 - val_loss: 4.1682 - val_accuracy: 0.2294\n",
      "Epoch 1188/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1977 - accuracy: 0.2247 - val_loss: 4.1679 - val_accuracy: 0.2294\n",
      "Epoch 1189/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1997 - accuracy: 0.2244 - val_loss: 4.1689 - val_accuracy: 0.2288\n",
      "Epoch 1190/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1986 - accuracy: 0.2249 - val_loss: 4.1681 - val_accuracy: 0.2290\n",
      "Epoch 1191/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1968 - accuracy: 0.2247 - val_loss: 4.1682 - val_accuracy: 0.2289\n",
      "Epoch 1192/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1983 - accuracy: 0.2243 - val_loss: 4.1680 - val_accuracy: 0.2289\n",
      "Epoch 1193/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1927 - accuracy: 0.2254 - val_loss: 4.1676 - val_accuracy: 0.2288\n",
      "Epoch 1194/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1936 - accuracy: 0.2256 - val_loss: 4.1670 - val_accuracy: 0.2289\n",
      "Epoch 1195/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1918 - accuracy: 0.2255 - val_loss: 4.1660 - val_accuracy: 0.2290\n",
      "Epoch 1196/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1915 - accuracy: 0.2254 - val_loss: 4.1647 - val_accuracy: 0.2291\n",
      "Epoch 1197/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1909 - accuracy: 0.2252 - val_loss: 4.1639 - val_accuracy: 0.2292\n",
      "Epoch 1198/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1914 - accuracy: 0.2256 - val_loss: 4.1634 - val_accuracy: 0.2294\n",
      "Epoch 1199/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1895 - accuracy: 0.2259 - val_loss: 4.1629 - val_accuracy: 0.2295\n",
      "Epoch 1200/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1891 - accuracy: 0.2260 - val_loss: 4.1623 - val_accuracy: 0.2294\n",
      "Epoch 1201/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1904 - accuracy: 0.2255 - val_loss: 4.1615 - val_accuracy: 0.2295\n",
      "Epoch 1202/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1875 - accuracy: 0.2259 - val_loss: 4.1607 - val_accuracy: 0.2295\n",
      "Epoch 1203/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1903 - accuracy: 0.2256 - val_loss: 4.1601 - val_accuracy: 0.2296\n",
      "Epoch 1204/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1908 - accuracy: 0.2254 - val_loss: 4.1595 - val_accuracy: 0.2299\n",
      "Epoch 1205/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1851 - accuracy: 0.2260 - val_loss: 4.1585 - val_accuracy: 0.2303\n",
      "Epoch 1206/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1883 - accuracy: 0.2259 - val_loss: 4.1579 - val_accuracy: 0.2303\n",
      "Epoch 1207/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1926 - accuracy: 0.2261 - val_loss: 4.1575 - val_accuracy: 0.2305\n",
      "Epoch 1208/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1867 - accuracy: 0.2256 - val_loss: 4.1571 - val_accuracy: 0.2308\n",
      "Epoch 1209/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1825 - accuracy: 0.2265 - val_loss: 4.1565 - val_accuracy: 0.2313\n",
      "Epoch 1210/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1867 - accuracy: 0.2260 - val_loss: 4.1559 - val_accuracy: 0.2319\n",
      "Epoch 1211/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1853 - accuracy: 0.2259 - val_loss: 4.1554 - val_accuracy: 0.2324\n",
      "Epoch 1212/12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 4.1864 - accuracy: 0.2259 - val_loss: 4.1548 - val_accuracy: 0.2322\n",
      "Epoch 1213/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1844 - accuracy: 0.2269 - val_loss: 4.1540 - val_accuracy: 0.2318\n",
      "Epoch 1214/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1829 - accuracy: 0.2263 - val_loss: 4.1532 - val_accuracy: 0.2317\n",
      "Epoch 1215/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1835 - accuracy: 0.2260 - val_loss: 4.1527 - val_accuracy: 0.2316\n",
      "Epoch 1216/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1825 - accuracy: 0.2266 - val_loss: 4.1528 - val_accuracy: 0.2317\n",
      "Epoch 1217/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1842 - accuracy: 0.2264 - val_loss: 4.1538 - val_accuracy: 0.2317\n",
      "Epoch 1218/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1820 - accuracy: 0.2260 - val_loss: 4.1546 - val_accuracy: 0.2313\n",
      "Epoch 1219/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1819 - accuracy: 0.2264 - val_loss: 4.1547 - val_accuracy: 0.2312\n",
      "Epoch 1220/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1796 - accuracy: 0.2263 - val_loss: 4.1543 - val_accuracy: 0.2315\n",
      "Epoch 1221/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1808 - accuracy: 0.2266 - val_loss: 4.1534 - val_accuracy: 0.2316\n",
      "Epoch 1222/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1814 - accuracy: 0.2269 - val_loss: 4.1527 - val_accuracy: 0.2316\n",
      "Epoch 1223/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1764 - accuracy: 0.2270 - val_loss: 4.1522 - val_accuracy: 0.2318\n",
      "Epoch 1224/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1826 - accuracy: 0.2262 - val_loss: 4.1520 - val_accuracy: 0.2317\n",
      "Epoch 1225/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1785 - accuracy: 0.2270 - val_loss: 4.1520 - val_accuracy: 0.2318\n",
      "Epoch 1226/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1798 - accuracy: 0.2263 - val_loss: 4.1521 - val_accuracy: 0.2322\n",
      "Epoch 1227/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1783 - accuracy: 0.2268 - val_loss: 4.1521 - val_accuracy: 0.2325\n",
      "Epoch 1228/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1778 - accuracy: 0.2265 - val_loss: 4.1520 - val_accuracy: 0.2326\n",
      "Epoch 1229/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1784 - accuracy: 0.2267 - val_loss: 4.1517 - val_accuracy: 0.2329\n",
      "Epoch 1230/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1776 - accuracy: 0.2270 - val_loss: 4.1514 - val_accuracy: 0.2328\n",
      "Epoch 1231/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1761 - accuracy: 0.2270 - val_loss: 4.1479 - val_accuracy: 0.2325\n",
      "Epoch 1232/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1728 - accuracy: 0.2268 - val_loss: 4.6300 - val_accuracy: 0.2328\n",
      "Epoch 1233/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.7141 - accuracy: 0.2262 - val_loss: 4.1543 - val_accuracy: 0.2329\n",
      "Epoch 1234/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1831 - accuracy: 0.2267 - val_loss: 4.1611 - val_accuracy: 0.2330\n",
      "Epoch 1235/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1872 - accuracy: 0.2268 - val_loss: 4.1644 - val_accuracy: 0.2332\n",
      "Epoch 1236/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1909 - accuracy: 0.2268 - val_loss: 4.1636 - val_accuracy: 0.2342\n",
      "Epoch 1237/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1895 - accuracy: 0.2280 - val_loss: 4.1605 - val_accuracy: 0.2352\n",
      "Epoch 1238/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1920 - accuracy: 0.2267 - val_loss: 4.1568 - val_accuracy: 0.2357\n",
      "Epoch 1239/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1905 - accuracy: 0.2275 - val_loss: 4.1541 - val_accuracy: 0.2360\n",
      "Epoch 1240/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1895 - accuracy: 0.2274 - val_loss: 4.1512 - val_accuracy: 0.2363\n",
      "Epoch 1241/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1890 - accuracy: 0.2270 - val_loss: 4.1488 - val_accuracy: 0.2356\n",
      "Epoch 1242/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1847 - accuracy: 0.2271 - val_loss: 4.1487 - val_accuracy: 0.2346\n",
      "Epoch 1243/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1840 - accuracy: 0.2272 - val_loss: 4.1503 - val_accuracy: 0.2332\n",
      "Epoch 1244/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1789 - accuracy: 0.2272 - val_loss: 4.1517 - val_accuracy: 0.2322\n",
      "Epoch 1245/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1826 - accuracy: 0.2264 - val_loss: 4.1528 - val_accuracy: 0.2317\n",
      "Epoch 1246/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1802 - accuracy: 0.2268 - val_loss: 4.1536 - val_accuracy: 0.2317\n",
      "Epoch 1247/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1765 - accuracy: 0.2273 - val_loss: 4.1533 - val_accuracy: 0.2316\n",
      "Epoch 1248/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1807 - accuracy: 0.2263 - val_loss: 4.1523 - val_accuracy: 0.2321\n",
      "Epoch 1249/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1790 - accuracy: 0.2265 - val_loss: 4.1513 - val_accuracy: 0.2325\n",
      "Epoch 1250/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1812 - accuracy: 0.2265 - val_loss: 4.1502 - val_accuracy: 0.2324\n",
      "Epoch 1251/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1797 - accuracy: 0.2269 - val_loss: 4.1492 - val_accuracy: 0.2329\n",
      "Epoch 1252/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1808 - accuracy: 0.2265 - val_loss: 4.1489 - val_accuracy: 0.2335\n",
      "Epoch 1253/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1811 - accuracy: 0.2266 - val_loss: 4.1486 - val_accuracy: 0.2339\n",
      "Epoch 1254/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1750 - accuracy: 0.2279 - val_loss: 4.1481 - val_accuracy: 0.2337\n",
      "Epoch 1255/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1785 - accuracy: 0.2269 - val_loss: 4.1474 - val_accuracy: 0.2339\n",
      "Epoch 1256/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1768 - accuracy: 0.2266 - val_loss: 4.1470 - val_accuracy: 0.2340\n",
      "Epoch 1257/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1730 - accuracy: 0.2281 - val_loss: 4.1463 - val_accuracy: 0.2343\n",
      "Epoch 1258/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1763 - accuracy: 0.2272 - val_loss: 4.1457 - val_accuracy: 0.2349\n",
      "Epoch 1259/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1738 - accuracy: 0.2280 - val_loss: 4.1464 - val_accuracy: 0.2347\n",
      "Epoch 1260/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1752 - accuracy: 0.2266 - val_loss: 4.1471 - val_accuracy: 0.2344\n",
      "Epoch 1261/12000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 4.1776 - accuracy: 0.2268 - val_loss: 4.1478 - val_accuracy: 0.2342\n",
      "Epoch 1262/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1746 - accuracy: 0.2277 - val_loss: 4.1493 - val_accuracy: 0.2340\n",
      "Epoch 1263/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1763 - accuracy: 0.2270 - val_loss: 4.1504 - val_accuracy: 0.2337\n",
      "Epoch 1264/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1728 - accuracy: 0.2279 - val_loss: 4.1508 - val_accuracy: 0.2332\n",
      "Epoch 1265/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1733 - accuracy: 0.2273 - val_loss: 4.1501 - val_accuracy: 0.2330\n",
      "Epoch 1266/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1760 - accuracy: 0.2267 - val_loss: 4.1485 - val_accuracy: 0.2333\n",
      "Epoch 1267/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1708 - accuracy: 0.2275 - val_loss: 4.1470 - val_accuracy: 0.2333\n",
      "Epoch 1268/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1712 - accuracy: 0.2275 - val_loss: 4.1463 - val_accuracy: 0.2339\n",
      "Epoch 1269/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1735 - accuracy: 0.2278 - val_loss: 4.1461 - val_accuracy: 0.2338\n",
      "Epoch 1270/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1733 - accuracy: 0.2266 - val_loss: 4.1462 - val_accuracy: 0.2332\n",
      "Epoch 1271/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1715 - accuracy: 0.2277 - val_loss: 4.1467 - val_accuracy: 0.2332\n",
      "Epoch 1272/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1706 - accuracy: 0.2275 - val_loss: 4.1471 - val_accuracy: 0.2332\n",
      "Epoch 1273/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1759 - accuracy: 0.2273 - val_loss: 4.1477 - val_accuracy: 0.2332\n",
      "Epoch 1274/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1697 - accuracy: 0.2277 - val_loss: 4.1477 - val_accuracy: 0.2335\n",
      "Epoch 1275/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1714 - accuracy: 0.2275 - val_loss: 4.1473 - val_accuracy: 0.2341\n",
      "Epoch 1276/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1730 - accuracy: 0.2275 - val_loss: 4.1466 - val_accuracy: 0.2344\n",
      "Epoch 1277/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1730 - accuracy: 0.2276 - val_loss: 4.1459 - val_accuracy: 0.2347\n",
      "Epoch 1278/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1732 - accuracy: 0.2277 - val_loss: 4.1456 - val_accuracy: 0.2343\n",
      "Epoch 1279/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1711 - accuracy: 0.2274 - val_loss: 4.1456 - val_accuracy: 0.2344\n",
      "Epoch 1280/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1707 - accuracy: 0.2273 - val_loss: 4.1453 - val_accuracy: 0.2344\n",
      "Epoch 1281/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1713 - accuracy: 0.2279 - val_loss: 4.1452 - val_accuracy: 0.2345\n",
      "Epoch 1282/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1685 - accuracy: 0.2278 - val_loss: 4.1453 - val_accuracy: 0.2340\n",
      "Epoch 1283/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1702 - accuracy: 0.2278 - val_loss: 4.1453 - val_accuracy: 0.2339\n",
      "Epoch 1284/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1686 - accuracy: 0.2284 - val_loss: 4.1449 - val_accuracy: 0.2339\n",
      "Epoch 1285/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1676 - accuracy: 0.2284 - val_loss: 4.1436 - val_accuracy: 0.2336\n",
      "Epoch 1286/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1724 - accuracy: 0.2278 - val_loss: 4.1435 - val_accuracy: 0.2339\n",
      "Epoch 1287/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1700 - accuracy: 0.2278 - val_loss: 4.1435 - val_accuracy: 0.2337\n",
      "Epoch 1288/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1670 - accuracy: 0.2278 - val_loss: 4.1437 - val_accuracy: 0.2338\n",
      "Epoch 1289/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1690 - accuracy: 0.2280 - val_loss: 4.1436 - val_accuracy: 0.2336\n",
      "Epoch 1290/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1677 - accuracy: 0.2280 - val_loss: 4.1435 - val_accuracy: 0.2345\n",
      "Epoch 1291/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1669 - accuracy: 0.2281 - val_loss: 4.1428 - val_accuracy: 0.2349\n",
      "Epoch 1292/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1678 - accuracy: 0.2278 - val_loss: 4.1427 - val_accuracy: 0.2348\n",
      "Epoch 1293/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1673 - accuracy: 0.2280 - val_loss: 4.1431 - val_accuracy: 0.2348\n",
      "Epoch 1294/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1698 - accuracy: 0.2277 - val_loss: 4.1426 - val_accuracy: 0.2348\n",
      "Epoch 1295/12000\n",
      "1/1 [==============================] - 7s 7s/step - loss: 4.1688 - accuracy: 0.2277 - val_loss: 4.1434 - val_accuracy: 0.2342\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1b88f52f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "gcn_generator = sg.mapper.RelationalFullBatchNodeGenerator(multilayer_graph, weighted=True)\n",
    "\n",
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = fold.unpack(val_split=0.1)\n",
    "        \n",
    "    X_train, y_train = gcn_generator.flow(X_train.index.to_numpy(), y_train)[0]\n",
    "    X_val, y_val = gcn_generator.flow(X_val.index.to_numpy(), y_val)[0]\n",
    "\n",
    "    X_test = gcn_generator.flow(X_test.index.to_numpy())\n",
    "\n",
    "    clf = create_rgcn_model(\n",
    "        Adam(learning_rate=0.1),\n",
    "        total_cities,\n",
    "        gcn_generator\n",
    "    )\n",
    "    \n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=200, min_delta=0.0001, restore_best_weights=True)],\n",
    "        epochs=12000,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "gcn_cross_val = GCNCrossValidator(\n",
    "    name=\"RGCN\",\n",
    "    encoder=LabelBinarizer()\n",
    ")\n",
    "\n",
    "rgcn_preds = gcn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(cities_true_enc, rgcn_preds, gcn_cross_val.classes_order(), cities_with_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ancient-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4858472193698702        \n",
      "Acc@161: 0.6441444950392681        \n",
      "Balanced Acc: 0.26529082859894076        \n",
      "ROC AUC Ovo: 0.9052932457264112        \n",
      "Mean Dist Err: 690.5788437720217        \n",
      "Median Dist Err: 6.351466891190705\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "weird-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graphsage_model(optimizer, num_classes, generator):\n",
    "    clear_session()\n",
    "    \n",
    "    graphsage_model = sg.layer.GraphSAGE(\n",
    "        layer_sizes=[128],\n",
    "        activations=[\"relu\"],\n",
    "        generator=generator,\n",
    "        bias=True,\n",
    "        dropout=0.2,\n",
    "        aggregator=sg.layer.MeanAggregator,#sg.layer.AttentionalAggregator,\n",
    "        normalize=\"l2\",\n",
    "        #kernel_regularizer=tf.keras.regularizers.l2(0.2)\n",
    "    )\n",
    "    \n",
    "    x_inp, x_out = graphsage_model.in_out_tensors()\n",
    "    \n",
    "    x_out = Dense(units=num_classes, activation=\"softmax\")(x_out)\n",
    "    \n",
    "    model = Model(inputs=x_inp, outputs=x_out)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-company",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240000\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 3.9715 - accuracy: 0.2368 - val_loss: 3.5129 - val_accuracy: 0.3020\n",
      "Epoch 2/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.3931 - accuracy: 0.3155 - val_loss: 3.2323 - val_accuracy: 0.3492\n",
      "Epoch 3/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.1839 - accuracy: 0.3485 - val_loss: 3.0884 - val_accuracy: 0.3736\n",
      "Epoch 4/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.0631 - accuracy: 0.3677 - val_loss: 3.0012 - val_accuracy: 0.3907\n",
      "Epoch 5/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9807 - accuracy: 0.3803 - val_loss: 2.9442 - val_accuracy: 0.4012\n",
      "Epoch 6/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9263 - accuracy: 0.3886 - val_loss: 2.9037 - val_accuracy: 0.4075\n",
      "Epoch 7/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.8838 - accuracy: 0.3945 - val_loss: 2.8728 - val_accuracy: 0.4152\n",
      "Epoch 8/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.8435 - accuracy: 0.4014 - val_loss: 2.8487 - val_accuracy: 0.4188\n",
      "Epoch 9/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.8064 - accuracy: 0.4069 - val_loss: 2.8337 - val_accuracy: 0.4208\n",
      "Epoch 10/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.7884 - accuracy: 0.4068 - val_loss: 2.8181 - val_accuracy: 0.4244\n",
      "Epoch 11/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.7655 - accuracy: 0.4099 - val_loss: 2.8072 - val_accuracy: 0.4258\n",
      "Epoch 12/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.7457 - accuracy: 0.4133 - val_loss: 2.8030 - val_accuracy: 0.4280\n",
      "Epoch 13/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.7339 - accuracy: 0.4136 - val_loss: 2.7914 - val_accuracy: 0.4284\n",
      "Epoch 14/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.7127 - accuracy: 0.4180 - val_loss: 2.7880 - val_accuracy: 0.4305\n",
      "Epoch 15/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.7037 - accuracy: 0.4184 - val_loss: 2.7839 - val_accuracy: 0.4315\n",
      "Epoch 16/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.6875 - accuracy: 0.4202 - val_loss: 2.7808 - val_accuracy: 0.4309\n",
      "Epoch 17/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6770 - accuracy: 0.4201 - val_loss: 2.7755 - val_accuracy: 0.4317\n",
      "Epoch 18/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.6660 - accuracy: 0.4224 - val_loss: 2.7733 - val_accuracy: 0.4331\n",
      "Epoch 19/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.6532 - accuracy: 0.4252 - val_loss: 2.7719 - val_accuracy: 0.4355\n",
      "Epoch 20/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6410 - accuracy: 0.4267 - val_loss: 2.7708 - val_accuracy: 0.4341\n",
      "Epoch 21/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6393 - accuracy: 0.4268 - val_loss: 2.7714 - val_accuracy: 0.4346\n",
      "Epoch 22/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.6266 - accuracy: 0.4290 - val_loss: 2.7699 - val_accuracy: 0.4363\n",
      "Epoch 23/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6209 - accuracy: 0.4294 - val_loss: 2.7683 - val_accuracy: 0.4362\n",
      "Epoch 24/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6097 - accuracy: 0.4320 - val_loss: 2.7673 - val_accuracy: 0.4357\n",
      "Epoch 25/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6054 - accuracy: 0.4310 - val_loss: 2.7691 - val_accuracy: 0.4355\n",
      "Epoch 26/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6007 - accuracy: 0.4322 - val_loss: 2.7710 - val_accuracy: 0.4360\n",
      "Epoch 27/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.5872 - accuracy: 0.4335 - val_loss: 2.7727 - val_accuracy: 0.4365\n",
      "Epoch 28/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.5836 - accuracy: 0.4337 - val_loss: 2.7713 - val_accuracy: 0.4364\n",
      "Epoch 29/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5788 - accuracy: 0.4339 - val_loss: 2.7732 - val_accuracy: 0.4352\n",
      "Epoch 30/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5733 - accuracy: 0.4346 - val_loss: 2.7736 - val_accuracy: 0.4362\n",
      "Epoch 31/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5646 - accuracy: 0.4381 - val_loss: 2.7765 - val_accuracy: 0.4361\n",
      "Epoch 32/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5615 - accuracy: 0.4363 - val_loss: 2.7759 - val_accuracy: 0.4354\n",
      "Epoch 33/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.5544 - accuracy: 0.4391 - val_loss: 2.7733 - val_accuracy: 0.4369\n",
      "Epoch 34/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5509 - accuracy: 0.4380 - val_loss: 2.7744 - val_accuracy: 0.4370\n",
      "Epoch 35/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5428 - accuracy: 0.4392 - val_loss: 2.7744 - val_accuracy: 0.4386\n",
      "Epoch 36/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5382 - accuracy: 0.4397 - val_loss: 2.7787 - val_accuracy: 0.4372\n",
      "Epoch 37/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5354 - accuracy: 0.4410 - val_loss: 2.7807 - val_accuracy: 0.4376\n",
      "Epoch 38/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.5294 - accuracy: 0.4416 - val_loss: 2.7817 - val_accuracy: 0.4366\n",
      "Epoch 39/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.5244 - accuracy: 0.4423 - val_loss: 2.7839 - val_accuracy: 0.4378\n",
      "Epoch 40/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.5187 - accuracy: 0.4422 - val_loss: 2.7847 - val_accuracy: 0.4385\n",
      "Epoch 41/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.5150 - accuracy: 0.4433 - val_loss: 2.7857 - val_accuracy: 0.4386\n",
      "Epoch 42/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5118 - accuracy: 0.4428 - val_loss: 2.7893 - val_accuracy: 0.4367\n",
      "Epoch 43/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5115 - accuracy: 0.4429 - val_loss: 2.7893 - val_accuracy: 0.4383\n",
      "Epoch 44/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5094 - accuracy: 0.4441 - val_loss: 2.7913 - val_accuracy: 0.4368\n",
      "Epoch 45/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5020 - accuracy: 0.4442 - val_loss: 2.7934 - val_accuracy: 0.4378\n",
      "Epoch 46/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.4945 - accuracy: 0.4455 - val_loss: 2.7924 - val_accuracy: 0.4380\n",
      "Epoch 47/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4960 - accuracy: 0.4453 - val_loss: 2.7948 - val_accuracy: 0.4377\n",
      "Epoch 48/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4882 - accuracy: 0.4466 - val_loss: 2.7991 - val_accuracy: 0.4368\n",
      "Epoch 49/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.4833 - accuracy: 0.4476 - val_loss: 2.8029 - val_accuracy: 0.4382\n",
      "Epoch 50/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4826 - accuracy: 0.4475 - val_loss: 2.8002 - val_accuracy: 0.4375\n",
      "Epoch 51/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4830 - accuracy: 0.4465 - val_loss: 2.8054 - val_accuracy: 0.4378\n",
      "Epoch 52/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4732 - accuracy: 0.4479 - val_loss: 2.8037 - val_accuracy: 0.4396\n",
      "Epoch 53/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4739 - accuracy: 0.4481 - val_loss: 2.8076 - val_accuracy: 0.4385\n",
      "Epoch 54/240000\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.4702 - accuracy: 0.4489 - val_loss: 2.8070 - val_accuracy: 0.4384\n",
      "Epoch 1/240000\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 3.9727 - accuracy: 0.2372 - val_loss: 3.5349 - val_accuracy: 0.2879\n",
      "Epoch 2/240000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.4053 - accuracy: 0.3156 - val_loss: 3.2414 - val_accuracy: 0.3434\n",
      "Epoch 3/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.1926 - accuracy: 0.3495 - val_loss: 3.0881 - val_accuracy: 0.3725\n",
      "Epoch 4/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.0618 - accuracy: 0.3681 - val_loss: 2.9923 - val_accuracy: 0.3902\n",
      "Epoch 5/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9788 - accuracy: 0.3815 - val_loss: 2.9292 - val_accuracy: 0.4022\n",
      "Epoch 6/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.9145 - accuracy: 0.3914 - val_loss: 2.8856 - val_accuracy: 0.4113\n",
      "Epoch 7/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.8703 - accuracy: 0.3960 - val_loss: 2.8558 - val_accuracy: 0.4159\n",
      "Epoch 8/240000\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 2.8372 - accuracy: 0.4001 - val_loss: 2.8296 - val_accuracy: 0.4194\n",
      "Epoch 9/240000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.8086 - accuracy: 0.4043 - val_loss: 2.8134 - val_accuracy: 0.4242\n",
      "Epoch 10/240000\n",
      " 778/1563 [=============>................] - ETA: 2s - loss: 2.7979 - accuracy: 0.4022"
     ]
    }
   ],
   "source": [
    "gcn_generator = sg.mapper.GraphSAGENodeGenerator(colmentions_graph, 50000, [100], weighted=True)\n",
    "\n",
    "def preprocess(fold):   \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = fold.unpack(val_split=0.1)\n",
    "        \n",
    "    X_train, y_train = gcn_generator.flow(X_train.index.to_numpy(), y_train)[0]\n",
    "    X_val, y_val = gcn_generator.flow(X_val.index.to_numpy(), y_val)[0]\n",
    "\n",
    "    X_test = gcn_generator.flow(X_test.index.to_numpy())\n",
    "\n",
    "    clf = create_graphsage_model(\n",
    "        \"adam\",#Adam(learning_rate=0.1),\n",
    "        total_cities,\n",
    "        gcn_generator\n",
    "    )\n",
    "    \n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=30, min_delta=0.0001, restore_best_weights=True)],\n",
    "        epochs=240000,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "gcn_cross_val = GCNCrossValidator(\n",
    "    name=\"GraphSAGE\",\n",
    "    encoder=LabelBinarizer()\n",
    ")\n",
    "\n",
    "graphsage_preds = gcn_cross_val.cross_predict(\n",
    "    folds_cities,\n",
    "    test_cities_idxs,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "count_score_city = get_all_metrics(cities_true_enc, graphsage_preds, gcn_cross_val.classes_order(), cities_with_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "intense-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43148099625377984        \n",
      "Acc@161: 0.5783200787485216        \n",
      "Balanced Acc: 0.22505963457707065        \n",
      "ROC AUC Ovo: 0.8680610644104378        \n",
      "Mean Dist Err: 798.3908668133037        \n",
      "Median Dist Err: 23.185572172281425\n"
     ]
    }
   ],
   "source": [
    "print(count_score_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-provision",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "significant-tanzania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_place</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asuncion,paraguay</td>\n",
       "      <td>-25.286461</td>\n",
       "      <td>-57.646999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avellaneda,argentina</td>\n",
       "      <td>-29.117611</td>\n",
       "      <td>-59.658340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caracas,venezuela</td>\n",
       "      <td>10.488010</td>\n",
       "      <td>-66.879189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ciudad autónoma de buenos aires,argentina</td>\n",
       "      <td>-34.613152</td>\n",
       "      <td>-58.377232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corrientes,argentina</td>\n",
       "      <td>-27.467840</td>\n",
       "      <td>-58.834400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               unified_place   latitude  longitude\n",
       "0                          asuncion,paraguay -25.286461 -57.646999\n",
       "1                       avellaneda,argentina -29.117611 -59.658340\n",
       "2                          caracas,venezuela  10.488010 -66.879189\n",
       "3  ciudad autónoma de buenos aires,argentina -34.613152 -58.377232\n",
       "4                       corrientes,argentina -27.467840 -58.834400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_determined_place[['city','country']] = min_determined_place.unified_place.str.split(',', expand=True) \n",
    "    \n",
    "places_with_coords = pd.merge(\n",
    "    left=min_determined_place,\n",
    "    right=geonames.loc[:,['alternatenames', 'country', 'latitude', 'longitude']],\n",
    "    how='left',\n",
    "    left_on=['city', 'country'],\n",
    "    right_on=['alternatenames', 'country'],\n",
    "    validate='m:1'\n",
    ").loc[:, [\"unified_place\", \"latitude\", \"longitude\"]]\n",
    "\n",
    "places_with_coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "catholic-christian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79642, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train = pd.merge(\n",
    "    left=users,\n",
    "    right=min_determined_place.loc[:, ['unified_place']],\n",
    "    how='inner',\n",
    "    left_on='unified_place',\n",
    "    right_on='unified_place',\n",
    "    validate='m:1'\n",
    ")\n",
    "\n",
    "users_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polish-bacon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32292, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train.dropna(subset=[\"full_text\", \"users_mentioned\"], inplace=True)\n",
    "users_train.dropna(subset=[\"followees\", \"followers\"], how='all', inplace=True)\n",
    "users_train.reset_index(drop=True, inplace=True)\n",
    "users_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interpreted-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train[\"full_text\"] = users_train[\"full_text\"].apply(lambda x: list(map(str, x)))\n",
    "users_train[\"users_mentioned\"] = users_train[\"users_mentioned\"].apply(lambda x: list(map(int, x)))\n",
    "users_train['followees'] = users_train['followees'].fillna(\"\").apply(list)\n",
    "users_train['followers'] = users_train['followers'].fillna(\"\").apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lyric-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(users_train['unified_place'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "clear-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = users_train[\"id\"].unique()\n",
    "\n",
    "set_users = set(users_ids)\n",
    "\n",
    "for x in users_train[\"users_mentioned\"].values:\n",
    "    set_users |= set(x)\n",
    "\n",
    "mentioned_users = list(set_users.difference(set(users_ids)))\n",
    "\n",
    "total_users_mentions = list(users_ids) + mentioned_users\n",
    "len(total_users_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "constitutional-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Verify order\n",
    "\n",
    "value = True\n",
    "\n",
    "for i in range(0, len(users_train[\"id\"])):\n",
    "    if total_users_mentions[i] != users_train[\"id\"][i]:\n",
    "        value = False\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "similar-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590490"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = users_train[\"id\"].unique()\n",
    "\n",
    "set_users = set(users_ids)\n",
    "\n",
    "for x in users_train[\"followees\"].values:\n",
    "    set_users |= set(x)\n",
    "    \n",
    "for x in users_train[\"followers\"].values:\n",
    "    set_users |= set(x)\n",
    "\n",
    "follows_users = list(set_users.difference(set(users_ids)))\n",
    "\n",
    "total_users_follows = list(users_ids) + follows_users\n",
    "len(total_users_follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statistical-blogger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Verify order\n",
    "\n",
    "value = True\n",
    "\n",
    "for i in range(0, len(users_train[\"id\"])):\n",
    "    if total_users_follows[i] != users_train[\"id\"][i]:\n",
    "        value = False\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exotic-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"user_id\": total_users_follows})\n",
    "df.to_csv(\"../../results/matrix/follows/users_follows_ids.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "elder-investigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32292x414528 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 645386 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents=None,\n",
    "    lowercase=False,\n",
    "    vocabulary=total_users_mentions,\n",
    "    analyzer=lambda x: x,\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "vector_of_mentions = vectorizer.fit_transform(users_train[\"users_mentioned\"]).astype(np.uint8)\n",
    "vector_of_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "anonymous-concert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<32292x32292 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 967006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_of_co_mentions = vector_of_mentions.dot(vector_of_mentions.T)\n",
    "vector_of_co_mentions.setdiag(0, k=0)\n",
    "vector_of_co_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "precious-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = vector_of_co_mentions.tocoo()\n",
    "edges = []\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_co_mentions.shape[0]):\n",
    "    already_passed[i] = []\n",
    "\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    if v <= 0:\n",
    "        continue\n",
    "    \n",
    "    if i in already_passed[j]:\n",
    "        continue\n",
    "        \n",
    "    format_str = str(i) + \" \" + str(j) + \" \" + str(v)\n",
    "    edges.append(format_str)\n",
    "    \n",
    "    already_passed[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "lovely-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"edges\": edges})\n",
    "df.to_csv(\"../../results/matrix/mentions/edges_comentions_w_final.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fresh-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32292x590490 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 3765640 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents=None,\n",
    "    lowercase=False,\n",
    "    vocabulary=total_users_follows,\n",
    "    analyzer=lambda x: x\n",
    ")\n",
    "\n",
    "vector_of_followees = vectorizer.fit_transform(users_train[\"followees\"]).astype(np.uint8)\n",
    "vector_of_followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "modular-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32292x590490 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 5332199 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents=None,\n",
    "    lowercase=False,\n",
    "    vocabulary=total_users_follows,\n",
    "    analyzer=lambda x: x\n",
    ")\n",
    "\n",
    "vector_of_followers = vectorizer.fit_transform(users_train[\"followers\"]).astype(np.uint8)\n",
    "vector_of_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cardiovascular-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx1 = vector_of_followees.tocoo()\n",
    "cx2 = vector_of_followers.tocoo()\n",
    "\n",
    "edges = []\n",
    "\n",
    "already_passed = {}\n",
    "\n",
    "for i in range(vector_of_followees.shape[0]):\n",
    "    already_passed[i] = []\n",
    "    \n",
    "for i,j,v in zip(cx1.row, cx1.col, cx1.data):\n",
    "    if v <= 0:\n",
    "        continue\n",
    "    \n",
    "    format_str = str(i) + \" \" + str(j)\n",
    "    edges.append(format_str)\n",
    "    \n",
    "    already_passed[i].append(j)\n",
    "\n",
    "for i,j,v in zip(cx2.row, cx2.col, cx2.data):\n",
    "    if v <= 0:\n",
    "        continue\n",
    "        \n",
    "    if already_passed[i] and j in already_passed[i]:\n",
    "        continue\n",
    "    \n",
    "    format_str = str(i) + \" \" + str(j)\n",
    "    edges.append(format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "regular-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"edges\": edges})\n",
    "df.to_csv(\"../../results/matrix/follows/edges_follows_final.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-orientation",
   "metadata": {},
   "source": [
    "# Búsqueda de comunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "identified-brief",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting -f\n",
      "setting -w\n",
      "setting -r\n",
      "setting -hr\n",
      "setting -seed\n",
      "setting -cp\n",
      "**************************************\n",
      "Threshold:\t\t\t0.1\n",
      "Network file:\t\t\t../../results/matrix/mentions/edges_comentions_w_final.csv\n",
      "Weighted: yes\n",
      "First Level Runs:\t\t\t1\n",
      "Higher Level Runs:\t\t\t0\n",
      "-cp:\t\t\t0.5\n",
      "Random number generator seed:\t\t\t42\n",
      "**************************************\n",
      "\n",
      "allocating 934714 factorials...\n",
      "done\n",
      "mkdir: cannot create directory ‘../../results/matrix/mentions/edges_comentions_w_final.csv_oslo_files’: File exists\n",
      "output files will be written in directory: ../../results/matrix/mentions/edges_comentions_w_final.csv_oslo_files\n",
      "network:: 26214 nodes and 934714 stubs;\t average degree = 35.6571\n",
      "STARTING! HIERARCHICAL LEVEL: 0\n",
      "***************************************************************** RUN: #1\n",
      "iteration: 0 number of modules: 5375\n",
      "iteration: 20 number of modules: 1177\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 1193. Percentage nodes done: 0\n",
      "checked 100 modules 100 were found significant.  Modules to check: 1093. Percentage nodes done: 0.526474\n",
      "checked 200 modules 200 were found significant.  Modules to check: 993. Percentage nodes done: 0.725834\n",
      "checked 300 modules 299 were found significant.  Modules to check: 893. Percentage nodes done: 0.789387\n",
      "checked 400 modules 399 were found significant.  Modules to check: 793. Percentage nodes done: 0.83753\n",
      "checked 500 modules 497 were found significant.  Modules to check: 693. Percentage nodes done: 0.874647\n",
      "checked 600 modules 596 were found significant.  Modules to check: 593. Percentage nodes done: 0.908446\n",
      "checked 700 modules 693 were found significant.  Modules to check: 493. Percentage nodes done: 0.931334\n",
      "checked 800 modules 786 were found significant.  Modules to check: 393. Percentage nodes done: 0.951476\n",
      "checked 900 modules 870 were found significant.  Modules to check: 293. Percentage nodes done: 0.968948\n",
      "checked 1000 modules 943 were found significant.  Modules to check: 193. Percentage nodes done: 0.982109\n",
      "checked 1100 modules 1006 were found significant.  Modules to check: 93. Percentage nodes done: 0.992103\n",
      "significance check done \n",
      "\n",
      "\n",
      "checking unions of not significant modules, modules to check: 156\n",
      "iteration: 0 number of modules: 156\n",
      "collection done \n",
      "\n",
      "\n",
      "checking unions of not significant modules done \n",
      "\n",
      "\n",
      "***************************************************************************\n",
      "COLLECTING SIGNIFICANT MODULES DONE\n",
      "\n",
      "minimality check: 879 modules to check, run: 0\n",
      "minimality check: 111 modules to check, run: 1\n",
      "***************************************************************************\n",
      "MINIMALITY CHECK DONE\n",
      "checking similar modules\n",
      "\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 1703\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 881\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 4\n",
      "checked 200 unions. Fused: 7\n",
      "checked 300 unions. Fused: 12\n",
      "checked 400 unions. Fused: 25\n",
      "checked 500 unions. Fused: 31\n",
      "checked 600 unions. Fused: 33\n",
      "checked 800 unions. Fused: 34\n",
      "check unions of modules using community network\n",
      "\n",
      "iteration: 0 number of modules: 1642\n",
      "collection done \n",
      "\n",
      "\n",
      "possible fusions to check: 883\n",
      "checked 0 unions. Fused: 0\n",
      "checked 100 unions. Fused: 0\n",
      "checked 200 unions. Fused: 5\n",
      "checked 300 unions. Fused: 11\n",
      "checked 400 unions. Fused: 19\n",
      "checked 500 unions. Fused: 24\n",
      "checked 600 unions. Fused: 25\n",
      "checked 700 unions. Fused: 25\n",
      "checking highly intersecting modules\n",
      "\n",
      "pairs to check: 1745\n",
      "minimality check: 10 modules to check, run: 1\n",
      "minimality check: 13 modules to check, run: 1\n",
      "minimality check: 7 modules to check, run: 1\n",
      "pairs to check: 411\n",
      "minimality check: 6 modules to check, run: 1\n",
      "pairs to check: 77\n",
      "pairs to check: 14\n",
      "pairs to check: 16\n",
      "***************************************************************************\n",
      "CHECK UNIONS AND SIMILAR MODULES DONE\n",
      "******** module_collection ******** 791 modules. writing... \n",
      "DONE   ****************************\n",
      "pruning all the modules collected. Partitions found: 1\n",
      "getting partition from tp-file: ../../results/matrix/mentions/edges_comentions_w_final.csv_oslo_files/partitions_level_0\n",
      "791 groups found\n",
      "791 bss found\n",
      "checking homeless nodes\n",
      "assigning homeless nodes. Homeless at this point: 9524\n",
      "assigning homeless nodes. Homeless at this point: 673\n",
      "assigning homeless nodes. Homeless at this point: 200\n",
      "assigning homeless nodes. Homeless at this point: 189\n",
      "assigning homeless nodes. Homeless at this point: 188\n",
      "writing final solution in file ../../results/matrix/mentions/edges_comentions_w_final.csv_oslo_files/tp\n",
      "******** module_collection ******** 791 modules. writing... \n",
      "DONE   ****************************\n",
      "network:: 979 nodes and 585546 stubs;\t average degree = 598.106\n",
      "STARTING! HIERARCHICAL LEVEL: 1\n",
      "pruning all the modules collected. Partitions found: 0\n",
      "getting partition from tp-file: ../../results/matrix/mentions/edges_comentions_w_final.csv_oslo_files/partitions_level_1\n",
      "0 groups found\n",
      "0 bss found\n",
      "checking homeless nodes\n",
      "writing final solution in file ../../results/matrix/mentions/edges_comentions_w_final.csv_oslo_files/short_tp1\n",
      "******** module_collection ******** 0 modules. writing... \n",
      "DONE   ****************************\n",
      "hierarchies done ********* \n",
      "143.97337675094604\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "!cd ../../oslom/OSLOM2 && \\\n",
    "./oslom_undir -f ../../results/matrix/mentions/edges_comentions_w_final.csv -w -r 1 -hr 0 -seed 42 -cp 0.5\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-coast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting -f\n",
      "setting -uw\n",
      "setting -r\n",
      "setting -hr\n",
      "setting -seed\n",
      "setting -cp\n",
      "**************************************\n",
      "Threshold:\t\t\t0.1\n",
      "Network file:\t\t\t../../results/matrix/follows/edges_follows_final.csv\n",
      "Weighted: no\n",
      "First Level Runs:\t\t\t1\n",
      "Higher Level Runs:\t\t\t0\n",
      "-cp:\t\t\t0.5\n",
      "Random number generator seed:\t\t\t42\n",
      "**************************************\n",
      "\n",
      "allocating 14687506 factorials...\n",
      "done\n",
      "rm: cannot remove '../../results/matrix/follows/edges_follows_final.csv_oslo_files/*': No such file or directory\n",
      "output files will be written in directory: ../../results/matrix/follows/edges_follows_final.csv_oslo_files\n",
      "network:: 590490 nodes and 1.46875e+07 stubs;\t average degree = 24.8734\n",
      "STARTING! HIERARCHICAL LEVEL: 0\n",
      "***************************************************************** RUN: #1\n",
      "iteration: 0 number of modules: 33892\n",
      "iteration: 20 number of modules: 14915\n",
      "collection done \n",
      "\n",
      "\n",
      "checked 0 modules 0 were found significant.  Modules to check: 14916. Percentage nodes done: 0\n",
      "checked 100 modules 97 were found significant.  Modules to check: 14816. Percentage nodes done: 0.309629\n",
      "checked 200 modules 189 were found significant.  Modules to check: 14716. Percentage nodes done: 0.34198\n",
      "checked 300 modules 287 were found significant.  Modules to check: 14616. Percentage nodes done: 0.357381\n",
      "checked 400 modules 385 were found significant.  Modules to check: 14516. Percentage nodes done: 0.371647\n",
      "checked 500 modules 485 were found significant.  Modules to check: 14416. Percentage nodes done: 0.386003\n",
      "checked 600 modules 582 were found significant.  Modules to check: 14316. Percentage nodes done: 0.399712\n",
      "checked 700 modules 680 were found significant.  Modules to check: 14216. Percentage nodes done: 0.415523\n",
      "checked 800 modules 777 were found significant.  Modules to check: 14116. Percentage nodes done: 0.424735\n",
      "checked 900 modules 874 were found significant.  Modules to check: 14016. Percentage nodes done: 0.436812\n",
      "checked 1000 modules 973 were found significant.  Modules to check: 13916. Percentage nodes done: 0.442959\n",
      "checked 1100 modules 1073 were found significant.  Modules to check: 13816. Percentage nodes done: 0.447271\n",
      "checked 1200 modules 1172 were found significant.  Modules to check: 13716. Percentage nodes done: 0.459107\n",
      "checked 1300 modules 1272 were found significant.  Modules to check: 13616. Percentage nodes done: 0.463249\n",
      "checked 1400 modules 1372 were found significant.  Modules to check: 13516. Percentage nodes done: 0.470533\n",
      "checked 1500 modules 1472 were found significant.  Modules to check: 13416. Percentage nodes done: 0.48168\n",
      "checked 1600 modules 1572 were found significant.  Modules to check: 13316. Percentage nodes done: 0.48653\n",
      "checked 1700 modules 1671 were found significant.  Modules to check: 13216. Percentage nodes done: 0.49172\n",
      "checked 1800 modules 1771 were found significant.  Modules to check: 13116. Percentage nodes done: 0.503048\n",
      "checked 1900 modules 1869 were found significant.  Modules to check: 13016. Percentage nodes done: 0.512461\n",
      "checked 2000 modules 1969 were found significant.  Modules to check: 12916. Percentage nodes done: 0.518822\n",
      "checked 2100 modules 2068 were found significant.  Modules to check: 12816. Percentage nodes done: 0.522966\n",
      "checked 2200 modules 2167 were found significant.  Modules to check: 12716. Percentage nodes done: 0.530463\n",
      "checked 2300 modules 2267 were found significant.  Modules to check: 12616. Percentage nodes done: 0.544783\n",
      "checked 2400 modules 2367 were found significant.  Modules to check: 12516. Percentage nodes done: 0.554075\n",
      "checked 2500 modules 2466 were found significant.  Modules to check: 12416. Percentage nodes done: 0.562384\n",
      "checked 2600 modules 2566 were found significant.  Modules to check: 12316. Percentage nodes done: 0.567346\n",
      "checked 2700 modules 2665 were found significant.  Modules to check: 12216. Percentage nodes done: 0.575705\n",
      "checked 2800 modules 2765 were found significant.  Modules to check: 12116. Percentage nodes done: 0.583466\n",
      "checked 2900 modules 2864 were found significant.  Modules to check: 12016. Percentage nodes done: 0.592113\n",
      "checked 3000 modules 2963 were found significant.  Modules to check: 11916. Percentage nodes done: 0.597919\n",
      "checked 3100 modules 3063 were found significant.  Modules to check: 11816. Percentage nodes done: 0.604942\n",
      "checked 3200 modules 3161 were found significant.  Modules to check: 11716. Percentage nodes done: 0.61337\n",
      "checked 3300 modules 3261 were found significant.  Modules to check: 11616. Percentage nodes done: 0.625677\n",
      "checked 3400 modules 3361 were found significant.  Modules to check: 11516. Percentage nodes done: 0.633669\n",
      "checked 3500 modules 3460 were found significant.  Modules to check: 11416. Percentage nodes done: 0.641413\n",
      "checked 3600 modules 3559 were found significant.  Modules to check: 11316. Percentage nodes done: 0.648085\n",
      "checked 3700 modules 3658 were found significant.  Modules to check: 11216. Percentage nodes done: 0.65434\n",
      "checked 3800 modules 3757 were found significant.  Modules to check: 11116. Percentage nodes done: 0.659649\n",
      "checked 3900 modules 3855 were found significant.  Modules to check: 11016. Percentage nodes done: 0.666259\n",
      "checked 4000 modules 3955 were found significant.  Modules to check: 10916. Percentage nodes done: 0.67212\n",
      "checked 4100 modules 4055 were found significant.  Modules to check: 10816. Percentage nodes done: 0.676745\n",
      "checked 4200 modules 4152 were found significant.  Modules to check: 10716. Percentage nodes done: 0.680232\n",
      "checked 4300 modules 4251 were found significant.  Modules to check: 10616. Percentage nodes done: 0.684277\n",
      "checked 4400 modules 4351 were found significant.  Modules to check: 10516. Percentage nodes done: 0.689573\n",
      "checked 4500 modules 4449 were found significant.  Modules to check: 10416. Percentage nodes done: 0.692354\n",
      "checked 4600 modules 4547 were found significant.  Modules to check: 10316. Percentage nodes done: 0.697014\n",
      "checked 4700 modules 4647 were found significant.  Modules to check: 10216. Percentage nodes done: 0.701008\n",
      "checked 4800 modules 4746 were found significant.  Modules to check: 10116. Percentage nodes done: 0.706415\n",
      "checked 4900 modules 4845 were found significant.  Modules to check: 10016. Percentage nodes done: 0.710154\n",
      "checked 5000 modules 4944 were found significant.  Modules to check: 9916. Percentage nodes done: 0.715011\n",
      "checked 5100 modules 5044 were found significant.  Modules to check: 9816. Percentage nodes done: 0.719336\n",
      "checked 5200 modules 5143 were found significant.  Modules to check: 9716. Percentage nodes done: 0.724534\n",
      "checked 5300 modules 5243 were found significant.  Modules to check: 9616. Percentage nodes done: 0.730483\n",
      "checked 5400 modules 5342 were found significant.  Modules to check: 9516. Percentage nodes done: 0.734493\n",
      "checked 5500 modules 5441 were found significant.  Modules to check: 9416. Percentage nodes done: 0.738368\n",
      "checked 5600 modules 5536 were found significant.  Modules to check: 9316. Percentage nodes done: 0.745406\n",
      "checked 5700 modules 5636 were found significant.  Modules to check: 9216. Percentage nodes done: 0.750875\n",
      "checked 5800 modules 5736 were found significant.  Modules to check: 9116. Percentage nodes done: 0.754782\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "!cd ../../oslom/OSLOM2 && \\\n",
    "./oslom_undir -f ../../results/matrix/follows/edges_follows_final.csv -uw -r 1 -hr 0 -seed 42 -cp 0.5\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-auditor",
   "metadata": {},
   "source": [
    "# Creación modelo Keras para NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "desirable-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 3000\n",
    "embedding_dim = 128\n",
    "sequence_length = 256\n",
    "number_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "spanish-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_161km_k(y_real, y_pred):\n",
    "    real_place = encoder.inverse_transform(y_real.numpy())\n",
    "    pred_place = encoder.inverse_transform(y_pred.numpy())\n",
    "\n",
    "    return accuracy_161km(real_place, pred_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "communist-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nlp_model(optimizer, input_length):\n",
    "    clear_session()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embedding_dim, input_length=input_length, mask_zero=True))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(number_classes, activation='softmax'))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        #metrics=['accuracy', 'AUC', accuracy_161km_k],\n",
    "        metrics=['accuracy'],\n",
    "        #run_eagerly=True\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-calvin",
   "metadata": {},
   "source": [
    "# Preparado de datos para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-country",
   "metadata": {},
   "source": [
    "Comunidades en menciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "professional-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, clusters = extract_oslom('../../results/matrix/mentions/edges_comentions_w_final.csv_oslo_files/tp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "functional-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_user_id(row):\n",
    "    return total_users_mentions[row[\"id\"]]\n",
    "\n",
    "train[\"id\"] = train.apply(get_original_user_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "concrete-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_clusters = pd.merge(\n",
    "    left=train,\n",
    "    right=users_train,\n",
    "    how='inner',\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\",\n",
    "    validate=\"m:1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "finished-cattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clusters_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>821923</td>\n",
       "      <td>[50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1190421</td>\n",
       "      <td>[401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1297311</td>\n",
       "      <td>[675]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id clusters_mentions\n",
       "0   821923              [50]\n",
       "1  1190421             [401]\n",
       "2  1297311             [675]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_clusters = users_clusters.loc[\n",
    "    :, [\"id\", \"cluster\"]\n",
    "]\n",
    "\n",
    "users_clusters = users_clusters.groupby(\n",
    "        [\"id\"]\n",
    "    )['cluster'].apply(list).reset_index(name='clusters_mentions')\n",
    "\n",
    "users_clusters.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "signal-armstrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>full_text</th>\n",
       "      <th>users_mentioned</th>\n",
       "      <th>followees</th>\n",
       "      <th>followers</th>\n",
       "      <th>unified_place</th>\n",
       "      <th>clusters_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1190421</td>\n",
       "      <td>ciudad autónoma de buenos aires</td>\n",
       "      <td>argentina</td>\n",
       "      <td>-34.613152</td>\n",
       "      <td>-58.377232</td>\n",
       "      <td>[Nos pasa a todos  quédate tranquilo , Por si ...</td>\n",
       "      <td>[239643295, 146155608, 4335595632]</td>\n",
       "      <td>[14071538, 116828061, 47491330, 217196502, 580...</td>\n",
       "      <td>[18636825, 719403685, 47734745, 23593416, 7948...</td>\n",
       "      <td>ciudad autónoma de buenos aires,argentina</td>\n",
       "      <td>[401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2591131</td>\n",
       "      <td>ciudad autónoma de buenos aires</td>\n",
       "      <td>argentina</td>\n",
       "      <td>-34.613152</td>\n",
       "      <td>-58.377232</td>\n",
       "      <td>[ Suerte, Genio , Mora en Palermo Soho , Arte ...</td>\n",
       "      <td>[201353361]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[197178351, 914218687632199682, 2747567856, 99...</td>\n",
       "      <td>ciudad autónoma de buenos aires,argentina</td>\n",
       "      <td>[773]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3367711</td>\n",
       "      <td>ciudad autónoma de buenos aires</td>\n",
       "      <td>argentina</td>\n",
       "      <td>-34.613152</td>\n",
       "      <td>-58.377232</td>\n",
       "      <td>[Con la cuenta me dieron este chocolatito en e...</td>\n",
       "      <td>[176226209]</td>\n",
       "      <td>[720786569792253952, 182644738, 138814032, 116...</td>\n",
       "      <td>[45260729, 24841574, 40654511, 528716709, 5679...</td>\n",
       "      <td>ciudad autónoma de buenos aires,argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       place_name place_country   latitude  \\\n",
       "0  1190421  ciudad autónoma de buenos aires     argentina -34.613152   \n",
       "1  2591131  ciudad autónoma de buenos aires     argentina -34.613152   \n",
       "2  3367711  ciudad autónoma de buenos aires     argentina -34.613152   \n",
       "\n",
       "   longitude                                          full_text  \\\n",
       "0 -58.377232  [Nos pasa a todos  quédate tranquilo , Por si ...   \n",
       "1 -58.377232  [ Suerte, Genio , Mora en Palermo Soho , Arte ...   \n",
       "2 -58.377232  [Con la cuenta me dieron este chocolatito en e...   \n",
       "\n",
       "                      users_mentioned  \\\n",
       "0  [239643295, 146155608, 4335595632]   \n",
       "1                         [201353361]   \n",
       "2                         [176226209]   \n",
       "\n",
       "                                           followees  \\\n",
       "0  [14071538, 116828061, 47491330, 217196502, 580...   \n",
       "1                                                 []   \n",
       "2  [720786569792253952, 182644738, 138814032, 116...   \n",
       "\n",
       "                                           followers  \\\n",
       "0  [18636825, 719403685, 47734745, 23593416, 7948...   \n",
       "1  [197178351, 914218687632199682, 2747567856, 99...   \n",
       "2  [45260729, 24841574, 40654511, 528716709, 5679...   \n",
       "\n",
       "                               unified_place clusters_mentions  \n",
       "0  ciudad autónoma de buenos aires,argentina             [401]  \n",
       "1  ciudad autónoma de buenos aires,argentina             [773]  \n",
       "2  ciudad autónoma de buenos aires,argentina               NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final = pd.merge(\n",
    "    left=users_train,\n",
    "    right=users_clusters,\n",
    "    how='left',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "\n",
    "users_train_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "conservative-mechanism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32292, 11)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-second",
   "metadata": {},
   "source": [
    "Seguidores/seguidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "billion-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, clusters = extract_oslom('../../results/matrix/follows/edges_follows_final.csv_oslo_files/tp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "general-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_user_id(row):\n",
    "    return total_users_follows[row[\"id\"]]\n",
    "\n",
    "train[\"id\"] = train.apply(get_original_user_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "processed-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_clusters = pd.merge(\n",
    "    left=train,\n",
    "    right=users_train,\n",
    "    how='inner',\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\",\n",
    "    validate=\"m:1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "rubber-pride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clusters_follows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>821923</td>\n",
       "      <td>[2080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1190421</td>\n",
       "      <td>[2957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1297311</td>\n",
       "      <td>[2991]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id clusters_follows\n",
       "0   821923           [2080]\n",
       "1  1190421           [2957]\n",
       "2  1297311           [2991]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_clusters = users_clusters.loc[\n",
    "    :, [\"id\", \"cluster\"]\n",
    "]\n",
    "\n",
    "users_clusters = users_clusters.groupby(\n",
    "        [\"id\"]\n",
    "    )['cluster'].apply(list).reset_index(name='clusters_follows')\n",
    "\n",
    "users_clusters.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "liable-disaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>full_text</th>\n",
       "      <th>users_mentioned</th>\n",
       "      <th>followees</th>\n",
       "      <th>followers</th>\n",
       "      <th>unified_place</th>\n",
       "      <th>clusters_mentions</th>\n",
       "      <th>clusters_follows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1190421</td>\n",
       "      <td>ciudad autónoma de buenos aires</td>\n",
       "      <td>argentina</td>\n",
       "      <td>-34.613152</td>\n",
       "      <td>-58.377232</td>\n",
       "      <td>[Nos pasa a todos  quédate tranquilo , Por si ...</td>\n",
       "      <td>[239643295, 146155608, 4335595632]</td>\n",
       "      <td>[14071538, 116828061, 47491330, 217196502, 580...</td>\n",
       "      <td>[18636825, 719403685, 47734745, 23593416, 7948...</td>\n",
       "      <td>ciudad autónoma de buenos aires,argentina</td>\n",
       "      <td>[401]</td>\n",
       "      <td>[2957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2591131</td>\n",
       "      <td>ciudad autónoma de buenos aires</td>\n",
       "      <td>argentina</td>\n",
       "      <td>-34.613152</td>\n",
       "      <td>-58.377232</td>\n",
       "      <td>[ Suerte, Genio , Mora en Palermo Soho , Arte ...</td>\n",
       "      <td>[201353361]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[197178351, 914218687632199682, 2747567856, 99...</td>\n",
       "      <td>ciudad autónoma de buenos aires,argentina</td>\n",
       "      <td>[773]</td>\n",
       "      <td>[3133]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3367711</td>\n",
       "      <td>ciudad autónoma de buenos aires</td>\n",
       "      <td>argentina</td>\n",
       "      <td>-34.613152</td>\n",
       "      <td>-58.377232</td>\n",
       "      <td>[Con la cuenta me dieron este chocolatito en e...</td>\n",
       "      <td>[176226209]</td>\n",
       "      <td>[720786569792253952, 182644738, 138814032, 116...</td>\n",
       "      <td>[45260729, 24841574, 40654511, 528716709, 5679...</td>\n",
       "      <td>ciudad autónoma de buenos aires,argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2349]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       place_name place_country   latitude  \\\n",
       "0  1190421  ciudad autónoma de buenos aires     argentina -34.613152   \n",
       "1  2591131  ciudad autónoma de buenos aires     argentina -34.613152   \n",
       "2  3367711  ciudad autónoma de buenos aires     argentina -34.613152   \n",
       "\n",
       "   longitude                                          full_text  \\\n",
       "0 -58.377232  [Nos pasa a todos  quédate tranquilo , Por si ...   \n",
       "1 -58.377232  [ Suerte, Genio , Mora en Palermo Soho , Arte ...   \n",
       "2 -58.377232  [Con la cuenta me dieron este chocolatito en e...   \n",
       "\n",
       "                      users_mentioned  \\\n",
       "0  [239643295, 146155608, 4335595632]   \n",
       "1                         [201353361]   \n",
       "2                         [176226209]   \n",
       "\n",
       "                                           followees  \\\n",
       "0  [14071538, 116828061, 47491330, 217196502, 580...   \n",
       "1                                                 []   \n",
       "2  [720786569792253952, 182644738, 138814032, 116...   \n",
       "\n",
       "                                           followers  \\\n",
       "0  [18636825, 719403685, 47734745, 23593416, 7948...   \n",
       "1  [197178351, 914218687632199682, 2747567856, 99...   \n",
       "2  [45260729, 24841574, 40654511, 528716709, 5679...   \n",
       "\n",
       "                               unified_place clusters_mentions  \\\n",
       "0  ciudad autónoma de buenos aires,argentina             [401]   \n",
       "1  ciudad autónoma de buenos aires,argentina             [773]   \n",
       "2  ciudad autónoma de buenos aires,argentina               NaN   \n",
       "\n",
       "  clusters_follows  \n",
       "0           [2957]  \n",
       "1           [3133]  \n",
       "2           [2349]  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final = pd.merge(\n",
    "    left=users_train_final,\n",
    "    right=users_clusters,\n",
    "    how='left',\n",
    "    validate=\"1:1\"\n",
    ")\n",
    "\n",
    "users_train_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "elect-independence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32292, 12)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-evidence",
   "metadata": {},
   "source": [
    "Selección de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eight-system",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26214, 12)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train_final = users_train_final.dropna(subset=[\"clusters_mentions\", \"clusters_follows\"], how='any')\n",
    "users_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "final-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "\n",
    "cities = users_train_final[\"unified_place\"].values\n",
    "cities_enc = encoder.fit_transform(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-glossary",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-galaxy",
   "metadata": {},
   "source": [
    "Generamos una matriz con vectores One-hot encoding para las comunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "played-clause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26214x979 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 27730 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents=None,\n",
    "    lowercase=False,\n",
    "    analyzer=lambda x: x\n",
    ")\n",
    "\n",
    "vector_of_clusters_mentions = vectorizer.fit_transform(users_train_final[\"clusters_mentions\"]).astype(np.float32)\n",
    "vector_of_clusters_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dental-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26214x3055 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 32866 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    strip_accents=None,\n",
    "    lowercase=False,\n",
    "    analyzer=lambda x: x\n",
    ")\n",
    "\n",
    "vector_of_clusters_follows = vectorizer.fit_transform(users_train_final[\"clusters_follows\"]).astype(np.float32)\n",
    "vector_of_clusters_follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-exhibit",
   "metadata": {},
   "source": [
    "Armamos un vocabulario de palabras de los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "emerging-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = users_train_final[\"full_text\"].apply(lambda x: ' '.join(x)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-japanese",
   "metadata": {},
   "source": [
    "Transformamos los contenidos de los tweets a vectores numéricos quedándonos con las N=max_features palabras más usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "identified-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens unicos 800082\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(all_tweets)\n",
    "word_index = tokenizer.word_index\n",
    "print('Tokens unicos %s' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "searching-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nlp = tokenizer.texts_to_sequences(all_tweets)\n",
    "input_nlp = pad_sequences(input_nlp, maxlen=sequence_length, truncating='post', padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-lucas",
   "metadata": {},
   "source": [
    "Entrenamos cada modelo separadamente con sus correspondientes datos usando nested cross predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "antique-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.9s remaining:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: Mentions got results: {'fit_time': array([7.3468039 , 7.42768979, 7.32264972, 7.34953594, 7.2340765 ]), 'score_time': array([0.32109094, 0.41415429, 0.31885791, 0.32054329, 0.41950488]), 'test_accuracy': array([0.49055884, 0.48712569, 0.49761587, 0.43410261, 0.43819153]), 'test_balanced_accuracy': array([0.42423867, 0.42362425, 0.41705194, 0.40215814, 0.40920559]), 'test_roc_auc_ovo_weighted': array([0.8053637 , 0.80567328, 0.79884526, 0.79180705, 0.79682233]), 'test_accuracy@161': array([0.65592218, 0.66717528, 0.66526798, 0.62387946, 0.62552461])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.4s remaining:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: Follows got results: {'fit_time': array([11.01861691, 11.40046859, 11.05853295, 11.02580762, 11.43620229]), 'score_time': array([0.32075763, 0.30682755, 0.32031822, 0.3195529 , 0.30882573]), 'test_accuracy': array([0.52050353, 0.53480832, 0.52679763, 0.49208468, 0.49027089]), 'test_balanced_accuracy': array([0.4189997 , 0.44890934, 0.4308342 , 0.39979281, 0.39749605]), 'test_roc_auc_ovo_weighted': array([0.78832355, 0.80631867, 0.79417777, 0.77558159, 0.78575497]), 'test_accuracy@161': array([0.68014496, 0.70570284, 0.69082586, 0.67804692, 0.68122854])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 85.7min remaining: 128.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 86.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 86.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: Contennt got results: {'fit_time': array([5155.21390438, 5131.00460625, 5145.97506094, 5127.82320809,\n",
      "       5110.4545722 ]), 'score_time': array([ 3.35193157, 10.16260123,  5.82438421, 10.20625138, 15.01501703]), 'test_score': array([0.62788481, 0.52469963, 0.        , 0.02593935, 0.02155666])}\n"
     ]
    }
   ],
   "source": [
    "mentions_estimator = {\n",
    "    \"name\": \"Mentions\",\n",
    "    \"estimator\": DecisionTreeClassifier(random_state=1500),\n",
    "    \"params_grid\": {'max_depth': [8, 80, 200, 500, None], 'min_samples_leaf': [1], 'class_weight': ['balanced']}\n",
    "}\n",
    "\n",
    "follows_estimator = {\n",
    "    \"name\": \"Follows\",\n",
    "    \"estimator\": DecisionTreeClassifier(random_state=1500),\n",
    "    \"params_grid\": {'max_depth': [8, 80, 200, 500, None], 'min_samples_leaf': [1], 'class_weight': ['balanced']}\n",
    "}\n",
    "\n",
    "content_estimator = {\n",
    "    \"name\": \"Contennt\",\n",
    "    \"estimator\": KerasClassifier(\n",
    "        build_fn=create_nlp_model,\n",
    "        verbose=2,\n",
    "        callbacks=[EarlyStopping(monitor='loss', patience=3, min_delta=0.0001)]\n",
    "    ),\n",
    "    \"params_grid\": {\n",
    "        \"optimizer\": [\"adam\"],\n",
    "        \"epochs\": [10],\n",
    "        \"batch_size\": [128],\n",
    "        \"input_length\": [input_nlp.shape[1]],\n",
    "    }\n",
    "}\n",
    "\n",
    "mentions_preds = nested_cross_val_predict(\n",
    "    mentions_estimator[\"name\"],\n",
    "    mentions_estimator[\"estimator\"],\n",
    "    mentions_estimator[\"params_grid\"],\n",
    "    vector_of_clusters_mentions,\n",
    "    cities,\n",
    "    scoringCV=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    scoringVAL={\n",
    "        'accuracy': 'accuracy',\n",
    "        'balanced_accuracy': 'balanced_accuracy',\n",
    "        'roc_auc_ovo_weighted': 'roc_auc_ovo_weighted',\n",
    "        'accuracy@161': make_scorer(accuracy_161km, greater_is_better=True)            \n",
    "    }\n",
    ")\n",
    "\n",
    "follows_preds = nested_cross_val_predict(\n",
    "    follows_estimator[\"name\"],\n",
    "    follows_estimator[\"estimator\"],\n",
    "    follows_estimator[\"params_grid\"],\n",
    "    vector_of_clusters_follows,\n",
    "    cities,\n",
    "    scoringCV=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    scoringVAL={\n",
    "        'accuracy': 'accuracy',\n",
    "        'balanced_accuracy': 'balanced_accuracy',\n",
    "        'roc_auc_ovo_weighted': 'roc_auc_ovo_weighted',\n",
    "        'accuracy@161': make_scorer(accuracy_161km, greater_is_better=True)            \n",
    "    }\n",
    ")\n",
    "\n",
    "content_preds = nested_cross_val_predict(\n",
    "    content_estimator[\"name\"],\n",
    "    content_estimator[\"estimator\"],\n",
    "    content_estimator[\"params_grid\"],\n",
    "    input_nlp,\n",
    "    cities_enc,\n",
    "    inner_cv=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-warren",
   "metadata": {},
   "source": [
    "Pasamos las salidas de cada método por un \"meta-clasificador\" para determinar la estimación final resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "sexual-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds = np.concatenate((mentions_preds, content_preds, follows_preds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "pediatric-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   21.7s remaining:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: Meta classifier got results: {'fit_time': array([20.86232257, 20.30633068, 19.70147943, 20.52390695, 19.98536611]), 'score_time': array([0.31909442, 0.33502746, 0.51532674, 0.3281219 , 0.33931088]), 'test_accuracy': array([0.61567805, 0.62902918, 0.60499714, 0.48312035, 0.46394506]), 'test_balanced_accuracy': array([0.67797737, 0.69220402, 0.67852126, 0.64689113, 0.62832667]), 'test_roc_auc_ovo_weighted': array([0.95122156, 0.95818599, 0.95508293, 0.94760775, 0.93997984]), 'test_accuracy@161': array([0.74880793, 0.76959756, 0.77093267, 0.757963  , 0.75410149])}\n"
     ]
    }
   ],
   "source": [
    "meta_estimator = {\n",
    "    \"name\": \"Meta classifier\",\n",
    "    \"estimator\": LogisticRegression(class_weight=\"balanced\",random_state=35,n_jobs=-1),\n",
    "    \"params_grid\": {'C': [0.5, 1.0], 'class_weight': ['balanced']}\n",
    "}\n",
    "\n",
    "meta_preds = nested_cross_val_predict(\n",
    "    meta_estimator[\"name\"],\n",
    "    meta_estimator[\"estimator\"],\n",
    "    meta_estimator[\"params_grid\"],\n",
    "    total_preds,\n",
    "    cities,\n",
    "    scoringCV=['accuracy', 'balanced_accuracy', 'roc_auc_ovo_weighted'],\n",
    "    refit='roc_auc_ovo_weighted',\n",
    "    scoringVAL={\n",
    "        'accuracy': 'accuracy',\n",
    "        'balanced_accuracy': 'balanced_accuracy',\n",
    "        'roc_auc_ovo_weighted': 'roc_auc_ovo_weighted',\n",
    "        'accuracy@161': make_scorer(accuracy_161km, greater_is_better=True)            \n",
    "    },\n",
    "    method='predict'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "welcome-sitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7602807660028992"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_161km(cities, meta_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "trying-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5593575951781491"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(cities, meta_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "spoken-relevance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6647887246213309"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(cities, meta_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afraid-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(25, 20))\n",
    "i = 0\n",
    "f.tight_layout(pad=30.0)\n",
    "\n",
    "cm = confusion_matrix(cities, meta_preds, labels=class_names)\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    #linewidths=.5,\n",
    "    fmt='d',\n",
    "    robust=True,\n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    ax=ax\n",
    ")\n",
    "    \n",
    "ax.set_title(\"Modelo final\", fontsize=20, fontweight='bold', pad=20)\n",
    "ax.xaxis.set_tick_params(labelsize=16)\n",
    "ax.yaxis.set_tick_params(labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abstract-river",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y',\n",
       " 'posta',\n",
       " 'no',\n",
       " 'hay',\n",
       " 'vuelta',\n",
       " 'eh',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'switch',\n",
       " 'un',\n",
       " 'camino',\n",
       " 'de',\n",
       " 'ida',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'yo',\n",
       " 'los',\n",
       " 'amo',\n",
       " 'kedecirte',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'yo',\n",
       " 'te',\n",
       " 'amo',\n",
       " 'que',\n",
       " 'decirte',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'jajajajajajaja',\n",
       " 'mori',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'no',\n",
       " 'se',\n",
       " 'puede',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'te',\n",
       " 'invito',\n",
       " 'a',\n",
       " 'materia',\n",
       " 'prima',\n",
       " 'a',\n",
       " 'tomar',\n",
       " 'vinapia',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'me',\n",
       " 'compre',\n",
       " 'un',\n",
       " 'helado',\n",
       " 'y',\n",
       " 'le',\n",
       " 'dije',\n",
       " 'a',\n",
       " 'mi',\n",
       " 'mamá',\n",
       " 'que',\n",
       " 'no',\n",
       " 'le',\n",
       " 'iba',\n",
       " 'a',\n",
       " 'compartir',\n",
       " 'pasaron',\n",
       " '3',\n",
       " 'minutos',\n",
       " 'se',\n",
       " 'me',\n",
       " 'cayó',\n",
       " 'al',\n",
       " 'piso',\n",
       " 'la',\n",
       " 'vida',\n",
       " 'no',\n",
       " 'me',\n",
       " 'deja',\n",
       " 'en',\n",
       " 'paz',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'con',\n",
       " 'quién',\n",
       " 'es',\n",
       " 'con',\n",
       " 'mi',\n",
       " 'amiga',\n",
       " 'marrti',\n",
       " 'ahre',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'como',\n",
       " 'que',\n",
       " 'te',\n",
       " 'faltó',\n",
       " 'expresarmelo',\n",
       " '|',\n",
       " '|',\n",
       " '|',\n",
       " 'mis',\n",
       " 'amigos',\n",
       " 'son',\n",
       " 'el',\n",
       " 'camino',\n",
       " 'al',\n",
       " 'mal',\n",
       " 'tenía',\n",
       " 'que',\n",
       " 'decirlo']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TweetTokenizer(reduce_len=3).tokenize(users_train_final[\"all_tweets\"][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffunes-3.8",
   "language": "python",
   "name": "ffunes-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
