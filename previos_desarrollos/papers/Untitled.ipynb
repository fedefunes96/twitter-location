{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "permanent-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, KFold, cross_val_predict, cross_validate\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import scipy.sparse\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from math import radians, sin, cos, atan2, sqrt\n",
    "import re\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.neighbors import KDTree\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from shapely.geometry import Polygon, box\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Concatenate, Input, Dropout, Bidirectional, concatenate\n",
    "from tensorflow.keras.layers import Reshape, Flatten, MultiHeadAttention, Attention\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.backend import clear_session\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os.path\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from pecanpy import node2vec\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2, SelectKBest, SelectFromModel, SelectFpr, SelectFdr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import hstack \n",
    "import stellargraph as sg\n",
    "from io import BytesIO\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promotional-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "unTPath = \"../../../../../unT/ffunes/\"\n",
    "tmp_save = unTPath + \"tmp_saves/\"\n",
    "figuresPath = unTPath + \"figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pressing-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'multilayer_graph_city_twitter_us.pickle', 'rb') as handle:\n",
    "    multilayer_graph_city = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "false-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp_save + 'cities_twitter_us.pickle', 'rb') as handle:\n",
    "    train_regions, val_regions, test_regions, encoder_t = pickle.load(handle)\n",
    "\n",
    "train_regions_enc = encoder_t.transform(train_regions)\n",
    "val_regions_enc = encoder_t.transform(val_regions)\n",
    "test_regions_enc = encoder_t.transform(test_regions)\n",
    "    \n",
    "#cities = [train_cities, val_cities, test_cities, encoder_city]\n",
    "\n",
    "#with open(tmp_save + 'cities_twitter_us.pickle', 'rb') as handle:\n",
    "#    train_cities, val_cities, test_cities, encoder_city = pickle.load(handle)\n",
    "\n",
    "train_na_shape = 429639\n",
    "test_na_shape = 10000\n",
    "val_na_shape = 9998\n",
    "\n",
    "total_regions = len(np.unique(train_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supposed-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rgcn_model(optimizer, num_classes, generator):\n",
    "    clear_session()\n",
    "    \n",
    "    rgcn = sg.layer.RGCN(\n",
    "        layer_sizes=[128, 64, num_classes],\n",
    "        activations=[\"relu\", \"relu\", \"softmax\"],\n",
    "        generator=generator,\n",
    "        num_bases=2,\n",
    "        dropout=0.2,\n",
    "        bias=True,\n",
    "        #kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "    )\n",
    "    \n",
    "    x_inp, x_out = rgcn.in_out_tensors()\n",
    "    \n",
    "    #x_out = tf.keras.layers.Dense(units=num_classes, activation=\"softmax\")(x_out)\n",
    "\n",
    "    model = tf.keras.Model(inputs=x_inp, outputs=x_out)\n",
    "\n",
    "    model.compile(optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/home/ffunes/.local/share/virtualenvs/python_env--wEOliWe/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/240000\n"
     ]
    }
   ],
   "source": [
    "train_idxs = np.arange(train_na_shape)\n",
    "val_idxs = np.arange(train_na_shape, train_na_shape + val_na_shape)\n",
    "test_idxs = np.arange(train_na_shape + val_na_shape, train_na_shape + val_na_shape + test_na_shape)\n",
    "\n",
    "gcn_generator = sg.mapper.RelationalFullBatchNodeGenerator(multilayer_graph_city, weighted=True)\n",
    "\n",
    "lr = ExponentialDecay(\n",
    "        0.1,\n",
    "        decay_steps=50,\n",
    "        decay_rate=0.8,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "clf = create_rgcn_model(\n",
    "    Adam(learning_rate=lr),\n",
    "    total_regions,\n",
    "    gcn_generator\n",
    ")\n",
    "\n",
    "X_train, y_train = gcn_generator.flow(train_idxs, train_regions_enc)[0]\n",
    "X_val, y_val = gcn_generator.flow(val_idxs, val_regions_enc)[0]\n",
    "\n",
    "X_test = gcn_generator.flow(test_idxs)\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=30, min_delta=0.0001, restore_best_weights=True),\n",
    "    ],\n",
    "    epochs=240000,\n",
    "    shuffle=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-nudist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffunes-3.8",
   "language": "python",
   "name": "ffunes-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
